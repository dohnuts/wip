Index: ./dev/pci/files.pci
===================================================================
RCS file: /cvs/src/sys/dev/pci/files.pci,v
retrieving revision 1.333
diff -u -p -r1.333 files.pci
--- ./dev/pci/files.pci	24 Dec 2017 19:50:56 -0000	1.333
+++ ./dev/pci/files.pci	17 Sep 2018 19:59:54 -0000
@@ -355,6 +355,7 @@ device	ix: ether, ifnet, ifmedia
 attach	ix at pci
 file	dev/pci/if_ix.c			ix
 file	dev/pci/ixgbe.c			ix
+file	dev/pci/ixgbe_api.c		ix
 file	dev/pci/ixgbe_82598.c		ix
 file	dev/pci/ixgbe_82599.c		ix
 file	dev/pci/ixgbe_x540.c		ix
Index: ./dev/pci/if_ix.c
===================================================================
RCS file: /cvs/src/sys/dev/pci/if_ix.c,v
retrieving revision 1.152
diff -u -p -r1.152 if_ix.c
--- ./dev/pci/if_ix.c	22 Jun 2017 02:44:37 -0000	1.152
+++ ./dev/pci/if_ix.c	17 Sep 2018 19:59:55 -0000
@@ -85,6 +85,8 @@ const struct pci_matchid ixgbe_devices[]
 	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_X550EM_X_SFP },
 	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_X550EM_X_10G_T },
 	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_X550EM_X_1G_T },
+	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_X550EM_A_SFP_N },
+	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_X550EM_A_SFP }
 };
 
 /*********************************************************************
@@ -141,6 +143,7 @@ void	ixgbe_iff(struct ix_softc *);
 void	ixgbe_print_hw_stats(struct ix_softc *);
 #endif
 void	ixgbe_update_link_status(struct ix_softc *);
+void	ixgbe_config_dmac(struct ix_softc *adapter);
 int	ixgbe_get_buf(struct rx_ring *, int);
 int	ixgbe_encap(struct tx_ring *, struct mbuf *);
 int	ixgbe_dma_malloc(struct ix_softc *, bus_size_t,
@@ -305,6 +308,13 @@ ixgbe_attach(struct device *parent, stru
 	/* Get the PCI-E bus info and determine LAN ID */
 	hw->mac.ops.get_bus_info(hw);
 
+	/* Enable EEE power saving */
+	 if (sc->feat_en & IXGBE_FEATURE_EEE)
+	 	printf("unsupported IXGBE_FEATURE_EEE");
+	// 	hw->mac.ops.setup_eee(hw, TRUE);
+	if (sc->feat_en & IXGBE_FEATURE_MSIX) 
+	 	printf("unsupported IXGBE_FEATURE_MSIX");
+
 	/* Set an initial default flow control value */
 	sc->fc = ixgbe_fc_full;
 
@@ -705,6 +715,9 @@ ixgbe_init(void *arg)
 	/* Set up VLAN support and filter */
 	ixgbe_setup_vlan_hw_support(sc);
 
+	/* 4.0 move that after // Setup DMA Coalescing */
+	// ixgbe_config_dmac(sc);
+
 	/* Enable Receive engine */
 	rxctrl = IXGBE_READ_REG(&sc->hw, IXGBE_RXCTRL);
 	if (sc->hw.mac.type == ixgbe_mac_82598EB)
@@ -712,6 +725,7 @@ ixgbe_init(void *arg)
 	rxctrl |= IXGBE_RXCTRL_RXEN;
 	sc->hw.mac.ops.enable_rx_dma(&sc->hw, rxctrl);
 
+    // callout_reset(&adapter->timer, hz, ixgbe_local_timer, adapter);
 	timeout_add_sec(&sc->timer, 1);
 
 	/* Set up MSI/X routing */
@@ -759,9 +773,19 @@ ixgbe_init(void *arg)
 	/* Initialize the FC settings */
 	sc->hw.mac.ops.start_hw(&sc->hw);
 
+	/* 4.0 Setup DMA Coalescing * must be done on link speed*/
+	ixgbe_config_dmac(sc);
+
 	/* And now turn on interrupts */
 	ixgbe_enable_intr(sc);
 
+	/* 4.0 Enable the use of the MBX by the VF's */
+	//if (adapter->feat_en & IXGBE_FEATURE_SRIOV) {
+	//	ctrl_ext = IXGBE_READ_REG(hw, IXGBE_CTRL_EXT);
+	//	ctrl_ext |= IXGBE_CTRL_EXT_PFRSTD;
+	//	IXGBE_WRITE_REG(hw, IXGBE_CTRL_EXT, ctrl_ext);
+	//}
+
 	/* Now inform the stack we're ready */
 	ifp->if_flags |= IFF_RUNNING;
 	ifq_clr_oactive(&ifp->if_snd);
@@ -777,9 +801,10 @@ ixgbe_config_gpie(struct ix_softc *sc)
 
 	gpie = IXGBE_READ_REG(&sc->hw, IXGBE_GPIE);
 
-	/* Fan Failure Interrupt */
-	if (hw->device_id == IXGBE_DEV_ID_82598AT)
+	if (sc->feat_en & IXGBE_FEATURE_FAN_FAIL) {
+		/* Fan Failure Interrupt */
 		gpie |= IXGBE_SDP1_GPIEN;
+	}
 
 	if (sc->hw.mac.type == ixgbe_mac_82599EB) {
 		/* Add for Module detection */
@@ -796,7 +821,16 @@ ixgbe_config_gpie(struct ix_softc *sc)
 		gpie |= 0xf << IXGBE_GPIE_LLI_DELAY_SHIFT;
 	}
 
+	/* 4.0 */
+	if (sc->hw.mac.type == ixgbe_mac_X550EM_x ||
+		sc->hw.mac.type == ixgbe_mac_X550EM_a )
+	{
+		gpie |= IXGBE_SDP0_GPIEN_X540;
+	}
+
 	if (sc->hw.mac.type == ixgbe_mac_X540 ||
+	    hw->device_id == IXGBE_DEV_ID_X550EM_A_SFP ||
+	    hw->device_id == IXGBE_DEV_ID_X550EM_A_SFP_N ||
 	    hw->device_id == IXGBE_DEV_ID_X550EM_X_SFP ||
 	    hw->device_id == IXGBE_DEV_ID_X550EM_X_10G_T) {
 		/*
@@ -812,6 +846,7 @@ ixgbe_config_gpie(struct ix_softc *sc)
 		gpie |= 0xf << IXGBE_GPIE_LLI_DELAY_SHIFT;
 	}
 
+
 	if (sc->msix > 1) {
 		/* Enable Enhanced MSIX mode */
 		gpie |= IXGBE_GPIE_MSIX_MODE;
@@ -838,6 +873,7 @@ ixgbe_config_delay_values(struct ix_soft
 	case ixgbe_mac_X540:
 	case ixgbe_mac_X550:
 	case ixgbe_mac_X550EM_x:
+	case ixgbe_mac_X550EM_a: /* 4.0 */
 		tmp = IXGBE_DV_X540(frame, frame);
 		break;
 	default:
@@ -853,6 +889,7 @@ ixgbe_config_delay_values(struct ix_soft
 	case ixgbe_mac_X540:
 	case ixgbe_mac_X550:
 	case ixgbe_mac_X550EM_x:
+	case ixgbe_mac_X550EM_a: /* 4.0 */
 		tmp = IXGBE_LOW_DV_X540(frame);
 		break;
 	default:
@@ -866,27 +903,6 @@ ixgbe_config_delay_values(struct ix_soft
 	hw->fc.send_xon = TRUE;
 }
 
-/*
- * MSIX Interrupt Handlers
- */
-void
-ixgbe_enable_queue(struct ix_softc *sc, uint32_t vector)
-{
-	uint64_t queue = 1ULL << vector;
-	uint32_t mask;
-
-	if (sc->hw.mac.type == ixgbe_mac_82598EB) {
-		mask = (IXGBE_EIMS_RTX_QUEUE & queue);
-		IXGBE_WRITE_REG(&sc->hw, IXGBE_EIMS, mask);
-	} else {
-		mask = (queue & 0xFFFFFFFF);
-		if (mask)
-			IXGBE_WRITE_REG(&sc->hw, IXGBE_EIMS_EX(0), mask);
-		mask = (queue >> 32);
-		if (mask)
-			IXGBE_WRITE_REG(&sc->hw, IXGBE_EIMS_EX(1), mask);
-	}
-}
 
 void
 ixgbe_disable_queue(struct ix_softc *sc, uint32_t vector)
@@ -998,7 +1014,8 @@ ixgbe_intr(void *arg)
 	}
 
 	/* Check for fan failure */
-	if ((hw->device_id == IXGBE_DEV_ID_82598AT) &&
+	if (sc->feat_en & IXGBE_FEATURE_FAN_FAIL &&
+	    (hw->device_id == IXGBE_DEV_ID_82598AT) &&
 	    (reg_eicr & IXGBE_EICR_GPI_SDP1)) {
 		printf("%s: CRITICAL: FAN FAILURE!! "
 		    "REPLACE IMMEDIATELY!!\n", ifp->if_xname);
@@ -1371,6 +1388,17 @@ ixgbe_update_link_status(struct ix_softc
 
 		/* Update any Flow Control changes */
 		sc->hw.mac.ops.fc_enable(&sc->hw);
+	} else {
+		//if (sc->link_speed == IXGBE_LINK_SPEED_10GB_FULL){
+			/*
+			 *  Discard count for both MAC Local Fault and
+			 * Remote Fault because those registers are
+			 * valid only when the link speed is up and
+			 * 10Gbps.
+			 */
+		//	IXGBE_READ_REG(hw, IXGBE_MLFC);
+		//	IXGBE_READ_REG(hw, IXGBE_MRFC);
+		// 
 	}
 	if (ifp->if_link_state != link_state) {
 		ifp->if_link_state = link_state;
@@ -1378,6 +1406,32 @@ ixgbe_update_link_status(struct ix_softc
 	}
 }
 
+/************************************************************************
+ * ixgbe_config_dmac - Configure DMA Coalescing Driver 4.0v
+ ************************************************************************/
+void
+ixgbe_config_dmac(struct ix_softc *adapter)
+{
+	struct ixgbe_hw *hw = &adapter->hw;
+	struct ixgbe_dmac_config *dcfg = &hw->mac.dmac_config;
+
+	if (hw->mac.type < ixgbe_mac_X550 || !hw->mac.ops.dmac_config)
+		return;
+
+	if (dcfg->watchdog_timer ^ adapter->dmac ||
+	    dcfg->link_speed ^ adapter->link_speed) {
+		dcfg->watchdog_timer = adapter->dmac;
+		dcfg->fcoe_en = false;
+		dcfg->link_speed = adapter->link_speed;
+		dcfg->num_tcs = 1;
+
+		INIT_DEBUGOUT2("dmac settings: watchdog %d, link speed %d\n",
+		    dcfg->watchdog_timer, dcfg->link_speed);
+
+		hw->mac.ops.dmac_config(hw);
+	}
+} /* ixgbe_config_dmac */
+
 
 /*********************************************************************
  *
@@ -2041,6 +2095,9 @@ ixgbe_initialize_transmit_units(struct i
 		IXGBE_WRITE_REG(hw, IXGBE_TDH(i), 0);
 		IXGBE_WRITE_REG(hw, IXGBE_TDT(i), 0);
 
+		/* 4.0 Cache the tail address */
+		txr->tail = IXGBE_TDT(txr->me);
+
 		/* Setup Transmit Descriptor Cmd Settings */
 		txr->txd_cmd = IXGBE_TXD_CMD_IFCS;
 		txr->queue_status = IXGBE_QUEUE_IDLE;
@@ -2653,7 +2710,8 @@ ixgbe_initialize_receive_units(struct ix
 	bufsz = (sc->rx_mbuf_sz - ETHER_ALIGN) >> IXGBE_SRRCTL_BSIZEPKT_SHIFT;
 
 	for (i = 0; i < sc->num_queues; i++, rxr++) {
-		uint64_t rdba = rxr->rxdma.dma_map->dm_segs[0].ds_addr;
+		uint64_t rdba = rxr->rxdma.dma_map->dm_segs[0].ds_addr; //netbsd rxr->rxdma.dma_paddr;
+		uint64_t reg;
 
 		/* Setup the Base and Length of the Rx Descriptor Ring */
 		IXGBE_WRITE_REG(hw, IXGBE_RDBAL(i),
@@ -2666,9 +2724,18 @@ ixgbe_initialize_receive_units(struct ix
 		srrctl = bufsz | IXGBE_SRRCTL_DESCTYPE_ADV_ONEBUF;
 		IXGBE_WRITE_REG(hw, IXGBE_SRRCTL(i), srrctl);
 
+		/* 4.0 Set RQSMR (Receive Queue Statistic Mapping) register */
+		reg = IXGBE_READ_REG(hw, IXGBE_RQSMR(i / 4));
+		reg &= ~(0x000000ff << (i % 4 * 8));
+		reg |= i << (i % 4 * 8);
+		IXGBE_WRITE_REG(hw, IXGBE_RQSMR(i / 4), reg);
+
 		/* Setup the HW Rx Head and Tail Descriptor Pointers */
 		IXGBE_WRITE_REG(hw, IXGBE_RDH(i), 0);
 		IXGBE_WRITE_REG(hw, IXGBE_RDT(i), 0);
+
+		/* 4.0 Set the driver rx tail address */
+		rxr->tail =  IXGBE_RDT(rxr->me);
 	}
 
 	if (sc->hw.mac.type != ixgbe_mac_82598EB) {
@@ -2682,10 +2749,10 @@ ixgbe_initialize_receive_units(struct ix
 	rxcsum = IXGBE_READ_REG(hw, IXGBE_RXCSUM);
 	rxcsum &= ~IXGBE_RXCSUM_PCSD;
 
+
+	ixgbe_initialize_rss_mapping(sc); /*4.0 driver always call that check feature ? */
 	/* Setup RSS */
 	if (sc->num_queues > 1) {
-		ixgbe_initialize_rss_mapping(sc);
-
 		/* RSS and RX IPP Checksum are mutually exclusive */
 		rxcsum |= IXGBE_RXCSUM_PCSD;
 	}
@@ -2703,6 +2770,7 @@ ixgbe_initialize_rss_mapping(struct ix_s
 	struct ixgbe_hw	*hw = &sc->hw;
 	uint32_t reta = 0, mrqc, rss_key[10];
 	int i, j, queue_id, table_size, index_mult;
+	uint32_t rss_hash_config;
 
 	/* set up random bits */
 	arc4random_buf(&rss_key, sizeof(rss_key));
@@ -2716,6 +2784,7 @@ ixgbe_initialize_rss_mapping(struct ix_s
 		break;
 	case ixgbe_mac_X550:
 	case ixgbe_mac_X550EM_x:
+	case ixgbe_mac_X550EM_a: /* 4.0 */
 		table_size = 512;
 		break;
 	default:
@@ -2725,7 +2794,19 @@ ixgbe_initialize_rss_mapping(struct ix_s
 	/* Set up the redirection table */
 	for (i = 0, j = 0; i < table_size; i++, j++) {
 		if (j == sc->num_queues) j = 0;
-		queue_id = (j * index_mult);
+		if (sc->feat_en & IXGBE_FEATURE_RSS) {
+			printf("4.0 ixgbe driver case");
+			/*
+			 * Fetch the RSS bucket id for the given indirection
+			 * entry. Cap it at the number of configured buckets
+			 * (which is num_queues.)
+			 * queue_id = rss_get_indirection_to_bucket(i); DEFINE at 0 ...
+			 * queue_id = queue_id % adapter->num_queues;
+			 */
+			queue_id = 0;
+		} else {
+			queue_id = (j * index_mult);
+		}
 		/*
 		 * The low 8 bits are for hash value (n+0);
 		 * The next 8 bits are for hash value (n+1), etc.
@@ -2746,6 +2827,8 @@ ixgbe_initialize_rss_mapping(struct ix_s
 	for (i = 0; i < 10; i++)
 		IXGBE_WRITE_REG(hw, IXGBE_RSSRK(i), rss_key[i]);
 
+	if (sc->feat_en & IXGBE_FEATURE_RSS)
+		rss_hash_config = 0x7E; /*4.0 rss_gethashconfig*/
 	/*
 	 * Disable UDP - IP fragments aren't currently being handled
 	 * and so we end up with a mix of 2-tuple and 4-tuple
@@ -2759,6 +2842,31 @@ ixgbe_initialize_rss_mapping(struct ix_s
 	     | IXGBE_MRQC_RSS_FIELD_IPV6
 	     | IXGBE_MRQC_RSS_FIELD_IPV6_TCP
 	;
+
+	/* 4.0 ixgbe_get_mrqc , reenable if IXGBE_FEATURE_RSS*//*
+	if (rss_hash_config & RSS_HASHTYPE_RSS_UDP_IPV4)
+		mrqc |= IXGBE_MRQC_RSS_FIELD_IPV4_UDP;
+	if (rss_hash_config & RSS_HASHTYPE_RSS_UDP_IPV6)
+		mrqc |= IXGBE_MRQC_RSS_FIELD_IPV6_UDP;
+	if (rss_hash_config & RSS_HASHTYPE_RSS_UDP_IPV6_EX)
+		mrqc |= IXGBE_MRQC_RSS_FIELD_IPV6_EX_UDP;*/
+	/* 4.0 ixgbe_get_mrqc *//*
+	switch (sc->iov_mode) {
+	case IXGBE_64_VM:
+		mrqc |= IXGBE_MRQC_VMDQRSS64EN;
+		break;
+	case IXGBE_32_VM:
+		mrqc |= IXGBE_MRQC_VMDQRSS32EN;
+		break;
+	case IXGBE_NO_VM:
+		mrqc |= 0;
+		break;
+	default:
+		panic("Unexpected SR-IOV mode %d", sc->iov_mode);
+	}
+	*/
+	/* e 4.0 */
+
 	IXGBE_WRITE_REG(hw, IXGBE_MRQC, mrqc);
 }
 
@@ -3030,6 +3138,59 @@ ixgbe_setup_vlan_hw_support(struct ix_so
 	}
 }
 
+
+/*
+ * MSIX Interrupt Handlers
+ */
+void
+ixgbe_enable_queue(struct ix_softc *sc, uint32_t vector)
+{
+	uint64_t queue = 1ULL << vector;
+	uint32_t mask;
+
+	if (sc->hw.mac.type == ixgbe_mac_82598EB) {
+		mask = (IXGBE_EIMS_RTX_QUEUE & queue);
+		IXGBE_WRITE_REG(&sc->hw, IXGBE_EIMS, mask);
+	} else {
+		mask = (queue & 0xFFFFFFFF);
+		if (mask)
+			IXGBE_WRITE_REG(&sc->hw, IXGBE_EIMS_EX(0), mask);
+		mask = (queue >> 32);
+		if (mask)
+			IXGBE_WRITE_REG(&sc->hw, IXGBE_EIMS_EX(1), mask);
+	}
+}
+/*v4.0 openbsd code
+
+#define IXGBE_EIMS_EX(_i)	(0x00AA0 + (_i) * 4)
+
+void
+ixgbe_enable_queue(struct adapter *adapter, u32 vector)
+{
+	struct ixgbe_hw *hw = &adapter->hw;
+	struct ix_queue *que = &adapter->queues[vector];
+	u64             queue = (u64)(1ULL << vector);
+	u32             mask;
+
+	mutex_enter(&que->dc_mtx);
+	if (que->disabled_count > 0 && --que->disabled_count > 0)
+		goto out;
+
+	if (hw->mac.type == ixgbe_mac_82598EB) {
+		mask = (IXGBE_EIMS_RTX_QUEUE & queue);
+		IXGBE_WRITE_REG(hw, IXGBE_EIMS, mask);
+	} else {
+		mask = (queue & 0xFFFFFFFF);
+		if (mask)
+			IXGBE_WRITE_REG(hw, IXGBE_EIMS_EX(0), mask);
+		mask = (queue >> 32);
+		if (mask)
+			IXGBE_WRITE_REG(hw, IXGBE_EIMS_EX(1), mask);
+	}
+out:
+	mutex_exit(&que->dc_mtx);
+}  ixgbe_enable_queue */
+
 void
 ixgbe_enable_intr(struct ix_softc *sc)
 {
@@ -3040,8 +3201,9 @@ ixgbe_enable_intr(struct ix_softc *sc)
 
 	mask = (IXGBE_EIMS_ENABLE_MASK & ~IXGBE_EIMS_RTX_QUEUE);
 	/* Enable Fan Failure detection */
-	if (hw->device_id == IXGBE_DEV_ID_82598AT)
-		    mask |= IXGBE_EIMS_GPI_SDP1;
+	if (sc->feat_en & IXGBE_FEATURE_FAN_FAIL) {
+		mask |= IXGBE_EIMS_GPI_SDP1;
+	}
 
 	switch (sc->hw.mac.type) {
 	case ixgbe_mac_82599EB:
@@ -3061,6 +3223,7 @@ ixgbe_enable_intr(struct ix_softc *sc)
 		break;
 	case ixgbe_mac_X550:
 	case ixgbe_mac_X550EM_x:
+	case ixgbe_mac_X550EM_a:
 		mask |= IXGBE_EIMS_ECC;
 		/* MAC thermal sensor is automatically enabled */
 		mask |= IXGBE_EIMS_TS;
@@ -3183,6 +3346,7 @@ ixgbe_set_ivar(struct ix_softc *sc, uint
 	case ixgbe_mac_X540:
 	case ixgbe_mac_X550:
 	case ixgbe_mac_X550EM_x:
+	case ixgbe_mac_X550EM_a:
 		if (type == -1) { /* MISC IVAR */
 			index = (entry & 1) * 8;
 			ivar = IXGBE_READ_REG(hw, IXGBE_IVAR_MISC);
Index: ./dev/pci/if_ix.h
===================================================================
RCS file: /cvs/src/sys/dev/pci/if_ix.h,v
retrieving revision 1.32
diff -u -p -r1.32 if_ix.h
--- ./dev/pci/if_ix.h	21 Nov 2016 17:21:33 -0000	1.32
+++ ./dev/pci/if_ix.h	17 Sep 2018 19:59:55 -0000
@@ -165,6 +165,7 @@ struct ix_queue {
 struct tx_ring {
 	struct ix_softc		*sc;
 	uint32_t		me;
+	uint32_t		tail; /* 4.0 just set during rx init ??>>.. */
 	uint32_t		watchdog_timer;
 	union ixgbe_adv_tx_desc	*tx_base;
 	struct ixgbe_tx_buf	*tx_buffers;
@@ -192,6 +193,7 @@ struct tx_ring {
 struct rx_ring {
 	struct ix_softc		*sc;
 	uint32_t		me;
+	uint32_t		tail;
 	union ixgbe_adv_rx_desc	*rx_base;
 	struct ixgbe_dma_alloc	rxdma;
 #if 0
@@ -252,10 +254,36 @@ struct ix_softc {
 	uint32_t		link_speed;
 	bool			link_up;
 	uint32_t		linkvec;
+	/* 4.0 driver (x550) */
+	uint16_t			dmac;
+	// uint32_t			phy_layer; // prob usseless in openbsd ixgbe_get_supported_physical_layer => ixgbe_add_media_types
+	/* Power management-related */
+	bool				wol_support;
+	uint32_t			wufc;
 
 	/* Mbuf cluster size */
 	uint32_t		rx_mbuf_sz;
 
+	/*4.0*/
+		/* Support for pluggable optics */
+	bool			sfp_probe;
+	void			*link_si;  /* Link tasklet */
+		/* Tasklets for Link, SFP, Multispeed Fiber and Flow Director */
+	/*
+	adapter->link_si = softint_establish(SOFTINT_NET |IXGBE_SOFTINFT_FLAGS,
+	    ixgbe_handle_link, adapter);
+	*/
+	void			*mod_si;   /* SFP tasklet */
+	void			*msf_si;   /* Multispeed Fiber */
+	void			*mbx_si;   /* VF -> PF mailbox interrupt */
+		/* Flow Director */
+	int			fdir_reinit;
+	void			*fdir_si;
+
+	void			*phy_si;   /* PHY intr tasklet */
+
+	/// and workqueue stuff ?
+
 	/*
 	 * Queues:
 	 *   This is the irq holder, it has
@@ -291,6 +319,35 @@ struct ix_softc {
 	unsigned long		link_irq;
 
 	struct ixgbe_hw_stats 	stats;
+
+	/* 4.0  features */
+	uint32_t		feat_cap;
+#define IXGBE_FEATURE_VF                        (uint32_t)(1 << 0)
+#ifndef PCI_IOV
+#define IXGBE_FEATURE_SRIOV                     (uint32_t)(1 << 1)
+#endif
+//#ifndef RSS
+#define IXGBE_FEATURE_RSS                       (uint32_t)(1 << 2)
+//#endif
+#ifndef DEV_NETMAP
+#define IXGBE_FEATURE_NETMAP                    (uint32_t)(1 << 3)
+#endif
+#define IXGBE_FEATURE_FAN_FAIL                  (uint32_t)(1 << 4)
+#define IXGBE_FEATURE_TEMP_SENSOR               (uint32_t)(1 << 5)
+#define IXGBE_FEATURE_BYPASS                    (uint32_t)(1 << 6)
+#define IXGBE_FEATURE_LEGACY_TX                 (uint32_t)(1 << 7)
+#define IXGBE_FEATURE_FDIR                      (uint32_t)(1 << 8)
+#define IXGBE_FEATURE_MSI                       (uint32_t)(1 << 9)
+#define IXGBE_FEATURE_MSIX                      (uint32_t)(1 << 10)
+#define IXGBE_FEATURE_EEE                       (uint32_t)(1 << 11)
+#define IXGBE_FEATURE_LEGACY_IRQ                (uint32_t)(1 << 12)
+#define IXGBE_FEATURE_NEEDS_CTXD                (uint32_t)(1 << 13)
+#define IXGBE_FEATURE_FLAGS "\20" \
+	"\1" "VF"	"\2" "SRIOV"	"\3" "RSS"	"\4" "NETMAP"	\
+	"\5" "FAN_FAIL"	"\6" "TEMP_SENSOR" "\7" "BYPASS" "\10" "LEGACY_TX" \
+	"\11" "FDIR"	"\12" "MSI"	"\13" "MSIX"	"\14" "EEE"	\
+	"\15" "LEGACY_IRQ" "\16" "NEEDS_CTXD"
+	uint32_t		feat_en;
 };
 
 #endif /* _IX_H_ */
Index: ./dev/pci/ixgbe.c
===================================================================
RCS file: /cvs/src/sys/dev/pci/ixgbe.c,v
retrieving revision 1.23
diff -u -p -r1.23 ixgbe.c
--- ./dev/pci/ixgbe.c	2 Dec 2016 15:22:57 -0000	1.23
+++ ./dev/pci/ixgbe.c	17 Sep 2018 19:59:55 -0000
@@ -1,8 +1,8 @@
-/*	$OpenBSD: ixgbe.c,v 1.23 2016/12/02 15:22:57 mikeb Exp $	*/
-
+/* $OpenBSD$ */
 /******************************************************************************
+  SPDX-License-Identifier: BSD-3-Clause
 
-  Copyright (c) 2001-2015, Intel Corporation
+  Copyright (c) 2001-2017, Intel Corporation
   All rights reserved.
 
   Redistribution and use in source and binary forms, with or without
@@ -32,17 +32,11 @@
   POSSIBILITY OF SUCH DAMAGE.
 
 ******************************************************************************/
-/*$FreeBSD: head/sys/dev/ixgbe/ixgbe_common.c 299200 2016-05-06 22:54:56Z pfg $*/
-/*$FreeBSD: head/sys/dev/ixgbe/ixgbe_mbx.c 299200 2016-05-06 22:54:56Z pfg $*/
+/*$FreeBSD$*/
 
 #include <dev/pci/ixgbe.h>
-
-#ifdef __sparc64__
-#include <dev/ofw/openfirm.h>
-#endif
-
-void ixgbe_set_pci_config_data_generic(struct ixgbe_hw *hw,
-				       uint16_t link_status);
+#include <dev/pci/ixgbe_type.h>
+#include <dev/pci/ixgbe_api.h>
 
 int32_t ixgbe_acquire_eeprom(struct ixgbe_hw *hw);
 int32_t ixgbe_get_eeprom_semaphore(struct ixgbe_hw *hw);
@@ -50,41 +44,30 @@ void ixgbe_release_eeprom_semaphore(stru
 int32_t ixgbe_ready_eeprom(struct ixgbe_hw *hw);
 void ixgbe_standby_eeprom(struct ixgbe_hw *hw);
 void ixgbe_shift_out_eeprom_bits(struct ixgbe_hw *hw, uint16_t data,
-				 uint16_t count);
+					uint16_t count);
 uint16_t ixgbe_shift_in_eeprom_bits(struct ixgbe_hw *hw, uint16_t count);
 void ixgbe_raise_eeprom_clk(struct ixgbe_hw *hw, uint32_t *eec);
 void ixgbe_lower_eeprom_clk(struct ixgbe_hw *hw, uint32_t *eec);
 void ixgbe_release_eeprom(struct ixgbe_hw *hw);
 
 int32_t ixgbe_mta_vector(struct ixgbe_hw *hw, uint8_t *mc_addr);
-int32_t ixgbe_fc_autoneg_fiber(struct ixgbe_hw *hw);
-int32_t ixgbe_fc_autoneg_backplane(struct ixgbe_hw *hw);
-int32_t ixgbe_fc_autoneg_copper(struct ixgbe_hw *hw);
-bool ixgbe_device_supports_autoneg_fc(struct ixgbe_hw *hw);
-int32_t ixgbe_negotiate_fc(struct ixgbe_hw *hw, uint32_t adv_reg,
-			   uint32_t lp_reg, uint32_t adv_sym, uint32_t adv_asm,
-			   uint32_t lp_sym, uint32_t lp_asm);
-
-int32_t prot_autoc_read_generic(struct ixgbe_hw *, bool *, uint32_t *);
-int32_t prot_autoc_write_generic(struct ixgbe_hw *, uint32_t, bool);
-
-int32_t ixgbe_find_vlvf_slot(struct ixgbe_hw *hw, uint32_t vlan);
-
-/* MBX */
-int32_t ixgbe_poll_for_msg(struct ixgbe_hw *hw, uint16_t mbx_id);
-int32_t ixgbe_poll_for_ack(struct ixgbe_hw *hw, uint16_t mbx_id);
-uint32_t ixgbe_read_v2p_mailbox(struct ixgbe_hw *hw);
-int32_t ixgbe_check_for_bit_pf(struct ixgbe_hw *hw, uint32_t mask,
-			       int32_t index);
-int32_t ixgbe_check_for_msg_pf(struct ixgbe_hw *hw, uint16_t vf_number);
-int32_t ixgbe_check_for_ack_pf(struct ixgbe_hw *hw, uint16_t vf_number);
-int32_t ixgbe_check_for_rst_pf(struct ixgbe_hw *hw, uint16_t vf_number);
-int32_t ixgbe_obtain_mbx_lock_pf(struct ixgbe_hw *hw, uint16_t vf_number);
-int32_t ixgbe_write_mbx_pf(struct ixgbe_hw *hw, uint32_t *msg, uint16_t size,
-			   uint16_t vf_number);
-int32_t ixgbe_read_mbx_pf(struct ixgbe_hw *hw, uint32_t *msg, uint16_t size,
-			  uint16_t vf_number);
-
+int32_t ixgbe_get_san_mac_addr_offset(struct ixgbe_hw *hw,
+					 uint16_t *san_mac_offset);
+int32_t ixgbe_read_eeprom_buffer_bit_bang(struct ixgbe_hw *hw, uint16_t offset,
+					     uint16_t words, uint16_t *data);
+int32_t ixgbe_write_eeprom_buffer_bit_bang(struct ixgbe_hw *hw, uint16_t offset,
+					      uint16_t words, uint16_t *data);
+int32_t ixgbe_detect_eeprom_page_size_generic(struct ixgbe_hw *hw,
+						 uint16_t offset);
+int32_t ixgbe_read_eerd_buffer_generic(struct ixgbe_hw *hw, uint16_t offset,
+                                   uint16_t words, uint16_t *data);
+int32_t ixgbe_read_eeprom_buffer_bit_bang_generic(struct ixgbe_hw *hw, uint16_t offset,
+                                              uint16_t words, uint16_t *data);
+int32_t ixgbe_write_eeprom_buffer_bit_bang_generic(struct ixgbe_hw *hw, uint16_t offset,
+                                               uint16_t words, uint16_t *data);
+int32_t ixgbe_init_led_link_act_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_update_uc_addr_list_generic(struct ixgbe_hw *hw, uint8_t *addr_list,
+                                      uint32_t addr_count, ixgbe_mc_addr_itr next);
 
 /**
  *  ixgbe_init_ops_generic - Inits function ptrs
@@ -96,18 +79,23 @@ int32_t ixgbe_init_ops_generic(struct ix
 {
 	struct ixgbe_eeprom_info *eeprom = &hw->eeprom;
 	struct ixgbe_mac_info *mac = &hw->mac;
-	uint32_t eec = IXGBE_READ_REG(hw, IXGBE_EEC);
+	uint32_t eec = IXGBE_READ_REG(hw, IXGBE_EEC_BY_MAC(hw));
 
 	DEBUGFUNC("ixgbe_init_ops_generic");
 
 	/* EEPROM */
 	eeprom->ops.init_params = ixgbe_init_eeprom_params_generic;
 	/* If EEPROM is valid (bit 8 = 1), use EERD otherwise use bit bang */
-	if (eec & IXGBE_EEC_PRES)
+	if (eec & IXGBE_EEC_PRES) {
 		eeprom->ops.read = ixgbe_read_eerd_generic;
-	else
+		eeprom->ops.read_buffer = ixgbe_read_eerd_buffer_generic;
+	} else {
 		eeprom->ops.read = ixgbe_read_eeprom_bit_bang_generic;
+		eeprom->ops.read_buffer =
+				 ixgbe_read_eeprom_buffer_bit_bang_generic;
+	}
 	eeprom->ops.write = ixgbe_write_eeprom_generic;
+	eeprom->ops.write_buffer = ixgbe_write_eeprom_buffer_bit_bang_generic;
 	eeprom->ops.validate_checksum =
 				      ixgbe_validate_eeprom_checksum_generic;
 	eeprom->ops.update_checksum = ixgbe_update_eeprom_checksum_generic;
@@ -135,6 +123,7 @@ int32_t ixgbe_init_ops_generic(struct ix
 	mac->ops.led_off = ixgbe_led_off_generic;
 	mac->ops.blink_led_start = ixgbe_blink_led_start_generic;
 	mac->ops.blink_led_stop = ixgbe_blink_led_stop_generic;
+	mac->ops.init_led_link_act = ixgbe_init_led_link_act_generic;
 
 	/* RAR, Multicast, VLAN */
 	mac->ops.set_rar = ixgbe_set_rar_generic;
@@ -143,11 +132,13 @@ int32_t ixgbe_init_ops_generic(struct ix
 	mac->ops.set_vmdq = NULL;
 	mac->ops.clear_vmdq = NULL;
 	mac->ops.init_rx_addrs = ixgbe_init_rx_addrs_generic;
+	mac->ops.update_uc_addr_list = ixgbe_update_uc_addr_list_generic;
 	mac->ops.update_mc_addr_list = ixgbe_update_mc_addr_list_generic;
 	mac->ops.enable_mc = ixgbe_enable_mc_generic;
 	mac->ops.disable_mc = ixgbe_disable_mc_generic;
 	mac->ops.clear_vfta = NULL;
 	mac->ops.set_vfta = NULL;
+	mac->ops.set_vlvf = NULL;
 	mac->ops.init_uta_tables = NULL;
 	mac->ops.enable_rx = ixgbe_enable_rx_generic;
 	mac->ops.disable_rx = ixgbe_disable_rx_generic;
@@ -155,11 +146,15 @@ int32_t ixgbe_init_ops_generic(struct ix
 	/* Flow Control */
 	mac->ops.fc_enable = ixgbe_fc_enable_generic;
 	mac->ops.setup_fc = ixgbe_setup_fc_generic;
+	mac->ops.fc_autoneg = ixgbe_fc_autoneg;
 
 	/* Link */
 	mac->ops.get_link_capabilities = NULL;
 	mac->ops.setup_link = NULL;
 	mac->ops.check_link = NULL;
+	mac->ops.dmac_config = NULL;
+	mac->ops.dmac_update_tcs = NULL;
+	mac->ops.dmac_config_tcs = NULL;
 
 	return IXGBE_SUCCESS;
 }
@@ -185,16 +180,30 @@ bool ixgbe_device_supports_autoneg_fc(st
 	case ixgbe_media_type_fiber_fixed:
 	case ixgbe_media_type_fiber_qsfp:
 	case ixgbe_media_type_fiber:
-		hw->mac.ops.check_link(hw, &speed, &link_up, FALSE);
-		/* if link is down, assume supported */
-		if (link_up)
-			supported = speed == IXGBE_LINK_SPEED_1GB_FULL ?
+		/* flow control autoneg black list */
+		switch (hw->device_id) {
+		case IXGBE_DEV_ID_X550EM_A_SFP:
+		case IXGBE_DEV_ID_X550EM_A_SFP_N:
+		case IXGBE_DEV_ID_X550EM_A_QSFP:
+		case IXGBE_DEV_ID_X550EM_A_QSFP_N:
+			supported = FALSE;
+			break;
+		default:
+			hw->mac.ops.check_link(hw, &speed, &link_up, FALSE);
+			/* if link is down, assume supported */
+			if (link_up)
+				supported = speed == IXGBE_LINK_SPEED_1GB_FULL ?
 				TRUE : FALSE;
-		else
-			supported = TRUE;
+			else
+				supported = TRUE;
+		}
+
 		break;
 	case ixgbe_media_type_backplane:
-		supported = TRUE;
+		if (hw->device_id == IXGBE_DEV_ID_X550EM_X_XFI)
+			supported = FALSE;
+		else
+			supported = TRUE;
 		break;
 	case ixgbe_media_type_copper:
 		/* only some copper devices support flow control autoneg */
@@ -206,6 +215,9 @@ bool ixgbe_device_supports_autoneg_fc(st
 		case IXGBE_DEV_ID_X550T:
 		case IXGBE_DEV_ID_X550T1:
 		case IXGBE_DEV_ID_X550EM_X_10G_T:
+		case IXGBE_DEV_ID_X550EM_A_10G_T:
+		case IXGBE_DEV_ID_X550EM_A_1G_T:
+		case IXGBE_DEV_ID_X550EM_A_1G_T_L:
 			supported = TRUE;
 			break;
 		default:
@@ -215,11 +227,10 @@ bool ixgbe_device_supports_autoneg_fc(st
 		break;
 	}
 
-	if (!supported) {
+	if (!supported)
 		ERROR_REPORT2(IXGBE_ERROR_UNSUPPORTED,
-		      "Device %x does not support flow control autoneg",
-		      hw->device_id);
-	}
+			      "Device %x does not support flow control autoneg",
+			      hw->device_id);
 
 	return supported;
 }
@@ -237,7 +248,7 @@ int32_t ixgbe_setup_fc_generic(struct ix
 	uint16_t reg_cu = 0;
 	bool locked = FALSE;
 
-	DEBUGFUNC("ixgbe_setup_fc");
+	DEBUGFUNC("ixgbe_setup_fc_generic");
 
 	/* Validate the requested mode */
 	if (hw->fc.strict_ieee && hw->fc.requested_mode == ixgbe_fc_rx_pause) {
@@ -266,7 +277,7 @@ int32_t ixgbe_setup_fc_generic(struct ix
 		if (ret_val != IXGBE_SUCCESS)
 			goto out;
 
-		/* only backplane uses autoc so fall though */
+		/* fall through - only backplane uses autoc */
 	case ixgbe_media_type_fiber_fixed:
 	case ixgbe_media_type_fiber_qsfp:
 	case ixgbe_media_type_fiber:
@@ -391,8 +402,9 @@ out:
  **/
 int32_t ixgbe_start_hw_generic(struct ixgbe_hw *hw)
 {
-	int32_t ret_val = IXGBE_SUCCESS;
+	int32_t ret_val;
 	uint32_t ctrl_ext;
+	uint16_t device_caps;
 
 	DEBUGFUNC("ixgbe_start_hw_generic");
 
@@ -414,17 +426,32 @@ int32_t ixgbe_start_hw_generic(struct ix
 	IXGBE_WRITE_FLUSH(hw);
 
 	/* Setup flow control */
-	if (hw->mac.ops.setup_fc) {
-		ret_val = hw->mac.ops.setup_fc(hw);
-		if (ret_val != IXGBE_SUCCESS)
-			goto out;
+	ret_val = ixgbe_setup_fc(hw);
+	if (ret_val != IXGBE_SUCCESS && ret_val != IXGBE_NOT_IMPLEMENTED) {
+		DEBUGOUT1("Flow control setup failed, returning %d\n", ret_val);
+		return ret_val;
+	}
+
+	/* Cache bit indicating need for crosstalk fix */
+	switch (hw->mac.type) {
+	case ixgbe_mac_82599EB:
+	case ixgbe_mac_X550EM_x:
+	case ixgbe_mac_X550EM_a:
+		hw->mac.ops.get_device_caps(hw, &device_caps);
+		if (device_caps & IXGBE_DEVICE_CAPS_NO_CROSSTALK_WR)
+			hw->need_crosstalk_fix = FALSE;
+		else
+			hw->need_crosstalk_fix = TRUE;
+		break;
+	default:
+		hw->need_crosstalk_fix = FALSE;
+		break;
 	}
 
 	/* Clear adapter stopped flag */
 	hw->adapter_stopped = FALSE;
 
-out:
-	return ret_val;
+	return IXGBE_SUCCESS;
 }
 
 /**
@@ -485,11 +512,18 @@ int32_t ixgbe_init_hw_generic(struct ixg
 	/* Reset the hardware */
 	status = hw->mac.ops.reset_hw(hw);
 
-	if (status == IXGBE_SUCCESS) {
+	if (status == IXGBE_SUCCESS || status == IXGBE_ERR_SFP_NOT_PRESENT) {
 		/* Start the HW */
 		status = hw->mac.ops.start_hw(hw);
 	}
 
+	/* Initialize the LED link active for LED blink support */
+	if (hw->mac.ops.init_led_link_act)
+		hw->mac.ops.init_led_link_act(hw);
+
+	if (status != IXGBE_SUCCESS)
+		DEBUGOUT1("Failed to initialize HW, STATUS = %d\n", status);
+
 	return status;
 }
 
@@ -608,6 +642,340 @@ int32_t ixgbe_clear_hw_cntrs_generic(str
 }
 
 /**
+ *  ixgbe_read_pba_string_generic - Reads part number string from EEPROM
+ *  @hw: pointer to hardware structure
+ *  @pba_num: stores the part number string from the EEPROM
+ *  @pba_num_size: part number string buffer length
+ *
+ *  Reads the part number string from the EEPROM.
+ **/
+int32_t ixgbe_read_pba_string_generic(struct ixgbe_hw *hw, uint8_t *pba_num,
+				  uint32_t pba_num_size)
+{
+	int32_t ret_val;
+	uint16_t data;
+	uint16_t pba_ptr;
+	uint16_t offset;
+	uint16_t length;
+
+	DEBUGFUNC("ixgbe_read_pba_string_generic");
+
+	if (pba_num == NULL) {
+		DEBUGOUT("PBA string buffer was null\n");
+		return IXGBE_ERR_INVALID_ARGUMENT;
+	}
+
+	ret_val = hw->eeprom.ops.read(hw, IXGBE_PBANUM0_PTR, &data);
+	if (ret_val) {
+		DEBUGOUT("NVM Read Error\n");
+		return ret_val;
+	}
+
+	ret_val = hw->eeprom.ops.read(hw, IXGBE_PBANUM1_PTR, &pba_ptr);
+	if (ret_val) {
+		DEBUGOUT("NVM Read Error\n");
+		return ret_val;
+	}
+
+	/*
+	 * if data is not ptr guard the PBA must be in legacy format which
+	 * means pba_ptr is actually our second data word for the PBA number
+	 * and we can decode it into an ascii string
+	 */
+	if (data != IXGBE_PBANUM_PTR_GUARD) {
+		DEBUGOUT("NVM PBA number is not stored as string\n");
+
+		/* we will need 11 characters to store the PBA */
+		if (pba_num_size < 11) {
+			DEBUGOUT("PBA string buffer too small\n");
+			return IXGBE_ERR_NO_SPACE;
+		}
+
+		/* extract hex string from data and pba_ptr */
+		pba_num[0] = (data >> 12) & 0xF;
+		pba_num[1] = (data >> 8) & 0xF;
+		pba_num[2] = (data >> 4) & 0xF;
+		pba_num[3] = data & 0xF;
+		pba_num[4] = (pba_ptr >> 12) & 0xF;
+		pba_num[5] = (pba_ptr >> 8) & 0xF;
+		pba_num[6] = '-';
+		pba_num[7] = 0;
+		pba_num[8] = (pba_ptr >> 4) & 0xF;
+		pba_num[9] = pba_ptr & 0xF;
+
+		/* put a null character on the end of our string */
+		pba_num[10] = '\0';
+
+		/* switch all the data but the '-' to hex char */
+		for (offset = 0; offset < 10; offset++) {
+			if (pba_num[offset] < 0xA)
+				pba_num[offset] += '0';
+			else if (pba_num[offset] < 0x10)
+				pba_num[offset] += 'A' - 0xA;
+		}
+
+		return IXGBE_SUCCESS;
+	}
+
+	ret_val = hw->eeprom.ops.read(hw, pba_ptr, &length);
+	if (ret_val) {
+		DEBUGOUT("NVM Read Error\n");
+		return ret_val;
+	}
+
+	if (length == 0xFFFF || length == 0) {
+		DEBUGOUT("NVM PBA number section invalid length\n");
+		return IXGBE_ERR_PBA_SECTION;
+	}
+
+	/* check if pba_num buffer is big enough */
+	if (pba_num_size  < (((uint32_t)length * 2) - 1)) {
+		DEBUGOUT("PBA string buffer too small\n");
+		return IXGBE_ERR_NO_SPACE;
+	}
+
+	/* trim pba length from start of string */
+	pba_ptr++;
+	length--;
+
+	for (offset = 0; offset < length; offset++) {
+		ret_val = hw->eeprom.ops.read(hw, pba_ptr + offset, &data);
+		if (ret_val) {
+			DEBUGOUT("NVM Read Error\n");
+			return ret_val;
+		}
+		pba_num[offset * 2] = (uint8_t)(data >> 8);
+		pba_num[(offset * 2) + 1] = (uint8_t)(data & 0xFF);
+	}
+	pba_num[offset * 2] = '\0';
+
+	return IXGBE_SUCCESS;
+}
+
+/**
+ *  ixgbe_read_pba_num_generic - Reads part number from EEPROM
+ *  @hw: pointer to hardware structure
+ *  @pba_num: stores the part number from the EEPROM
+ *
+ *  Reads the part number from the EEPROM.
+ **/
+int32_t ixgbe_read_pba_num_generic(struct ixgbe_hw *hw, uint32_t *pba_num)
+{
+	int32_t ret_val;
+	uint16_t data;
+
+	DEBUGFUNC("ixgbe_read_pba_num_generic");
+
+	ret_val = hw->eeprom.ops.read(hw, IXGBE_PBANUM0_PTR, &data);
+	if (ret_val) {
+		DEBUGOUT("NVM Read Error\n");
+		return ret_val;
+	} else if (data == IXGBE_PBANUM_PTR_GUARD) {
+		DEBUGOUT("NVM Not supported\n");
+		return IXGBE_NOT_IMPLEMENTED;
+	}
+	*pba_num = (uint32_t)(data << 16);
+
+	ret_val = hw->eeprom.ops.read(hw, IXGBE_PBANUM1_PTR, &data);
+	if (ret_val) {
+		DEBUGOUT("NVM Read Error\n");
+		return ret_val;
+	}
+	*pba_num |= data;
+
+	return IXGBE_SUCCESS;
+}
+
+/**
+ *  ixgbe_read_pba_raw
+ *  @hw: pointer to the HW structure
+ *  @eeprom_buf: optional pointer to EEPROM image
+ *  @eeprom_buf_size: size of EEPROM image in words
+ *  @max_pba_block_size: PBA block size limit
+ *  @pba: pointer to output PBA structure
+ *
+ *  Reads PBA from EEPROM image when eeprom_buf is not NULL.
+ *  Reads PBA from physical EEPROM device when eeprom_buf is NULL.
+ *
+ **/
+int32_t ixgbe_read_pba_raw(struct ixgbe_hw *hw, uint16_t *eeprom_buf,
+		       uint32_t eeprom_buf_size, uint16_t max_pba_block_size,
+		       struct ixgbe_pba *pba)
+{
+	int32_t ret_val;
+	uint16_t pba_block_size;
+
+	if (pba == NULL)
+		return IXGBE_ERR_PARAM;
+
+	if (eeprom_buf == NULL) {
+		ret_val = hw->eeprom.ops.read_buffer(hw, IXGBE_PBANUM0_PTR, 2,
+						     &pba->word[0]);
+		if (ret_val)
+			return ret_val;
+	} else {
+		if (eeprom_buf_size > IXGBE_PBANUM1_PTR) {
+			pba->word[0] = eeprom_buf[IXGBE_PBANUM0_PTR];
+			pba->word[1] = eeprom_buf[IXGBE_PBANUM1_PTR];
+		} else {
+			return IXGBE_ERR_PARAM;
+		}
+	}
+
+	if (pba->word[0] == IXGBE_PBANUM_PTR_GUARD) {
+		if (pba->pba_block == NULL)
+			return IXGBE_ERR_PARAM;
+
+		ret_val = ixgbe_get_pba_block_size(hw, eeprom_buf,
+						   eeprom_buf_size,
+						   &pba_block_size);
+		if (ret_val)
+			return ret_val;
+
+		if (pba_block_size > max_pba_block_size)
+			return IXGBE_ERR_PARAM;
+
+		if (eeprom_buf == NULL) {
+			ret_val = hw->eeprom.ops.read_buffer(hw, pba->word[1],
+							     pba_block_size,
+							     pba->pba_block);
+			if (ret_val)
+				return ret_val;
+		} else {
+			if (eeprom_buf_size > (uint32_t)(pba->word[1] +
+					      pba_block_size)) {
+				memcpy(pba->pba_block,
+				       &eeprom_buf[pba->word[1]],
+				       pba_block_size * sizeof(uint16_t));
+			} else {
+				return IXGBE_ERR_PARAM;
+			}
+		}
+	}
+
+	return IXGBE_SUCCESS;
+}
+
+/**
+ *  ixgbe_write_pba_raw
+ *  @hw: pointer to the HW structure
+ *  @eeprom_buf: optional pointer to EEPROM image
+ *  @eeprom_buf_size: size of EEPROM image in words
+ *  @pba: pointer to PBA structure
+ *
+ *  Writes PBA to EEPROM image when eeprom_buf is not NULL.
+ *  Writes PBA to physical EEPROM device when eeprom_buf is NULL.
+ *
+ **/
+int32_t ixgbe_write_pba_raw(struct ixgbe_hw *hw, uint16_t *eeprom_buf,
+			uint32_t eeprom_buf_size, struct ixgbe_pba *pba)
+{
+	int32_t ret_val;
+
+	if (pba == NULL)
+		return IXGBE_ERR_PARAM;
+
+	if (eeprom_buf == NULL) {
+		ret_val = hw->eeprom.ops.write_buffer(hw, IXGBE_PBANUM0_PTR, 2,
+						      &pba->word[0]);
+		if (ret_val)
+			return ret_val;
+	} else {
+		if (eeprom_buf_size > IXGBE_PBANUM1_PTR) {
+			eeprom_buf[IXGBE_PBANUM0_PTR] = pba->word[0];
+			eeprom_buf[IXGBE_PBANUM1_PTR] = pba->word[1];
+		} else {
+			return IXGBE_ERR_PARAM;
+		}
+	}
+
+	if (pba->word[0] == IXGBE_PBANUM_PTR_GUARD) {
+		if (pba->pba_block == NULL)
+			return IXGBE_ERR_PARAM;
+
+		if (eeprom_buf == NULL) {
+			ret_val = hw->eeprom.ops.write_buffer(hw, pba->word[1],
+							      pba->pba_block[0],
+							      pba->pba_block);
+			if (ret_val)
+				return ret_val;
+		} else {
+			if (eeprom_buf_size > (uint32_t)(pba->word[1] +
+					      pba->pba_block[0])) {
+				memcpy(&eeprom_buf[pba->word[1]],
+				       pba->pba_block,
+				       pba->pba_block[0] * sizeof(uint16_t));
+			} else {
+				return IXGBE_ERR_PARAM;
+			}
+		}
+	}
+
+	return IXGBE_SUCCESS;
+}
+
+/**
+ *  ixgbe_get_pba_block_size
+ *  @hw: pointer to the HW structure
+ *  @eeprom_buf: optional pointer to EEPROM image
+ *  @eeprom_buf_size: size of EEPROM image in words
+ *  @pba_data_size: pointer to output variable
+ *
+ *  Returns the size of the PBA block in words. Function operates on EEPROM
+ *  image if the eeprom_buf pointer is not NULL otherwise it accesses physical
+ *  EEPROM device.
+ *
+ **/
+int32_t ixgbe_get_pba_block_size(struct ixgbe_hw *hw, uint16_t *eeprom_buf,
+			     uint32_t eeprom_buf_size, uint16_t *pba_block_size)
+{
+	int32_t ret_val;
+	uint16_t pba_word[2];
+	uint16_t length;
+
+	DEBUGFUNC("ixgbe_get_pba_block_size");
+
+	if (eeprom_buf == NULL) {
+		ret_val = hw->eeprom.ops.read_buffer(hw, IXGBE_PBANUM0_PTR, 2,
+						     &pba_word[0]);
+		if (ret_val)
+			return ret_val;
+	} else {
+		if (eeprom_buf_size > IXGBE_PBANUM1_PTR) {
+			pba_word[0] = eeprom_buf[IXGBE_PBANUM0_PTR];
+			pba_word[1] = eeprom_buf[IXGBE_PBANUM1_PTR];
+		} else {
+			return IXGBE_ERR_PARAM;
+		}
+	}
+
+	if (pba_word[0] == IXGBE_PBANUM_PTR_GUARD) {
+		if (eeprom_buf == NULL) {
+			ret_val = hw->eeprom.ops.read(hw, pba_word[1] + 0,
+						      &length);
+			if (ret_val)
+				return ret_val;
+		} else {
+			if (eeprom_buf_size > pba_word[1])
+				length = eeprom_buf[pba_word[1] + 0];
+			else
+				return IXGBE_ERR_PARAM;
+		}
+
+		if (length == 0xFFFF || length == 0)
+			return IXGBE_ERR_PBA_SECTION;
+	} else {
+		/* PBA number in legacy format, there is no PBA Block. */
+		length = 0;
+	}
+
+	if (pba_block_size != NULL)
+		*pba_block_size = length;
+
+	return IXGBE_SUCCESS;
+}
+
+/**
  *  ixgbe_get_mac_addr_generic - Generic get MAC address
  *  @hw: pointer to hardware structure
  *  @mac_addr: Adapter MAC address
@@ -624,14 +992,6 @@ int32_t ixgbe_get_mac_addr_generic(struc
 
 	DEBUGFUNC("ixgbe_get_mac_addr_generic");
 
-#ifdef __sparc64__
-	struct ixgbe_osdep *os = hw->back;
- 
-	if (OF_getprop(PCITAG_NODE(os->os_pa.pa_tag), "local-mac-address",
-	    mac_addr, ETHER_ADDR_LEN) == ETHER_ADDR_LEN)
-		return IXGBE_SUCCESS;
-#endif
-
 	rar_high = IXGBE_READ_REG(hw, IXGBE_RAH(0));
 	rar_low = IXGBE_READ_REG(hw, IXGBE_RAL(0));
 
@@ -651,12 +1011,12 @@ int32_t ixgbe_get_mac_addr_generic(struc
  *
  *  Stores the PCI bus info (speed, width, type) within the ixgbe_hw structure
  **/
-void ixgbe_set_pci_config_data_generic(struct ixgbe_hw *hw,
-				       uint16_t link_status)
+void ixgbe_set_pci_config_data_generic(struct ixgbe_hw *hw, uint16_t link_status)
 {
 	struct ixgbe_mac_info *mac = &hw->mac;
 
-	hw->bus.type = ixgbe_bus_type_pci_express;
+	if (hw->bus.type == ixgbe_bus_type_unknown)
+		hw->bus.type = ixgbe_bus_type_pci_express;
 
 	switch (link_status & IXGBE_PCI_LINK_WIDTH) {
 	case IXGBE_PCI_LINK_WIDTH_1:
@@ -719,24 +1079,33 @@ int32_t ixgbe_get_bus_info_generic(struc
  *  ixgbe_set_lan_id_multi_port_pcie - Set LAN id for PCIe multiple port devices
  *  @hw: pointer to the HW structure
  *
- *  Determines the LAN function id by reading memory-mapped registers
- *  and swaps the port value if requested.
+ *  Determines the LAN function id by reading memory-mapped registers and swaps
+ *  the port value if requested, and set MAC instance for devices that share
+ *  CS4227.
  **/
 void ixgbe_set_lan_id_multi_port_pcie(struct ixgbe_hw *hw)
 {
 	struct ixgbe_bus_info *bus = &hw->bus;
 	uint32_t reg;
+	uint16_t ee_ctrl_4;
 
 	DEBUGFUNC("ixgbe_set_lan_id_multi_port_pcie");
 
 	reg = IXGBE_READ_REG(hw, IXGBE_STATUS);
 	bus->func = (reg & IXGBE_STATUS_LAN_ID) >> IXGBE_STATUS_LAN_ID_SHIFT;
-	bus->lan_id = bus->func;
+	bus->lan_id = (uint8_t)bus->func;
 
 	/* check for a port swap */
-	reg = IXGBE_READ_REG(hw, IXGBE_FACTPS);
+	reg = IXGBE_READ_REG(hw, IXGBE_FACTPS_BY_MAC(hw));
 	if (reg & IXGBE_FACTPS_LFS)
 		bus->func ^= 0x1;
+
+	/* Get MAC instance from EEPROM for configuring CS4227 */
+	if (hw->device_id == IXGBE_DEV_ID_X550EM_A_SFP) {
+		hw->eeprom.ops.read(hw, IXGBE_EEPROM_CTRL_4, &ee_ctrl_4);
+		bus->instance_id = (ee_ctrl_4 & IXGBE_EE_CTRL_4_INST_ID) >>
+				   IXGBE_EE_CTRL_4_INST_ID_SHIFT;
+	}
 }
 
 /**
@@ -794,6 +1163,47 @@ int32_t ixgbe_stop_adapter_generic(struc
 }
 
 /**
+ *  ixgbe_init_led_link_act_generic - Store the LED index link/activity.
+ *  @hw: pointer to hardware structure
+ *
+ *  Store the index for the link active LED. This will be used to support
+ *  blinking the LED.
+ **/
+int32_t ixgbe_init_led_link_act_generic(struct ixgbe_hw *hw)
+{
+	struct ixgbe_mac_info *mac = &hw->mac;
+	uint32_t led_reg, led_mode;
+	uint8_t i;
+
+	led_reg = IXGBE_READ_REG(hw, IXGBE_LEDCTL);
+
+	/* Get LED link active from the LEDCTL register */
+	for (i = 0; i < 4; i++) {
+		led_mode = led_reg >> IXGBE_LED_MODE_SHIFT(i);
+
+		if ((led_mode & IXGBE_LED_MODE_MASK_BASE) ==
+		     IXGBE_LED_LINK_ACTIVE) {
+			mac->led_link_act = i;
+			return IXGBE_SUCCESS;
+		}
+	}
+
+	/*
+	 * If LEDCTL register does not have the LED link active set, then use
+	 * known MAC defaults.
+	 */
+	switch (hw->mac.type) {
+	case ixgbe_mac_X550EM_a:
+	case ixgbe_mac_X550EM_x:
+		mac->led_link_act = 1;
+		break;
+	default:
+		mac->led_link_act = 2;
+	}
+	return IXGBE_SUCCESS;
+}
+
+/**
  *  ixgbe_led_on_generic - Turns on the software controllable LEDs.
  *  @hw: pointer to hardware structure
  *  @index: led number to turn on
@@ -804,6 +1214,9 @@ int32_t ixgbe_led_on_generic(struct ixgb
 
 	DEBUGFUNC("ixgbe_led_on_generic");
 
+	if (index > 3)
+		return IXGBE_ERR_PARAM;
+
 	/* To turn on the LED, set mode to ON. */
 	led_reg &= ~IXGBE_LED_MODE_MASK(index);
 	led_reg |= IXGBE_LED_ON << IXGBE_LED_MODE_SHIFT(index);
@@ -824,6 +1237,9 @@ int32_t ixgbe_led_off_generic(struct ixg
 
 	DEBUGFUNC("ixgbe_led_off_generic");
 
+	if (index > 3)
+		return IXGBE_ERR_PARAM;
+
 	/* To turn off the LED, set mode to OFF. */
 	led_reg &= ~IXGBE_LED_MODE_MASK(index);
 	led_reg |= IXGBE_LED_OFF << IXGBE_LED_MODE_SHIFT(index);
@@ -860,7 +1276,7 @@ int32_t ixgbe_init_eeprom_params_generic
 		 * Check for EEPROM present first.
 		 * If not present leave as none
 		 */
-		eec = IXGBE_READ_REG(hw, IXGBE_EEC);
+		eec = IXGBE_READ_REG(hw, IXGBE_EEC_BY_MAC(hw));
 		if (eec & IXGBE_EEC_PRES) {
 			eeprom->type = ixgbe_eeprom_spi;
 
@@ -887,6 +1303,62 @@ int32_t ixgbe_init_eeprom_params_generic
 }
 
 /**
+ *  ixgbe_write_eeprom_buffer_bit_bang_generic - Write EEPROM using bit-bang
+ *  @hw: pointer to hardware structure
+ *  @offset: offset within the EEPROM to write
+ *  @words: number of word(s)
+ *  @data: 16 bit word(s) to write to EEPROM
+ *
+ *  Reads 16 bit word(s) from EEPROM through bit-bang method
+ **/
+int32_t ixgbe_write_eeprom_buffer_bit_bang_generic(struct ixgbe_hw *hw, uint16_t offset,
+					       uint16_t words, uint16_t *data)
+{
+	int32_t status = IXGBE_SUCCESS;
+	uint16_t i, count;
+
+	DEBUGFUNC("ixgbe_write_eeprom_buffer_bit_bang_generic");
+
+	hw->eeprom.ops.init_params(hw);
+
+	if (words == 0) {
+		status = IXGBE_ERR_INVALID_ARGUMENT;
+		goto out;
+	}
+
+	if (offset + words > hw->eeprom.word_size) {
+		status = IXGBE_ERR_EEPROM;
+		goto out;
+	}
+
+	/*
+	 * The EEPROM page size cannot be queried from the chip. We do lazy
+	 * initialization. It is worth to do that when we write large buffer.
+	 */
+	if ((hw->eeprom.word_page_size == 0) &&
+	    (words > IXGBE_EEPROM_PAGE_SIZE_MAX))
+		ixgbe_detect_eeprom_page_size_generic(hw, offset);
+
+	/*
+	 * We cannot hold synchronization semaphores for too long
+	 * to avoid other entity starvation. However it is more efficient
+	 * to read in bursts than synchronizing access for each word.
+	 */
+	for (i = 0; i < words; i += IXGBE_EEPROM_RD_BUFFER_MAX_COUNT) {
+		count = (words - i) / IXGBE_EEPROM_RD_BUFFER_MAX_COUNT > 0 ?
+			IXGBE_EEPROM_RD_BUFFER_MAX_COUNT : (words - i);
+		status = ixgbe_write_eeprom_buffer_bit_bang(hw, offset + i,
+							    count, &data[i]);
+
+		if (status != IXGBE_SUCCESS)
+			break;
+	}
+
+out:
+	return status;
+}
+
+/**
  *  ixgbe_write_eeprom_buffer_bit_bang - Writes 16 bit word(s) to EEPROM
  *  @hw: pointer to hardware structure
  *  @offset: offset within the EEPROM to be written to
@@ -896,7 +1368,7 @@ int32_t ixgbe_init_eeprom_params_generic
  *  If ixgbe_eeprom_update_checksum is not called after this function, the
  *  EEPROM will most likely contain an invalid checksum.
  **/
-static int32_t ixgbe_write_eeprom_buffer_bit_bang(struct ixgbe_hw *hw, uint16_t offset,
+int32_t ixgbe_write_eeprom_buffer_bit_bang(struct ixgbe_hw *hw, uint16_t offset,
 					      uint16_t words, uint16_t *data)
 {
 	int32_t status;
@@ -998,26 +1470,75 @@ out:
 }
 
 /**
- *  ixgbe_read_eeprom_buffer_bit_bang - Read EEPROM using bit-bang
+ *  ixgbe_read_eeprom_buffer_bit_bang_generic - Read EEPROM using bit-bang
  *  @hw: pointer to hardware structure
  *  @offset: offset within the EEPROM to be read
+ *  @data: read 16 bit words(s) from EEPROM
  *  @words: number of word(s)
- *  @data: read 16 bit word(s) from EEPROM
  *
  *  Reads 16 bit word(s) from EEPROM through bit-bang method
  **/
-static int32_t ixgbe_read_eeprom_buffer_bit_bang(struct ixgbe_hw *hw, uint16_t offset,
-					     uint16_t words, uint16_t *data)
+int32_t ixgbe_read_eeprom_buffer_bit_bang_generic(struct ixgbe_hw *hw, uint16_t offset,
+					      uint16_t words, uint16_t *data)
 {
-	int32_t status;
-	uint16_t word_in;
-	uint8_t read_opcode = IXGBE_EEPROM_READ_OPCODE_SPI;
-	uint16_t i;
+	int32_t status = IXGBE_SUCCESS;
+	uint16_t i, count;
 
-	DEBUGFUNC("ixgbe_read_eeprom_buffer_bit_bang");
+	DEBUGFUNC("ixgbe_read_eeprom_buffer_bit_bang_generic");
 
-	/* Prepare the EEPROM for reading  */
-	status = ixgbe_acquire_eeprom(hw);
+	hw->eeprom.ops.init_params(hw);
+
+	if (words == 0) {
+		status = IXGBE_ERR_INVALID_ARGUMENT;
+		goto out;
+	}
+
+	if (offset + words > hw->eeprom.word_size) {
+		status = IXGBE_ERR_EEPROM;
+		goto out;
+	}
+
+	/*
+	 * We cannot hold synchronization semaphores for too long
+	 * to avoid other entity starvation. However it is more efficient
+	 * to read in bursts than synchronizing access for each word.
+	 */
+	for (i = 0; i < words; i += IXGBE_EEPROM_RD_BUFFER_MAX_COUNT) {
+		count = (words - i) / IXGBE_EEPROM_RD_BUFFER_MAX_COUNT > 0 ?
+			IXGBE_EEPROM_RD_BUFFER_MAX_COUNT : (words - i);
+
+		status = ixgbe_read_eeprom_buffer_bit_bang(hw, offset + i,
+							   count, &data[i]);
+
+		if (status != IXGBE_SUCCESS)
+			break;
+	}
+
+out:
+	return status;
+}
+
+/**
+ *  ixgbe_read_eeprom_buffer_bit_bang - Read EEPROM using bit-bang
+ *  @hw: pointer to hardware structure
+ *  @offset: offset within the EEPROM to be read
+ *  @words: number of word(s)
+ *  @data: read 16 bit word(s) from EEPROM
+ *
+ *  Reads 16 bit word(s) from EEPROM through bit-bang method
+ **/
+int32_t ixgbe_read_eeprom_buffer_bit_bang(struct ixgbe_hw *hw, uint16_t offset,
+					     uint16_t words, uint16_t *data)
+{
+	int32_t status;
+	uint16_t word_in;
+	uint8_t read_opcode = IXGBE_EEPROM_READ_OPCODE_SPI;
+	uint16_t i;
+
+	DEBUGFUNC("ixgbe_read_eeprom_buffer_bit_bang");
+
+	/* Prepare the EEPROM for reading  */
+	status = ixgbe_acquire_eeprom(hw);
 
 	if (status == IXGBE_SUCCESS) {
 		if (ixgbe_ready_eeprom(hw) != IXGBE_SUCCESS) {
@@ -1135,6 +1656,50 @@ out:
 }
 
 /**
+ *  ixgbe_detect_eeprom_page_size_generic - Detect EEPROM page size
+ *  @hw: pointer to hardware structure
+ *  @offset: offset within the EEPROM to be used as a scratch pad
+ *
+ *  Discover EEPROM page size by writing marching data at given offset.
+ *  This function is called only when we are writing a new large buffer
+ *  at given offset so the data would be overwritten anyway.
+ **/
+int32_t ixgbe_detect_eeprom_page_size_generic(struct ixgbe_hw *hw,
+						 uint16_t offset)
+{
+	uint16_t data[IXGBE_EEPROM_PAGE_SIZE_MAX];
+	int32_t status = IXGBE_SUCCESS;
+	uint16_t i;
+
+	DEBUGFUNC("ixgbe_detect_eeprom_page_size_generic");
+
+	for (i = 0; i < IXGBE_EEPROM_PAGE_SIZE_MAX; i++)
+		data[i] = i;
+
+	hw->eeprom.word_page_size = IXGBE_EEPROM_PAGE_SIZE_MAX;
+	status = ixgbe_write_eeprom_buffer_bit_bang(hw, offset,
+					     IXGBE_EEPROM_PAGE_SIZE_MAX, data);
+	hw->eeprom.word_page_size = 0;
+	if (status != IXGBE_SUCCESS)
+		goto out;
+
+	status = ixgbe_read_eeprom_buffer_bit_bang(hw, offset, 1, data);
+	if (status != IXGBE_SUCCESS)
+		goto out;
+
+	/*
+	 * When writing in burst more than the actual page size
+	 * EEPROM address wraps around current page.
+	 */
+	hw->eeprom.word_page_size = IXGBE_EEPROM_PAGE_SIZE_MAX - data[0];
+
+	DEBUGOUT1("Detected EEPROM page size = %d words.",
+		  hw->eeprom.word_page_size);
+out:
+	return status;
+}
+
+/**
  *  ixgbe_read_eerd_generic - Read EEPROM word using EERD
  *  @hw: pointer to hardware structure
  *  @offset: offset of  word in the EEPROM to read
@@ -1272,14 +1837,14 @@ int32_t ixgbe_acquire_eeprom(struct ixgb
 		status = IXGBE_ERR_SWFW_SYNC;
 
 	if (status == IXGBE_SUCCESS) {
-		eec = IXGBE_READ_REG(hw, IXGBE_EEC);
+		eec = IXGBE_READ_REG(hw, IXGBE_EEC_BY_MAC(hw));
 
 		/* Request EEPROM Access */
 		eec |= IXGBE_EEC_REQ;
-		IXGBE_WRITE_REG(hw, IXGBE_EEC, eec);
+		IXGBE_WRITE_REG(hw, IXGBE_EEC_BY_MAC(hw), eec);
 
 		for (i = 0; i < IXGBE_EEPROM_GRANT_ATTEMPTS; i++) {
-			eec = IXGBE_READ_REG(hw, IXGBE_EEC);
+			eec = IXGBE_READ_REG(hw, IXGBE_EEC_BY_MAC(hw));
 			if (eec & IXGBE_EEC_GNT)
 				break;
 			usec_delay(5);
@@ -1288,7 +1853,7 @@ int32_t ixgbe_acquire_eeprom(struct ixgb
 		/* Release if grant not acquired */
 		if (!(eec & IXGBE_EEC_GNT)) {
 			eec &= ~IXGBE_EEC_REQ;
-			IXGBE_WRITE_REG(hw, IXGBE_EEC, eec);
+			IXGBE_WRITE_REG(hw, IXGBE_EEC_BY_MAC(hw), eec);
 			DEBUGOUT("Could not acquire EEPROM grant\n");
 
 			hw->mac.ops.release_swfw_sync(hw, IXGBE_GSSR_EEP_SM);
@@ -1299,7 +1864,7 @@ int32_t ixgbe_acquire_eeprom(struct ixgb
 		if (status == IXGBE_SUCCESS) {
 			/* Clear CS and SK */
 			eec &= ~(IXGBE_EEC_CS | IXGBE_EEC_SK);
-			IXGBE_WRITE_REG(hw, IXGBE_EEC, eec);
+			IXGBE_WRITE_REG(hw, IXGBE_EEC_BY_MAC(hw), eec);
 			IXGBE_WRITE_FLUSH(hw);
 			usec_delay(1);
 		}
@@ -1329,7 +1894,7 @@ int32_t ixgbe_get_eeprom_semaphore(struc
 		 * If the SMBI bit is 0 when we read it, then the bit will be
 		 * set and we have the semaphore
 		 */
-		swsm = IXGBE_READ_REG(hw, IXGBE_SWSM);
+		swsm = IXGBE_READ_REG(hw, IXGBE_SWSM_BY_MAC(hw));
 		if (!(swsm & IXGBE_SWSM_SMBI)) {
 			status = IXGBE_SUCCESS;
 			break;
@@ -1354,7 +1919,7 @@ int32_t ixgbe_get_eeprom_semaphore(struc
 		 * If the SMBI bit is 0 when we read it, then the bit will be
 		 * set and we have the semaphore
 		 */
-		swsm = IXGBE_READ_REG(hw, IXGBE_SWSM);
+		swsm = IXGBE_READ_REG(hw, IXGBE_SWSM_BY_MAC(hw));
 		if (!(swsm & IXGBE_SWSM_SMBI))
 			status = IXGBE_SUCCESS;
 	}
@@ -1362,17 +1927,17 @@ int32_t ixgbe_get_eeprom_semaphore(struc
 	/* Now get the semaphore between SW/FW through the SWESMBI bit */
 	if (status == IXGBE_SUCCESS) {
 		for (i = 0; i < timeout; i++) {
-			swsm = IXGBE_READ_REG(hw, IXGBE_SWSM);
+			swsm = IXGBE_READ_REG(hw, IXGBE_SWSM_BY_MAC(hw));
 
 			/* Set the SW EEPROM semaphore bit to request access */
 			swsm |= IXGBE_SWSM_SWESMBI;
-			IXGBE_WRITE_REG(hw, IXGBE_SWSM, swsm);
+			IXGBE_WRITE_REG(hw, IXGBE_SWSM_BY_MAC(hw), swsm);
 
 			/*
 			 * If we set the bit successfully then we got the
 			 * semaphore.
 			 */
-			swsm = IXGBE_READ_REG(hw, IXGBE_SWSM);
+			swsm = IXGBE_READ_REG(hw, IXGBE_SWSM_BY_MAC(hw));
 			if (swsm & IXGBE_SWSM_SWESMBI)
 				break;
 
@@ -1469,15 +2034,15 @@ void ixgbe_standby_eeprom(struct ixgbe_h
 
 	DEBUGFUNC("ixgbe_standby_eeprom");
 
-	eec = IXGBE_READ_REG(hw, IXGBE_EEC);
+	eec = IXGBE_READ_REG(hw, IXGBE_EEC_BY_MAC(hw));
 
 	/* Toggle CS to flush commands */
 	eec |= IXGBE_EEC_CS;
-	IXGBE_WRITE_REG(hw, IXGBE_EEC, eec);
+	IXGBE_WRITE_REG(hw, IXGBE_EEC_BY_MAC(hw), eec);
 	IXGBE_WRITE_FLUSH(hw);
 	usec_delay(1);
 	eec &= ~IXGBE_EEC_CS;
-	IXGBE_WRITE_REG(hw, IXGBE_EEC, eec);
+	IXGBE_WRITE_REG(hw, IXGBE_EEC_BY_MAC(hw), eec);
 	IXGBE_WRITE_FLUSH(hw);
 	usec_delay(1);
 }
@@ -1489,7 +2054,7 @@ void ixgbe_standby_eeprom(struct ixgbe_h
  *  @count: number of bits to shift out
  **/
 void ixgbe_shift_out_eeprom_bits(struct ixgbe_hw *hw, uint16_t data,
-				 uint16_t count)
+					uint16_t count)
 {
 	uint32_t eec;
 	uint32_t mask;
@@ -1497,7 +2062,7 @@ void ixgbe_shift_out_eeprom_bits(struct 
 
 	DEBUGFUNC("ixgbe_shift_out_eeprom_bits");
 
-	eec = IXGBE_READ_REG(hw, IXGBE_EEC);
+	eec = IXGBE_READ_REG(hw, IXGBE_EEC_BY_MAC(hw));
 
 	/*
 	 * Mask is used to shift "count" bits of "data" out to the EEPROM
@@ -1518,7 +2083,7 @@ void ixgbe_shift_out_eeprom_bits(struct 
 		else
 			eec &= ~IXGBE_EEC_DI;
 
-		IXGBE_WRITE_REG(hw, IXGBE_EEC, eec);
+		IXGBE_WRITE_REG(hw, IXGBE_EEC_BY_MAC(hw), eec);
 		IXGBE_WRITE_FLUSH(hw);
 
 		usec_delay(1);
@@ -1535,13 +2100,14 @@ void ixgbe_shift_out_eeprom_bits(struct 
 
 	/* We leave the "DI" bit set to "0" when we leave this routine. */
 	eec &= ~IXGBE_EEC_DI;
-	IXGBE_WRITE_REG(hw, IXGBE_EEC, eec);
+	IXGBE_WRITE_REG(hw, IXGBE_EEC_BY_MAC(hw), eec);
 	IXGBE_WRITE_FLUSH(hw);
 }
 
 /**
  *  ixgbe_shift_in_eeprom_bits - Shift data bits in from the EEPROM
  *  @hw: pointer to hardware structure
+ *  @count: number of bits to shift
  **/
 uint16_t ixgbe_shift_in_eeprom_bits(struct ixgbe_hw *hw, uint16_t count)
 {
@@ -1558,7 +2124,7 @@ uint16_t ixgbe_shift_in_eeprom_bits(stru
 	 * the value of the "DO" bit.  During this "shifting in" process the
 	 * "DI" bit should always be clear.
 	 */
-	eec = IXGBE_READ_REG(hw, IXGBE_EEC);
+	eec = IXGBE_READ_REG(hw, IXGBE_EEC_BY_MAC(hw));
 
 	eec &= ~(IXGBE_EEC_DO | IXGBE_EEC_DI);
 
@@ -1566,7 +2132,7 @@ uint16_t ixgbe_shift_in_eeprom_bits(stru
 		data = data << 1;
 		ixgbe_raise_eeprom_clk(hw, &eec);
 
-		eec = IXGBE_READ_REG(hw, IXGBE_EEC);
+		eec = IXGBE_READ_REG(hw, IXGBE_EEC_BY_MAC(hw));
 
 		eec &= ~(IXGBE_EEC_DI);
 		if (eec & IXGBE_EEC_DO)
@@ -1592,7 +2158,7 @@ void ixgbe_raise_eeprom_clk(struct ixgbe
 	 * (setting the SK bit), then delay
 	 */
 	*eec = *eec | IXGBE_EEC_SK;
-	IXGBE_WRITE_REG(hw, IXGBE_EEC, *eec);
+	IXGBE_WRITE_REG(hw, IXGBE_EEC_BY_MAC(hw), *eec);
 	IXGBE_WRITE_FLUSH(hw);
 	usec_delay(1);
 }
@@ -1600,7 +2166,7 @@ void ixgbe_raise_eeprom_clk(struct ixgbe
 /**
  *  ixgbe_lower_eeprom_clk - Lowers the EEPROM's clock input.
  *  @hw: pointer to hardware structure
- *  @eecd: EECD's current value
+ *  @eec: EEC's current value
  **/
 void ixgbe_lower_eeprom_clk(struct ixgbe_hw *hw, uint32_t *eec)
 {
@@ -1611,7 +2177,7 @@ void ixgbe_lower_eeprom_clk(struct ixgbe
 	 * delay
 	 */
 	*eec = *eec & ~IXGBE_EEC_SK;
-	IXGBE_WRITE_REG(hw, IXGBE_EEC, *eec);
+	IXGBE_WRITE_REG(hw, IXGBE_EEC_BY_MAC(hw), *eec);
 	IXGBE_WRITE_FLUSH(hw);
 	usec_delay(1);
 }
@@ -1626,19 +2192,19 @@ void ixgbe_release_eeprom(struct ixgbe_h
 
 	DEBUGFUNC("ixgbe_release_eeprom");
 
-	eec = IXGBE_READ_REG(hw, IXGBE_EEC);
+	eec = IXGBE_READ_REG(hw, IXGBE_EEC_BY_MAC(hw));
 
 	eec |= IXGBE_EEC_CS;  /* Pull CS high */
 	eec &= ~IXGBE_EEC_SK; /* Lower SCK */
 
-	IXGBE_WRITE_REG(hw, IXGBE_EEC, eec);
+	IXGBE_WRITE_REG(hw, IXGBE_EEC_BY_MAC(hw), eec);
 	IXGBE_WRITE_FLUSH(hw);
 
 	usec_delay(1);
 
 	/* Stop requesting EEPROM access */
 	eec &= ~IXGBE_EEC_REQ;
-	IXGBE_WRITE_REG(hw, IXGBE_EEC, eec);
+	IXGBE_WRITE_REG(hw, IXGBE_EEC_BY_MAC(hw), eec);
 
 	hw->mac.ops.release_swfw_sync(hw, IXGBE_GSSR_EEP_SM);
 
@@ -1714,7 +2280,7 @@ int32_t ixgbe_calc_eeprom_checksum_gener
  *  caller does not need checksum_val, the value can be NULL.
  **/
 int32_t ixgbe_validate_eeprom_checksum_generic(struct ixgbe_hw *hw,
-					       uint16_t *checksum_val)
+					   uint16_t *checksum_val)
 {
 	int32_t status;
 	uint16_t checksum;
@@ -1793,7 +2359,7 @@ int32_t ixgbe_update_eeprom_checksum_gen
  *  ixgbe_validate_mac_addr - Validate MAC address
  *  @mac_addr: pointer to MAC address.
  *
- *  Tests a MAC address to ensure it is a valid Individual Address
+ *  Tests a MAC address to ensure it is a valid Individual Address.
  **/
 int32_t ixgbe_validate_mac_addr(uint8_t *mac_addr)
 {
@@ -1803,16 +2369,13 @@ int32_t ixgbe_validate_mac_addr(uint8_t 
 
 	/* Make sure it is not a multicast address */
 	if (IXGBE_IS_MULTICAST(mac_addr)) {
-		DEBUGOUT("MAC address is multicast\n");
 		status = IXGBE_ERR_INVALID_MAC_ADDR;
 	/* Not a broadcast address */
 	} else if (IXGBE_IS_BROADCAST(mac_addr)) {
-		DEBUGOUT("MAC address is broadcast\n");
 		status = IXGBE_ERR_INVALID_MAC_ADDR;
 	/* Reject the zero address */
 	} else if (mac_addr[0] == 0 && mac_addr[1] == 0 && mac_addr[2] == 0 &&
 		   mac_addr[3] == 0 && mac_addr[4] == 0 && mac_addr[5] == 0) {
-		DEBUGOUT("MAC address is all zeros\n");
 		status = IXGBE_ERR_INVALID_MAC_ADDR;
 	}
 	return status;
@@ -1828,8 +2391,8 @@ int32_t ixgbe_validate_mac_addr(uint8_t 
  *
  *  Puts an ethernet address into a receive address register.
  **/
-int32_t ixgbe_set_rar_generic(struct ixgbe_hw *hw, uint32_t index, uint8_t *addr,
-			      uint32_t vmdq, uint32_t enable_addr)
+int32_t ixgbe_set_rar_generic(struct ixgbe_hw *hw, uint32_t index, uint8_t *addr, uint32_t vmdq,
+			  uint32_t enable_addr)
 {
 	uint32_t rar_low, rar_high;
 	uint32_t rar_entries = hw->mac.num_rar_entries;
@@ -1950,10 +2513,11 @@ int32_t ixgbe_init_rx_addrs_generic(stru
 			  hw->mac.addr[4], hw->mac.addr[5]);
 
 		hw->mac.ops.set_rar(hw, 0, hw->mac.addr, 0, IXGBE_RAH_AV);
-
-		/* clear VMDq pool/queue selection for RAR 0 */
-		hw->mac.ops.clear_vmdq(hw, 0, IXGBE_CLEAR_VMDQ_ALL);
 	}
+
+	/* clear VMDq pool/queue selection for RAR 0 */
+	hw->mac.ops.clear_vmdq(hw, 0, IXGBE_CLEAR_VMDQ_ALL);
+
 	hw->addr_ctrl.overflow_promisc = 0;
 
 	hw->addr_ctrl.rar_used_count = 1;
@@ -1982,6 +2546,7 @@ int32_t ixgbe_init_rx_addrs_generic(stru
  *  ixgbe_add_uc_addr - Adds a secondary unicast address.
  *  @hw: pointer to hardware structure
  *  @addr: new address
+ *  @vmdq: VMDq "set" or "pool" index
  *
  *  Adds it to unused receive address register or goes into promiscuous mode.
  **/
@@ -2012,6 +2577,76 @@ void ixgbe_add_uc_addr(struct ixgbe_hw *
 }
 
 /**
+ *  ixgbe_update_uc_addr_list_generic - Updates MAC list of secondary addresses
+ *  @hw: pointer to hardware structure
+ *  @addr_list: the list of new addresses
+ *  @addr_count: number of addresses
+ *  @next: iterator function to walk the address list
+ *
+ *  The given list replaces any existing list.  Clears the secondary addrs from
+ *  receive address registers.  Uses unused receive address registers for the
+ *  first secondary addresses, and falls back to promiscuous mode as needed.
+ *
+ *  Drivers using secondary unicast addresses must set user_set_promisc when
+ *  manually putting the device into promiscuous mode.
+ **/
+int32_t ixgbe_update_uc_addr_list_generic(struct ixgbe_hw *hw, uint8_t *addr_list,
+				      uint32_t addr_count, ixgbe_mc_addr_itr next)
+{
+	uint8_t *addr;
+	uint32_t i;
+	uint32_t old_promisc_setting = hw->addr_ctrl.overflow_promisc;
+	uint32_t uc_addr_in_use;
+	uint32_t fctrl;
+	uint32_t vmdq;
+
+	DEBUGFUNC("ixgbe_update_uc_addr_list_generic");
+
+	/*
+	 * Clear accounting of old secondary address list,
+	 * don't count RAR[0]
+	 */
+	uc_addr_in_use = hw->addr_ctrl.rar_used_count - 1;
+	hw->addr_ctrl.rar_used_count -= uc_addr_in_use;
+	hw->addr_ctrl.overflow_promisc = 0;
+
+	/* Zero out the other receive addresses */
+	DEBUGOUT1("Clearing RAR[1-%d]\n", uc_addr_in_use+1);
+	for (i = 0; i < uc_addr_in_use; i++) {
+		IXGBE_WRITE_REG(hw, IXGBE_RAL(1+i), 0);
+		IXGBE_WRITE_REG(hw, IXGBE_RAH(1+i), 0);
+	}
+
+	/* Add the new addresses */
+	for (i = 0; i < addr_count; i++) {
+		DEBUGOUT(" Adding the secondary addresses:\n");
+		addr = next(hw, &addr_list, &vmdq);
+		ixgbe_add_uc_addr(hw, addr, vmdq);
+	}
+
+	if (hw->addr_ctrl.overflow_promisc) {
+		/* enable promisc if not already in overflow or set by user */
+		if (!old_promisc_setting && !hw->addr_ctrl.user_set_promisc) {
+			DEBUGOUT(" Entering address overflow promisc mode\n");
+			fctrl = IXGBE_READ_REG(hw, IXGBE_FCTRL);
+			fctrl |= IXGBE_FCTRL_UPE;
+			IXGBE_WRITE_REG(hw, IXGBE_FCTRL, fctrl);
+		}
+	} else {
+		/* only disable if set by overflow, not by user */
+		if (old_promisc_setting && !hw->addr_ctrl.user_set_promisc) {
+			DEBUGOUT(" Leaving address overflow promisc mode\n");
+			fctrl = IXGBE_READ_REG(hw, IXGBE_FCTRL);
+			fctrl &= ~IXGBE_FCTRL_UPE;
+			IXGBE_WRITE_REG(hw, IXGBE_FCTRL, fctrl);
+		}
+	}
+
+	DEBUGOUT("ixgbe_update_uc_addr_list_generic Complete\n");
+	return IXGBE_SUCCESS;
+}
+
+/**
  *  ixgbe_mta_vector - Determines bit-vector in multicast table to set
  *  @hw: pointer to hardware structure
  *  @mc_addr: the multicast address
@@ -2044,7 +2679,7 @@ int32_t ixgbe_mta_vector(struct ixgbe_hw
 		break;
 	default:  /* Invalid mc_filter_type */
 		DEBUGOUT("MC filter type param set incorrectly\n");
-		panic("incorrect multicast filter type");
+		ASSERT(0);
 		break;
 	}
 
@@ -2056,7 +2691,7 @@ int32_t ixgbe_mta_vector(struct ixgbe_hw
 /**
  *  ixgbe_set_mta - Set bit-vector in multicast table
  *  @hw: pointer to hardware structure
- *  @hash_value: Multicast address hash value
+ *  @mc_addr: Multicast address
  *
  *  Sets the bit-vector in the multicast table.
  **/
@@ -2099,8 +2734,8 @@ void ixgbe_set_mta(struct ixgbe_hw *hw, 
  *  Hashes the given addresses into the multicast table.
  **/
 int32_t ixgbe_update_mc_addr_list_generic(struct ixgbe_hw *hw, uint8_t *mc_addr_list,
-					  uint32_t mc_addr_count, ixgbe_mc_addr_itr next,
-					  bool clear)
+				      uint32_t mc_addr_count, ixgbe_mc_addr_itr next,
+				      bool clear)
 {
 	uint32_t i;
 	uint32_t vmdq;
@@ -2212,7 +2847,7 @@ int32_t ixgbe_fc_enable_generic(struct i
 	}
 
 	/* Negotiate the fc mode to use */
-	ixgbe_fc_autoneg(hw);
+	hw->mac.ops.fc_autoneg(hw);
 
 	/* Disable any previous flow control settings */
 	mflcn_reg = IXGBE_READ_REG(hw, IXGBE_MFLCN);
@@ -2291,7 +2926,7 @@ int32_t ixgbe_fc_enable_generic(struct i
 			 * the Tx switch to function even under heavy Rx
 			 * workloads.
 			 */
-			fcrth = IXGBE_READ_REG(hw, IXGBE_RXPBSIZE(i)) - 0x6000;
+			fcrth = IXGBE_READ_REG(hw, IXGBE_RXPBSIZE(i)) - 24576;
 		}
 
 		IXGBE_WRITE_REG(hw, IXGBE_FCRTH_82599(i), fcrth);
@@ -2322,10 +2957,8 @@ out:
  *  Find the intersection between advertised settings and link partner's
  *  advertised settings
  **/
-int32_t ixgbe_negotiate_fc(struct ixgbe_hw *hw, uint32_t adv_reg,
-			   uint32_t lp_reg, uint32_t adv_sym,
-			   uint32_t adv_asm, uint32_t lp_sym,
-			   uint32_t lp_asm)
+int32_t ixgbe_negotiate_fc(struct ixgbe_hw *hw, uint32_t adv_reg, uint32_t lp_reg,
+		       uint32_t adv_sym, uint32_t adv_asm, uint32_t lp_sym, uint32_t lp_asm)
 {
 	if ((!(adv_reg)) ||  (!(lp_reg))) {
 		ERROR_REPORT3(IXGBE_ERROR_UNSUPPORTED,
@@ -2546,7 +3179,7 @@ out:
  * completion timeout, in units of 100 microsec.  Never return less than
  * 800 = 80 millisec.
  */
-static uint32_t ixgbe_pcie_timeout_poll(struct ixgbe_hw *hw)
+uint32_t ixgbe_pcie_timeout_poll(struct ixgbe_hw *hw)
 {
 	int16_t devctl2;
 	uint32_t pollcnt;
@@ -2596,6 +3229,7 @@ int32_t ixgbe_disable_pcie_master(struct
 {
 	int32_t status = IXGBE_SUCCESS;
 	uint32_t i, poll;
+	uint16_t value;
 
 	DEBUGFUNC("ixgbe_disable_pcie_master");
 
@@ -2603,7 +3237,8 @@ int32_t ixgbe_disable_pcie_master(struct
 	IXGBE_WRITE_REG(hw, IXGBE_CTRL, IXGBE_CTRL_GIO_DIS);
 
 	/* Exit if master requests are blocked */
-	if (!(IXGBE_READ_REG(hw, IXGBE_STATUS) & IXGBE_STATUS_GIO))
+	if (!(IXGBE_READ_REG(hw, IXGBE_STATUS) & IXGBE_STATUS_GIO) ||
+	    IXGBE_REMOVED(hw->hw_addr))
 		goto out;
 
 	/* Poll for master request bit to clear */
@@ -2634,8 +3269,10 @@ int32_t ixgbe_disable_pcie_master(struct
 	poll = ixgbe_pcie_timeout_poll(hw);
 	for (i = 0; i < poll; i++) {
 		usec_delay(100);
-		if (!(IXGBE_READ_PCIE_WORD(hw, IXGBE_PCI_DEVICE_STATUS) &
-		    IXGBE_PCI_DEVICE_STATUS_TRANSACTION_PENDING))
+		value = IXGBE_READ_PCIE_WORD(hw, IXGBE_PCI_DEVICE_STATUS);
+		if (IXGBE_REMOVED(hw->hw_addr))
+			goto out;
+		if (!(value & IXGBE_PCI_DEVICE_STATUS_TRANSACTION_PENDING))
 			goto out;
 	}
 
@@ -2758,12 +3395,12 @@ int32_t ixgbe_disable_sec_rx_path_generi
 /**
  *  prot_autoc_read_generic - Hides MAC differences needed for AUTOC read
  *  @hw: pointer to hardware structure
+ *  @locked: bool to indicate whether the SW/FW lock was taken
  *  @reg_val: Value we read from AUTOC
  *
  *  The default case requires no protection so just to the register read.
  */
-int32_t prot_autoc_read_generic(struct ixgbe_hw *hw, bool *locked,
-				uint32_t *reg_val)
+int32_t prot_autoc_read_generic(struct ixgbe_hw *hw, bool *locked, uint32_t *reg_val)
 {
 	*locked = FALSE;
 	*reg_val = IXGBE_READ_REG(hw, IXGBE_AUTOC);
@@ -2779,8 +3416,7 @@ int32_t prot_autoc_read_generic(struct i
  *
  * The default case requires no protection so just to the register write.
  */
-int32_t prot_autoc_write_generic(struct ixgbe_hw *hw, uint32_t reg_val,
-				 bool locked)
+int32_t prot_autoc_write_generic(struct ixgbe_hw *hw, uint32_t reg_val, UNUSED bool locked)
 {
 	IXGBE_WRITE_REG(hw, IXGBE_AUTOC, reg_val);
 	return IXGBE_SUCCESS;
@@ -2794,7 +3430,7 @@ int32_t prot_autoc_write_generic(struct 
  **/
 int32_t ixgbe_enable_sec_rx_path_generic(struct ixgbe_hw *hw)
 {
-	int secrxreg;
+	uint32_t secrxreg;
 
 	DEBUGFUNC("ixgbe_enable_sec_rx_path_generic");
 
@@ -2841,6 +3477,9 @@ int32_t ixgbe_blink_led_start_generic(st
 
 	DEBUGFUNC("ixgbe_blink_led_start_generic");
 
+	if (index > 3)
+		return IXGBE_ERR_PARAM;
+
 	/*
 	 * Link must be up to auto-blink the LEDs;
 	 * Force it if link is down.
@@ -2886,6 +3525,9 @@ int32_t ixgbe_blink_led_stop_generic(str
 
 	DEBUGFUNC("ixgbe_blink_led_stop_generic");
 
+	if (index > 3)
+		return IXGBE_ERR_PARAM;
+
 	ret_val = hw->mac.ops.prot_autoc_read(hw, &locked, &autoc_reg);
 	if (ret_val != IXGBE_SUCCESS)
 		goto out;
@@ -2908,6 +3550,129 @@ out:
 }
 
 /**
+ *  ixgbe_get_san_mac_addr_offset - Get SAN MAC address offset from the EEPROM
+ *  @hw: pointer to hardware structure
+ *  @san_mac_offset: SAN MAC address offset
+ *
+ *  This function will read the EEPROM location for the SAN MAC address
+ *  pointer, and returns the value at that location.  This is used in both
+ *  get and set mac_addr routines.
+ **/
+int32_t ixgbe_get_san_mac_addr_offset(struct ixgbe_hw *hw,
+					 uint16_t *san_mac_offset)
+{
+	int32_t ret_val;
+
+	DEBUGFUNC("ixgbe_get_san_mac_addr_offset");
+
+	/*
+	 * First read the EEPROM pointer to see if the MAC addresses are
+	 * available.
+	 */
+	ret_val = hw->eeprom.ops.read(hw, IXGBE_SAN_MAC_ADDR_PTR,
+				      san_mac_offset);
+	if (ret_val) {
+		ERROR_REPORT2(IXGBE_ERROR_INVALID_STATE,
+			      "eeprom at offset %d failed",
+			      IXGBE_SAN_MAC_ADDR_PTR);
+	}
+
+	return ret_val;
+}
+
+/**
+ *  ixgbe_get_san_mac_addr_generic - SAN MAC address retrieval from the EEPROM
+ *  @hw: pointer to hardware structure
+ *  @san_mac_addr: SAN MAC address
+ *
+ *  Reads the SAN MAC address from the EEPROM, if it's available.  This is
+ *  per-port, so set_lan_id() must be called before reading the addresses.
+ *  set_lan_id() is called by identify_sfp(), but this cannot be relied
+ *  upon for non-SFP connections, so we must call it here.
+ **/
+int32_t ixgbe_get_san_mac_addr_generic(struct ixgbe_hw *hw, uint8_t *san_mac_addr)
+{
+	uint16_t san_mac_data, san_mac_offset;
+	uint8_t i;
+	int32_t ret_val;
+
+	DEBUGFUNC("ixgbe_get_san_mac_addr_generic");
+
+	/*
+	 * First read the EEPROM pointer to see if the MAC addresses are
+	 * available.  If they're not, no point in calling set_lan_id() here.
+	 */
+	ret_val = ixgbe_get_san_mac_addr_offset(hw, &san_mac_offset);
+	if (ret_val || san_mac_offset == 0 || san_mac_offset == 0xFFFF)
+		goto san_mac_addr_out;
+
+	/* make sure we know which port we need to program */
+	hw->mac.ops.set_lan_id(hw);
+	/* apply the port offset to the address offset */
+	(hw->bus.func) ? (san_mac_offset += IXGBE_SAN_MAC_ADDR_PORT1_OFFSET) :
+			 (san_mac_offset += IXGBE_SAN_MAC_ADDR_PORT0_OFFSET);
+	for (i = 0; i < 3; i++) {
+		ret_val = hw->eeprom.ops.read(hw, san_mac_offset,
+					      &san_mac_data);
+		if (ret_val) {
+			ERROR_REPORT2(IXGBE_ERROR_INVALID_STATE,
+				      "eeprom read at offset %d failed",
+				      san_mac_offset);
+			goto san_mac_addr_out;
+		}
+		san_mac_addr[i * 2] = (uint8_t)(san_mac_data);
+		san_mac_addr[i * 2 + 1] = (uint8_t)(san_mac_data >> 8);
+		san_mac_offset++;
+	}
+	return IXGBE_SUCCESS;
+
+san_mac_addr_out:
+	/*
+	 * No addresses available in this EEPROM.  It's not an
+	 * error though, so just wipe the local address and return.
+	 */
+	for (i = 0; i < 6; i++)
+		san_mac_addr[i] = 0xFF;
+	return IXGBE_SUCCESS;
+}
+
+/**
+ *  ixgbe_set_san_mac_addr_generic - Write the SAN MAC address to the EEPROM
+ *  @hw: pointer to hardware structure
+ *  @san_mac_addr: SAN MAC address
+ *
+ *  Write a SAN MAC address to the EEPROM.
+ **/
+int32_t ixgbe_set_san_mac_addr_generic(struct ixgbe_hw *hw, uint8_t *san_mac_addr)
+{
+	int32_t ret_val;
+	uint16_t san_mac_data, san_mac_offset;
+	uint8_t i;
+
+	DEBUGFUNC("ixgbe_set_san_mac_addr_generic");
+
+	/* Look for SAN mac address pointer.  If not defined, return */
+	ret_val = ixgbe_get_san_mac_addr_offset(hw, &san_mac_offset);
+	if (ret_val || san_mac_offset == 0 || san_mac_offset == 0xFFFF)
+		return IXGBE_ERR_NO_SAN_ADDR_PTR;
+
+	/* Make sure we know which port we need to write */
+	hw->mac.ops.set_lan_id(hw);
+	/* Apply the port offset to the address offset */
+	(hw->bus.func) ? (san_mac_offset += IXGBE_SAN_MAC_ADDR_PORT1_OFFSET) :
+			 (san_mac_offset += IXGBE_SAN_MAC_ADDR_PORT0_OFFSET);
+
+	for (i = 0; i < 3; i++) {
+		san_mac_data = (uint16_t)((uint16_t)(san_mac_addr[i * 2 + 1]) << 8);
+		san_mac_data |= (uint16_t)(san_mac_addr[i * 2]);
+		hw->eeprom.ops.write(hw, san_mac_offset, san_mac_data);
+		san_mac_offset++;
+	}
+
+	return IXGBE_SUCCESS;
+}
+
+/**
  *  ixgbe_get_pcie_msix_count_generic - Gets MSI-X vector count
  *  @hw: pointer to hardware structure
  *
@@ -2929,6 +3694,7 @@ uint16_t ixgbe_get_pcie_msix_count_gener
 	case ixgbe_mac_X540:
 	case ixgbe_mac_X550:
 	case ixgbe_mac_X550EM_x:
+	case ixgbe_mac_X550EM_a:
 		pcie_offset = IXGBE_PCIE_MSIX_82599_CAPS;
 		max_msix_count = IXGBE_MAX_MSIX_VECTORS_82599;
 		break;
@@ -2938,6 +3704,8 @@ uint16_t ixgbe_get_pcie_msix_count_gener
 
 	DEBUGFUNC("ixgbe_get_pcie_msix_count_generic");
 	msix_count = IXGBE_READ_PCIE_WORD(hw, pcie_offset);
+	if (IXGBE_REMOVED(hw->hw_addr))
+		msix_count = 0;
 	msix_count &= IXGBE_PCIE_MSIX_TBL_SZ_MASK;
 
 	/* MSI-X count is zero-based in HW */
@@ -3041,6 +3809,9 @@ int32_t ixgbe_clear_vmdq_generic(struct 
 	mpsar_lo = IXGBE_READ_REG(hw, IXGBE_MPSAR_LO(rar));
 	mpsar_hi = IXGBE_READ_REG(hw, IXGBE_MPSAR_HI(rar));
 
+	if (IXGBE_REMOVED(hw->hw_addr))
+		goto done;
+
 	if (!mpsar_lo && !mpsar_hi)
 		goto done;
 
@@ -3062,7 +3833,8 @@ int32_t ixgbe_clear_vmdq_generic(struct 
 	}
 
 	/* was that the last pool using this rar? */
-	if (mpsar_lo == 0 && mpsar_hi == 0 && rar != 0)
+	if (mpsar_lo == 0 && mpsar_hi == 0 &&
+	    rar != 0 && rar != hw->mac.san_mac_rar_index)
 		hw->mac.ops.clear_rar(hw, rar);
 done:
 	return IXGBE_SUCCESS;
@@ -3101,6 +3873,33 @@ int32_t ixgbe_set_vmdq_generic(struct ix
 }
 
 /**
+ *  This function should only be involved in the IOV mode.
+ *  In IOV mode, Default pool is next pool after the number of
+ *  VFs advertized and not 0.
+ *  MPSAR table needs to be updated for SAN_MAC RAR [hw->mac.san_mac_rar_index]
+ *
+ *  ixgbe_set_vmdq_san_mac - Associate default VMDq pool index with a rx address
+ *  @hw: pointer to hardware struct
+ *  @vmdq: VMDq pool index
+ **/
+int32_t ixgbe_set_vmdq_san_mac_generic(struct ixgbe_hw *hw, uint32_t vmdq)
+{
+	uint32_t rar = hw->mac.san_mac_rar_index;
+
+	DEBUGFUNC("ixgbe_set_vmdq_san_mac");
+
+	if (vmdq < 32) {
+		IXGBE_WRITE_REG(hw, IXGBE_MPSAR_LO(rar), 1 << vmdq);
+		IXGBE_WRITE_REG(hw, IXGBE_MPSAR_HI(rar), 0);
+	} else {
+		IXGBE_WRITE_REG(hw, IXGBE_MPSAR_LO(rar), 0);
+		IXGBE_WRITE_REG(hw, IXGBE_MPSAR_HI(rar), 1 << (vmdq - 32));
+	}
+
+	return IXGBE_SUCCESS;
+}
+
+/**
  *  ixgbe_init_uta_tables_generic - Initialize the Unicast Table Array
  *  @hw: pointer to hardware structure
  **/
@@ -3121,72 +3920,72 @@ int32_t ixgbe_init_uta_tables_generic(st
  *  ixgbe_find_vlvf_slot - find the vlanid or the first empty slot
  *  @hw: pointer to hardware structure
  *  @vlan: VLAN id to write to VLAN filter
+ *  @vlvf_bypass: TRUE to find vlanid only, FALSE returns first empty slot if
+ *		  vlanid not found
+ *
  *
  *  return the VLVF index where this VLAN id should be placed
  *
  **/
-int32_t ixgbe_find_vlvf_slot(struct ixgbe_hw *hw, uint32_t vlan)
+int32_t ixgbe_find_vlvf_slot(struct ixgbe_hw *hw, uint32_t vlan, bool vlvf_bypass)
 {
-	uint32_t bits = 0;
-	uint32_t first_empty_slot = 0;
-	int32_t regindex;
+	int32_t regindex, first_empty_slot;
+	uint32_t bits;
 
 	/* short cut the special case */
 	if (vlan == 0)
 		return 0;
 
-	/*
-	  * Search for the vlan id in the VLVF entries. Save off the first empty
-	  * slot found along the way
-	  */
-	for (regindex = 1; regindex < IXGBE_VLVF_ENTRIES; regindex++) {
+	/* if vlvf_bypass is set we don't want to use an empty slot, we
+	 * will simply bypass the VLVF if there are no entries present in the
+	 * VLVF that contain our VLAN
+	 */
+	first_empty_slot = vlvf_bypass ? IXGBE_ERR_NO_SPACE : 0;
+
+	/* add VLAN enable bit for comparison */
+	vlan |= IXGBE_VLVF_VIEN;
+
+	/* Search for the vlan id in the VLVF entries. Save off the first empty
+	 * slot found along the way.
+	 *
+	 * pre-decrement loop covering (IXGBE_VLVF_ENTRIES - 1) .. 1
+	 */
+	for (regindex = IXGBE_VLVF_ENTRIES; --regindex;) {
 		bits = IXGBE_READ_REG(hw, IXGBE_VLVF(regindex));
-		if (!bits && !(first_empty_slot))
+		if (bits == vlan)
+			return regindex;
+		if (!first_empty_slot && !bits)
 			first_empty_slot = regindex;
-		else if ((bits & 0x0FFF) == vlan)
-			break;
 	}
 
-	/*
-	  * If regindex is less than IXGBE_VLVF_ENTRIES, then we found the vlan
-	  * in the VLVF. Else use the first empty VLVF register for this
-	  * vlan id.
-	  */
-	if (regindex >= IXGBE_VLVF_ENTRIES) {
-		if (first_empty_slot)
-			regindex = first_empty_slot;
-		else {
-			ERROR_REPORT1(IXGBE_ERROR_SOFTWARE,
-				     "No space in VLVF.\n");
-			regindex = IXGBE_ERR_NO_SPACE;
-		}
-	}
+	/* If we are here then we didn't find the VLAN.  Return first empty
+	 * slot we found during our search, else error.
+	 */
+	if (!first_empty_slot)
+		ERROR_REPORT1(IXGBE_ERROR_SOFTWARE, "No space in VLVF.\n");
 
-	return regindex;
+	return first_empty_slot ? first_empty_slot : IXGBE_ERR_NO_SPACE;
 }
 
 /**
  *  ixgbe_set_vfta_generic - Set VLAN filter table
  *  @hw: pointer to hardware structure
  *  @vlan: VLAN id to write to VLAN filter
- *  @vind: VMDq output index that maps queue to VLAN id in VFVFB
- *  @vlan_on: boolean flag to turn on/off VLAN in VFVF
+ *  @vind: VMDq output index that maps queue to VLAN id in VLVFB
+ *  @vlan_on: boolean flag to turn on/off VLAN
+ *  @vlvf_bypass: boolean flag indicating updating default pool is okay
  *
  *  Turn on/off specified VLAN in the VLAN filter table.
  **/
 int32_t ixgbe_set_vfta_generic(struct ixgbe_hw *hw, uint32_t vlan, uint32_t vind,
-			       bool vlan_on)
+			   bool vlan_on, bool vlvf_bypass)
 {
-	int32_t regindex;
-	uint32_t bitindex;
-	uint32_t vfta;
-	uint32_t targetbit;
-	int32_t ret_val = IXGBE_SUCCESS;
-	bool vfta_changed = FALSE;
+	uint32_t regidx, vfta_delta, vfta;
+	int32_t ret_val;
 
 	DEBUGFUNC("ixgbe_set_vfta_generic");
 
-	if (vlan > 4095)
+	if (vlan > 4095 || vind > 63)
 		return IXGBE_ERR_PARAM;
 
 	/*
@@ -3201,33 +4000,33 @@ int32_t ixgbe_set_vfta_generic(struct ix
 	 *    bits[11-5]: which register
 	 *    bits[4-0]:  which bit in the register
 	 */
-	regindex = (vlan >> 5) & 0x7F;
-	bitindex = vlan & 0x1F;
-	targetbit = (1 << bitindex);
-	vfta = IXGBE_READ_REG(hw, IXGBE_VFTA(regindex));
-
-	if (vlan_on) {
-		if (!(vfta & targetbit)) {
-			vfta |= targetbit;
-			vfta_changed = TRUE;
-		}
-	} else {
-		if ((vfta & targetbit)) {
-			vfta &= ~targetbit;
-			vfta_changed = TRUE;
-		}
-	}
+	regidx = vlan / 32;
+	vfta_delta = 1 << (vlan % 32);
+	vfta = IXGBE_READ_REG(hw, IXGBE_VFTA(regidx));
+
+	/*
+	 * vfta_delta represents the difference between the current value
+	 * of vfta and the value we want in the register.  Since the diff
+	 * is an XOR mask we can just update the vfta using an XOR
+	 */
+	vfta_delta &= vlan_on ? ~vfta : vfta;
+	vfta ^= vfta_delta;
 
 	/* Part 2
 	 * Call ixgbe_set_vlvf_generic to set VLVFB and VLVF
 	 */
-	ret_val = ixgbe_set_vlvf_generic(hw, vlan, vind, vlan_on,
-					 &vfta_changed);
-	if (ret_val != IXGBE_SUCCESS)
+	ret_val = ixgbe_set_vlvf_generic(hw, vlan, vind, vlan_on, &vfta_delta,
+					 vfta, vlvf_bypass);
+	if (ret_val != IXGBE_SUCCESS) {
+		if (vlvf_bypass)
+			goto vfta_update;
 		return ret_val;
+	}
 
-	if (vfta_changed)
-		IXGBE_WRITE_REG(hw, IXGBE_VFTA(regindex), vfta);
+vfta_update:
+	/* Update VFTA now that we are ready for traffic */
+	if (vfta_delta)
+		IXGBE_WRITE_REG(hw, IXGBE_VFTA(regidx), vfta);
 
 	return IXGBE_SUCCESS;
 }
@@ -3236,21 +4035,25 @@ int32_t ixgbe_set_vfta_generic(struct ix
  *  ixgbe_set_vlvf_generic - Set VLAN Pool Filter
  *  @hw: pointer to hardware structure
  *  @vlan: VLAN id to write to VLAN filter
- *  @vind: VMDq output index that maps queue to VLAN id in VFVFB
- *  @vlan_on: boolean flag to turn on/off VLAN in VFVF
- *  @vfta_changed: pointer to boolean flag which indicates whether VFTA
- *                 should be changed
+ *  @vind: VMDq output index that maps queue to VLAN id in VLVFB
+ *  @vlan_on: boolean flag to turn on/off VLAN in VLVF
+ *  @vfta_delta: pointer to the difference between the current value of VFTA
+ *		 and the desired value
+ *  @vfta: the desired value of the VFTA
+ *  @vlvf_bypass: boolean flag indicating updating default pool is okay
  *
  *  Turn on/off specified bit in VLVF table.
  **/
 int32_t ixgbe_set_vlvf_generic(struct ixgbe_hw *hw, uint32_t vlan, uint32_t vind,
-			       bool vlan_on, bool *vfta_changed)
+			   bool vlan_on, uint32_t *vfta_delta, uint32_t vfta,
+			   bool vlvf_bypass)
 {
-	uint32_t vt;
+	uint32_t bits;
+	int32_t vlvf_index;
 
 	DEBUGFUNC("ixgbe_set_vlvf_generic");
 
-	if (vlan > 4095)
+	if (vlan > 4095 || vind > 63)
 		return IXGBE_ERR_PARAM;
 
 	/* If VT Mode is set
@@ -3260,83 +4063,60 @@ int32_t ixgbe_set_vlvf_generic(struct ix
 	 *   Or !vlan_on
 	 *     clear the pool bit and possibly the vind
 	 */
-	vt = IXGBE_READ_REG(hw, IXGBE_VT_CTL);
-	if (vt & IXGBE_VT_CTL_VT_ENABLE) {
-		int32_t vlvf_index;
-		uint32_t bits;
-
-		vlvf_index = ixgbe_find_vlvf_slot(hw, vlan);
-		if (vlvf_index < 0)
-			return vlvf_index;
-
-		if (vlan_on) {
-			/* set the pool bit */
-			if (vind < 32) {
-				bits = IXGBE_READ_REG(hw,
-						IXGBE_VLVFB(vlvf_index * 2));
-				bits |= (1 << vind);
-				IXGBE_WRITE_REG(hw,
-						IXGBE_VLVFB(vlvf_index * 2),
-						bits);
-			} else {
-				bits = IXGBE_READ_REG(hw,
-					IXGBE_VLVFB((vlvf_index * 2) + 1));
-				bits |= (1 << (vind - 32));
-				IXGBE_WRITE_REG(hw,
-					IXGBE_VLVFB((vlvf_index * 2) + 1),
-					bits);
-			}
-		} else {
-			/* clear the pool bit */
-			if (vind < 32) {
-				bits = IXGBE_READ_REG(hw,
-						IXGBE_VLVFB(vlvf_index * 2));
-				bits &= ~(1 << vind);
-				IXGBE_WRITE_REG(hw,
-						IXGBE_VLVFB(vlvf_index * 2),
-						bits);
-				bits |= IXGBE_READ_REG(hw,
-					IXGBE_VLVFB((vlvf_index * 2) + 1));
-			} else {
-				bits = IXGBE_READ_REG(hw,
-					IXGBE_VLVFB((vlvf_index * 2) + 1));
-				bits &= ~(1 << (vind - 32));
-				IXGBE_WRITE_REG(hw,
-					IXGBE_VLVFB((vlvf_index * 2) + 1),
-					bits);
-				bits |= IXGBE_READ_REG(hw,
-						IXGBE_VLVFB(vlvf_index * 2));
-			}
-		}
+	if (!(IXGBE_READ_REG(hw, IXGBE_VT_CTL) & IXGBE_VT_CTL_VT_ENABLE))
+		return IXGBE_SUCCESS;
 
-		/*
-		 * If there are still bits set in the VLVFB registers
-		 * for the VLAN ID indicated we need to see if the
-		 * caller is requesting that we clear the VFTA entry bit.
-		 * If the caller has requested that we clear the VFTA
-		 * entry bit but there are still pools/VFs using this VLAN
-		 * ID entry then ignore the request.  We're not worried
-		 * about the case where we're turning the VFTA VLAN ID
-		 * entry bit on, only when requested to turn it off as
-		 * there may be multiple pools and/or VFs using the
-		 * VLAN ID entry.  In that case we cannot clear the
-		 * VFTA bit until all pools/VFs using that VLAN ID have also
-		 * been cleared.  This will be indicated by "bits" being
-		 * zero.
+	vlvf_index = ixgbe_find_vlvf_slot(hw, vlan, vlvf_bypass);
+	if (vlvf_index < 0)
+		return vlvf_index;
+
+	bits = IXGBE_READ_REG(hw, IXGBE_VLVFB(vlvf_index * 2 + vind / 32));
+
+	/* set the pool bit */
+	bits |= 1 << (vind % 32);
+	if (vlan_on)
+		goto vlvf_update;
+
+	/* clear the pool bit */
+	bits ^= 1 << (vind % 32);
+
+	if (!bits &&
+	    !IXGBE_READ_REG(hw, IXGBE_VLVFB(vlvf_index * 2 + 1 - vind / 32))) {
+		/* Clear VFTA first, then disable VLVF.  Otherwise
+		 * we run the risk of stray packets leaking into
+		 * the PF via the default pool
 		 */
-		if (bits) {
-			IXGBE_WRITE_REG(hw, IXGBE_VLVF(vlvf_index),
-					(IXGBE_VLVF_VIEN | vlan));
-			if ((!vlan_on) && (vfta_changed != NULL)) {
-				/* someone wants to clear the vfta entry
-				 * but some pools/VFs are still using it.
-				 * Ignore it. */
-				*vfta_changed = FALSE;
-			}
-		} else
-			IXGBE_WRITE_REG(hw, IXGBE_VLVF(vlvf_index), 0);
+		if (*vfta_delta)
+			IXGBE_WRITE_REG(hw, IXGBE_VFTA(vlan / 32), vfta);
+
+		/* disable VLVF and clear remaining bit from pool */
+		IXGBE_WRITE_REG(hw, IXGBE_VLVF(vlvf_index), 0);
+		IXGBE_WRITE_REG(hw, IXGBE_VLVFB(vlvf_index * 2 + vind / 32), 0);
+
+		return IXGBE_SUCCESS;
 	}
 
+	/* If there are still bits set in the VLVFB registers
+	 * for the VLAN ID indicated we need to see if the
+	 * caller is requesting that we clear the VFTA entry bit.
+	 * If the caller has requested that we clear the VFTA
+	 * entry bit but there are still pools/VFs using this VLAN
+	 * ID entry then ignore the request.  We're not worried
+	 * about the case where we're turning the VFTA VLAN ID
+	 * entry bit on, only when requested to turn it off as
+	 * there may be multiple pools and/or VFs using the
+	 * VLAN ID entry.  In that case we cannot clear the
+	 * VFTA bit until all pools/VFs using that VLAN ID have also
+	 * been cleared.  This will be indicated by "bits" being
+	 * zero.
+	 */
+	*vfta_delta = 0;
+
+vlvf_update:
+	/* record pool change and enable VLAN ID if not already enabled */
+	IXGBE_WRITE_REG(hw, IXGBE_VLVFB(vlvf_index * 2 + vind / 32), bits);
+	IXGBE_WRITE_REG(hw, IXGBE_VLVF(vlvf_index), IXGBE_VLVF_VIEN | vlan);
+
 	return IXGBE_SUCCESS;
 }
 
@@ -3365,6 +4145,32 @@ int32_t ixgbe_clear_vfta_generic(struct 
 }
 
 /**
+ *  ixgbe_need_crosstalk_fix - Determine if we need to do cross talk fix
+ *  @hw: pointer to hardware structure
+ *
+ *  Contains the logic to identify if we need to verify link for the
+ *  crosstalk fix
+ **/
+bool ixgbe_need_crosstalk_fix(struct ixgbe_hw *hw)
+{
+
+	/* Does FW say we need the fix */
+	if (!hw->need_crosstalk_fix)
+		return FALSE;
+
+	/* Only consider SFP+ PHYs i.e. media type fiber */
+	switch (hw->mac.ops.get_media_type(hw)) {
+	case ixgbe_media_type_fiber:
+	case ixgbe_media_type_fiber_qsfp:
+		break;
+	default:
+		return FALSE;
+	}
+
+	return TRUE;
+}
+
+/**
  *  ixgbe_check_mac_link_generic - Determine link and speed status
  *  @hw: pointer to hardware structure
  *  @speed: pointer to link speed
@@ -3374,13 +4180,42 @@ int32_t ixgbe_clear_vfta_generic(struct 
  *  Reads the links register to determine if link is up and the current speed
  **/
 int32_t ixgbe_check_mac_link_generic(struct ixgbe_hw *hw, ixgbe_link_speed *speed,
-				     bool *link_up, bool link_up_wait_to_complete)
+				 bool *link_up, bool link_up_wait_to_complete)
 {
 	uint32_t links_reg, links_orig;
 	uint32_t i;
 
 	DEBUGFUNC("ixgbe_check_mac_link_generic");
 
+	/* If Crosstalk fix enabled do the sanity check of making sure
+	 * the SFP+ cage is full.
+	 */
+	if (ixgbe_need_crosstalk_fix(hw)) {
+		uint32_t sfp_cage_full;
+
+		switch (hw->mac.type) {
+		case ixgbe_mac_82599EB:
+			sfp_cage_full = IXGBE_READ_REG(hw, IXGBE_ESDP) &
+					IXGBE_ESDP_SDP2;
+			break;
+		case ixgbe_mac_X550EM_x:
+		case ixgbe_mac_X550EM_a:
+			sfp_cage_full = IXGBE_READ_REG(hw, IXGBE_ESDP) &
+					IXGBE_ESDP_SDP0;
+			break;
+		default:
+			/* sanity check - No SFP+ devices here */
+			sfp_cage_full = FALSE;
+			break;
+		}
+
+		if (!sfp_cage_full) {
+			*link_up = FALSE;
+			*speed = IXGBE_LINK_SPEED_UNKNOWN;
+			return IXGBE_SUCCESS;
+		}
+	}
+
 	/* clear the old state */
 	links_orig = IXGBE_READ_REG(hw, IXGBE_LINKS);
 
@@ -3422,11 +4257,17 @@ int32_t ixgbe_check_mac_link_generic(str
 		break;
 	case IXGBE_LINKS_SPEED_100_82599:
 		*speed = IXGBE_LINK_SPEED_100_FULL;
-		if (hw->mac.type >= ixgbe_mac_X550) {
+		if (hw->mac.type == ixgbe_mac_X550) {
 			if (links_reg & IXGBE_LINKS_SPEED_NON_STD)
 				*speed = IXGBE_LINK_SPEED_5GB_FULL;
 		}
 		break;
+	case IXGBE_LINKS_SPEED_10_X550EM_A:
+		*speed = IXGBE_LINK_SPEED_UNKNOWN;
+		if (hw->device_id == IXGBE_DEV_ID_X550EM_A_1G_T ||
+		    hw->device_id == IXGBE_DEV_ID_X550EM_A_1G_T_L)
+			*speed = IXGBE_LINK_SPEED_10_FULL;
+		break;
 	default:
 		*speed = IXGBE_LINK_SPEED_UNKNOWN;
 	}
@@ -3435,67 +4276,268 @@ int32_t ixgbe_check_mac_link_generic(str
 }
 
 /**
- *  ixgbe_get_device_caps_generic - Get additional device capabilities
+ *  ixgbe_get_wwn_prefix_generic - Get alternative WWNN/WWPN prefix from
+ *  the EEPROM
  *  @hw: pointer to hardware structure
- *  @device_caps: the EEPROM word with the extra device capabilities
+ *  @wwnn_prefix: the alternative WWNN prefix
+ *  @wwpn_prefix: the alternative WWPN prefix
  *
- *  This function will read the EEPROM location for the device capabilities,
- *  and return the word through device_caps.
+ *  This function will read the EEPROM from the alternative SAN MAC address
+ *  block to check the support for the alternative WWNN/WWPN prefix support.
  **/
-int32_t ixgbe_get_device_caps_generic(struct ixgbe_hw *hw, uint16_t *device_caps)
+int32_t ixgbe_get_wwn_prefix_generic(struct ixgbe_hw *hw, uint16_t *wwnn_prefix,
+				 uint16_t *wwpn_prefix)
 {
-	DEBUGFUNC("ixgbe_get_device_caps_generic");
+	uint16_t offset, caps;
+	uint16_t alt_san_mac_blk_offset;
 
-	hw->eeprom.ops.read(hw, IXGBE_DEVICE_CAPS, device_caps);
+	DEBUGFUNC("ixgbe_get_wwn_prefix_generic");
+
+	/* clear output first */
+	*wwnn_prefix = 0xFFFF;
+	*wwpn_prefix = 0xFFFF;
+
+	/* check if alternative SAN MAC is supported */
+	offset = IXGBE_ALT_SAN_MAC_ADDR_BLK_PTR;
+	if (hw->eeprom.ops.read(hw, offset, &alt_san_mac_blk_offset))
+		goto wwn_prefix_err;
+
+	if ((alt_san_mac_blk_offset == 0) ||
+	    (alt_san_mac_blk_offset == 0xFFFF))
+		goto wwn_prefix_out;
+
+	/* check capability in alternative san mac address block */
+	offset = alt_san_mac_blk_offset + IXGBE_ALT_SAN_MAC_ADDR_CAPS_OFFSET;
+	if (hw->eeprom.ops.read(hw, offset, &caps))
+		goto wwn_prefix_err;
+	if (!(caps & IXGBE_ALT_SAN_MAC_ADDR_CAPS_ALTWWN))
+		goto wwn_prefix_out;
+
+	/* get the corresponding prefix for WWNN/WWPN */
+	offset = alt_san_mac_blk_offset + IXGBE_ALT_SAN_MAC_ADDR_WWNN_OFFSET;
+	if (hw->eeprom.ops.read(hw, offset, wwnn_prefix)) {
+		ERROR_REPORT2(IXGBE_ERROR_INVALID_STATE,
+			      "eeprom read at offset %d failed", offset);
+	}
+
+	offset = alt_san_mac_blk_offset + IXGBE_ALT_SAN_MAC_ADDR_WWPN_OFFSET;
+	if (hw->eeprom.ops.read(hw, offset, wwpn_prefix))
+		goto wwn_prefix_err;
 
+wwn_prefix_out:
+	return IXGBE_SUCCESS;
+
+wwn_prefix_err:
+	ERROR_REPORT2(IXGBE_ERROR_INVALID_STATE,
+		      "eeprom read at offset %d failed", offset);
 	return IXGBE_SUCCESS;
 }
 
 /**
- *  ixgbe_host_interface_command - Issue command to manageability block
- *  @hw: pointer to the HW structure
- *  @buffer: contains the command to write and where the return status will
- *   be placed
- *  @length: length of buffer, must be multiple of 4 bytes
- *  @timeout: time in ms to wait for command completion
- *  @return_data: read and return data from the buffer (TRUE) or not (FALSE)
- *   Needed because FW structures are big endian and decoding of
- *   these fields can be 8 bit or 16 bit based on command. Decoding
- *   is not easily understood without making a table of commands.
- *   So we will leave this up to the caller to read back the data
- *   in these cases.
+ *  ixgbe_get_fcoe_boot_status_generic - Get FCOE boot status from EEPROM
+ *  @hw: pointer to hardware structure
+ *  @bs: the fcoe boot status
  *
- *  Communicates with the manageability block.  On success return IXGBE_SUCCESS
- *  else return IXGBE_ERR_HOST_INTERFACE_COMMAND.
+ *  This function will read the FCOE boot status from the iSCSI FCOE block
  **/
-int32_t ixgbe_host_interface_command(struct ixgbe_hw *hw, uint32_t *buffer,
-				     uint32_t length, uint32_t timeout,
-				     bool return_data)
+int32_t ixgbe_get_fcoe_boot_status_generic(struct ixgbe_hw *hw, uint16_t *bs)
 {
-	uint32_t hicr, i, bi, fwsts;
-	uint32_t hdr_size = sizeof(struct ixgbe_hic_hdr);
-	uint16_t buf_len;
+	uint16_t offset, caps, flags;
+	int32_t status;
+
+	DEBUGFUNC("ixgbe_get_fcoe_boot_status_generic");
+
+	/* clear output first */
+	*bs = ixgbe_fcoe_bootstatus_unavailable;
+
+	/* check if FCOE IBA block is present */
+	offset = IXGBE_FCOE_IBA_CAPS_BLK_PTR;
+	status = hw->eeprom.ops.read(hw, offset, &caps);
+	if (status != IXGBE_SUCCESS)
+		goto out;
+
+	if (!(caps & IXGBE_FCOE_IBA_CAPS_FCOE))
+		goto out;
+
+	/* check if iSCSI FCOE block is populated */
+	status = hw->eeprom.ops.read(hw, IXGBE_ISCSI_FCOE_BLK_PTR, &offset);
+	if (status != IXGBE_SUCCESS)
+		goto out;
+
+	if ((offset == 0) || (offset == 0xFFFF))
+		goto out;
+
+	/* read fcoe flags in iSCSI FCOE block */
+	offset = offset + IXGBE_ISCSI_FCOE_FLAGS_OFFSET;
+	status = hw->eeprom.ops.read(hw, offset, &flags);
+	if (status != IXGBE_SUCCESS)
+		goto out;
+
+	if (flags & IXGBE_ISCSI_FCOE_FLAGS_ENABLE)
+		*bs = ixgbe_fcoe_bootstatus_enabled;
+	else
+		*bs = ixgbe_fcoe_bootstatus_disabled;
+
+out:
+	return status;
+}
+
+/**
+ *  ixgbe_set_mac_anti_spoofing - Enable/Disable MAC anti-spoofing
+ *  @hw: pointer to hardware structure
+ *  @enable: enable or disable switch for MAC anti-spoofing
+ *  @vf: Virtual Function pool - VF Pool to set for MAC anti-spoofing
+ *
+ **/
+void ixgbe_set_mac_anti_spoofing(struct ixgbe_hw *hw, bool enable, int vf)
+{
+	int vf_target_reg = vf >> 3;
+	int vf_target_shift = vf % 8;
+	uint32_t pfvfspoof;
+
+	if (hw->mac.type == ixgbe_mac_82598EB)
+		return;
+
+	pfvfspoof = IXGBE_READ_REG(hw, IXGBE_PFVFSPOOF(vf_target_reg));
+	if (enable)
+		pfvfspoof |= (1 << vf_target_shift);
+	else
+		pfvfspoof &= ~(1 << vf_target_shift);
+	IXGBE_WRITE_REG(hw, IXGBE_PFVFSPOOF(vf_target_reg), pfvfspoof);
+}
+
+/**
+ *  ixgbe_set_vlan_anti_spoofing - Enable/Disable VLAN anti-spoofing
+ *  @hw: pointer to hardware structure
+ *  @enable: enable or disable switch for VLAN anti-spoofing
+ *  @vf: Virtual Function pool - VF Pool to set for VLAN anti-spoofing
+ *
+ **/
+void ixgbe_set_vlan_anti_spoofing(struct ixgbe_hw *hw, bool enable, int vf)
+{
+	int vf_target_reg = vf >> 3;
+	int vf_target_shift = vf % 8 + IXGBE_SPOOF_VLANAS_SHIFT;
+	uint32_t pfvfspoof;
+
+	if (hw->mac.type == ixgbe_mac_82598EB)
+		return;
+
+	pfvfspoof = IXGBE_READ_REG(hw, IXGBE_PFVFSPOOF(vf_target_reg));
+	if (enable)
+		pfvfspoof |= (1 << vf_target_shift);
+	else
+		pfvfspoof &= ~(1 << vf_target_shift);
+	IXGBE_WRITE_REG(hw, IXGBE_PFVFSPOOF(vf_target_reg), pfvfspoof);
+}
+
+/**
+ *  ixgbe_get_device_caps_generic - Get additional device capabilities
+ *  @hw: pointer to hardware structure
+ *  @device_caps: the EEPROM word with the extra device capabilities
+ *
+ *  This function will read the EEPROM location for the device capabilities,
+ *  and return the word through device_caps.
+ **/
+int32_t ixgbe_get_device_caps_generic(struct ixgbe_hw *hw, uint16_t *device_caps)
+{
+	DEBUGFUNC("ixgbe_get_device_caps_generic");
+
+	hw->eeprom.ops.read(hw, IXGBE_DEVICE_CAPS, device_caps);
+
+	return IXGBE_SUCCESS;
+}
+
+/**
+ *  ixgbe_enable_relaxed_ordering_gen2 - Enable relaxed ordering
+ *  @hw: pointer to hardware structure
+ *
+ **/
+void ixgbe_enable_relaxed_ordering_gen2(struct ixgbe_hw *hw)
+{
+	uint32_t regval;
+	uint32_t i;
+
+	DEBUGFUNC("ixgbe_enable_relaxed_ordering_gen2");
+
+	/* Enable relaxed ordering */
+	for (i = 0; i < hw->mac.max_tx_queues; i++) {
+		regval = IXGBE_READ_REG(hw, IXGBE_DCA_TXCTRL_82599(i));
+		regval |= IXGBE_DCA_TXCTRL_DESC_WRO_EN;
+		IXGBE_WRITE_REG(hw, IXGBE_DCA_TXCTRL_82599(i), regval);
+	}
+
+	for (i = 0; i < hw->mac.max_rx_queues; i++) {
+		regval = IXGBE_READ_REG(hw, IXGBE_DCA_RXCTRL(i));
+		regval |= IXGBE_DCA_RXCTRL_DATA_WRO_EN |
+			  IXGBE_DCA_RXCTRL_HEAD_WRO_EN;
+		IXGBE_WRITE_REG(hw, IXGBE_DCA_RXCTRL(i), regval);
+	}
+
+}
+
+/**
+ *  ixgbe_calculate_checksum - Calculate checksum for buffer
+ *  @buffer: pointer to EEPROM
+ *  @length: size of EEPROM to calculate a checksum for
+ *  Calculates the checksum for some buffer on a specified length.  The
+ *  checksum calculated is returned.
+ **/
+uint8_t ixgbe_calculate_checksum(uint8_t *buffer, uint32_t length)
+{
+	uint32_t i;
+	uint8_t sum = 0;
+
+	DEBUGFUNC("ixgbe_calculate_checksum");
+
+	if (!buffer)
+		return 0;
+
+	for (i = 0; i < length; i++)
+		sum += buffer[i];
+
+	return (uint8_t) (0 - sum);
+}
+
+/**
+ *  ixgbe_hic_unlocked - Issue command to manageability block unlocked
+ *  @hw: pointer to the HW structure
+ *  @buffer: command to write and where the return status will be placed
+ *  @length: length of buffer, must be multiple of 4 bytes
+ *  @timeout: time in ms to wait for command completion
+ *
+ *  Communicates with the manageability block. On success return IXGBE_SUCCESS
+ *  else returns semaphore error when encountering an error acquiring
+ *  semaphore or IXGBE_ERR_HOST_INTERFACE_COMMAND when command fails.
+ *
+ *  This function assumes that the IXGBE_GSSR_SW_MNG_SM semaphore is held
+ *  by the caller.
+ **/
+int32_t ixgbe_hic_unlocked(struct ixgbe_hw *hw, uint32_t *buffer, uint32_t length,
+		       uint32_t timeout)
+{
+	uint32_t hicr, i, fwsts;
 	uint16_t dword_len;
 
-	DEBUGFUNC("ixgbe_host_interface_command");
+	DEBUGFUNC("ixgbe_hic_unlocked");
 
-	if (length == 0 || length > IXGBE_HI_MAX_BLOCK_BYTE_LENGTH) {
+	if (!length || length > IXGBE_HI_MAX_BLOCK_BYTE_LENGTH) {
 		DEBUGOUT1("Buffer length failure buffersize=%d.\n", length);
 		return IXGBE_ERR_HOST_INTERFACE_COMMAND;
 	}
+
 	/* Set bit 9 of FWSTS clearing FW reset indication */
 	fwsts = IXGBE_READ_REG(hw, IXGBE_FWSTS);
 	IXGBE_WRITE_REG(hw, IXGBE_FWSTS, fwsts | IXGBE_FWSTS_FWRI);
 
 	/* Check that the host interface is enabled. */
 	hicr = IXGBE_READ_REG(hw, IXGBE_HICR);
-	if ((hicr & IXGBE_HICR_EN) == 0) {
+	if (!(hicr & IXGBE_HICR_EN)) {
 		DEBUGOUT("IXGBE_HOST_EN bit disabled.\n");
 		return IXGBE_ERR_HOST_INTERFACE_COMMAND;
 	}
 
 	/* Calculate length in DWORDs. We must be DWORD aligned */
-	if ((length % (sizeof(uint32_t))) != 0) {
+	if (length % sizeof(uint32_t)) {
 		DEBUGOUT("Buffer length failure, not aligned to dword");
 		return IXGBE_ERR_INVALID_ARGUMENT;
 	}
@@ -3507,7 +4549,7 @@ int32_t ixgbe_host_interface_command(str
 	 */
 	for (i = 0; i < dword_len; i++)
 		IXGBE_WRITE_REG_ARRAY(hw, IXGBE_FLEX_MNG,
-				      i, htole32(buffer[i]));
+				      i, IXGBE_CPU_TO_LE32(buffer[i]));
 
 	/* Setting this bit tells the ARC that a new command is pending. */
 	IXGBE_WRITE_REG(hw, IXGBE_HICR, hicr | IXGBE_HICR_C);
@@ -3520,32 +4562,96 @@ int32_t ixgbe_host_interface_command(str
 	}
 
 	/* Check command completion */
-	if ((timeout != 0 && i == timeout) ||
+	if ((timeout && i == timeout) ||
 	    !(IXGBE_READ_REG(hw, IXGBE_HICR) & IXGBE_HICR_SV)) {
-		DEBUGOUT("Command has failed with no status valid.\n");
+		ERROR_REPORT1(IXGBE_ERROR_CAUTION,
+			     "Command has failed with no status valid.\n");
+		return IXGBE_ERR_HOST_INTERFACE_COMMAND;
+	}
+
+	return IXGBE_SUCCESS;
+}
+
+/**
+ *  ixgbe_host_interface_command - Issue command to manageability block
+ *  @hw: pointer to the HW structure
+ *  @buffer: contains the command to write and where the return status will
+ *   be placed
+ *  @length: length of buffer, must be multiple of 4 bytes
+ *  @timeout: time in ms to wait for command completion
+ *  @return_data: read and return data from the buffer (TRUE) or not (FALSE)
+ *   Needed because FW structures are big endian and decoding of
+ *   these fields can be 8 bit or 16 bit based on command. Decoding
+ *   is not easily understood without making a table of commands.
+ *   So we will leave this up to the caller to read back the data
+ *   in these cases.
+ *
+ *  Communicates with the manageability block. On success return IXGBE_SUCCESS
+ *  else returns semaphore error when encountering an error acquiring
+ *  semaphore or IXGBE_ERR_HOST_INTERFACE_COMMAND when command fails.
+ **/
+int32_t ixgbe_host_interface_command(struct ixgbe_hw *hw, uint32_t *buffer,
+				 uint32_t length, uint32_t timeout, bool return_data)
+{
+	uint32_t hdr_size = sizeof(struct ixgbe_hic_hdr);
+	struct ixgbe_hic_hdr *resp = (struct ixgbe_hic_hdr *)buffer;
+	uint16_t buf_len;
+	int32_t status;
+	uint32_t bi;
+	uint32_t dword_len;
+
+	DEBUGFUNC("ixgbe_host_interface_command");
+
+	if (length == 0 || length > IXGBE_HI_MAX_BLOCK_BYTE_LENGTH) {
+		DEBUGOUT1("Buffer length failure buffersize=%d.\n", length);
 		return IXGBE_ERR_HOST_INTERFACE_COMMAND;
 	}
 
+	/* Take management host interface semaphore */
+	status = hw->mac.ops.acquire_swfw_sync(hw, IXGBE_GSSR_SW_MNG_SM);
+	if (status)
+		return status;
+
+	status = ixgbe_hic_unlocked(hw, buffer, length, timeout);
+	if (status)
+		goto rel_out;
+
 	if (!return_data)
-		return 0;
+		goto rel_out;
 
 	/* Calculate length in DWORDs */
 	dword_len = hdr_size >> 2;
 
 	/* first pull in the header so we know the buffer length */
 	for (bi = 0; bi < dword_len; bi++) {
-		buffer[bi] = letoh32(IXGBE_READ_REG_ARRAY(hw,
-		    IXGBE_FLEX_MNG, bi));
+		buffer[bi] = IXGBE_READ_REG_ARRAY(hw, IXGBE_FLEX_MNG, bi);
+		IXGBE_LE32_TO_CPUS(&buffer[bi]);
 	}
 
-	/* If there is any thing in data position pull it in */
-	buf_len = ((struct ixgbe_hic_hdr *)buffer)->buf_len;
-	if (buf_len == 0)
-		return 0;
+	/*
+	 * If there is any thing in data position pull it in
+	 * Read Flash command requires reading buffer length from
+	 * two byes instead of one byte
+	 */
+	if (resp->cmd == 0x30) {
+		for (; bi < dword_len + 2; bi++) {
+			buffer[bi] = IXGBE_READ_REG_ARRAY(hw, IXGBE_FLEX_MNG,
+							  bi);
+			IXGBE_LE32_TO_CPUS(&buffer[bi]);
+		}
+		buf_len = (((uint16_t)(resp->cmd_or_resp.ret_status) << 3)
+				  & 0xF00) | resp->buf_len;
+		hdr_size += (2 << 2);
+	} else {
+		buf_len = resp->buf_len;
+	}
+	if (!buf_len)
+		goto rel_out;
 
 	if (length < buf_len + hdr_size) {
 		DEBUGOUT("Buffer not large enough for reply message.\n");
-		return IXGBE_ERR_HOST_INTERFACE_COMMAND;
+		status = IXGBE_ERR_HOST_INTERFACE_COMMAND;
+		goto rel_out;
 	}
 
 	/* Calculate length in DWORDs, add 3 for odd lengths */
@@ -3553,11 +4659,132 @@ int32_t ixgbe_host_interface_command(str
 
 	/* Pull in the rest of the buffer (bi is where we left off) */
 	for (; bi <= dword_len; bi++) {
-		buffer[bi] = letoh32(IXGBE_READ_REG_ARRAY(hw,
-		    IXGBE_FLEX_MNG, bi));
+		buffer[bi] = IXGBE_READ_REG_ARRAY(hw, IXGBE_FLEX_MNG, bi);
+		IXGBE_LE32_TO_CPUS(&buffer[bi]);
+	}
+
+rel_out:
+	hw->mac.ops.release_swfw_sync(hw, IXGBE_GSSR_SW_MNG_SM);
+
+	return status;
+}
+
+/**
+ *  ixgbe_set_fw_drv_ver_generic - Sends driver version to firmware
+ *  @hw: pointer to the HW structure
+ *  @maj: driver version major number
+ *  @min: driver version minor number
+ *  @build: driver version build number
+ *  @sub: driver version sub build number
+ *  @len: unused
+ *  @driver_ver: unused
+ *
+ *  Sends driver version number to firmware through the manageability
+ *  block.  On success return IXGBE_SUCCESS
+ *  else returns IXGBE_ERR_SWFW_SYNC when encountering an error acquiring
+ *  semaphore or IXGBE_ERR_HOST_INTERFACE_COMMAND when command fails.
+ **/
+int32_t ixgbe_set_fw_drv_ver_generic(struct ixgbe_hw *hw, uint8_t maj, uint8_t min,
+				 uint8_t build, uint8_t sub, UNUSED uint16_t len,
+				 UNUSED const char *driver_ver)
+{
+	struct ixgbe_hic_drv_info fw_cmd;
+	int i;
+	int32_t ret_val = IXGBE_SUCCESS;
+
+	DEBUGFUNC("ixgbe_set_fw_drv_ver_generic");
+
+	fw_cmd.hdr.cmd = FW_CEM_CMD_DRIVER_INFO;
+	fw_cmd.hdr.buf_len = FW_CEM_CMD_DRIVER_INFO_LEN;
+	fw_cmd.hdr.cmd_or_resp.cmd_resv = FW_CEM_CMD_RESERVED;
+	fw_cmd.port_num = (uint8_t)hw->bus.func;
+	fw_cmd.ver_maj = maj;
+	fw_cmd.ver_min = min;
+	fw_cmd.ver_build = build;
+	fw_cmd.ver_sub = sub;
+	fw_cmd.hdr.checksum = 0;
+	fw_cmd.pad = 0;
+	fw_cmd.pad2 = 0;
+	fw_cmd.hdr.checksum = ixgbe_calculate_checksum((uint8_t *)&fw_cmd,
+				(FW_CEM_HDR_LEN + fw_cmd.hdr.buf_len));
+
+	for (i = 0; i <= FW_CEM_MAX_RETRIES; i++) {
+		ret_val = ixgbe_host_interface_command(hw, (uint32_t *)&fw_cmd,
+						       sizeof(fw_cmd),
+						       IXGBE_HI_COMMAND_TIMEOUT,
+						       TRUE);
+		if (ret_val != IXGBE_SUCCESS)
+			continue;
+
+		if (fw_cmd.hdr.cmd_or_resp.ret_status ==
+		    FW_CEM_RESP_STATUS_SUCCESS)
+			ret_val = IXGBE_SUCCESS;
+		else
+			ret_val = IXGBE_ERR_HOST_INTERFACE_COMMAND;
+
+		break;
 	}
 
-	return 0;
+	return ret_val;
+}
+
+/**
+ * ixgbe_set_rxpba_generic - Initialize Rx packet buffer
+ * @hw: pointer to hardware structure
+ * @num_pb: number of packet buffers to allocate
+ * @headroom: reserve n KB of headroom
+ * @strategy: packet buffer allocation strategy
+ **/
+void ixgbe_set_rxpba_generic(struct ixgbe_hw *hw, int num_pb, uint32_t headroom,
+			     int strategy)
+{
+	uint32_t pbsize = hw->mac.rx_pb_size;
+	int i = 0;
+	uint32_t rxpktsize, txpktsize, txpbthresh;
+
+	/* Reserve headroom */
+	pbsize -= headroom;
+
+	if (!num_pb)
+		num_pb = 1;
+
+	/* Divide remaining packet buffer space amongst the number of packet
+	 * buffers requested using supplied strategy.
+	 */
+	switch (strategy) {
+	case PBA_STRATEGY_WEIGHTED:
+		/* ixgbe_dcb_pba_80_48 strategy weight first half of packet
+		 * buffer with 5/8 of the packet buffer space.
+		 */
+		rxpktsize = (pbsize * 5) / (num_pb * 4);
+		pbsize -= rxpktsize * (num_pb / 2);
+		rxpktsize <<= IXGBE_RXPBSIZE_SHIFT;
+		for (; i < (num_pb / 2); i++)
+			IXGBE_WRITE_REG(hw, IXGBE_RXPBSIZE(i), rxpktsize);
+		/* fall through - configure remaining packet buffers */
+	case PBA_STRATEGY_EQUAL:
+		rxpktsize = (pbsize / (num_pb - i)) << IXGBE_RXPBSIZE_SHIFT;
+		for (; i < num_pb; i++)
+			IXGBE_WRITE_REG(hw, IXGBE_RXPBSIZE(i), rxpktsize);
+		break;
+	default:
+		break;
+	}
+
+	/* Only support an equally distributed Tx packet buffer strategy. */
+	txpktsize = IXGBE_TXPBSIZE_MAX / num_pb;
+	txpbthresh = (txpktsize / 1024) - IXGBE_TXPKT_SIZE_MAX;
+	for (i = 0; i < num_pb; i++) {
+		IXGBE_WRITE_REG(hw, IXGBE_TXPBSIZE(i), txpktsize);
+		IXGBE_WRITE_REG(hw, IXGBE_TXPBTHRESH(i), txpbthresh);
+	}
+
+	/* Clear unused TCs, if any, to zero buffer size*/
+	for (; i < IXGBE_MAX_PB; i++) {
+		IXGBE_WRITE_REG(hw, IXGBE_RXPBSIZE(i), 0);
+		IXGBE_WRITE_REG(hw, IXGBE_TXPBSIZE(i), 0);
+		IXGBE_WRITE_REG(hw, IXGBE_TXPBTHRESH(i), 0);
+	}
 }
 
 /**
@@ -3600,6 +4827,8 @@ void ixgbe_clear_tx_pending(struct ixgbe
 	for (i = 0; i < poll; i++) {
 		usec_delay(100);
 		value = IXGBE_READ_PCIE_WORD(hw, IXGBE_PCI_DEVICE_STATUS);
+		if (IXGBE_REMOVED(hw->hw_addr))
+			goto out;
 		if (!(value & IXGBE_PCI_DEVICE_STATUS_TRANSACTION_PENDING))
 			goto out;
 	}
@@ -3619,53 +4848,451 @@ out:
 	IXGBE_WRITE_REG(hw, IXGBE_HLREG0, hlreg0);
 }
 
-void ixgbe_disable_rx_generic(struct ixgbe_hw *hw)
+/**
+ *  ixgbe_bypass_rw_generic - Bit bang data into by_pass FW
+ *
+ *  @hw: pointer to hardware structure
+ *  @cmd: Command we send to the FW
+ *  @status: The reply from the FW
+ *
+ *  Bit-bangs the cmd to the by_pass FW status points to what is returned.
+ **/
+#define IXGBE_BYPASS_BB_WAIT 1
+int32_t ixgbe_bypass_rw_generic(struct ixgbe_hw *hw, uint32_t cmd, uint32_t *status)
 {
-	uint32_t rxctrl;
+	int i;
+	uint32_t sck, sdi, sdo, dir_sck, dir_sdi, dir_sdo;
+	uint32_t esdp;
 
-	rxctrl = IXGBE_READ_REG(hw, IXGBE_RXCTRL);
-	if (rxctrl & IXGBE_RXCTRL_RXEN) {
-		rxctrl &= ~IXGBE_RXCTRL_RXEN;
-		IXGBE_WRITE_REG(hw, IXGBE_RXCTRL, rxctrl);
+	if (!status)
+		return IXGBE_ERR_PARAM;
+
+	*status = 0;
+
+	/* SDP vary by MAC type */
+	switch (hw->mac.type) {
+	case ixgbe_mac_82599EB:
+		sck = IXGBE_ESDP_SDP7;
+		sdi = IXGBE_ESDP_SDP0;
+		sdo = IXGBE_ESDP_SDP6;
+		dir_sck = IXGBE_ESDP_SDP7_DIR;
+		dir_sdi = IXGBE_ESDP_SDP0_DIR;
+		dir_sdo = IXGBE_ESDP_SDP6_DIR;
+		break;
+	case ixgbe_mac_X540:
+		sck = IXGBE_ESDP_SDP2;
+		sdi = IXGBE_ESDP_SDP0;
+		sdo = IXGBE_ESDP_SDP1;
+		dir_sck = IXGBE_ESDP_SDP2_DIR;
+		dir_sdi = IXGBE_ESDP_SDP0_DIR;
+		dir_sdo = IXGBE_ESDP_SDP1_DIR;
+		break;
+	default:
+		return IXGBE_ERR_DEVICE_NOT_SUPPORTED;
 	}
-}
 
-void ixgbe_enable_rx_generic(struct ixgbe_hw *hw)
-{
-	uint32_t rxctrl;
+	/* Set SDP pins direction */
+	esdp = IXGBE_READ_REG(hw, IXGBE_ESDP);
+	esdp |= dir_sck;	/* SCK as output */
+	esdp |= dir_sdi;	/* SDI as output */
+	esdp &= ~dir_sdo;	/* SDO as input */
+	esdp |= sck;
+	esdp |= sdi;
+	IXGBE_WRITE_REG(hw, IXGBE_ESDP, esdp);
+	IXGBE_WRITE_FLUSH(hw);
+	msec_delay(IXGBE_BYPASS_BB_WAIT);
 
-	rxctrl = IXGBE_READ_REG(hw, IXGBE_RXCTRL);
-	IXGBE_WRITE_REG(hw, IXGBE_RXCTRL, (rxctrl | IXGBE_RXCTRL_RXEN));
-}
+	/* Generate start condition */
+	esdp &= ~sdi;
+	IXGBE_WRITE_REG(hw, IXGBE_ESDP, esdp);
+	IXGBE_WRITE_FLUSH(hw);
+	msec_delay(IXGBE_BYPASS_BB_WAIT);
 
-/**
- * ixgbe_mng_present - returns TRUE when management capability is present
- * @hw: pointer to hardware structure
- */
-bool ixgbe_mng_present(struct ixgbe_hw *hw)
-{
-	uint32_t fwsm;
+	esdp &= ~sck;
+	IXGBE_WRITE_REG(hw, IXGBE_ESDP, esdp);
+	IXGBE_WRITE_FLUSH(hw);
+	msec_delay(IXGBE_BYPASS_BB_WAIT);
 
-	if (hw->mac.type < ixgbe_mac_82599EB)
-		return FALSE;
+	/* Clock out the new control word and clock in the status */
+	for (i = 0; i < 32; i++) {
+		if ((cmd >> (31 - i)) & 0x01) {
+			esdp |= sdi;
+			IXGBE_WRITE_REG(hw, IXGBE_ESDP, esdp);
+		} else {
+			esdp &= ~sdi;
+			IXGBE_WRITE_REG(hw, IXGBE_ESDP, esdp);
+		}
+		IXGBE_WRITE_FLUSH(hw);
+		msec_delay(IXGBE_BYPASS_BB_WAIT);
+
+		esdp |= sck;
+		IXGBE_WRITE_REG(hw, IXGBE_ESDP, esdp);
+		IXGBE_WRITE_FLUSH(hw);
+		msec_delay(IXGBE_BYPASS_BB_WAIT);
+
+		esdp &= ~sck;
+		IXGBE_WRITE_REG(hw, IXGBE_ESDP, esdp);
+		IXGBE_WRITE_FLUSH(hw);
+		msec_delay(IXGBE_BYPASS_BB_WAIT);
+
+		esdp = IXGBE_READ_REG(hw, IXGBE_ESDP);
+		if (esdp & sdo)
+			*status = (*status << 1) | 0x01;
+		else
+			*status = (*status << 1) | 0x00;
+		msec_delay(IXGBE_BYPASS_BB_WAIT);
+	}
+
+	/* stop condition */
+	esdp |= sck;
+	esdp &= ~sdi;
+	IXGBE_WRITE_REG(hw, IXGBE_ESDP, esdp);
+	IXGBE_WRITE_FLUSH(hw);
+	msec_delay(IXGBE_BYPASS_BB_WAIT);
 
-	fwsm = IXGBE_READ_REG(hw, IXGBE_FWSM);
-	fwsm &= IXGBE_FWSM_MODE_MASK;
-	return fwsm == IXGBE_FWSM_FW_MODE_PT;
+	esdp |= sdi;
+	IXGBE_WRITE_REG(hw, IXGBE_ESDP, esdp);
+	IXGBE_WRITE_FLUSH(hw);
+
+	/* set the page bits to match the cmd that the status it belongs to */
+	*status = (*status & 0x3fffffff) | (cmd & 0xc0000000);
+
+	return IXGBE_SUCCESS;
 }
 
 /**
- * ixgbe_mng_enabled - Is the manageability engine enabled?
- * @hw: pointer to hardware structure
+ * ixgbe_bypass_valid_rd_generic - Verify valid return from bit-bang.
  *
- * Returns TRUE if the manageability engine is enabled.
+ * If we send a write we can't be sure it took until we can read back
+ * that same register.  It can be a problem as some of the feilds may
+ * for valid reasons change inbetween the time wrote the register and
+ * we read it again to verify.  So this function check everything we
+ * can check and then assumes it worked.
+ *
+ * @uint32_t in_reg - The register cmd for the bit-bang read.
+ * @uint32_t out_reg - The register returned from a bit-bang read.
  **/
-bool ixgbe_mng_enabled(struct ixgbe_hw *hw)
+bool ixgbe_bypass_valid_rd_generic(uint32_t in_reg, uint32_t out_reg)
 {
-	uint32_t fwsm, manc, factps;
+	uint32_t mask;
 
-	fwsm = IXGBE_READ_REG(hw, IXGBE_FWSM);
-	if ((fwsm & IXGBE_FWSM_MODE_MASK) != IXGBE_FWSM_FW_MODE_PT)
+	/* Page must match for all control pages */
+	if ((in_reg & BYPASS_PAGE_M) != (out_reg & BYPASS_PAGE_M))
+		return FALSE;
+
+	switch (in_reg & BYPASS_PAGE_M) {
+	case BYPASS_PAGE_CTL0:
+		/* All the following can't change since the last write
+		 *  - All the event actions
+		 *  - The timeout value
+		 */
+		mask = BYPASS_AUX_ON_M | BYPASS_MAIN_ON_M |
+		       BYPASS_MAIN_OFF_M | BYPASS_AUX_OFF_M |
+		       BYPASS_WDTIMEOUT_M |
+		       BYPASS_WDT_VALUE_M;
+		if ((out_reg & mask) != (in_reg & mask))
+			return FALSE;
+
+		/* 0x0 is never a valid value for bypass status */
+		if (!(out_reg & BYPASS_STATUS_OFF_M))
+			return FALSE;
+		break;
+	case BYPASS_PAGE_CTL1:
+		/* All the following can't change since the last write
+		 *  - time valid bit
+		 *  - time we last sent
+		 */
+		mask = BYPASS_CTL1_VALID_M | BYPASS_CTL1_TIME_M;
+		if ((out_reg & mask) != (in_reg & mask))
+			return FALSE;
+		break;
+	case BYPASS_PAGE_CTL2:
+		/* All we can check in this page is control number
+		 * which is already done above.
+		 */
+		break;
+	}
+
+	/* We are as sure as we can be return TRUE */
+	return TRUE;
+}
+
+/**
+ *  ixgbe_bypass_set_generic - Set a bypass field in the FW CTRL Regiter.
+ *
+ *  @hw: pointer to hardware structure
+ *  @cmd: The control word we are setting.
+ *  @event: The event we are setting in the FW.  This also happens to
+ *	    be the mask for the event we are setting (handy)
+ *  @action: The action we set the event to in the FW. This is in a
+ *	     bit field that happens to be what we want to put in
+ *	     the event spot (also handy)
+ **/
+int32_t ixgbe_bypass_set_generic(struct ixgbe_hw *hw, uint32_t ctrl, uint32_t event,
+			     uint32_t action)
+{
+	uint32_t by_ctl = 0;
+	uint32_t cmd, verify;
+	uint32_t count = 0;
+
+	/* Get current values */
+	cmd = ctrl;	/* just reading only need control number */
+	if (ixgbe_bypass_rw_generic(hw, cmd, &by_ctl))
+		return IXGBE_ERR_INVALID_ARGUMENT;
+
+	/* Set to new action */
+	cmd = (by_ctl & ~event) | BYPASS_WE | action;
+	if (ixgbe_bypass_rw_generic(hw, cmd, &by_ctl))
+		return IXGBE_ERR_INVALID_ARGUMENT;
+
+	/* Page 0 force a FW eeprom write which is slow so verify */
+	if ((cmd & BYPASS_PAGE_M) == BYPASS_PAGE_CTL0) {
+		verify = BYPASS_PAGE_CTL0;
+		do {
+			if (count++ > 5)
+				return IXGBE_BYPASS_FW_WRITE_FAILURE;
+
+			if (ixgbe_bypass_rw_generic(hw, verify, &by_ctl))
+				return IXGBE_ERR_INVALID_ARGUMENT;
+		} while (!ixgbe_bypass_valid_rd_generic(cmd, by_ctl));
+	} else {
+		/* We have give the FW time for the write to stick */
+		msec_delay(100);
+	}
+
+	return IXGBE_SUCCESS;
+}
+
+/**
+ *  ixgbe_bypass_rd_eep_generic - Read the bypass FW eeprom addres.
+ *
+ *  @hw: pointer to hardware structure
+ *  @addr: The bypass eeprom address to read.
+ *  @value: The 8b of data at the address above.
+ **/
+int32_t ixgbe_bypass_rd_eep_generic(struct ixgbe_hw *hw, uint32_t addr, uint8_t *value)
+{
+	uint32_t cmd;
+	uint32_t status;
+
+
+	/* send the request */
+	cmd = BYPASS_PAGE_CTL2 | BYPASS_WE;
+	cmd |= (addr << BYPASS_CTL2_OFFSET_SHIFT) & BYPASS_CTL2_OFFSET_M;
+	if (ixgbe_bypass_rw_generic(hw, cmd, &status))
+		return IXGBE_ERR_INVALID_ARGUMENT;
+
+	/* We have give the FW time for the write to stick */
+	msec_delay(100);
+
+	/* now read the results */
+	cmd &= ~BYPASS_WE;
+	if (ixgbe_bypass_rw_generic(hw, cmd, &status))
+		return IXGBE_ERR_INVALID_ARGUMENT;
+
+	*value = status & BYPASS_CTL2_DATA_M;
+
+	return IXGBE_SUCCESS;
+}
+
+/**
+ *  ixgbe_get_orom_version - Return option ROM from EEPROM
+ *
+ *  @hw: pointer to hardware structure
+ *  @nvm_ver: pointer to output structure
+ *
+ *  if valid option ROM version, nvm_ver->or_valid set to TRUE
+ *  else nvm_ver->or_valid is FALSE.
+ **/
+void ixgbe_get_orom_version(struct ixgbe_hw *hw,
+			    struct ixgbe_nvm_version *nvm_ver)
+{
+	uint16_t offset, eeprom_cfg_blkh, eeprom_cfg_blkl;
+
+	nvm_ver->or_valid = FALSE;
+	/* Option Rom may or may not be present.  Start with pointer */
+	hw->eeprom.ops.read(hw, NVM_OROM_OFFSET, &offset);
+
+	/* make sure offset is valid */
+	if ((offset == 0x0) || (offset == NVM_INVALID_PTR))
+		return;
+
+	hw->eeprom.ops.read(hw, offset + NVM_OROM_BLK_HI, &eeprom_cfg_blkh);
+	hw->eeprom.ops.read(hw, offset + NVM_OROM_BLK_LOW, &eeprom_cfg_blkl);
+
+	/* option rom exists and is valid */
+	if ((eeprom_cfg_blkl | eeprom_cfg_blkh) == 0x0 ||
+	    eeprom_cfg_blkl == NVM_VER_INVALID ||
+	    eeprom_cfg_blkh == NVM_VER_INVALID)
+		return;
+
+	nvm_ver->or_valid = TRUE;
+	nvm_ver->or_major = eeprom_cfg_blkl >> NVM_OROM_SHIFT;
+	nvm_ver->or_build = (eeprom_cfg_blkl << NVM_OROM_SHIFT) |
+			    (eeprom_cfg_blkh >> NVM_OROM_SHIFT);
+	nvm_ver->or_patch = eeprom_cfg_blkh & NVM_OROM_PATCH_MASK;
+}
+
+/**
+ *  ixgbe_get_oem_prod_version - Return OEM Product version
+ *
+ *  @hw: pointer to hardware structure
+ *  @nvm_ver: pointer to output structure
+ *
+ *  if valid OEM product version, nvm_ver->oem_valid set to TRUE
+ *  else nvm_ver->oem_valid is FALSE.
+ **/
+void ixgbe_get_oem_prod_version(struct ixgbe_hw *hw,
+				struct ixgbe_nvm_version *nvm_ver)
+{
+	uint16_t rel_num, prod_ver, mod_len, cap, offset;
+
+	nvm_ver->oem_valid = FALSE;
+	hw->eeprom.ops.read(hw, NVM_OEM_PROD_VER_PTR, &offset);
+
+	/* Return is offset to OEM Product Version block is invalid */
+	if (offset == 0x0 && offset == NVM_INVALID_PTR)
+		return;
+
+	/* Read product version block */
+	hw->eeprom.ops.read(hw, offset, &mod_len);
+	hw->eeprom.ops.read(hw, offset + NVM_OEM_PROD_VER_CAP_OFF, &cap);
+
+	/* Return if OEM product version block is invalid */
+	if (mod_len != NVM_OEM_PROD_VER_MOD_LEN ||
+	    (cap & NVM_OEM_PROD_VER_CAP_MASK) != 0x0)
+		return;
+
+	hw->eeprom.ops.read(hw, offset + NVM_OEM_PROD_VER_OFF_L, &prod_ver);
+	hw->eeprom.ops.read(hw, offset + NVM_OEM_PROD_VER_OFF_H, &rel_num);
+
+	/* Return if version is invalid */
+	if ((rel_num | prod_ver) == 0x0 ||
+	    rel_num == NVM_VER_INVALID || prod_ver == NVM_VER_INVALID)
+		return;
+
+	nvm_ver->oem_major = prod_ver >> NVM_VER_SHIFT;
+	nvm_ver->oem_minor = prod_ver & NVM_VER_MASK;
+	nvm_ver->oem_release = rel_num;
+	nvm_ver->oem_valid = TRUE;
+}
+
+/**
+ *  ixgbe_get_etk_id - Return Etrack ID from EEPROM
+ *
+ *  @hw: pointer to hardware structure
+ *  @nvm_ver: pointer to output structure
+ *
+ *  word read errors will return 0xFFFF
+ **/
+void ixgbe_get_etk_id(struct ixgbe_hw *hw, struct ixgbe_nvm_version *nvm_ver)
+{
+	uint16_t etk_id_l, etk_id_h;
+
+	if (hw->eeprom.ops.read(hw, NVM_ETK_OFF_LOW, &etk_id_l))
+		etk_id_l = NVM_VER_INVALID;
+	if (hw->eeprom.ops.read(hw, NVM_ETK_OFF_HI, &etk_id_h))
+		etk_id_h = NVM_VER_INVALID;
+
+	/* The word order for the version format is determined by high order
+	 * word bit 15.
+	 */
+	if ((etk_id_h & NVM_ETK_VALID) == 0) {
+		nvm_ver->etk_id = etk_id_h;
+		nvm_ver->etk_id |= (etk_id_l << NVM_ETK_SHIFT);
+	} else {
+		nvm_ver->etk_id = etk_id_l;
+		nvm_ver->etk_id |= (etk_id_h << NVM_ETK_SHIFT);
+	}
+}
+
+
+/**
+ * ixgbe_dcb_get_rtrup2tc_generic - read rtrup2tc reg
+ * @hw: pointer to hardware structure
+ * @map: pointer to uint8_t arr for returning map
+ *
+ * Read the rtrup2tc HW register and resolve its content into map
+ **/
+void ixgbe_dcb_get_rtrup2tc_generic(struct ixgbe_hw *hw, uint8_t *map)
+{
+	uint32_t reg, i;
+
+	reg = IXGBE_READ_REG(hw, IXGBE_RTRUP2TC);
+	for (i = 0; i < IXGBE_DCB_MAX_USER_PRIORITY; i++)
+		map[i] = IXGBE_RTRUP2TC_UP_MASK &
+			(reg >> (i * IXGBE_RTRUP2TC_UP_SHIFT));
+	return;
+}
+
+void ixgbe_disable_rx_generic(struct ixgbe_hw *hw)
+{
+	uint32_t pfdtxgswc;
+	uint32_t rxctrl;
+
+	rxctrl = IXGBE_READ_REG(hw, IXGBE_RXCTRL);
+	if (rxctrl & IXGBE_RXCTRL_RXEN) {
+		if (hw->mac.type != ixgbe_mac_82598EB) {
+			pfdtxgswc = IXGBE_READ_REG(hw, IXGBE_PFDTXGSWC);
+			if (pfdtxgswc & IXGBE_PFDTXGSWC_VT_LBEN) {
+				pfdtxgswc &= ~IXGBE_PFDTXGSWC_VT_LBEN;
+				IXGBE_WRITE_REG(hw, IXGBE_PFDTXGSWC, pfdtxgswc);
+				hw->mac.set_lben = TRUE;
+			} else {
+				hw->mac.set_lben = FALSE;
+			}
+		}
+		rxctrl &= ~IXGBE_RXCTRL_RXEN;
+		IXGBE_WRITE_REG(hw, IXGBE_RXCTRL, rxctrl);
+	}
+}
+
+void ixgbe_enable_rx_generic(struct ixgbe_hw *hw)
+{
+	uint32_t pfdtxgswc;
+	uint32_t rxctrl;
+
+	rxctrl = IXGBE_READ_REG(hw, IXGBE_RXCTRL);
+	IXGBE_WRITE_REG(hw, IXGBE_RXCTRL, (rxctrl | IXGBE_RXCTRL_RXEN));
+
+	if (hw->mac.type != ixgbe_mac_82598EB) {
+		if (hw->mac.set_lben) {
+			pfdtxgswc = IXGBE_READ_REG(hw, IXGBE_PFDTXGSWC);
+			pfdtxgswc |= IXGBE_PFDTXGSWC_VT_LBEN;
+			IXGBE_WRITE_REG(hw, IXGBE_PFDTXGSWC, pfdtxgswc);
+			hw->mac.set_lben = FALSE;
+		}
+	}
+}
+
+/**
+ * ixgbe_mng_present - returns TRUE when management capability is present
+ * @hw: pointer to hardware structure
+ */
+bool ixgbe_mng_present(struct ixgbe_hw *hw)
+{
+	uint32_t fwsm;
+
+	if (hw->mac.type < ixgbe_mac_82599EB)
+		return FALSE;
+
+	fwsm = IXGBE_READ_REG(hw, IXGBE_FWSM_BY_MAC(hw));
+
+	return !!(fwsm & IXGBE_FWSM_FW_MODE_PT);
+}
+
+/**
+ * ixgbe_mng_enabled - Is the manageability engine enabled?
+ * @hw: pointer to hardware structure
+ *
+ * Returns TRUE if the manageability engine is enabled.
+ **/
+bool ixgbe_mng_enabled(struct ixgbe_hw *hw)
+{
+	uint32_t fwsm, manc, factps;
+
+	fwsm = IXGBE_READ_REG(hw, IXGBE_FWSM_BY_MAC(hw));
+	if ((fwsm & IXGBE_FWSM_MODE_MASK) != IXGBE_FWSM_FW_MODE_PT)
 		return FALSE;
 
 	manc = IXGBE_READ_REG(hw, IXGBE_MANC);
@@ -3673,7 +5300,7 @@ bool ixgbe_mng_enabled(struct ixgbe_hw *
 		return FALSE;
 
 	if (hw->mac.type <= ixgbe_mac_X540) {
-		factps = IXGBE_READ_REG(hw, IXGBE_FACTPS);
+		factps = IXGBE_READ_REG(hw, IXGBE_FACTPS_BY_MAC(hw));
 		if (factps & IXGBE_FACTPS_MNGCG)
 			return FALSE;
 	}
@@ -3690,8 +5317,8 @@ bool ixgbe_mng_enabled(struct ixgbe_hw *
  *  Set the link speed in the MAC and/or PHY register and restarts link.
  **/
 int32_t ixgbe_setup_mac_link_multispeed_fiber(struct ixgbe_hw *hw,
-					      ixgbe_link_speed speed,
-					      bool autoneg_wait_to_complete)
+					  ixgbe_link_speed speed,
+					  bool autoneg_wait_to_complete)
 {
 	ixgbe_link_speed link_speed = IXGBE_LINK_SPEED_UNKNOWN;
 	ixgbe_link_speed highest_link_speed = IXGBE_LINK_SPEED_UNKNOWN;
@@ -3703,9 +5330,7 @@ int32_t ixgbe_setup_mac_link_multispeed_
 	DEBUGFUNC("ixgbe_setup_mac_link_multispeed_fiber");
 
 	/* Mask off requested but non-supported speeds */
-	if (!hw->mac.ops.get_link_capabilities)
-		return IXGBE_NOT_IMPLEMENTED;
-	status = hw->mac.ops.get_link_capabilities(hw, &link_speed, &autoneg);
+	status = ixgbe_get_link_capabilities(hw, &link_speed, &autoneg);
 	if (status != IXGBE_SUCCESS)
 		return status;
 
@@ -3718,21 +5343,12 @@ int32_t ixgbe_setup_mac_link_multispeed_
 		speedcnt++;
 		highest_link_speed = IXGBE_LINK_SPEED_10GB_FULL;
 
-		/* If we already have link at this speed, just jump out */
-		status = ixgbe_check_link(hw, &link_speed, &link_up, FALSE);
-		if (status != IXGBE_SUCCESS)
-			return status;
-
-		if ((link_speed == IXGBE_LINK_SPEED_10GB_FULL) && link_up)
-			goto out;
-
 		/* Set the module link speed */
 		switch (hw->phy.media_type) {
 		case ixgbe_media_type_fiber_fixed:
 		case ixgbe_media_type_fiber:
-			if (hw->mac.ops.set_rate_select_speed)
-				hw->mac.ops.set_rate_select_speed(hw,
-				    IXGBE_LINK_SPEED_10GB_FULL);
+			ixgbe_set_rate_select_speed(hw,
+						    IXGBE_LINK_SPEED_10GB_FULL);
 			break;
 		case ixgbe_media_type_fiber_qsfp:
 			/* QSFP module automatically detects MAC link speed */
@@ -3745,11 +5361,9 @@ int32_t ixgbe_setup_mac_link_multispeed_
 		/* Allow module to change analog characteristics (1G->10G) */
 		msec_delay(40);
 
-		if (!hw->mac.ops.setup_mac_link)
-			return IXGBE_NOT_IMPLEMENTED;
-		status = hw->mac.ops.setup_mac_link(hw,
-						    IXGBE_LINK_SPEED_10GB_FULL,
-						    autoneg_wait_to_complete);
+		status = ixgbe_setup_mac_link(hw,
+					      IXGBE_LINK_SPEED_10GB_FULL,
+					      autoneg_wait_to_complete);
 		if (status != IXGBE_SUCCESS)
 			return status;
 
@@ -3780,21 +5394,12 @@ int32_t ixgbe_setup_mac_link_multispeed_
 		if (highest_link_speed == IXGBE_LINK_SPEED_UNKNOWN)
 			highest_link_speed = IXGBE_LINK_SPEED_1GB_FULL;
 
-		/* If we already have link at this speed, just jump out */
-		status = ixgbe_check_link(hw, &link_speed, &link_up, FALSE);
-		if (status != IXGBE_SUCCESS)
-			return status;
-
-		if ((link_speed == IXGBE_LINK_SPEED_1GB_FULL) && link_up)
-			goto out;
-
 		/* Set the module link speed */
 		switch (hw->phy.media_type) {
 		case ixgbe_media_type_fiber_fixed:
 		case ixgbe_media_type_fiber:
-			if (hw->mac.ops.set_rate_select_speed)
-				hw->mac.ops.set_rate_select_speed(hw,
-				    IXGBE_LINK_SPEED_1GB_FULL);
+			ixgbe_set_rate_select_speed(hw,
+						    IXGBE_LINK_SPEED_1GB_FULL);
 			break;
 		case ixgbe_media_type_fiber_qsfp:
 			/* QSFP module automatically detects link speed */
@@ -3807,11 +5412,9 @@ int32_t ixgbe_setup_mac_link_multispeed_
 		/* Allow module to change analog characteristics (10G->1G) */
 		msec_delay(40);
 
-		if (!hw->mac.ops.setup_mac_link)
-			return IXGBE_NOT_IMPLEMENTED;
-		status = hw->mac.ops.setup_mac_link(hw,
-						    IXGBE_LINK_SPEED_1GB_FULL,
-						    autoneg_wait_to_complete);
+		status = ixgbe_setup_mac_link(hw,
+					      IXGBE_LINK_SPEED_1GB_FULL,
+					      autoneg_wait_to_complete);
 		if (status != IXGBE_SUCCESS)
 			return status;
 
@@ -3837,493 +5440,86 @@ int32_t ixgbe_setup_mac_link_multispeed_
 	if (speedcnt > 1)
 		status = ixgbe_setup_mac_link_multispeed_fiber(hw,
 						      highest_link_speed,
-						      autoneg_wait_to_complete);
-
-out:
-	/* Set autoneg_advertised value based on input link speed */
-	hw->phy.autoneg_advertised = 0;
-
-	if (speed & IXGBE_LINK_SPEED_10GB_FULL)
-		hw->phy.autoneg_advertised |= IXGBE_LINK_SPEED_10GB_FULL;
-
-	if (speed & IXGBE_LINK_SPEED_1GB_FULL)
-		hw->phy.autoneg_advertised |= IXGBE_LINK_SPEED_1GB_FULL;
-
-	return status;
-}
-
-/**
- *  ixgbe_set_soft_rate_select_speed - Set module link speed
- *  @hw: pointer to hardware structure
- *  @speed: link speed to set
- *
- *  Set module link speed via the soft rate select.
- */
-void ixgbe_set_soft_rate_select_speed(struct ixgbe_hw *hw,
-					ixgbe_link_speed speed)
-{
-	int32_t status;
-	uint8_t rs, eeprom_data;
-
-	switch (speed) {
-	case IXGBE_LINK_SPEED_10GB_FULL:
-		/* one bit mask same as setting on */
-		rs = IXGBE_SFF_SOFT_RS_SELECT_10G;
-		break;
-	case IXGBE_LINK_SPEED_1GB_FULL:
-		rs = IXGBE_SFF_SOFT_RS_SELECT_1G;
-		break;
-	default:
-		DEBUGOUT("Invalid fixed module speed\n");
-		return;
-	}
-
-	/* Set RS0 */
-	status = hw->phy.ops.read_i2c_byte(hw, IXGBE_SFF_SFF_8472_OSCB,
-					   IXGBE_I2C_EEPROM_DEV_ADDR2,
-					   &eeprom_data);
-	if (status) {
-		DEBUGOUT("Failed to read Rx Rate Select RS0\n");
-		goto out;
-	}
-
-	eeprom_data = (eeprom_data & ~IXGBE_SFF_SOFT_RS_SELECT_MASK) | rs;
-
-	status = hw->phy.ops.write_i2c_byte(hw, IXGBE_SFF_SFF_8472_OSCB,
-					    IXGBE_I2C_EEPROM_DEV_ADDR2,
-					    eeprom_data);
-	if (status) {
-		DEBUGOUT("Failed to write Rx Rate Select RS0\n");
-		goto out;
-	}
-
-	/* Set RS1 */
-	status = hw->phy.ops.read_i2c_byte(hw, IXGBE_SFF_SFF_8472_ESCB,
-					   IXGBE_I2C_EEPROM_DEV_ADDR2,
-					   &eeprom_data);
-	if (status) {
-		DEBUGOUT("Failed to read Rx Rate Select RS1\n");
-		goto out;
-	}
-
-	eeprom_data = (eeprom_data & ~IXGBE_SFF_SOFT_RS_SELECT_MASK) | rs;
-
-	status = hw->phy.ops.write_i2c_byte(hw, IXGBE_SFF_SFF_8472_ESCB,
-					    IXGBE_I2C_EEPROM_DEV_ADDR2,
-					    eeprom_data);
-	if (status) {
-		DEBUGOUT("Failed to write Rx Rate Select RS1\n");
-		goto out;
-	}
-out:
-	return;
-}
-
-/* MAC Operations */
-
-/**
- *  ixgbe_init_shared_code - Initialize the shared code
- *  @hw: pointer to hardware structure
- *
- *  This will assign function pointers and assign the MAC type and PHY code.
- *  Does not touch the hardware. This function must be called prior to any
- *  other function in the shared code. The ixgbe_hw structure should be
- *  memset to 0 prior to calling this function.  The following fields in
- *  hw structure should be filled in prior to calling this function:
- *  hw_addr, back, device_id, vendor_id, subsystem_device_id,
- *  subsystem_vendor_id, and revision_id
- **/
-int32_t ixgbe_init_shared_code(struct ixgbe_hw *hw)
-{
-	int32_t status;
-
-	DEBUGFUNC("ixgbe_init_shared_code");
-
-	/*
-	 * Set the mac type
-	 */
-	ixgbe_set_mac_type(hw);
-
-	switch (hw->mac.type) {
-	case ixgbe_mac_82598EB:
-		status = ixgbe_init_ops_82598(hw);
-		break;
-	case ixgbe_mac_82599EB:
-		status = ixgbe_init_ops_82599(hw);
-		break;
-	case ixgbe_mac_X540:
-		status = ixgbe_init_ops_X540(hw);
-		break;
-	case ixgbe_mac_X550:
-		status = ixgbe_init_ops_X550(hw);
-		break;
-	case ixgbe_mac_X550EM_x:
-		status = ixgbe_init_ops_X550EM(hw);
-		break;
-	default:
-		status = IXGBE_ERR_DEVICE_NOT_SUPPORTED;
-		break;
-	}
-	hw->mac.max_link_up_time = IXGBE_LINK_UP_TIME;
-
-	return status;
-}
-
-/**
- *  ixgbe_set_mac_type - Sets MAC type
- *  @hw: pointer to the HW structure
- *
- *  This function sets the mac type of the adapter based on the
- *  vendor ID and device ID stored in the hw structure.
- **/
-int32_t ixgbe_set_mac_type(struct ixgbe_hw *hw)
-{
-	int32_t ret_val = IXGBE_SUCCESS;
-
-	DEBUGFUNC("ixgbe_set_mac_type\n");
-
-	if (hw->vendor_id != IXGBE_INTEL_VENDOR_ID)
-		return IXGBE_ERR_DEVICE_NOT_SUPPORTED;
-
-	switch (hw->device_id) {
-	case IXGBE_DEV_ID_82598:
-	case IXGBE_DEV_ID_82598_BX:
-	case IXGBE_DEV_ID_82598AF_SINGLE_PORT:
-	case IXGBE_DEV_ID_82598AF_DUAL_PORT:
-	case IXGBE_DEV_ID_82598AT:
-	case IXGBE_DEV_ID_82598AT2:
-	case IXGBE_DEV_ID_82598AT_DUAL_PORT:
-	case IXGBE_DEV_ID_82598EB_CX4:
-	case IXGBE_DEV_ID_82598_CX4_DUAL_PORT:
-	case IXGBE_DEV_ID_82598_DA_DUAL_PORT:
-	case IXGBE_DEV_ID_82598_SR_DUAL_PORT_EM:
-	case IXGBE_DEV_ID_82598EB_XF_LR:
-	case IXGBE_DEV_ID_82598EB_SFP_LOM:
-		hw->mac.type = ixgbe_mac_82598EB;
-		break;
-	case IXGBE_DEV_ID_82599_KX4:
-	case IXGBE_DEV_ID_82599_KX4_MEZZ:
-	case IXGBE_DEV_ID_82599_XAUI_LOM:
-	case IXGBE_DEV_ID_82599_COMBO_BACKPLANE:
-	case IXGBE_DEV_ID_82599_KR:
-	case IXGBE_DEV_ID_82599_SFP:
-	case IXGBE_DEV_ID_82599_BACKPLANE_FCOE:
-	case IXGBE_DEV_ID_82599_SFP_FCOE:
-	case IXGBE_DEV_ID_82599_SFP_EM:
-	case IXGBE_DEV_ID_82599_SFP_SF2:
-	case IXGBE_DEV_ID_82599_SFP_SF_QP:
-	case IXGBE_DEV_ID_82599_QSFP_SF_QP:
-	case IXGBE_DEV_ID_82599EN_SFP:
-	case IXGBE_DEV_ID_82599_CX4:
-	case IXGBE_DEV_ID_82599_BYPASS:
-	case IXGBE_DEV_ID_82599_T3_LOM:
-		hw->mac.type = ixgbe_mac_82599EB;
-		break;
-	case IXGBE_DEV_ID_82599_VF:
-	case IXGBE_DEV_ID_82599_VF_HV:
-		hw->mac.type = ixgbe_mac_82599_vf;
-		break;
-	case IXGBE_DEV_ID_X540_VF:
-	case IXGBE_DEV_ID_X540_VF_HV:
-		hw->mac.type = ixgbe_mac_X540_vf;
-		break;
-	case IXGBE_DEV_ID_X540T:
-	case IXGBE_DEV_ID_X540T1:
-	case IXGBE_DEV_ID_X540_BYPASS:
-		hw->mac.type = ixgbe_mac_X540;
-		break;
-	case IXGBE_DEV_ID_X550T:
-	case IXGBE_DEV_ID_X550T1:
-		hw->mac.type = ixgbe_mac_X550;
-		break;
-	case IXGBE_DEV_ID_X550EM_X_KX4:
-	case IXGBE_DEV_ID_X550EM_X_KR:
-	case IXGBE_DEV_ID_X550EM_X_10G_T:
-	case IXGBE_DEV_ID_X550EM_X_1G_T:
-	case IXGBE_DEV_ID_X550EM_X_SFP:
-		hw->mac.type = ixgbe_mac_X550EM_x;
-		break;
-	case IXGBE_DEV_ID_X550_VF:
-	case IXGBE_DEV_ID_X550_VF_HV:
-		hw->mac.type = ixgbe_mac_X550_vf;
-		break;
-	case IXGBE_DEV_ID_X550EM_X_VF:
-	case IXGBE_DEV_ID_X550EM_X_VF_HV:
-		hw->mac.type = ixgbe_mac_X550EM_x_vf;
-		break;
-	default:
-		ret_val = IXGBE_ERR_DEVICE_NOT_SUPPORTED;
-		break;
-	}
-
-	return ret_val;
-}
-
-/**
- *  ixgbe_init_hw - Initialize the hardware
- *  @hw: pointer to hardware structure
- *
- *  Initialize the hardware by resetting and then starting the hardware
- **/
-int32_t ixgbe_init_hw(struct ixgbe_hw *hw)
-{
-	if (hw->mac.ops.init_hw)
-		return hw->mac.ops.init_hw(hw);
-	else
-		return IXGBE_NOT_IMPLEMENTED;
-}
-
-/**
- *  ixgbe_get_media_type - Get media type
- *  @hw: pointer to hardware structure
- *
- *  Returns the media type (fiber, copper, backplane)
- **/
-enum ixgbe_media_type ixgbe_get_media_type(struct ixgbe_hw *hw)
-{
-	if (hw->mac.ops.get_media_type)
-		return hw->mac.ops.get_media_type(hw);
-	else
-		return ixgbe_media_type_unknown;
-}
-
-/**
- *  ixgbe_identify_phy - Get PHY type
- *  @hw: pointer to hardware structure
- *
- *  Determines the physical layer module found on the current adapter.
- **/
-int32_t ixgbe_identify_phy(struct ixgbe_hw *hw)
-{
-	int32_t status = IXGBE_SUCCESS;
-
-	if (hw->phy.type == ixgbe_phy_unknown) {
-		if (hw->phy.ops.identify)
-			status = hw->phy.ops.identify(hw);
-		else
-			status = IXGBE_NOT_IMPLEMENTED;
-	}
-
-	return status;
-}
-
-/**
- *  ixgbe_check_link - Get link and speed status
- *  @hw: pointer to hardware structure
- *
- *  Reads the links register to determine if link is up and the current speed
- **/
-int32_t ixgbe_check_link(struct ixgbe_hw *hw, ixgbe_link_speed *speed,
-			 bool *link_up, bool link_up_wait_to_complete)
-{
-	if (hw->mac.ops.check_link)
-		return hw->mac.ops.check_link(hw, speed, link_up,
-					      link_up_wait_to_complete);
-	else
-		return IXGBE_NOT_IMPLEMENTED;
-}
-
-/**
- *  ixgbe_flap_tx_laser - flap Tx laser to start autotry process
- *  @hw: pointer to hardware structure
- *
- *  When the driver changes the link speeds that it can support then
- *  flap the tx laser to alert the link partner to start autotry
- *  process on its end.
- **/
-void ixgbe_flap_tx_laser(struct ixgbe_hw *hw)
-{
-	if (hw->mac.ops.flap_tx_laser)
-		hw->mac.ops.flap_tx_laser(hw);
-}
-
-/**
- *  ixgbe_set_rar - Set Rx address register
- *  @hw: pointer to hardware structure
- *  @index: Receive address register to write
- *  @addr: Address to put into receive address register
- *  @vmdq: VMDq "set"
- *  @enable_addr: set flag that address is active
- *
- *  Puts an ethernet address into a receive address register.
- **/
-int32_t ixgbe_set_rar(struct ixgbe_hw *hw, uint32_t index, uint8_t *addr,
-		      uint32_t vmdq, uint32_t enable_addr)
-{
-	if (hw->mac.ops.set_rar)
-		return hw->mac.ops.set_rar(hw, index, addr, vmdq, enable_addr);
-	else
-		return IXGBE_NOT_IMPLEMENTED;
-}
-
-/**
- *  ixgbe_set_vmdq - Associate a VMDq index with a receive address
- *  @hw: pointer to hardware structure
- *  @rar: receive address register index to associate with VMDq index
- *  @vmdq: VMDq set or pool index
- **/
-int32_t ixgbe_set_vmdq(struct ixgbe_hw *hw, uint32_t rar, uint32_t vmdq)
-{
-	if (hw->mac.ops.set_vmdq)
-		return hw->mac.ops.set_vmdq(hw, rar, vmdq);
-	else
-		return IXGBE_NOT_IMPLEMENTED;
-}
-
-/**
- *  ixgbe_clear_vmdq - Disassociate a VMDq index from a receive address
- *  @hw: pointer to hardware structure
- *  @rar: receive address register index to disassociate with VMDq index
- *  @vmdq: VMDq set or pool index
- **/
-int32_t ixgbe_clear_vmdq(struct ixgbe_hw *hw, uint32_t rar, uint32_t vmdq)
-{
-	if (hw->mac.ops.clear_vmdq)
-		return hw->mac.ops.clear_vmdq(hw, rar, vmdq);
-	else
-		return IXGBE_NOT_IMPLEMENTED;
-}
-
-/**
- *  ixgbe_init_uta_tables - Initializes Unicast Table Arrays.
- *  @hw: pointer to hardware structure
- *
- *  Initializes the Unicast Table Arrays to zero on device load.  This
- *  is part of the Rx init addr execution path.
- **/
-int32_t ixgbe_init_uta_tables(struct ixgbe_hw *hw)
-{
-	if (hw->mac.ops.init_uta_tables)
-		return hw->mac.ops.init_uta_tables(hw);
-	else
-		return IXGBE_NOT_IMPLEMENTED;
-}
-
-void ixgbe_disable_rx(struct ixgbe_hw *hw)
-{
-	if (hw->mac.ops.disable_rx)
-		hw->mac.ops.disable_rx(hw);
-}
-
-void ixgbe_enable_rx(struct ixgbe_hw *hw)
-{
-	if (hw->mac.ops.enable_rx)
-		hw->mac.ops.enable_rx(hw);
-}
-
-/*
- * MBX: Mailbox handling
- */
-
-/**
- *  ixgbe_read_mbx - Reads a message from the mailbox
- *  @hw: pointer to the HW structure
- *  @msg: The message buffer
- *  @size: Length of buffer
- *  @mbx_id: id of mailbox to read
- *
- *  returns SUCCESS if it successfully read message from buffer
- **/
-int32_t ixgbe_read_mbx(struct ixgbe_hw *hw, uint32_t *msg, uint16_t size, uint16_t mbx_id)
-{
-	struct ixgbe_mbx_info *mbx = &hw->mbx;
-	int32_t ret_val = IXGBE_ERR_MBX;
-
-	DEBUGFUNC("ixgbe_read_mbx");
-
-	/* limit read to size of mailbox */
-	if (size > mbx->size)
-		size = mbx->size;
-
-	if (mbx->ops.read)
-		ret_val = mbx->ops.read(hw, msg, size, mbx_id);
-
-	return ret_val;
-}
-
-/**
- *  ixgbe_write_mbx - Write a message to the mailbox
- *  @hw: pointer to the HW structure
- *  @msg: The message buffer
- *  @size: Length of buffer
- *  @mbx_id: id of mailbox to write
- *
- *  returns SUCCESS if it successfully copied message into the buffer
- **/
-int32_t ixgbe_write_mbx(struct ixgbe_hw *hw, uint32_t *msg, uint16_t size, uint16_t mbx_id)
-{
-	struct ixgbe_mbx_info *mbx = &hw->mbx;
-	int32_t ret_val = IXGBE_SUCCESS;
-
-	DEBUGFUNC("ixgbe_write_mbx");
-
-	if (size > mbx->size)
-		ret_val = IXGBE_ERR_MBX;
-
-	else if (mbx->ops.write)
-		ret_val = mbx->ops.write(hw, msg, size, mbx_id);
-
-	return ret_val;
-}
-
-/**
- *  ixgbe_check_for_msg - checks to see if someone sent us mail
- *  @hw: pointer to the HW structure
- *  @mbx_id: id of mailbox to check
- *
- *  returns SUCCESS if the Status bit was found or else ERR_MBX
- **/
-int32_t ixgbe_check_for_msg(struct ixgbe_hw *hw, uint16_t mbx_id)
-{
-	struct ixgbe_mbx_info *mbx = &hw->mbx;
-	int32_t ret_val = IXGBE_ERR_MBX;
+						      autoneg_wait_to_complete);
 
-	DEBUGFUNC("ixgbe_check_for_msg");
+out:
+	/* Set autoneg_advertised value based on input link speed */
+	hw->phy.autoneg_advertised = 0;
 
-	if (mbx->ops.check_for_msg)
-		ret_val = mbx->ops.check_for_msg(hw, mbx_id);
+	if (speed & IXGBE_LINK_SPEED_10GB_FULL)
+		hw->phy.autoneg_advertised |= IXGBE_LINK_SPEED_10GB_FULL;
 
-	return ret_val;
+	if (speed & IXGBE_LINK_SPEED_1GB_FULL)
+		hw->phy.autoneg_advertised |= IXGBE_LINK_SPEED_1GB_FULL;
+
+	return status;
 }
 
 /**
- *  ixgbe_check_for_ack - checks to see if someone sent us ACK
- *  @hw: pointer to the HW structure
- *  @mbx_id: id of mailbox to check
+ *  ixgbe_set_soft_rate_select_speed - Set module link speed
+ *  @hw: pointer to hardware structure
+ *  @speed: link speed to set
  *
- *  returns SUCCESS if the Status bit was found or else ERR_MBX
- **/
-int32_t ixgbe_check_for_ack(struct ixgbe_hw *hw, uint16_t mbx_id)
+ *  Set module link speed via the soft rate select.
+ */
+void ixgbe_set_soft_rate_select_speed(struct ixgbe_hw *hw,
+					ixgbe_link_speed speed)
 {
-	struct ixgbe_mbx_info *mbx = &hw->mbx;
-	int32_t ret_val = IXGBE_ERR_MBX;
+	int32_t status;
+	uint8_t rs, eeprom_data;
 
-	DEBUGFUNC("ixgbe_check_for_ack");
+	switch (speed) {
+	case IXGBE_LINK_SPEED_10GB_FULL:
+		/* one bit mask same as setting on */
+		rs = IXGBE_SFF_SOFT_RS_SELECT_10G;
+		break;
+	case IXGBE_LINK_SPEED_1GB_FULL:
+		rs = IXGBE_SFF_SOFT_RS_SELECT_1G;
+		break;
+	default:
+		DEBUGOUT("Invalid fixed module speed\n");
+		return;
+	}
 
-	if (mbx->ops.check_for_ack)
-		ret_val = mbx->ops.check_for_ack(hw, mbx_id);
+	/* Set RS0 */
+	status = hw->phy.ops.read_i2c_byte(hw, IXGBE_SFF_SFF_8472_OSCB,
+					   IXGBE_I2C_EEPROM_DEV_ADDR2,
+					   &eeprom_data);
+	if (status) {
+		DEBUGOUT("Failed to read Rx Rate Select RS0\n");
+		goto out;
+	}
 
-	return ret_val;
-}
+	eeprom_data = (eeprom_data & ~IXGBE_SFF_SOFT_RS_SELECT_MASK) | rs;
 
-/**
- *  ixgbe_check_for_rst - checks to see if other side has reset
- *  @hw: pointer to the HW structure
- *  @mbx_id: id of mailbox to check
- *
- *  returns SUCCESS if the Status bit was found or else ERR_MBX
- **/
-int32_t ixgbe_check_for_rst(struct ixgbe_hw *hw, uint16_t mbx_id)
-{
-	struct ixgbe_mbx_info *mbx = &hw->mbx;
-	int32_t ret_val = IXGBE_ERR_MBX;
+	status = hw->phy.ops.write_i2c_byte(hw, IXGBE_SFF_SFF_8472_OSCB,
+					    IXGBE_I2C_EEPROM_DEV_ADDR2,
+					    eeprom_data);
+	if (status) {
+		DEBUGOUT("Failed to write Rx Rate Select RS0\n");
+		goto out;
+	}
 
-	DEBUGFUNC("ixgbe_check_for_rst");
+	/* Set RS1 */
+	status = hw->phy.ops.read_i2c_byte(hw, IXGBE_SFF_SFF_8472_ESCB,
+					   IXGBE_I2C_EEPROM_DEV_ADDR2,
+					   &eeprom_data);
+	if (status) {
+		DEBUGOUT("Failed to read Rx Rate Select RS1\n");
+		goto out;
+	}
 
-	if (mbx->ops.check_for_rst)
-		ret_val = mbx->ops.check_for_rst(hw, mbx_id);
+	eeprom_data = (eeprom_data & ~IXGBE_SFF_SOFT_RS_SELECT_MASK) | rs;
 
-	return ret_val;
+	status = hw->phy.ops.write_i2c_byte(hw, IXGBE_SFF_SFF_8472_ESCB,
+					    IXGBE_I2C_EEPROM_DEV_ADDR2,
+					    eeprom_data);
+	if (status) {
+		DEBUGOUT("Failed to write Rx Rate Select RS1\n");
+		goto out;
+	}
+out:
+	return;
 }
 
 /**
@@ -4350,6 +5546,10 @@ int32_t ixgbe_poll_for_msg(struct ixgbe_
 		usec_delay(mbx->usec_delay);
 	}
 
+	if (countdown == 0)
+		ERROR_REPORT2(IXGBE_ERROR_POLLING,
+			   "Polling for VF%d mailbox message timedout", mbx_id);
+
 out:
 	return countdown ? IXGBE_SUCCESS : IXGBE_ERR_MBX;
 }
@@ -4378,6 +5578,10 @@ int32_t ixgbe_poll_for_ack(struct ixgbe_
 		usec_delay(mbx->usec_delay);
 	}
 
+	if (countdown == 0)
+		ERROR_REPORT2(IXGBE_ERROR_POLLING,
+			     "Polling for VF%d mailbox ack timedout", mbx_id);
+
 out:
 	return countdown ? IXGBE_SUCCESS : IXGBE_ERR_MBX;
 }
@@ -4392,7 +5596,8 @@ out:
  *  returns SUCCESS if it successfully received a message notification and
  *  copied it into the receive buffer.
  **/
-int32_t ixgbe_read_posted_mbx(struct ixgbe_hw *hw, uint32_t *msg, uint16_t size, uint16_t mbx_id)
+int32_t ixgbe_read_posted_mbx(struct ixgbe_hw *hw, uint32_t *msg, uint16_t size,
+				 uint16_t mbx_id)
 {
 	struct ixgbe_mbx_info *mbx = &hw->mbx;
 	int32_t ret_val = IXGBE_ERR_MBX;
@@ -4422,7 +5627,7 @@ out:
  *  received an ack to that message within delay * timeout period
  **/
 int32_t ixgbe_write_posted_mbx(struct ixgbe_hw *hw, uint32_t *msg, uint16_t size,
-			   uint16_t mbx_id)
+				  uint16_t mbx_id)
 {
 	struct ixgbe_mbx_info *mbx = &hw->mbx;
 	int32_t ret_val = IXGBE_ERR_MBX;
@@ -4474,6 +5679,221 @@ uint32_t ixgbe_read_v2p_mailbox(struct i
 	return v2p_mailbox;
 }
 
+/**
+ *  ixgbe_check_for_bit_vf - Determine if a status bit was set
+ *  @hw: pointer to the HW structure
+ *  @mask: bitmask for bits to be tested and cleared
+ *
+ *  This function is used to check for the read to clear bits within
+ *  the V2P mailbox.
+ **/
+int32_t ixgbe_check_for_bit_vf(struct ixgbe_hw *hw, uint32_t mask)
+{
+	uint32_t v2p_mailbox = ixgbe_read_v2p_mailbox(hw);
+	int32_t ret_val = IXGBE_ERR_MBX;
+
+	if (v2p_mailbox & mask)
+		ret_val = IXGBE_SUCCESS;
+
+	hw->mbx.v2p_mailbox &= ~mask;
+
+	return ret_val;
+}
+
+/**
+ *  ixgbe_check_for_msg_vf - checks to see if the PF has sent mail
+ *  @hw: pointer to the HW structure
+ *  @mbx_id: id of mailbox to check
+ *
+ *  returns SUCCESS if the PF has set the Status bit or else ERR_MBX
+ **/
+int32_t ixgbe_check_for_msg_vf(struct ixgbe_hw *hw, UNUSED uint16_t mbx_id)
+{
+	int32_t ret_val = IXGBE_ERR_MBX;
+
+	DEBUGFUNC("ixgbe_check_for_msg_vf");
+
+	if (!ixgbe_check_for_bit_vf(hw, IXGBE_VFMAILBOX_PFSTS)) {
+		ret_val = IXGBE_SUCCESS;
+		hw->mbx.stats.reqs++;
+	}
+
+	return ret_val;
+}
+
+/**
+ *  ixgbe_check_for_ack_vf - checks to see if the PF has ACK'd
+ *  @hw: pointer to the HW structure
+ *  @mbx_id: id of mailbox to check
+ *
+ *  returns SUCCESS if the PF has set the ACK bit or else ERR_MBX
+ **/
+int32_t ixgbe_check_for_ack_vf(struct ixgbe_hw *hw, UNUSED uint16_t mbx_id)
+{
+	int32_t ret_val = IXGBE_ERR_MBX;
+
+	DEBUGFUNC("ixgbe_check_for_ack_vf");
+
+	if (!ixgbe_check_for_bit_vf(hw, IXGBE_VFMAILBOX_PFACK)) {
+		ret_val = IXGBE_SUCCESS;
+		hw->mbx.stats.acks++;
+	}
+
+	return ret_val;
+}
+
+/**
+ *  ixgbe_check_for_rst_vf - checks to see if the PF has reset
+ *  @hw: pointer to the HW structure
+ *  @mbx_id: id of mailbox to check
+ *
+ *  returns TRUE if the PF has set the reset done bit or else FALSE
+ **/
+int32_t ixgbe_check_for_rst_vf(struct ixgbe_hw *hw, UNUSED uint16_t mbx_id)
+{
+	int32_t ret_val = IXGBE_ERR_MBX;
+
+	DEBUGFUNC("ixgbe_check_for_rst_vf");
+
+	if (!ixgbe_check_for_bit_vf(hw, (IXGBE_VFMAILBOX_RSTD |
+	    IXGBE_VFMAILBOX_RSTI))) {
+		ret_val = IXGBE_SUCCESS;
+		hw->mbx.stats.rsts++;
+	}
+
+	return ret_val;
+}
+
+/**
+ *  ixgbe_obtain_mbx_lock_vf - obtain mailbox lock
+ *  @hw: pointer to the HW structure
+ *
+ *  return SUCCESS if we obtained the mailbox lock
+ **/
+int32_t ixgbe_obtain_mbx_lock_vf(struct ixgbe_hw *hw)
+{
+	int32_t ret_val = IXGBE_ERR_MBX;
+
+	DEBUGFUNC("ixgbe_obtain_mbx_lock_vf");
+
+	/* Take ownership of the buffer */
+	IXGBE_WRITE_REG(hw, IXGBE_VFMAILBOX, IXGBE_VFMAILBOX_VFU);
+
+	/* reserve mailbox for vf use */
+	if (ixgbe_read_v2p_mailbox(hw) & IXGBE_VFMAILBOX_VFU)
+		ret_val = IXGBE_SUCCESS;
+
+	return ret_val;
+}
+
+/**
+ *  ixgbe_write_mbx_vf - Write a message to the mailbox
+ *  @hw: pointer to the HW structure
+ *  @msg: The message buffer
+ *  @size: Length of buffer
+ *  @mbx_id: id of mailbox to write
+ *
+ *  returns SUCCESS if it successfully copied message into the buffer
+ **/
+int32_t ixgbe_write_mbx_vf(struct ixgbe_hw *hw, uint32_t *msg, uint16_t size,
+			      UNUSED uint16_t mbx_id)
+{
+	int32_t ret_val;
+	uint16_t i;
+
+	DEBUGFUNC("ixgbe_write_mbx_vf");
+
+	/* lock the mailbox to prevent pf/vf race condition */
+	ret_val = ixgbe_obtain_mbx_lock_vf(hw);
+	if (ret_val)
+		goto out_no_write;
+
+	/* flush msg and acks as we are overwriting the message buffer */
+	ixgbe_check_for_msg_vf(hw, 0);
+	ixgbe_check_for_ack_vf(hw, 0);
+
+	/* copy the caller specified message to the mailbox memory buffer */
+	for (i = 0; i < size; i++)
+		IXGBE_WRITE_REG_ARRAY(hw, IXGBE_VFMBMEM, i, msg[i]);
+
+	/* update stats */
+	hw->mbx.stats.msgs_tx++;
+
+	/* Drop VFU and interrupt the PF to tell it a message has been sent */
+	IXGBE_WRITE_REG(hw, IXGBE_VFMAILBOX, IXGBE_VFMAILBOX_REQ);
+
+out_no_write:
+	return ret_val;
+}
+
+/**
+ *  ixgbe_read_mbx_vf - Reads a message from the inbox intended for vf
+ *  @hw: pointer to the HW structure
+ *  @msg: The message buffer
+ *  @size: Length of buffer
+ *  @mbx_id: id of mailbox to read
+ *
+ *  returns SUCCESS if it successfully read message from buffer
+ **/
+int32_t ixgbe_read_mbx_vf(struct ixgbe_hw *hw, uint32_t *msg, uint16_t size,
+			     UNUSED uint16_t mbx_id)
+{
+	int32_t ret_val = IXGBE_SUCCESS;
+	uint16_t i;
+
+	DEBUGFUNC("ixgbe_read_mbx_vf");
+
+	/* lock the mailbox to prevent pf/vf race condition */
+	ret_val = ixgbe_obtain_mbx_lock_vf(hw);
+	if (ret_val)
+		goto out_no_read;
+
+	/* copy the message from the mailbox memory buffer */
+	for (i = 0; i < size; i++)
+		msg[i] = IXGBE_READ_REG_ARRAY(hw, IXGBE_VFMBMEM, i);
+
+	/* Acknowledge receipt and release mailbox, then we're done */
+	IXGBE_WRITE_REG(hw, IXGBE_VFMAILBOX, IXGBE_VFMAILBOX_ACK);
+
+	/* update stats */
+	hw->mbx.stats.msgs_rx++;
+
+out_no_read:
+	return ret_val;
+}
+
+/**
+ *  ixgbe_init_mbx_params_vf - set initial values for vf mailbox
+ *  @hw: pointer to the HW structure
+ *
+ *  Initializes the hw->mbx struct to correct values for vf mailbox
+ */
+void ixgbe_init_mbx_params_vf(struct ixgbe_hw *hw)
+{
+	struct ixgbe_mbx_info *mbx = &hw->mbx;
+
+	/* start mailbox as timed out and let the reset_hw call set the timeout
+	 * value to begin communications */
+	mbx->timeout = 0;
+	mbx->usec_delay = IXGBE_VF_MBX_INIT_DELAY;
+
+	mbx->size = IXGBE_VFMAILBOX_SIZE;
+
+	mbx->ops.read = ixgbe_read_mbx_vf;
+	mbx->ops.write = ixgbe_write_mbx_vf;
+	mbx->ops.read_posted = ixgbe_read_posted_mbx;
+	mbx->ops.write_posted = ixgbe_write_posted_mbx;
+	mbx->ops.check_for_msg = ixgbe_check_for_msg_vf;
+	mbx->ops.check_for_ack = ixgbe_check_for_ack_vf;
+	mbx->ops.check_for_rst = ixgbe_check_for_rst_vf;
+
+	mbx->stats.msgs_tx = 0;
+	mbx->stats.msgs_rx = 0;
+	mbx->stats.reqs = 0;
+	mbx->stats.acks = 0;
+	mbx->stats.rsts = 0;
+}
+
 int32_t ixgbe_check_for_bit_pf(struct ixgbe_hw *hw, uint32_t mask, int32_t index)
 {
 	uint32_t mbvficr = IXGBE_READ_REG(hw, IXGBE_MBVFICR(index));
@@ -4557,6 +5977,7 @@ int32_t ixgbe_check_for_rst_pf(struct ix
 		break;
 	case ixgbe_mac_X550:
 	case ixgbe_mac_X550EM_x:
+	case ixgbe_mac_X550EM_a:
 	case ixgbe_mac_X540:
 		vflre = IXGBE_READ_REG(hw, IXGBE_VFLREC(reg_offset));
 		break;
@@ -4594,6 +6015,10 @@ int32_t ixgbe_obtain_mbx_lock_pf(struct 
 	p2v_mailbox = IXGBE_READ_REG(hw, IXGBE_PFMAILBOX(vf_number));
 	if (p2v_mailbox & IXGBE_PFMAILBOX_PFU)
 		ret_val = IXGBE_SUCCESS;
+	else
+		ERROR_REPORT2(IXGBE_ERROR_POLLING,
+			   "Failed to obtain mailbox lock for VF%d", vf_number);
+
 
 	return ret_val;
 }
@@ -4608,7 +6033,7 @@ int32_t ixgbe_obtain_mbx_lock_pf(struct 
  *  returns SUCCESS if it successfully copied message into the buffer
  **/
 int32_t ixgbe_write_mbx_pf(struct ixgbe_hw *hw, uint32_t *msg, uint16_t size,
-			   uint16_t vf_number)
+			      uint16_t vf_number)
 {
 	int32_t ret_val;
 	uint16_t i;
@@ -4651,7 +6076,7 @@ out_no_write:
  *  a message due to a VF request so no polling for message is needed.
  **/
 int32_t ixgbe_read_mbx_pf(struct ixgbe_hw *hw, uint32_t *msg, uint16_t size,
-			  uint16_t vf_number)
+			     uint16_t vf_number)
 {
 	int32_t ret_val;
 	uint16_t i;
@@ -4690,6 +6115,7 @@ void ixgbe_init_mbx_params_pf(struct ixg
 	if (hw->mac.type != ixgbe_mac_82599EB &&
 	    hw->mac.type != ixgbe_mac_X550 &&
 	    hw->mac.type != ixgbe_mac_X550EM_x &&
+	    hw->mac.type != ixgbe_mac_X550EM_a &&
 	    hw->mac.type != ixgbe_mac_X540)
 		return;
 
@@ -4712,3 +6138,34 @@ void ixgbe_init_mbx_params_pf(struct ixg
 	mbx->stats.acks = 0;
 	mbx->stats.rsts = 0;
 }
+
+/* ? */
+
+/************************************************************************
+ * ixgbe_is_sfp
+ ************************************************************************/
+bool ixgbe_is_sfp(struct ixgbe_hw *hw)
+{
+	switch (hw->mac.type) {
+	case ixgbe_mac_82598EB:
+		if (hw->phy.type == ixgbe_phy_nl)
+			return (TRUE);
+		return (FALSE);
+	case ixgbe_mac_82599EB:
+		switch (hw->mac.ops.get_media_type(hw)) {
+		case ixgbe_media_type_fiber:
+		case ixgbe_media_type_fiber_qsfp:
+			return (TRUE);
+		default:
+			return (FALSE);
+		}
+	case ixgbe_mac_X550EM_x:
+	case ixgbe_mac_X550EM_a:
+		if (hw->mac.ops.get_media_type(hw) == ixgbe_media_type_fiber)
+			return (TRUE);
+		return (FALSE);
+	default:
+		return (FALSE);
+	}
+} /* ixgbe_is_sfp */
+
Index: ./dev/pci/ixgbe.h
===================================================================
RCS file: /cvs/src/sys/dev/pci/ixgbe.h,v
retrieving revision 1.26
diff -u -p -r1.26 ixgbe.h
--- ./dev/pci/ixgbe.h	17 Nov 2016 21:08:27 -0000	1.26
+++ ./dev/pci/ixgbe.h	17 Sep 2018 19:59:55 -0000
@@ -74,6 +74,10 @@ typedef int	boolean_t;
 #include <dev/pci/pcidevs.h>
 #include <dev/pci/ixgbe_type.h>
 
+#include <dev/pci/ixgbe_common.h>
+#include <dev/pci/ixgbe_dcb.h>
+#include <dev/pci/ixgbe_dcb_82599.h>
+
 #define DBG 0
 #define MSGOUT(S, A, B)     printf(S "\n", A, B)
 #define DEBUGFUNC(F)        DEBUGOUT(F);
@@ -104,6 +108,19 @@ typedef int	boolean_t;
 	#define ERROR_REPORT3(S,A,B,C)
 #endif
 
+#define UNUSED __attribute__((unused))
+#define ASSERT(x) if(!(x)) panic("IXGB: x")
+
+#define IXGBE_CPU_TO_LE16 htole16
+#define IXGBE_CPU_TO_LE32 htole32
+#define IXGBE_LE32_TO_CPU le32toh
+#define IXGBE_LE32_TO_CPUS(x)
+#define IXGBE_CPU_TO_BE16 htobe16
+#define IXGBE_CPU_TO_BE32 htobe32
+#define IXGBE_BE32_TO_CPU be32toh
+#define IXGBE_NTOHL(_i)	ntohl(_i)
+#define IXGBE_NTOHS(_i)	ntohs(_i)
+
 #define FALSE		    		0
 #define TRUE		    		1
 #define CMD_MEM_WRT_INVALIDATE          0x0010  /* BIT_4 */
@@ -215,9 +232,9 @@ int32_t ixgbe_clear_vmdq_generic(struct 
 int32_t ixgbe_insert_mac_addr_generic(struct ixgbe_hw *hw, uint8_t *addr, uint32_t vmdq);
 int32_t ixgbe_init_uta_tables_generic(struct ixgbe_hw *hw);
 int32_t ixgbe_set_vfta_generic(struct ixgbe_hw *hw, uint32_t vlan,
-			       uint32_t vind, bool vlan_on);
+			       uint32_t vind, bool vlan_on, bool);
 int32_t ixgbe_set_vlvf_generic(struct ixgbe_hw *hw, uint32_t vlan, uint32_t vind,
-			       bool vlan_on, bool *vfta_changed);
+			       bool vlan_on, uint32_t*, uint32_t, bool);
 int32_t ixgbe_clear_vfta_generic(struct ixgbe_hw *hw);
 
 int32_t ixgbe_check_mac_link_generic(struct ixgbe_hw *hw,
@@ -316,7 +333,6 @@ bool ixgbe_is_sfp(struct ixgbe_hw *hw);
 int32_t ixgbe_set_copper_phy_power(struct ixgbe_hw *hw, bool on);
 int32_t ixgbe_identify_module_generic(struct ixgbe_hw *hw);
 int32_t ixgbe_identify_sfp_module_generic(struct ixgbe_hw *hw);
-int32_t ixgbe_get_supported_phy_sfp_layer_generic(struct ixgbe_hw *hw);
 int32_t ixgbe_identify_qsfp_module_generic(struct ixgbe_hw *hw);
 int32_t ixgbe_get_sfp_init_sequence_offsets(struct ixgbe_hw *hw,
 					    uint16_t *list_offset,
Index: ./dev/pci/ixgbe_82598.c
===================================================================
RCS file: /cvs/src/sys/dev/pci/ixgbe_82598.c,v
retrieving revision 1.15
diff -u -p -r1.15 ixgbe_82598.c
--- ./dev/pci/ixgbe_82598.c	17 Nov 2016 19:26:57 -0000	1.15
+++ ./dev/pci/ixgbe_82598.c	17 Sep 2018 19:59:55 -0000
@@ -1,8 +1,7 @@
-/*	$OpenBSD: ixgbe_82598.c,v 1.15 2016/11/17 19:26:57 mikeb Exp $	*/
-
 /******************************************************************************
+  SPDX-License-Identifier: BSD-3-Clause
 
-  Copyright (c) 2001-2015, Intel Corporation
+  Copyright (c) 2001-2017, Intel Corporation
   All rights reserved.
 
   Redistribution and use in source and binary forms, with or without
@@ -32,10 +31,11 @@
   POSSIBILITY OF SUCH DAMAGE.
 
 ******************************************************************************/
-/*$FreeBSD: head/sys/dev/ixgbe/ixgbe_82598.c 292674 2015-12-23 22:45:17Z sbruno $*/
+/*$FreeBSD$*/
 
 #include <dev/pci/ixgbe.h>
 #include <dev/pci/ixgbe_type.h>
+#include <dev/pci/ixgbe_api.h>
 
 #define IXGBE_82598_MAX_TX_QUEUES 32
 #define IXGBE_82598_MAX_RX_QUEUES 64
@@ -44,39 +44,41 @@
 #define IXGBE_82598_VFT_TBL_SIZE 128
 #define IXGBE_82598_RX_PB_SIZE   512
 
-uint32_t ixgbe_get_pcie_msix_count_82598(struct ixgbe_hw *hw);
-int32_t ixgbe_get_link_capabilities_82598(struct ixgbe_hw *hw,
-					  ixgbe_link_speed *speed,
-					  bool *autoneg);
-enum ixgbe_media_type ixgbe_get_media_type_82598(struct ixgbe_hw *hw);
-int32_t ixgbe_fc_enable_82598(struct ixgbe_hw *hw);
-int32_t ixgbe_start_mac_link_82598(struct ixgbe_hw *hw,
-				   bool autoneg_wait_to_complete);
-int32_t ixgbe_validate_link_ready(struct ixgbe_hw *hw);
-int32_t ixgbe_check_mac_link_82598(struct ixgbe_hw *hw,
-				   ixgbe_link_speed *speed, bool *link_up,
-				   bool link_up_wait_to_complete);
-int32_t ixgbe_setup_mac_link_82598(struct ixgbe_hw *hw,
-				   ixgbe_link_speed speed,
-				   bool autoneg_wait_to_complete);
-int32_t ixgbe_setup_copper_link_82598(struct ixgbe_hw *hw,
+static int32_t ixgbe_get_link_capabilities_82598(struct ixgbe_hw *hw,
+					     ixgbe_link_speed *speed,
+					     bool *autoneg);
+static enum ixgbe_media_type ixgbe_get_media_type_82598(struct ixgbe_hw *hw);
+static int32_t ixgbe_start_mac_link_82598(struct ixgbe_hw *hw,
+				      bool autoneg_wait_to_complete);
+static int32_t ixgbe_check_mac_link_82598(struct ixgbe_hw *hw,
+				      ixgbe_link_speed *speed, bool *link_up,
+				      bool link_up_wait_to_complete);
+static int32_t ixgbe_setup_mac_link_82598(struct ixgbe_hw *hw,
 				      ixgbe_link_speed speed,
 				      bool autoneg_wait_to_complete);
-int32_t ixgbe_reset_hw_82598(struct ixgbe_hw *hw);
+static int32_t ixgbe_setup_copper_link_82598(struct ixgbe_hw *hw,
+					 ixgbe_link_speed speed,
+					 bool autoneg_wait_to_complete);
+static int32_t ixgbe_reset_hw_82598(struct ixgbe_hw *hw);
+static int32_t ixgbe_clear_vmdq_82598(struct ixgbe_hw *hw, uint32_t rar, uint32_t vmdq);
+static int32_t ixgbe_clear_vfta_82598(struct ixgbe_hw *hw);
+static void ixgbe_set_rxpba_82598(struct ixgbe_hw *hw, int num_pb,
+				  uint32_t headroom, int strategy);
+static int32_t ixgbe_read_i2c_sff8472_82598(struct ixgbe_hw *hw, uint8_t byte_offset,
+					uint8_t *sff8472_data);
+
+uint32_t ixgbe_get_pcie_msix_count_82598(struct ixgbe_hw *hw);
+int32_t ixgbe_fc_enable_82598(struct ixgbe_hw *hw);
 int32_t ixgbe_start_hw_82598(struct ixgbe_hw *hw);
 void ixgbe_enable_relaxed_ordering_82598(struct ixgbe_hw *hw);
 int32_t ixgbe_set_vmdq_82598(struct ixgbe_hw *hw, uint32_t rar, uint32_t vmdq);
-int32_t ixgbe_clear_vmdq_82598(struct ixgbe_hw *hw, uint32_t rar, uint32_t vmdq);
-int32_t ixgbe_set_vfta_82598(struct ixgbe_hw *hw, uint32_t vlan,
-			     uint32_t vind, bool vlan_on);
-int32_t ixgbe_clear_vfta_82598(struct ixgbe_hw *hw);
+int32_t ixgbe_set_vfta_82598(struct ixgbe_hw *hw, uint32_t vlan, uint32_t vind, bool vlan_on,
+			 bool vlvf_bypass);
 int32_t ixgbe_read_analog_reg8_82598(struct ixgbe_hw *hw, uint32_t reg, uint8_t *val);
 int32_t ixgbe_write_analog_reg8_82598(struct ixgbe_hw *hw, uint32_t reg, uint8_t val);
-int32_t ixgbe_read_i2c_phy_82598(struct ixgbe_hw *hw, uint8_t dev_addr,
-				 uint8_t byte_offset, uint8_t *eeprom_data);
 int32_t ixgbe_read_i2c_eeprom_82598(struct ixgbe_hw *hw, uint8_t byte_offset,
-				    uint8_t *eeprom_data);
-uint32_t ixgbe_get_supported_physical_layer_82598(struct ixgbe_hw *hw);
+				uint8_t *eeprom_data);
+uint64_t ixgbe_get_supported_physical_layer_82598(struct ixgbe_hw *hw);
 int32_t ixgbe_init_phy_ops_82598(struct ixgbe_hw *hw);
 void ixgbe_set_lan_id_multi_port_pcie_82598(struct ixgbe_hw *hw);
 void ixgbe_set_pcie_completion_timeout(struct ixgbe_hw *hw);
@@ -147,6 +149,7 @@ int32_t ixgbe_init_ops_82598(struct ixgb
 
 	/* MAC */
 	mac->ops.start_hw = ixgbe_start_hw_82598;
+	mac->ops.enable_relaxed_ordering = ixgbe_enable_relaxed_ordering_82598;
 	mac->ops.reset_hw = ixgbe_reset_hw_82598;
 	mac->ops.get_media_type = ixgbe_get_media_type_82598;
 	mac->ops.get_supported_physical_layer =
@@ -160,6 +163,7 @@ int32_t ixgbe_init_ops_82598(struct ixgb
 	mac->ops.set_vmdq = ixgbe_set_vmdq_82598;
 	mac->ops.clear_vmdq = ixgbe_clear_vmdq_82598;
 	mac->ops.set_vfta = ixgbe_set_vfta_82598;
+	mac->ops.set_vlvf = NULL;
 	mac->ops.clear_vfta = ixgbe_clear_vfta_82598;
 
 	/* Flow Control */
@@ -175,12 +179,19 @@ int32_t ixgbe_init_ops_82598(struct ixgb
 
 	/* SFP+ Module */
 	phy->ops.read_i2c_eeprom = ixgbe_read_i2c_eeprom_82598;
+	phy->ops.read_i2c_sff8472 = ixgbe_read_i2c_sff8472_82598;
 
 	/* Link */
 	mac->ops.check_link = ixgbe_check_mac_link_82598;
 	mac->ops.setup_link = ixgbe_setup_mac_link_82598;
 	mac->ops.flap_tx_laser = NULL;
 	mac->ops.get_link_capabilities = ixgbe_get_link_capabilities_82598;
+	mac->ops.setup_rxpba = ixgbe_set_rxpba_82598;
+
+	/* Manageability interface */
+	mac->ops.set_fw_drv_ver = NULL;
+
+	mac->ops.get_rtrup2tc = NULL;
 
 	return ret_val;
 }
@@ -254,7 +265,7 @@ out:
  *  @hw: pointer to hardware structure
  *
  *  Starts the hardware using the generic start_hw function.
- *  Disables relaxed ordering, then set pcie completion timeout
+ *  Disables relaxed ordering Then set pcie completion timeout
  *
  **/
 int32_t ixgbe_start_hw_82598(struct ixgbe_hw *hw)
@@ -299,9 +310,9 @@ int32_t ixgbe_start_hw_82598(struct ixgb
  *
  *  Determines the link capabilities by reading the AUTOC register.
  **/
-int32_t ixgbe_get_link_capabilities_82598(struct ixgbe_hw *hw,
-					  ixgbe_link_speed *speed,
-					  bool *autoneg)
+static int32_t ixgbe_get_link_capabilities_82598(struct ixgbe_hw *hw,
+					     ixgbe_link_speed *speed,
+					     bool *autoneg)
 {
 	int32_t status = IXGBE_SUCCESS;
 	uint32_t autoc = 0;
@@ -358,7 +369,7 @@ int32_t ixgbe_get_link_capabilities_8259
  *
  *  Returns the media type (fiber, copper, backplane)
  **/
-enum ixgbe_media_type ixgbe_get_media_type_82598(struct ixgbe_hw *hw)
+static enum ixgbe_media_type ixgbe_get_media_type_82598(struct ixgbe_hw *hw)
 {
 	enum ixgbe_media_type media_type;
 
@@ -555,12 +566,13 @@ out:
 /**
  *  ixgbe_start_mac_link_82598 - Configures MAC link settings
  *  @hw: pointer to hardware structure
+ *  @autoneg_wait_to_complete: TRUE when waiting for completion is needed
  *
  *  Configures link settings based on values in the ixgbe_hw struct.
  *  Restarts the link.  Performs autonegotiation if needed.
  **/
-int32_t ixgbe_start_mac_link_82598(struct ixgbe_hw *hw,
-				   bool autoneg_wait_to_complete)
+static int32_t ixgbe_start_mac_link_82598(struct ixgbe_hw *hw,
+				      bool autoneg_wait_to_complete)
 {
 	uint32_t autoc_reg;
 	uint32_t links_reg;
@@ -607,7 +619,7 @@ int32_t ixgbe_start_mac_link_82598(struc
  *  Function indicates success when phy link is available. If phy is not ready
  *  within 5 seconds of MAC indicating link, the function returns error.
  **/
-int32_t ixgbe_validate_link_ready(struct ixgbe_hw *hw)
+static int32_t ixgbe_validate_link_ready(struct ixgbe_hw *hw)
 {
 	uint32_t timeout;
 	uint16_t an_reg;
@@ -644,9 +656,9 @@ int32_t ixgbe_validate_link_ready(struct
  *
  *  Reads the links register to determine if link is up and the current speed
  **/
-int32_t ixgbe_check_mac_link_82598(struct ixgbe_hw *hw,
-				   ixgbe_link_speed *speed, bool *link_up,
-				   bool link_up_wait_to_complete)
+static int32_t ixgbe_check_mac_link_82598(struct ixgbe_hw *hw,
+				      ixgbe_link_speed *speed, bool *link_up,
+				      bool link_up_wait_to_complete)
 {
 	uint32_t links_reg;
 	uint32_t i;
@@ -733,9 +745,9 @@ out:
  *
  *  Set the link speed in the AUTOC register and restarts link.
  **/
-int32_t ixgbe_setup_mac_link_82598(struct ixgbe_hw *hw,
-				   ixgbe_link_speed speed,
-				   bool autoneg_wait_to_complete)
+static int32_t ixgbe_setup_mac_link_82598(struct ixgbe_hw *hw,
+				      ixgbe_link_speed speed,
+				      bool autoneg_wait_to_complete)
 {
 	bool autoneg = FALSE;
 	int32_t status = IXGBE_SUCCESS;
@@ -747,7 +759,7 @@ int32_t ixgbe_setup_mac_link_82598(struc
 	DEBUGFUNC("ixgbe_setup_mac_link_82598");
 
 	/* Check to see if speed passed in is supported. */
-	ixgbe_get_link_capabilities_82598(hw, &link_capabilities, &autoneg);
+	ixgbe_get_link_capabilities(hw, &link_capabilities, &autoneg);
 	speed &= link_capabilities;
 
 	if (speed == IXGBE_LINK_SPEED_UNKNOWN)
@@ -787,9 +799,9 @@ int32_t ixgbe_setup_mac_link_82598(struc
  *
  *  Sets the link speed in the AUTOC register in the MAC and restarts link.
  **/
-int32_t ixgbe_setup_copper_link_82598(struct ixgbe_hw *hw,
-				      ixgbe_link_speed speed,
-				      bool autoneg_wait_to_complete)
+static int32_t ixgbe_setup_copper_link_82598(struct ixgbe_hw *hw,
+					 ixgbe_link_speed speed,
+					 bool autoneg_wait_to_complete)
 {
 	int32_t status;
 
@@ -812,7 +824,7 @@ int32_t ixgbe_setup_copper_link_82598(st
  *  clears all interrupts, performing a PHY reset, and performing a link (MAC)
  *  reset.
  **/
-int32_t ixgbe_reset_hw_82598(struct ixgbe_hw *hw)
+static int32_t ixgbe_reset_hw_82598(struct ixgbe_hw *hw)
 {
 	int32_t status = IXGBE_SUCCESS;
 	int32_t phy_status = IXGBE_SUCCESS;
@@ -974,7 +986,7 @@ int32_t ixgbe_set_vmdq_82598(struct ixgb
  *  @rar: receive address register index to associate with a VMDq index
  *  @vmdq: VMDq clear index (not used in 82598, but elsewhere)
  **/
-int32_t ixgbe_clear_vmdq_82598(struct ixgbe_hw *hw, uint32_t rar, uint32_t vmdq)
+static int32_t ixgbe_clear_vmdq_82598(struct ixgbe_hw *hw, uint32_t rar, UNUSED uint32_t vmdq)
 {
 	uint32_t rar_high;
 	uint32_t rar_entries = hw->mac.num_rar_entries;
@@ -1000,11 +1012,12 @@ int32_t ixgbe_clear_vmdq_82598(struct ix
  *  @vlan: VLAN id to write to VLAN filter
  *  @vind: VMDq output index that maps queue to VLAN id in VFTA
  *  @vlan_on: boolean flag to turn on/off VLAN in VFTA
+ *  @vlvf_bypass: boolean flag - unused
  *
  *  Turn on/off specified VLAN in the VLAN filter table.
  **/
 int32_t ixgbe_set_vfta_82598(struct ixgbe_hw *hw, uint32_t vlan, uint32_t vind,
-			     bool vlan_on)
+			 bool vlan_on, UNUSED bool vlvf_bypass)
 {
 	uint32_t regindex;
 	uint32_t bitindex;
@@ -1050,7 +1063,7 @@ int32_t ixgbe_set_vfta_82598(struct ixgb
  *
  *  Clears the VLAN filer table, and the VMDq index associated with the filter
  **/
-int32_t ixgbe_clear_vfta_82598(struct ixgbe_hw *hw)
+static int32_t ixgbe_clear_vfta_82598(struct ixgbe_hw *hw)
 {
 	uint32_t offset;
 	uint32_t vlanbyte;
@@ -1123,8 +1136,8 @@ int32_t ixgbe_write_analog_reg8_82598(st
  *
  *  Performs 8 byte read operation to SFP module's EEPROM over I2C interface.
  **/
-int32_t ixgbe_read_i2c_phy_82598(struct ixgbe_hw *hw, uint8_t dev_addr,
-				 uint8_t byte_offset, uint8_t *eeprom_data)
+static int32_t ixgbe_read_i2c_phy_82598(struct ixgbe_hw *hw, uint8_t dev_addr,
+				    uint8_t byte_offset, uint8_t *eeprom_data)
 {
 	int32_t status = IXGBE_SUCCESS;
 	uint16_t sfp_addr = 0;
@@ -1197,21 +1210,36 @@ out:
  *  Performs 8 byte read operation to SFP module's EEPROM over I2C interface.
  **/
 int32_t ixgbe_read_i2c_eeprom_82598(struct ixgbe_hw *hw, uint8_t byte_offset,
-				    uint8_t *eeprom_data)
+				uint8_t *eeprom_data)
 {
 	return ixgbe_read_i2c_phy_82598(hw, IXGBE_I2C_EEPROM_DEV_ADDR,
 					byte_offset, eeprom_data);
 }
 
 /**
+ *  ixgbe_read_i2c_sff8472_82598 - Reads 8 bit word over I2C interface.
+ *  @hw: pointer to hardware structure
+ *  @byte_offset: byte offset at address 0xA2
+ *  @sff8472_data: value read
+ *
+ *  Performs 8 byte read operation to SFP module's SFF-8472 data over I2C
+ **/
+static int32_t ixgbe_read_i2c_sff8472_82598(struct ixgbe_hw *hw, uint8_t byte_offset,
+					uint8_t *sff8472_data)
+{
+	return ixgbe_read_i2c_phy_82598(hw, IXGBE_I2C_EEPROM_DEV_ADDR2,
+					byte_offset, sff8472_data);
+}
+
+/**
  *  ixgbe_get_supported_physical_layer_82598 - Returns physical layer type
  *  @hw: pointer to hardware structure
  *
  *  Determines physical layer capabilities of the current configuration.
  **/
-uint32_t ixgbe_get_supported_physical_layer_82598(struct ixgbe_hw *hw)
+uint64_t ixgbe_get_supported_physical_layer_82598(struct ixgbe_hw *hw)
 {
-	uint32_t physical_layer = IXGBE_PHYSICAL_LAYER_UNKNOWN;
+	uint64_t physical_layer = IXGBE_PHYSICAL_LAYER_UNKNOWN;
 	uint32_t autoc = IXGBE_READ_REG(hw, IXGBE_AUTOC);
 	uint32_t pma_pmd_10g = autoc & IXGBE_AUTOC_10G_PMA_PMD_MASK;
 	uint32_t pma_pmd_1g = autoc & IXGBE_AUTOC_1G_PMA_PMD_MASK;
@@ -1252,14 +1280,8 @@ uint32_t ixgbe_get_supported_physical_la
 			physical_layer = IXGBE_PHYSICAL_LAYER_10GBASE_CX4;
 		else if (pma_pmd_10g == IXGBE_AUTOC_10G_KX4)
 			physical_layer = IXGBE_PHYSICAL_LAYER_10GBASE_KX4;
-		else { /* XAUI */
-			if (autoc & IXGBE_AUTOC_KX_SUPP)
-				physical_layer |=
-				    IXGBE_PHYSICAL_LAYER_1000BASE_KX;
-			if (autoc & IXGBE_AUTOC_KX4_SUPP)
-				physical_layer |=
-				    IXGBE_PHYSICAL_LAYER_10GBASE_KX4;
-		}
+		else /* XAUI */
+			physical_layer = IXGBE_PHYSICAL_LAYER_UNKNOWN;
 		break;
 	case IXGBE_AUTOC_LMS_KX4_AN:
 	case IXGBE_AUTOC_LMS_KX4_AN_1G_AN:
@@ -1343,6 +1365,75 @@ void ixgbe_set_lan_id_multi_port_pcie_82
 			bus->func = 0;
 		}
 	}
+}
+
+/**
+ *  ixgbe_enable_relaxed_ordering_82598 - enable relaxed ordering
+ *  @hw: pointer to hardware structure
+ *
+ **/
+void ixgbe_enable_relaxed_ordering_82598(struct ixgbe_hw *hw)
+{
+	uint32_t regval;
+	uint32_t i;
+
+	DEBUGFUNC("ixgbe_enable_relaxed_ordering_82598");
+
+	/* Enable relaxed ordering */
+	for (i = 0; ((i < hw->mac.max_tx_queues) &&
+	     (i < IXGBE_DCA_MAX_QUEUES_82598)); i++) {
+		regval = IXGBE_READ_REG(hw, IXGBE_DCA_TXCTRL(i));
+		regval |= IXGBE_DCA_TXCTRL_DESC_WRO_EN;
+		IXGBE_WRITE_REG(hw, IXGBE_DCA_TXCTRL(i), regval);
+	}
+
+	for (i = 0; ((i < hw->mac.max_rx_queues) &&
+	     (i < IXGBE_DCA_MAX_QUEUES_82598)); i++) {
+		regval = IXGBE_READ_REG(hw, IXGBE_DCA_RXCTRL(i));
+		regval |= IXGBE_DCA_RXCTRL_DATA_WRO_EN |
+			  IXGBE_DCA_RXCTRL_HEAD_WRO_EN;
+		IXGBE_WRITE_REG(hw, IXGBE_DCA_RXCTRL(i), regval);
+	}
+
+}
+
+/**
+ * ixgbe_set_rxpba_82598 - Initialize RX packet buffer
+ * @hw: pointer to hardware structure
+ * @num_pb: number of packet buffers to allocate
+ * @headroom: reserve n KB of headroom
+ * @strategy: packet buffer allocation strategy
+ **/
+static void ixgbe_set_rxpba_82598(struct ixgbe_hw *hw, int num_pb,
+				  UNUSED uint32_t headroom, int strategy)
+{
+	uint32_t rxpktsize = IXGBE_RXPBSIZE_64KB;
+	uint8_t i = 0;
+
+	if (!num_pb)
+		return;
+
+	/* Setup Rx packet buffer sizes */
+	switch (strategy) {
+	case PBA_STRATEGY_WEIGHTED:
+		/* Setup the first four at 80KB */
+		rxpktsize = IXGBE_RXPBSIZE_80KB;
+		for (; i < 4; i++)
+			IXGBE_WRITE_REG(hw, IXGBE_RXPBSIZE(i), rxpktsize);
+		/* Setup the last four at 48KB...don't re-init i */
+		rxpktsize = IXGBE_RXPBSIZE_48KB;
+		/* Fall Through */
+	case PBA_STRATEGY_EQUAL:
+	default:
+		/* Divide the remaining Rx packet buffer evenly among the TCs */
+		for (; i < IXGBE_MAX_PACKET_BUFFERS; i++)
+			IXGBE_WRITE_REG(hw, IXGBE_RXPBSIZE(i), rxpktsize);
+		break;
+	}
+
+	/* Setup Tx packet buffer sizes */
+	for (i = 0; i < IXGBE_MAX_PACKET_BUFFERS; i++)
+		IXGBE_WRITE_REG(hw, IXGBE_TXPBSIZE(i), IXGBE_TXPBSIZE_40KB);
 }
 
 /**
Index: ./dev/pci/ixgbe_82599.c
===================================================================
RCS file: /cvs/src/sys/dev/pci/ixgbe_82599.c,v
retrieving revision 1.16
diff -u -p -r1.16 ixgbe_82599.c
--- ./dev/pci/ixgbe_82599.c	17 Nov 2016 21:08:27 -0000	1.16
+++ ./dev/pci/ixgbe_82599.c	17 Sep 2018 19:59:55 -0000
@@ -1,8 +1,7 @@
-/*	$OpenBSD: ixgbe_82599.c,v 1.16 2016/11/17 21:08:27 mikeb Exp $	*/
-
 /******************************************************************************
+  SPDX-License-Identifier: BSD-3-Clause
 
-  Copyright (c) 2001-2015, Intel Corporation
+  Copyright (c) 2001-2017, Intel Corporation
   All rights reserved.
 
   Redistribution and use in source and binary forms, with or without
@@ -32,10 +31,12 @@
   POSSIBILITY OF SUCH DAMAGE.
 
 ******************************************************************************/
-/*$FreeBSD: head/sys/dev/ixgbe/ixgbe_82599.c 292674 2015-12-23 22:45:17Z sbruno $*/
+/*$FreeBSD$*/
 
 #include <dev/pci/ixgbe.h>
 #include <dev/pci/ixgbe_type.h>
+#include <dev/pci/ixgbe_api.h>
+#include <dev/pci/ixgbe_phy.h>
 
 #define IXGBE_82599_MAX_TX_QUEUES 128
 #define IXGBE_82599_MAX_RX_QUEUES 128
@@ -44,53 +45,46 @@
 #define IXGBE_82599_VFT_TBL_SIZE  128
 #define IXGBE_82599_RX_PB_SIZE	  512
 
+static int32_t ixgbe_setup_copper_link_82599(struct ixgbe_hw *hw,
+					 ixgbe_link_speed speed,
+					 bool autoneg_wait_to_complete);
+static int32_t ixgbe_verify_fw_version_82599(struct ixgbe_hw *hw);
+static int32_t ixgbe_read_eeprom_82599(struct ixgbe_hw *hw,
+				   uint16_t offset, uint16_t *data);
+static int32_t ixgbe_read_eeprom_buffer_82599(struct ixgbe_hw *hw, uint16_t offset,
+					  uint16_t words, uint16_t *data);
+static int32_t ixgbe_read_i2c_byte_82599(struct ixgbe_hw *hw, uint8_t byte_offset,
+					uint8_t dev_addr, uint8_t *data);
+static int32_t ixgbe_write_i2c_byte_82599(struct ixgbe_hw *hw, uint8_t byte_offset,
+					uint8_t dev_addr, uint8_t data);
+
 int32_t ixgbe_get_link_capabilities_82599(struct ixgbe_hw *hw,
-					  ixgbe_link_speed *speed,
-					  bool *autoneg);
+				      ixgbe_link_speed *speed, bool *autoneg);
 enum ixgbe_media_type ixgbe_get_media_type_82599(struct ixgbe_hw *hw);
 void ixgbe_disable_tx_laser_multispeed_fiber(struct ixgbe_hw *hw);
 void ixgbe_enable_tx_laser_multispeed_fiber(struct ixgbe_hw *hw);
 void ixgbe_flap_tx_laser_multispeed_fiber(struct ixgbe_hw *hw);
 void ixgbe_set_hard_rate_select_speed(struct ixgbe_hw *hw,
-				      ixgbe_link_speed speed);
+					ixgbe_link_speed speed);
 int32_t ixgbe_setup_mac_link_smartspeed(struct ixgbe_hw *hw,
-					ixgbe_link_speed speed,
-					bool autoneg_wait_to_complete);
+				    ixgbe_link_speed speed,
+				    bool autoneg_wait_to_complete);
 int32_t ixgbe_start_mac_link_82599(struct ixgbe_hw *hw,
-				   bool autoneg_wait_to_complete);
-int32_t ixgbe_setup_mac_link_82599(struct ixgbe_hw *hw,
-				   ixgbe_link_speed speed,
-				   bool autoneg_wait_to_complete);
+			       bool autoneg_wait_to_complete);
+int32_t ixgbe_setup_mac_link_82599(struct ixgbe_hw *hw, ixgbe_link_speed speed,
+			       bool autoneg_wait_to_complete);
 int32_t ixgbe_setup_sfp_modules_82599(struct ixgbe_hw *hw);
 void ixgbe_init_mac_link_ops_82599(struct ixgbe_hw *hw);
 int32_t ixgbe_reset_hw_82599(struct ixgbe_hw *hw);
-int32_t ixgbe_read_analog_reg8_82599(struct ixgbe_hw *hw, uint32_t reg,
-				     uint8_t *val);
-int32_t ixgbe_write_analog_reg8_82599(struct ixgbe_hw *hw, uint32_t reg,
-				      uint8_t val);
+int32_t ixgbe_read_analog_reg8_82599(struct ixgbe_hw *hw, uint32_t reg, uint8_t *val);
+int32_t ixgbe_write_analog_reg8_82599(struct ixgbe_hw *hw, uint32_t reg, uint8_t val);
 int32_t ixgbe_start_hw_82599(struct ixgbe_hw *hw);
 int32_t ixgbe_identify_phy_82599(struct ixgbe_hw *hw);
 int32_t ixgbe_init_phy_ops_82599(struct ixgbe_hw *hw);
-uint32_t ixgbe_get_supported_physical_layer_82599(struct ixgbe_hw *hw);
+uint64_t ixgbe_get_supported_physical_layer_82599(struct ixgbe_hw *hw);
 int32_t ixgbe_enable_rx_dma_82599(struct ixgbe_hw *hw, uint32_t regval);
-int32_t prot_autoc_read_82599(struct ixgbe_hw *, bool *locked, uint32_t *reg_val);
-int32_t prot_autoc_write_82599(struct ixgbe_hw *, uint32_t reg_val, bool locked);
-
-void ixgbe_stop_mac_link_on_d3_82599(struct ixgbe_hw *hw);
-
-int32_t ixgbe_setup_copper_link_82599(struct ixgbe_hw *hw,
-				      ixgbe_link_speed speed,
-				      bool autoneg_wait_to_complete);
-
-int32_t ixgbe_verify_fw_version_82599(struct ixgbe_hw *hw);
-bool ixgbe_verify_lesm_fw_enabled_82599(struct ixgbe_hw *hw);
-int32_t ixgbe_reset_pipeline_82599(struct ixgbe_hw *hw);
-int32_t ixgbe_read_eeprom_82599(struct ixgbe_hw *hw,
-				uint16_t offset, uint16_t *data);
-int32_t ixgbe_read_i2c_byte_82599(struct ixgbe_hw *hw, uint8_t byte_offset,
-				  uint8_t dev_addr, uint8_t *data);
-int32_t ixgbe_write_i2c_byte_82599(struct ixgbe_hw *hw, uint8_t byte_offset,
-				   uint8_t dev_addr, uint8_t data);
+int32_t prot_autoc_read_82599(struct ixgbe_hw *hw, bool *locked, uint32_t *reg_val);
+int32_t prot_autoc_write_82599(struct ixgbe_hw *hw, uint32_t reg_val, bool locked);
 
 void ixgbe_init_mac_link_ops_82599(struct ixgbe_hw *hw)
 {
@@ -281,8 +275,7 @@ setup_sfp_err:
  *  FW/SW lock.  It is assumed this lock will be freed with the next
  *  prot_autoc_write_82599().
  */
-int32_t prot_autoc_read_82599(struct ixgbe_hw *hw, bool *locked,
-    uint32_t *reg_val)
+int32_t prot_autoc_read_82599(struct ixgbe_hw *hw, bool *locked, uint32_t *reg_val)
 {
 	int32_t ret_val;
 
@@ -304,7 +297,7 @@ int32_t prot_autoc_read_82599(struct ixg
 /**
  * prot_autoc_write_82599 - Hides MAC differences needed for AUTOC write
  * @hw: pointer to hardware structure
- * @reg_val: value to write to AUTOC
+ * @autoc: value to write to AUTOC
  * @locked: bool to indicate whether the SW/FW lock was already taken by
  *           previous proc_autoc_read_82599.
  *
@@ -362,7 +355,7 @@ int32_t ixgbe_init_ops_82599(struct ixgb
 
 	DEBUGFUNC("ixgbe_init_ops_82599");
 
-	ret_val = ixgbe_init_phy_ops_generic(hw);
+	ixgbe_init_phy_ops_generic(hw);
 	ret_val = ixgbe_init_ops_generic(hw);
 
 	/* PHY */
@@ -371,6 +364,7 @@ int32_t ixgbe_init_ops_82599(struct ixgb
 
 	/* MAC */
 	mac->ops.reset_hw = ixgbe_reset_hw_82599;
+	mac->ops.enable_relaxed_ordering = ixgbe_enable_relaxed_ordering_gen2;
 	mac->ops.get_media_type = ixgbe_get_media_type_82599;
 	mac->ops.get_supported_physical_layer =
 				    ixgbe_get_supported_physical_layer_82599;
@@ -380,12 +374,17 @@ int32_t ixgbe_init_ops_82599(struct ixgb
 	mac->ops.read_analog_reg8 = ixgbe_read_analog_reg8_82599;
 	mac->ops.write_analog_reg8 = ixgbe_write_analog_reg8_82599;
 	mac->ops.start_hw = ixgbe_start_hw_82599;
-
+	mac->ops.get_san_mac_addr = ixgbe_get_san_mac_addr_generic;
+	mac->ops.set_san_mac_addr = ixgbe_set_san_mac_addr_generic;
+	mac->ops.get_device_caps = ixgbe_get_device_caps_generic;
+	mac->ops.get_wwn_prefix = ixgbe_get_wwn_prefix_generic;
+	mac->ops.get_fcoe_boot_status = ixgbe_get_fcoe_boot_status_generic;
 	mac->ops.prot_autoc_read = prot_autoc_read_82599;
 	mac->ops.prot_autoc_write = prot_autoc_write_82599;
 
 	/* RAR, Multicast, VLAN */
 	mac->ops.set_vmdq = ixgbe_set_vmdq_generic;
+	mac->ops.set_vmdq_san_mac = ixgbe_set_vmdq_san_mac_generic;
 	mac->ops.clear_vmdq = ixgbe_clear_vmdq_generic;
 	mac->ops.insert_mac_addr = ixgbe_insert_mac_addr_generic;
 	mac->rar_highwater = 1;
@@ -394,11 +393,13 @@ int32_t ixgbe_init_ops_82599(struct ixgb
 	mac->ops.clear_vfta = ixgbe_clear_vfta_generic;
 	mac->ops.init_uta_tables = ixgbe_init_uta_tables_generic;
 	mac->ops.setup_sfp = ixgbe_setup_sfp_modules_82599;
+	mac->ops.set_mac_anti_spoofing = ixgbe_set_mac_anti_spoofing;
+	mac->ops.set_vlan_anti_spoofing = ixgbe_set_vlan_anti_spoofing;
 
 	/* Link */
 	mac->ops.get_link_capabilities = ixgbe_get_link_capabilities_82599;
 	mac->ops.check_link = ixgbe_check_mac_link_generic;
-	mac->ops.stop_mac_link_on_d3 = ixgbe_stop_mac_link_on_d3_82599;
+	mac->ops.setup_rxpba = ixgbe_set_rxpba_generic;
 	ixgbe_init_mac_link_ops_82599(hw);
 
 	mac->mcft_size		= IXGBE_82599_MC_TBL_SIZE;
@@ -407,12 +408,26 @@ int32_t ixgbe_init_ops_82599(struct ixgb
 	mac->rx_pb_size		= IXGBE_82599_RX_PB_SIZE;
 	mac->max_rx_queues	= IXGBE_82599_MAX_RX_QUEUES;
 	mac->max_tx_queues	= IXGBE_82599_MAX_TX_QUEUES;
-	mac->max_msix_vectors	= 0 /*ixgbe_get_pcie_msix_count_generic(hw)*/;
+	mac->max_msix_vectors	= ixgbe_get_pcie_msix_count_generic(hw);
+
+	mac->arc_subsystem_valid = !!(IXGBE_READ_REG(hw, IXGBE_FWSM_BY_MAC(hw))
+				      & IXGBE_FWSM_MODE_MASK);
 
 	hw->mbx.ops.init_params = ixgbe_init_mbx_params_pf;
 
 	/* EEPROM */
 	eeprom->ops.read = ixgbe_read_eeprom_82599;
+	eeprom->ops.read_buffer = ixgbe_read_eeprom_buffer_82599;
+
+	/* Manageability interface */
+	mac->ops.set_fw_drv_ver = ixgbe_set_fw_drv_ver_generic;
+
+	mac->ops.bypass_rw = ixgbe_bypass_rw_generic;
+	mac->ops.bypass_valid_rd = ixgbe_bypass_valid_rd_generic;
+	mac->ops.bypass_set = ixgbe_bypass_set_generic;
+	mac->ops.bypass_rd_eep = ixgbe_bypass_rd_eep_generic;
+
+	mac->ops.get_rtrup2tc = ixgbe_dcb_get_rtrup2tc_generic;
 
 	return ret_val;
 }
@@ -434,6 +449,7 @@ int32_t ixgbe_get_link_capabilities_8259
 
 	DEBUGFUNC("ixgbe_get_link_capabilities_82599");
 
+
 	/* Check if 1G SFP module. */
 	if (hw->phy.sfp_type == ixgbe_sfp_type_1g_cu_core0 ||
 	    hw->phy.sfp_type == ixgbe_sfp_type_1g_cu_core1 ||
@@ -602,10 +618,10 @@ void ixgbe_stop_mac_link_on_d3_82599(str
 	uint16_t ee_ctrl_2 = 0;
 
 	DEBUGFUNC("ixgbe_stop_mac_link_on_d3_82599");
-	ixgbe_read_eeprom_82599(hw, IXGBE_EEPROM_CTRL_2, &ee_ctrl_2);
+	ixgbe_read_eeprom(hw, IXGBE_EEPROM_CTRL_2, &ee_ctrl_2);
 
-	if (!ixgbe_mng_present(hw) &&
-	    (ee_ctrl_2 & IXGBE_EEPROM_CCD_BIT)) {
+	if (!ixgbe_mng_present(hw) && !hw->wol_enabled &&
+	    ee_ctrl_2 & IXGBE_EEPROM_CCD_BIT) {
 		autoc2_reg = IXGBE_READ_REG(hw, IXGBE_AUTOC2);
 		autoc2_reg |= IXGBE_AUTOC2_LINK_DISABLE_ON_D3_MASK;
 		IXGBE_WRITE_REG(hw, IXGBE_AUTOC2, autoc2_reg);
@@ -621,7 +637,7 @@ void ixgbe_stop_mac_link_on_d3_82599(str
  *  Restarts the link.  Performs autonegotiation if needed.
  **/
 int32_t ixgbe_start_mac_link_82599(struct ixgbe_hw *hw,
-				   bool autoneg_wait_to_complete)
+			       bool autoneg_wait_to_complete)
 {
 	uint32_t autoc_reg;
 	uint32_t links_reg;
@@ -757,7 +773,7 @@ void ixgbe_flap_tx_laser_multispeed_fibe
  *  Set module link speed via RS0/RS1 rate select pins.
  */
 void ixgbe_set_hard_rate_select_speed(struct ixgbe_hw *hw,
-				      ixgbe_link_speed speed)
+					ixgbe_link_speed speed)
 {
 	uint32_t esdp_reg = IXGBE_READ_REG(hw, IXGBE_ESDP);
 
@@ -787,8 +803,8 @@ void ixgbe_set_hard_rate_select_speed(st
  *  Implements the Intel SmartSpeed algorithm.
  **/
 int32_t ixgbe_setup_mac_link_smartspeed(struct ixgbe_hw *hw,
-					ixgbe_link_speed speed,
-					bool autoneg_wait_to_complete)
+				    ixgbe_link_speed speed,
+				    bool autoneg_wait_to_complete)
 {
 	int32_t status = IXGBE_SUCCESS;
 	ixgbe_link_speed link_speed = IXGBE_LINK_SPEED_UNKNOWN;
@@ -899,18 +915,15 @@ out:
  *  Set the link speed in the AUTOC register and restarts link.
  **/
 int32_t ixgbe_setup_mac_link_82599(struct ixgbe_hw *hw,
-				   ixgbe_link_speed speed,
-				   bool autoneg_wait_to_complete)
+			       ixgbe_link_speed speed,
+			       bool autoneg_wait_to_complete)
 {
 	bool autoneg = FALSE;
 	int32_t status = IXGBE_SUCCESS;
 	uint32_t pma_pmd_1g, link_mode;
-	/* holds the value of AUTOC register at this current point in time */
-	uint32_t current_autoc = IXGBE_READ_REG(hw, IXGBE_AUTOC);
-	/* holds the cached value of AUTOC register */
-	uint32_t orig_autoc = 0;
-	/* Temporary variable used for comparison purposes */
-	uint32_t autoc = current_autoc;
+	uint32_t current_autoc = IXGBE_READ_REG(hw, IXGBE_AUTOC); /* holds the value of AUTOC register at this current point in time */
+	uint32_t orig_autoc = 0; /* holds the cached value of AUTOC register */
+	uint32_t autoc = current_autoc; /* Temporary variable used for comparison purposes */
 	uint32_t autoc2 = IXGBE_READ_REG(hw, IXGBE_AUTOC2);
 	uint32_t pma_pmd_10g_serial = autoc2 & IXGBE_AUTOC2_10G_SERIAL_PMA_PMD_MASK;
 	uint32_t links_reg;
@@ -920,8 +933,7 @@ int32_t ixgbe_setup_mac_link_82599(struc
 	DEBUGFUNC("ixgbe_setup_mac_link_82599");
 
 	/* Check to see if speed passed in is supported. */
-	status = ixgbe_get_link_capabilities_82599(hw, &link_capabilities,
-	    &autoneg);
+	status = ixgbe_get_link_capabilities(hw, &link_capabilities, &autoneg);
 	if (status)
 		goto out;
 
@@ -1020,9 +1032,9 @@ out:
  *
  *  Restarts link on PHY and MAC based on settings passed in.
  **/
-int32_t ixgbe_setup_copper_link_82599(struct ixgbe_hw *hw,
-				      ixgbe_link_speed speed,
-				      bool autoneg_wait_to_complete)
+static int32_t ixgbe_setup_copper_link_82599(struct ixgbe_hw *hw,
+					 ixgbe_link_speed speed,
+					 bool autoneg_wait_to_complete)
 {
 	int32_t status;
 
@@ -1158,7 +1170,8 @@ mac_reset_top:
 		 * Likewise if we support WoL we don't want change the
 		 * LMS state.
 		 */
-		if (hw->phy.multispeed_fiber && ixgbe_mng_enabled(hw))
+		if ((hw->phy.multispeed_fiber && ixgbe_mng_enabled(hw)) ||
+		    hw->wol_enabled)
 			hw->mac.orig_autoc =
 				(hw->mac.orig_autoc & ~IXGBE_AUTOC_LMS_MASK) |
 				curr_lms;
@@ -1191,11 +1204,891 @@ mac_reset_top:
 	hw->mac.num_rar_entries = 128;
 	hw->mac.ops.init_rx_addrs(hw);
 
+	/* Store the permanent SAN mac address */
+	hw->mac.ops.get_san_mac_addr(hw, hw->mac.san_addr);
+
+	/* Add the SAN MAC address to the RAR only if it's a valid address */
+	if (ixgbe_validate_mac_addr(hw->mac.san_addr) == 0) {
+		/* Save the SAN MAC RAR index */
+		hw->mac.san_mac_rar_index = hw->mac.num_rar_entries - 1;
+
+		hw->mac.ops.set_rar(hw, hw->mac.san_mac_rar_index,
+				    hw->mac.san_addr, 0, IXGBE_RAH_AV);
+
+		/* clear VMDq pool/queue selection for this RAR */
+		hw->mac.ops.clear_vmdq(hw, hw->mac.san_mac_rar_index,
+				       IXGBE_CLEAR_VMDQ_ALL);
+
+		/* Reserve the last RAR for the SAN MAC address */
+		hw->mac.num_rar_entries--;
+	}
+
+	/* Store the alternative WWNN/WWPN prefix */
+	hw->mac.ops.get_wwn_prefix(hw, &hw->mac.wwnn_prefix,
+				   &hw->mac.wwpn_prefix);
+
 reset_hw_out:
 	return status;
 }
 
 /**
+ * ixgbe_fdir_check_cmd_complete - poll to check whether FDIRCMD is complete
+ * @hw: pointer to hardware structure
+ * @fdircmd: current value of FDIRCMD register
+ */
+static int32_t ixgbe_fdir_check_cmd_complete(struct ixgbe_hw *hw, uint32_t *fdircmd)
+{
+	int i;
+
+	for (i = 0; i < IXGBE_FDIRCMD_CMD_POLL; i++) {
+		*fdircmd = IXGBE_READ_REG(hw, IXGBE_FDIRCMD);
+		if (!(*fdircmd & IXGBE_FDIRCMD_CMD_MASK))
+			return IXGBE_SUCCESS;
+		usec_delay(10);
+	}
+
+	return IXGBE_ERR_FDIR_CMD_INCOMPLETE;
+}
+
+/**
+ *  ixgbe_reinit_fdir_tables_82599 - Reinitialize Flow Director tables.
+ *  @hw: pointer to hardware structure
+ **/
+int32_t ixgbe_reinit_fdir_tables_82599(struct ixgbe_hw *hw)
+{
+	int32_t err;
+	int i;
+	uint32_t fdirctrl = IXGBE_READ_REG(hw, IXGBE_FDIRCTRL);
+	uint32_t fdircmd;
+	fdirctrl &= ~IXGBE_FDIRCTRL_INIT_DONE;
+
+	DEBUGFUNC("ixgbe_reinit_fdir_tables_82599");
+
+	/*
+	 * Before starting reinitialization process,
+	 * FDIRCMD.CMD must be zero.
+	 */
+	err = ixgbe_fdir_check_cmd_complete(hw, &fdircmd);
+	if (err) {
+		DEBUGOUT("Flow Director previous command did not complete, aborting table re-initialization.\n");
+		return err;
+	}
+
+	IXGBE_WRITE_REG(hw, IXGBE_FDIRFREE, 0);
+	IXGBE_WRITE_FLUSH(hw);
+	/*
+	 * 82599 adapters flow director init flow cannot be restarted,
+	 * Workaround 82599 silicon errata by performing the following steps
+	 * before re-writing the FDIRCTRL control register with the same value.
+	 * - write 1 to bit 8 of FDIRCMD register &
+	 * - write 0 to bit 8 of FDIRCMD register
+	 */
+	IXGBE_WRITE_REG(hw, IXGBE_FDIRCMD,
+			(IXGBE_READ_REG(hw, IXGBE_FDIRCMD) |
+			 IXGBE_FDIRCMD_CLEARHT));
+	IXGBE_WRITE_FLUSH(hw);
+	IXGBE_WRITE_REG(hw, IXGBE_FDIRCMD,
+			(IXGBE_READ_REG(hw, IXGBE_FDIRCMD) &
+			 ~IXGBE_FDIRCMD_CLEARHT));
+	IXGBE_WRITE_FLUSH(hw);
+	/*
+	 * Clear FDIR Hash register to clear any leftover hashes
+	 * waiting to be programmed.
+	 */
+	IXGBE_WRITE_REG(hw, IXGBE_FDIRHASH, 0x00);
+	IXGBE_WRITE_FLUSH(hw);
+
+	IXGBE_WRITE_REG(hw, IXGBE_FDIRCTRL, fdirctrl);
+	IXGBE_WRITE_FLUSH(hw);
+
+	/* Poll init-done after we write FDIRCTRL register */
+	for (i = 0; i < IXGBE_FDIR_INIT_DONE_POLL; i++) {
+		if (IXGBE_READ_REG(hw, IXGBE_FDIRCTRL) &
+				   IXGBE_FDIRCTRL_INIT_DONE)
+			break;
+		msec_delay(1);
+	}
+	if (i >= IXGBE_FDIR_INIT_DONE_POLL) {
+		DEBUGOUT("Flow Director Signature poll time exceeded!\n");
+		return IXGBE_ERR_FDIR_REINIT_FAILED;
+	}
+
+	/* Clear FDIR statistics registers (read to clear) */
+	IXGBE_READ_REG(hw, IXGBE_FDIRUSTAT);
+	IXGBE_READ_REG(hw, IXGBE_FDIRFSTAT);
+	IXGBE_READ_REG(hw, IXGBE_FDIRMATCH);
+	IXGBE_READ_REG(hw, IXGBE_FDIRMISS);
+	IXGBE_READ_REG(hw, IXGBE_FDIRLEN);
+
+	return IXGBE_SUCCESS;
+}
+
+/**
+ *  ixgbe_fdir_enable_82599 - Initialize Flow Director control registers
+ *  @hw: pointer to hardware structure
+ *  @fdirctrl: value to write to flow director control register
+ **/
+static void ixgbe_fdir_enable_82599(struct ixgbe_hw *hw, uint32_t fdirctrl)
+{
+	int i;
+
+	DEBUGFUNC("ixgbe_fdir_enable_82599");
+
+	/* Prime the keys for hashing */
+	IXGBE_WRITE_REG(hw, IXGBE_FDIRHKEY, IXGBE_ATR_BUCKET_HASH_KEY);
+	IXGBE_WRITE_REG(hw, IXGBE_FDIRSKEY, IXGBE_ATR_SIGNATURE_HASH_KEY);
+
+	/*
+	 * Poll init-done after we write the register.  Estimated times:
+	 *      10G: PBALLOC = 11b, timing is 60us
+	 *       1G: PBALLOC = 11b, timing is 600us
+	 *     100M: PBALLOC = 11b, timing is 6ms
+	 *
+	 *     Multiple these timings by 4 if under full Rx load
+	 *
+	 * So we'll poll for IXGBE_FDIR_INIT_DONE_POLL times, sleeping for
+	 * 1 msec per poll time.  If we're at line rate and drop to 100M, then
+	 * this might not finish in our poll time, but we can live with that
+	 * for now.
+	 */
+	IXGBE_WRITE_REG(hw, IXGBE_FDIRCTRL, fdirctrl);
+	IXGBE_WRITE_FLUSH(hw);
+	for (i = 0; i < IXGBE_FDIR_INIT_DONE_POLL; i++) {
+		if (IXGBE_READ_REG(hw, IXGBE_FDIRCTRL) &
+				   IXGBE_FDIRCTRL_INIT_DONE)
+			break;
+		msec_delay(1);
+	}
+
+	if (i >= IXGBE_FDIR_INIT_DONE_POLL)
+		DEBUGOUT("Flow Director poll time exceeded!\n");
+}
+
+/**
+ *  ixgbe_init_fdir_signature_82599 - Initialize Flow Director signature filters
+ *  @hw: pointer to hardware structure
+ *  @fdirctrl: value to write to flow director control register, initially
+ *	     contains just the value of the Rx packet buffer allocation
+ **/
+int32_t ixgbe_init_fdir_signature_82599(struct ixgbe_hw *hw, uint32_t fdirctrl)
+{
+	DEBUGFUNC("ixgbe_init_fdir_signature_82599");
+
+	/*
+	 * Continue setup of fdirctrl register bits:
+	 *  Move the flexible bytes to use the ethertype - shift 6 words
+	 *  Set the maximum length per hash bucket to 0xA filters
+	 *  Send interrupt when 64 filters are left
+	 */
+	fdirctrl |= (0x6 << IXGBE_FDIRCTRL_FLEX_SHIFT) |
+		    (0xA << IXGBE_FDIRCTRL_MAX_LENGTH_SHIFT) |
+		    (4 << IXGBE_FDIRCTRL_FULL_THRESH_SHIFT);
+
+	/* write hashes and fdirctrl register, poll for completion */
+	ixgbe_fdir_enable_82599(hw, fdirctrl);
+
+	return IXGBE_SUCCESS;
+}
+
+/**
+ *  ixgbe_init_fdir_perfect_82599 - Initialize Flow Director perfect filters
+ *  @hw: pointer to hardware structure
+ *  @fdirctrl: value to write to flow director control register, initially
+ *	     contains just the value of the Rx packet buffer allocation
+ *  @cloud_mode: TRUE - cloud mode, FALSE - other mode
+ **/
+int32_t ixgbe_init_fdir_perfect_82599(struct ixgbe_hw *hw, uint32_t fdirctrl,
+			UNUSED bool cloud_mode)
+{
+	DEBUGFUNC("ixgbe_init_fdir_perfect_82599");
+
+	/*
+	 * Continue setup of fdirctrl register bits:
+	 *  Turn perfect match filtering on
+	 *  Report hash in RSS field of Rx wb descriptor
+	 *  Initialize the drop queue to queue 127
+	 *  Move the flexible bytes to use the ethertype - shift 6 words
+	 *  Set the maximum length per hash bucket to 0xA filters
+	 *  Send interrupt when 64 (0x4 * 16) filters are left
+	 */
+	fdirctrl |= IXGBE_FDIRCTRL_PERFECT_MATCH |
+		    IXGBE_FDIRCTRL_REPORT_STATUS |
+		    (IXGBE_FDIR_DROP_QUEUE << IXGBE_FDIRCTRL_DROP_Q_SHIFT) |
+		    (0x6 << IXGBE_FDIRCTRL_FLEX_SHIFT) |
+		    (0xA << IXGBE_FDIRCTRL_MAX_LENGTH_SHIFT) |
+		    (4 << IXGBE_FDIRCTRL_FULL_THRESH_SHIFT);
+
+	if (cloud_mode)
+		fdirctrl |=(IXGBE_FDIRCTRL_FILTERMODE_CLOUD <<
+					IXGBE_FDIRCTRL_FILTERMODE_SHIFT);
+
+	/* write hashes and fdirctrl register, poll for completion */
+	ixgbe_fdir_enable_82599(hw, fdirctrl);
+
+	return IXGBE_SUCCESS;
+}
+
+/**
+ *  ixgbe_set_fdir_drop_queue_82599 - Set Flow Director drop queue
+ *  @hw: pointer to hardware structure
+ *  @dropqueue: Rx queue index used for the dropped packets
+ **/
+void ixgbe_set_fdir_drop_queue_82599(struct ixgbe_hw *hw, uint8_t dropqueue)
+{
+	uint32_t fdirctrl;
+
+	DEBUGFUNC("ixgbe_set_fdir_drop_queue_82599");
+	/* Clear init done bit and drop queue field */
+	fdirctrl = IXGBE_READ_REG(hw, IXGBE_FDIRCTRL);
+	fdirctrl &= ~(IXGBE_FDIRCTRL_DROP_Q_MASK | IXGBE_FDIRCTRL_INIT_DONE);
+
+	/* Set drop queue */
+	fdirctrl |= (dropqueue << IXGBE_FDIRCTRL_DROP_Q_SHIFT);
+	if ((hw->mac.type == ixgbe_mac_X550) ||
+	    (hw->mac.type == ixgbe_mac_X550EM_x) ||
+	    (hw->mac.type == ixgbe_mac_X550EM_a))
+		fdirctrl |= IXGBE_FDIRCTRL_DROP_NO_MATCH;
+
+	IXGBE_WRITE_REG(hw, IXGBE_FDIRCMD,
+			(IXGBE_READ_REG(hw, IXGBE_FDIRCMD) |
+			 IXGBE_FDIRCMD_CLEARHT));
+	IXGBE_WRITE_FLUSH(hw);
+	IXGBE_WRITE_REG(hw, IXGBE_FDIRCMD,
+			(IXGBE_READ_REG(hw, IXGBE_FDIRCMD) &
+			 ~IXGBE_FDIRCMD_CLEARHT));
+	IXGBE_WRITE_FLUSH(hw);
+
+	/* write hashes and fdirctrl register, poll for completion */
+	ixgbe_fdir_enable_82599(hw, fdirctrl);
+}
+
+/*
+ * These defines allow us to quickly generate all of the necessary instructions
+ * in the function below by simply calling out IXGBE_COMPUTE_SIG_HASH_ITERATION
+ * for values 0 through 15
+ */
+#define IXGBE_ATR_COMMON_HASH_KEY \
+		(IXGBE_ATR_BUCKET_HASH_KEY & IXGBE_ATR_SIGNATURE_HASH_KEY)
+#define IXGBE_COMPUTE_SIG_HASH_ITERATION(_n) \
+do { \
+	uint32_t n = (_n); \
+	if (IXGBE_ATR_COMMON_HASH_KEY & (0x01 << n)) \
+		common_hash ^= lo_hash_dword >> n; \
+	else if (IXGBE_ATR_BUCKET_HASH_KEY & (0x01 << n)) \
+		bucket_hash ^= lo_hash_dword >> n; \
+	else if (IXGBE_ATR_SIGNATURE_HASH_KEY & (0x01 << n)) \
+		sig_hash ^= lo_hash_dword << (16 - n); \
+	if (IXGBE_ATR_COMMON_HASH_KEY & (0x01 << (n + 16))) \
+		common_hash ^= hi_hash_dword >> n; \
+	else if (IXGBE_ATR_BUCKET_HASH_KEY & (0x01 << (n + 16))) \
+		bucket_hash ^= hi_hash_dword >> n; \
+	else if (IXGBE_ATR_SIGNATURE_HASH_KEY & (0x01 << (n + 16))) \
+		sig_hash ^= hi_hash_dword << (16 - n); \
+} while (0)
+
+/**
+ *  ixgbe_atr_compute_sig_hash_82599 - Compute the signature hash
+ *  @input: input bitstream to compute the hash on
+ *  @common: compressed common input dword
+ *
+ *  This function is almost identical to the function above but contains
+ *  several optimizations such as unwinding all of the loops, letting the
+ *  compiler work out all of the conditional ifs since the keys are static
+ *  defines, and computing two keys at once since the hashed dword stream
+ *  will be the same for both keys.
+ **/
+uint32_t ixgbe_atr_compute_sig_hash_82599(union ixgbe_atr_hash_dword input,
+				     union ixgbe_atr_hash_dword common)
+{
+	uint32_t hi_hash_dword, lo_hash_dword, flow_vm_vlan;
+	uint32_t sig_hash = 0, bucket_hash = 0, common_hash = 0;
+
+	/* record the flow_vm_vlan bits as they are a key part to the hash */
+	flow_vm_vlan = IXGBE_NTOHL(input.dword);
+
+	/* generate common hash dword */
+	hi_hash_dword = IXGBE_NTOHL(common.dword);
+
+	/* low dword is word swapped version of common */
+	lo_hash_dword = (hi_hash_dword >> 16) | (hi_hash_dword << 16);
+
+	/* apply flow ID/VM pool/VLAN ID bits to hash words */
+	hi_hash_dword ^= flow_vm_vlan ^ (flow_vm_vlan >> 16);
+
+	/* Process bits 0 and 16 */
+	IXGBE_COMPUTE_SIG_HASH_ITERATION(0);
+
+	/*
+	 * apply flow ID/VM pool/VLAN ID bits to lo hash dword, we had to
+	 * delay this because bit 0 of the stream should not be processed
+	 * so we do not add the VLAN until after bit 0 was processed
+	 */
+	lo_hash_dword ^= flow_vm_vlan ^ (flow_vm_vlan << 16);
+
+	/* Process remaining 30 bit of the key */
+	IXGBE_COMPUTE_SIG_HASH_ITERATION(1);
+	IXGBE_COMPUTE_SIG_HASH_ITERATION(2);
+	IXGBE_COMPUTE_SIG_HASH_ITERATION(3);
+	IXGBE_COMPUTE_SIG_HASH_ITERATION(4);
+	IXGBE_COMPUTE_SIG_HASH_ITERATION(5);
+	IXGBE_COMPUTE_SIG_HASH_ITERATION(6);
+	IXGBE_COMPUTE_SIG_HASH_ITERATION(7);
+	IXGBE_COMPUTE_SIG_HASH_ITERATION(8);
+	IXGBE_COMPUTE_SIG_HASH_ITERATION(9);
+	IXGBE_COMPUTE_SIG_HASH_ITERATION(10);
+	IXGBE_COMPUTE_SIG_HASH_ITERATION(11);
+	IXGBE_COMPUTE_SIG_HASH_ITERATION(12);
+	IXGBE_COMPUTE_SIG_HASH_ITERATION(13);
+	IXGBE_COMPUTE_SIG_HASH_ITERATION(14);
+	IXGBE_COMPUTE_SIG_HASH_ITERATION(15);
+
+	/* combine common_hash result with signature and bucket hashes */
+	bucket_hash ^= common_hash;
+	bucket_hash &= IXGBE_ATR_HASH_MASK;
+
+	sig_hash ^= common_hash << 16;
+	sig_hash &= IXGBE_ATR_HASH_MASK << 16;
+
+	/* return completed signature hash */
+	return sig_hash ^ bucket_hash;
+}
+
+/**
+ *  ixgbe_atr_add_signature_filter_82599 - Adds a signature hash filter
+ *  @hw: pointer to hardware structure
+ *  @input: unique input dword
+ *  @common: compressed common input dword
+ *  @queue: queue index to direct traffic to
+ *
+ * Note that the tunnel bit in input must not be set when the hardware
+ * tunneling support does not exist.
+ **/
+void ixgbe_fdir_add_signature_filter_82599(struct ixgbe_hw *hw,
+					   union ixgbe_atr_hash_dword input,
+					   union ixgbe_atr_hash_dword common,
+					   uint8_t queue)
+{
+	uint64_t fdirhashcmd;
+	uint8_t flow_type;
+	bool tunnel;
+	uint32_t fdircmd;
+
+	DEBUGFUNC("ixgbe_fdir_add_signature_filter_82599");
+
+	/*
+	 * Get the flow_type in order to program FDIRCMD properly
+	 * lowest 2 bits are FDIRCMD.L4TYPE, third lowest bit is FDIRCMD.IPV6
+	 * fifth is FDIRCMD.TUNNEL_FILTER
+	 */
+	tunnel = !!(input.formatted.flow_type & IXGBE_ATR_L4TYPE_TUNNEL_MASK);
+	flow_type = input.formatted.flow_type &
+		    (IXGBE_ATR_L4TYPE_TUNNEL_MASK - 1);
+	switch (flow_type) {
+	case IXGBE_ATR_FLOW_TYPE_TCPV4:
+	case IXGBE_ATR_FLOW_TYPE_UDPV4:
+	case IXGBE_ATR_FLOW_TYPE_SCTPV4:
+	case IXGBE_ATR_FLOW_TYPE_TCPV6:
+	case IXGBE_ATR_FLOW_TYPE_UDPV6:
+	case IXGBE_ATR_FLOW_TYPE_SCTPV6:
+		break;
+	default:
+		DEBUGOUT(" Error on flow type input\n");
+		return;
+	}
+
+	/* configure FDIRCMD register */
+	fdircmd = IXGBE_FDIRCMD_CMD_ADD_FLOW | IXGBE_FDIRCMD_FILTER_UPDATE |
+		  IXGBE_FDIRCMD_LAST | IXGBE_FDIRCMD_QUEUE_EN;
+	fdircmd |= (uint32_t)flow_type << IXGBE_FDIRCMD_FLOW_TYPE_SHIFT;
+	fdircmd |= (uint32_t)queue << IXGBE_FDIRCMD_RX_QUEUE_SHIFT;
+	if (tunnel)
+		fdircmd |= IXGBE_FDIRCMD_TUNNEL_FILTER;
+
+	/*
+	 * The lower 32-bits of fdirhashcmd is for FDIRHASH, the upper 32-bits
+	 * is for FDIRCMD.  Then do a 64-bit register write from FDIRHASH.
+	 */
+	fdirhashcmd = (uint64_t)fdircmd << 32;
+	fdirhashcmd |= ixgbe_atr_compute_sig_hash_82599(input, common);
+	IXGBE_WRITE_REG64(hw, IXGBE_FDIRHASH, fdirhashcmd);
+
+	DEBUGOUT2("Tx Queue=%x hash=%x\n", queue, (uint32_t)fdirhashcmd);
+
+	return;
+}
+
+#define IXGBE_COMPUTE_BKT_HASH_ITERATION(_n) \
+do { \
+	uint32_t n = (_n); \
+	if (IXGBE_ATR_BUCKET_HASH_KEY & (0x01 << n)) \
+		bucket_hash ^= lo_hash_dword >> n; \
+	if (IXGBE_ATR_BUCKET_HASH_KEY & (0x01 << (n + 16))) \
+		bucket_hash ^= hi_hash_dword >> n; \
+} while (0)
+
+/**
+ *  ixgbe_atr_compute_perfect_hash_82599 - Compute the perfect filter hash
+ *  @input: input bitstream to compute the hash on
+ *  @input_mask: mask for the input bitstream
+ *
+ *  This function serves two main purposes.  First it applies the input_mask
+ *  to the atr_input resulting in a cleaned up atr_input data stream.
+ *  Secondly it computes the hash and stores it in the bkt_hash field at
+ *  the end of the input byte stream.  This way it will be available for
+ *  future use without needing to recompute the hash.
+ **/
+void ixgbe_atr_compute_perfect_hash_82599(union ixgbe_atr_input *input,
+					  union ixgbe_atr_input *input_mask)
+{
+
+	uint32_t hi_hash_dword, lo_hash_dword, flow_vm_vlan;
+	uint32_t bucket_hash = 0;
+	uint32_t hi_dword = 0;
+	uint32_t i = 0;
+
+	/* Apply masks to input data */
+	for (i = 0; i < 14; i++)
+		input->dword_stream[i]  &= input_mask->dword_stream[i];
+
+	/* record the flow_vm_vlan bits as they are a key part to the hash */
+	flow_vm_vlan = IXGBE_NTOHL(input->dword_stream[0]);
+
+	/* generate common hash dword */
+	for (i = 1; i <= 13; i++)
+		hi_dword ^= input->dword_stream[i];
+	hi_hash_dword = IXGBE_NTOHL(hi_dword);
+
+	/* low dword is word swapped version of common */
+	lo_hash_dword = (hi_hash_dword >> 16) | (hi_hash_dword << 16);
+
+	/* apply flow ID/VM pool/VLAN ID bits to hash words */
+	hi_hash_dword ^= flow_vm_vlan ^ (flow_vm_vlan >> 16);
+
+	/* Process bits 0 and 16 */
+	IXGBE_COMPUTE_BKT_HASH_ITERATION(0);
+
+	/*
+	 * apply flow ID/VM pool/VLAN ID bits to lo hash dword, we had to
+	 * delay this because bit 0 of the stream should not be processed
+	 * so we do not add the VLAN until after bit 0 was processed
+	 */
+	lo_hash_dword ^= flow_vm_vlan ^ (flow_vm_vlan << 16);
+
+	/* Process remaining 30 bit of the key */
+	for (i = 1; i <= 15; i++)
+		IXGBE_COMPUTE_BKT_HASH_ITERATION(i);
+
+	/*
+	 * Limit hash to 13 bits since max bucket count is 8K.
+	 * Store result at the end of the input stream.
+	 */
+	input->formatted.bkt_hash = bucket_hash & 0x1FFF;
+}
+
+/**
+ *  ixgbe_get_fdirtcpm_82599 - generate a TCP port from atr_input_masks
+ *  @input_mask: mask to be bit swapped
+ *
+ *  The source and destination port masks for flow director are bit swapped
+ *  in that bit 15 effects bit 0, 14 effects 1, 13, 2 etc.  In order to
+ *  generate a correctly swapped value we need to bit swap the mask and that
+ *  is what is accomplished by this function.
+ **/
+static uint32_t ixgbe_get_fdirtcpm_82599(union ixgbe_atr_input *input_mask)
+{
+	uint32_t mask = IXGBE_NTOHS(input_mask->formatted.dst_port);
+	mask <<= IXGBE_FDIRTCPM_DPORTM_SHIFT;
+	mask |= IXGBE_NTOHS(input_mask->formatted.src_port);
+	mask = ((mask & 0x55555555) << 1) | ((mask & 0xAAAAAAAA) >> 1);
+	mask = ((mask & 0x33333333) << 2) | ((mask & 0xCCCCCCCC) >> 2);
+	mask = ((mask & 0x0F0F0F0F) << 4) | ((mask & 0xF0F0F0F0) >> 4);
+	return ((mask & 0x00FF00FF) << 8) | ((mask & 0xFF00FF00) >> 8);
+}
+
+/*
+ * These two macros are meant to address the fact that we have registers
+ * that are either all or in part big-endian.  As a result on big-endian
+ * systems we will end up byte swapping the value to little-endian before
+ * it is byte swapped again and written to the hardware in the original
+ * big-endian format.
+ */
+#define IXGBE_STORE_AS_BE32(_value) \
+	(((uint32_t)(_value) >> 24) | (((uint32_t)(_value) & 0x00FF0000) >> 8) | \
+	 (((uint32_t)(_value) & 0x0000FF00) << 8) | ((uint32_t)(_value) << 24))
+
+#define IXGBE_WRITE_REG_BE32(a, reg, value) \
+	IXGBE_WRITE_REG((a), (reg), IXGBE_STORE_AS_BE32(IXGBE_NTOHL(value)))
+
+#define IXGBE_STORE_AS_BE16(_value) \
+	IXGBE_NTOHS(((uint16_t)(_value) >> 8) | ((uint16_t)(_value) << 8))
+
+int32_t ixgbe_fdir_set_input_mask_82599(struct ixgbe_hw *hw,
+				    union ixgbe_atr_input *input_mask, UNUSED bool cloud_mode)
+{
+	/* mask IPv6 since it is currently not supported */
+	uint32_t fdirm = IXGBE_FDIRM_DIPv6;
+	uint32_t fdirtcpm;
+	uint32_t fdirip6m;
+	DEBUGFUNC("ixgbe_fdir_set_atr_input_mask_82599");
+
+	/*
+	 * Program the relevant mask registers.  If src/dst_port or src/dst_addr
+	 * are zero, then assume a full mask for that field.  Also assume that
+	 * a VLAN of 0 is unspecified, so mask that out as well.  L4type
+	 * cannot be masked out in this implementation.
+	 *
+	 * This also assumes IPv4 only.  IPv6 masking isn't supported at this
+	 * point in time.
+	 */
+
+	/* verify bucket hash is cleared on hash generation */
+	if (input_mask->formatted.bkt_hash)
+		DEBUGOUT(" bucket hash should always be 0 in mask\n");
+
+	/* Program FDIRM and verify partial masks */
+	switch (input_mask->formatted.vm_pool & 0x7F) {
+	case 0x0:
+		fdirm |= IXGBE_FDIRM_POOL;
+	case 0x7F:
+		break;
+	default:
+		DEBUGOUT(" Error on vm pool mask\n");
+		return IXGBE_ERR_CONFIG;
+	}
+
+	switch (input_mask->formatted.flow_type & IXGBE_ATR_L4TYPE_MASK) {
+	case 0x0:
+		fdirm |= IXGBE_FDIRM_L4P;
+		if (input_mask->formatted.dst_port ||
+		    input_mask->formatted.src_port) {
+			DEBUGOUT(" Error on src/dst port mask\n");
+			return IXGBE_ERR_CONFIG;
+		}
+	case IXGBE_ATR_L4TYPE_MASK:
+		break;
+	default:
+		DEBUGOUT(" Error on flow type mask\n");
+		return IXGBE_ERR_CONFIG;
+	}
+
+	switch (IXGBE_NTOHS(input_mask->formatted.vlan_id) & 0xEFFF) {
+	case 0x0000:
+		/* mask VLAN ID */
+		fdirm |= IXGBE_FDIRM_VLANID;
+		/* fall through */
+	case 0x0FFF:
+		/* mask VLAN priority */
+		fdirm |= IXGBE_FDIRM_VLANP;
+		break;
+	case 0xE000:
+		/* mask VLAN ID only */
+		fdirm |= IXGBE_FDIRM_VLANID;
+		/* fall through */
+	case 0xEFFF:
+		/* no VLAN fields masked */
+		break;
+	default:
+		DEBUGOUT(" Error on VLAN mask\n");
+		return IXGBE_ERR_CONFIG;
+	}
+
+	switch (input_mask->formatted.flex_bytes & 0xFFFF) {
+	case 0x0000:
+		/* Mask Flex Bytes */
+		fdirm |= IXGBE_FDIRM_FLEX;
+		/* fall through */
+	case 0xFFFF:
+		break;
+	default:
+		DEBUGOUT(" Error on flexible byte mask\n");
+		return IXGBE_ERR_CONFIG;
+	}
+
+	if (cloud_mode) {
+		fdirm |= IXGBE_FDIRM_L3P;
+		fdirip6m = ((uint32_t) 0xFFFFU << IXGBE_FDIRIP6M_DIPM_SHIFT);
+		fdirip6m |= IXGBE_FDIRIP6M_ALWAYS_MASK;
+
+		switch (input_mask->formatted.inner_mac[0] & 0xFF) {
+		case 0x00:
+			/* Mask inner MAC, fall through */
+			fdirip6m |= IXGBE_FDIRIP6M_INNER_MAC;
+		case 0xFF:
+			break;
+		default:
+			DEBUGOUT(" Error on inner_mac byte mask\n");
+			return IXGBE_ERR_CONFIG;
+		}
+
+		switch (input_mask->formatted.tni_vni & 0xFFFFFFFF) {
+		case 0x0:
+			/* Mask vxlan id */
+			fdirip6m |= IXGBE_FDIRIP6M_TNI_VNI;
+			break;
+		case 0x00FFFFFF:
+			fdirip6m |= IXGBE_FDIRIP6M_TNI_VNI_24;
+			break;
+		case 0xFFFFFFFF:
+			break;
+		default:
+			DEBUGOUT(" Error on TNI/VNI byte mask\n");
+			return IXGBE_ERR_CONFIG;
+		}
+
+		switch (input_mask->formatted.tunnel_type & 0xFFFF) {
+		case 0x0:
+			/* Mask turnnel type, fall through */
+			fdirip6m |= IXGBE_FDIRIP6M_TUNNEL_TYPE;
+		case 0xFFFF:
+			break;
+		default:
+			DEBUGOUT(" Error on tunnel type byte mask\n");
+			return IXGBE_ERR_CONFIG;
+		}
+		IXGBE_WRITE_REG_BE32(hw, IXGBE_FDIRIP6M, fdirip6m);
+
+		/* Set all bits in FDIRTCPM, FDIRUDPM, FDIRSCTPM,
+		 * FDIRSIP4M and FDIRDIP4M in cloud mode to allow
+		 * L3/L3 packets to tunnel.
+		 */
+		IXGBE_WRITE_REG(hw, IXGBE_FDIRTCPM, 0xFFFFFFFF);
+		IXGBE_WRITE_REG(hw, IXGBE_FDIRUDPM, 0xFFFFFFFF);
+		IXGBE_WRITE_REG_BE32(hw, IXGBE_FDIRDIP4M, 0xFFFFFFFF);
+		IXGBE_WRITE_REG_BE32(hw, IXGBE_FDIRSIP4M, 0xFFFFFFFF);
+		switch (hw->mac.type) {
+		case ixgbe_mac_X550:
+		case ixgbe_mac_X550EM_x:
+		case ixgbe_mac_X550EM_a:
+			IXGBE_WRITE_REG(hw, IXGBE_FDIRSCTPM, 0xFFFFFFFF);
+			break;
+		default:
+			break;
+		}
+	}
+
+	/* Now mask VM pool and destination IPv6 - bits 5 and 2 */
+	IXGBE_WRITE_REG(hw, IXGBE_FDIRM, fdirm);
+
+	if (!cloud_mode) {
+		/* store the TCP/UDP port masks, bit reversed from port
+		 * layout */
+		fdirtcpm = ixgbe_get_fdirtcpm_82599(input_mask);
+
+		/* write both the same so that UDP and TCP use the same mask */
+		IXGBE_WRITE_REG(hw, IXGBE_FDIRTCPM, ~fdirtcpm);
+		IXGBE_WRITE_REG(hw, IXGBE_FDIRUDPM, ~fdirtcpm);
+		/* also use it for SCTP */
+		switch (hw->mac.type) {
+		case ixgbe_mac_X550:
+		case ixgbe_mac_X550EM_x:
+		case ixgbe_mac_X550EM_a:
+			IXGBE_WRITE_REG(hw, IXGBE_FDIRSCTPM, ~fdirtcpm);
+			break;
+		default:
+			break;
+		}
+
+		/* store source and destination IP masks (big-enian) */
+		IXGBE_WRITE_REG_BE32(hw, IXGBE_FDIRSIP4M,
+				     ~input_mask->formatted.src_ip[0]);
+		IXGBE_WRITE_REG_BE32(hw, IXGBE_FDIRDIP4M,
+				     ~input_mask->formatted.dst_ip[0]);
+	}
+	return IXGBE_SUCCESS;
+}
+
+int32_t ixgbe_fdir_write_perfect_filter_82599(struct ixgbe_hw *hw,
+					  union ixgbe_atr_input *input,
+					  uint16_t soft_id, uint8_t queue, UNUSED bool cloud_mode)
+{
+	uint32_t fdirport, fdirvlan, fdirhash, fdircmd;
+	uint32_t addr_low, addr_high;
+	uint32_t cloud_type = 0;
+	int32_t err;
+
+	DEBUGFUNC("ixgbe_fdir_write_perfect_filter_82599");
+	if (!cloud_mode) {
+		/* currently IPv6 is not supported, must be programmed with 0 */
+		IXGBE_WRITE_REG_BE32(hw, IXGBE_FDIRSIPv6(0),
+				     input->formatted.src_ip[0]);
+		IXGBE_WRITE_REG_BE32(hw, IXGBE_FDIRSIPv6(1),
+				     input->formatted.src_ip[1]);
+		IXGBE_WRITE_REG_BE32(hw, IXGBE_FDIRSIPv6(2),
+				     input->formatted.src_ip[2]);
+
+		/* record the source address (big-endian) */
+		IXGBE_WRITE_REG_BE32(hw, IXGBE_FDIRIPSA,
+			input->formatted.src_ip[0]);
+
+		/* record the first 32 bits of the destination address
+		 * (big-endian) */
+		IXGBE_WRITE_REG_BE32(hw, IXGBE_FDIRIPDA,
+			input->formatted.dst_ip[0]);
+
+		/* record source and destination port (little-endian)*/
+		fdirport = IXGBE_NTOHS(input->formatted.dst_port);
+		fdirport <<= IXGBE_FDIRPORT_DESTINATION_SHIFT;
+		fdirport |= IXGBE_NTOHS(input->formatted.src_port);
+		IXGBE_WRITE_REG(hw, IXGBE_FDIRPORT, fdirport);
+	}
+
+	/* record VLAN (little-endian) and flex_bytes(big-endian) */
+	fdirvlan = IXGBE_STORE_AS_BE16(input->formatted.flex_bytes);
+	fdirvlan <<= IXGBE_FDIRVLAN_FLEX_SHIFT;
+	fdirvlan |= IXGBE_NTOHS(input->formatted.vlan_id);
+	IXGBE_WRITE_REG(hw, IXGBE_FDIRVLAN, fdirvlan);
+
+	if (cloud_mode) {
+		if (input->formatted.tunnel_type != 0)
+			cloud_type = 0x80000000;
+
+		addr_low = ((uint32_t)input->formatted.inner_mac[0] |
+				((uint32_t)input->formatted.inner_mac[1] << 8) |
+				((uint32_t)input->formatted.inner_mac[2] << 16) |
+				((uint32_t)input->formatted.inner_mac[3] << 24));
+		addr_high = ((uint32_t)input->formatted.inner_mac[4] |
+				((uint32_t)input->formatted.inner_mac[5] << 8));
+		cloud_type |= addr_high;
+		IXGBE_WRITE_REG_BE32(hw, IXGBE_FDIRSIPv6(0), addr_low);
+		IXGBE_WRITE_REG_BE32(hw, IXGBE_FDIRSIPv6(1), cloud_type);
+		IXGBE_WRITE_REG_BE32(hw, IXGBE_FDIRSIPv6(2), input->formatted.tni_vni);
+	}
+
+	/* configure FDIRHASH register */
+	fdirhash = input->formatted.bkt_hash;
+	fdirhash |= soft_id << IXGBE_FDIRHASH_SIG_SW_INDEX_SHIFT;
+	IXGBE_WRITE_REG(hw, IXGBE_FDIRHASH, fdirhash);
+
+	/*
+	 * flush all previous writes to make certain registers are
+	 * programmed prior to issuing the command
+	 */
+	IXGBE_WRITE_FLUSH(hw);
+
+	/* configure FDIRCMD register */
+	fdircmd = IXGBE_FDIRCMD_CMD_ADD_FLOW | IXGBE_FDIRCMD_FILTER_UPDATE |
+		  IXGBE_FDIRCMD_LAST | IXGBE_FDIRCMD_QUEUE_EN;
+	if (queue == IXGBE_FDIR_DROP_QUEUE)
+		fdircmd |= IXGBE_FDIRCMD_DROP;
+	if (input->formatted.flow_type & IXGBE_ATR_L4TYPE_TUNNEL_MASK)
+		fdircmd |= IXGBE_FDIRCMD_TUNNEL_FILTER;
+	fdircmd |= input->formatted.flow_type << IXGBE_FDIRCMD_FLOW_TYPE_SHIFT;
+	fdircmd |= (uint32_t)queue << IXGBE_FDIRCMD_RX_QUEUE_SHIFT;
+	fdircmd |= (uint32_t)input->formatted.vm_pool << IXGBE_FDIRCMD_VT_POOL_SHIFT;
+
+	IXGBE_WRITE_REG(hw, IXGBE_FDIRCMD, fdircmd);
+	err = ixgbe_fdir_check_cmd_complete(hw, &fdircmd);
+	if (err) {
+		DEBUGOUT("Flow Director command did not complete!\n");
+		return err;
+	}
+
+	return IXGBE_SUCCESS;
+}
+
+int32_t ixgbe_fdir_erase_perfect_filter_82599(struct ixgbe_hw *hw,
+					  union ixgbe_atr_input *input,
+					  uint16_t soft_id)
+{
+	uint32_t fdirhash;
+	uint32_t fdircmd;
+	int32_t err;
+
+	/* configure FDIRHASH register */
+	fdirhash = input->formatted.bkt_hash;
+	fdirhash |= soft_id << IXGBE_FDIRHASH_SIG_SW_INDEX_SHIFT;
+	IXGBE_WRITE_REG(hw, IXGBE_FDIRHASH, fdirhash);
+
+	/* flush hash to HW */
+	IXGBE_WRITE_FLUSH(hw);
+
+	/* Query if filter is present */
+	IXGBE_WRITE_REG(hw, IXGBE_FDIRCMD, IXGBE_FDIRCMD_CMD_QUERY_REM_FILT);
+
+	err = ixgbe_fdir_check_cmd_complete(hw, &fdircmd);
+	if (err) {
+		DEBUGOUT("Flow Director command did not complete!\n");
+		return err;
+	}
+
+	/* if filter exists in hardware then remove it */
+	if (fdircmd & IXGBE_FDIRCMD_FILTER_VALID) {
+		IXGBE_WRITE_REG(hw, IXGBE_FDIRHASH, fdirhash);
+		IXGBE_WRITE_FLUSH(hw);
+		IXGBE_WRITE_REG(hw, IXGBE_FDIRCMD,
+				IXGBE_FDIRCMD_CMD_REMOVE_FLOW);
+	}
+
+	return IXGBE_SUCCESS;
+}
+
+/**
+ *  ixgbe_fdir_add_perfect_filter_82599 - Adds a perfect filter
+ *  @hw: pointer to hardware structure
+ *  @input: input bitstream
+ *  @input_mask: mask for the input bitstream
+ *  @soft_id: software index for the filters
+ *  @queue: queue index to direct traffic to
+ *  @cloud_mode: unused
+ *
+ *  Note that the caller to this function must lock before calling, since the
+ *  hardware writes must be protected from one another.
+ **/
+int32_t ixgbe_fdir_add_perfect_filter_82599(struct ixgbe_hw *hw,
+					union ixgbe_atr_input *input,
+					union ixgbe_atr_input *input_mask,
+					uint16_t soft_id, uint8_t queue, UNUSED bool cloud_mode)
+{
+	int32_t err = IXGBE_ERR_CONFIG;
+
+	DEBUGFUNC("ixgbe_fdir_add_perfect_filter_82599");
+
+	/*
+	 * Check flow_type formatting, and bail out before we touch the hardware
+	 * if there's a configuration issue
+	 */
+	switch (input->formatted.flow_type) {
+	case IXGBE_ATR_FLOW_TYPE_IPV4:
+	case IXGBE_ATR_FLOW_TYPE_TUNNELED_IPV4:
+		input_mask->formatted.flow_type = IXGBE_ATR_L4TYPE_IPV6_MASK;
+		if (input->formatted.dst_port || input->formatted.src_port) {
+			DEBUGOUT(" Error on src/dst port\n");
+			return IXGBE_ERR_CONFIG;
+		}
+		break;
+	case IXGBE_ATR_FLOW_TYPE_SCTPV4:
+	case IXGBE_ATR_FLOW_TYPE_TUNNELED_SCTPV4:
+		if (input->formatted.dst_port || input->formatted.src_port) {
+			DEBUGOUT(" Error on src/dst port\n");
+			return IXGBE_ERR_CONFIG;
+		}
+		/* fall through */
+	case IXGBE_ATR_FLOW_TYPE_TCPV4:
+	case IXGBE_ATR_FLOW_TYPE_TUNNELED_TCPV4:
+	case IXGBE_ATR_FLOW_TYPE_UDPV4:
+	case IXGBE_ATR_FLOW_TYPE_TUNNELED_UDPV4:
+		input_mask->formatted.flow_type = IXGBE_ATR_L4TYPE_IPV6_MASK |
+						  IXGBE_ATR_L4TYPE_MASK;
+		break;
+	default:
+		DEBUGOUT(" Error on flow type input\n");
+		return err;
+	}
+
+	/* program input mask into the HW */
+	err = ixgbe_fdir_set_input_mask_82599(hw, input_mask, cloud_mode);
+	if (err)
+		return err;
+
+	/* apply mask and compute/store hash */
+	ixgbe_atr_compute_perfect_hash_82599(input, input_mask);
+
+	/* program filters to filter memory */
+	return ixgbe_fdir_write_perfect_filter_82599(hw, input,
+						     soft_id, queue, cloud_mode);
+}
+
+/**
  *  ixgbe_read_analog_reg8_82599 - Reads 8 bit Omer analog register
  *  @hw: pointer to hardware structure
  *  @reg: analog register to read
@@ -1203,8 +2096,7 @@ reset_hw_out:
  *
  *  Performs read operation to Omer analog register specified.
  **/
-int32_t ixgbe_read_analog_reg8_82599(struct ixgbe_hw *hw, uint32_t reg,
-				     uint8_t *val)
+int32_t ixgbe_read_analog_reg8_82599(struct ixgbe_hw *hw, uint32_t reg, uint8_t *val)
 {
 	uint32_t  core_ctl;
 
@@ -1228,8 +2120,7 @@ int32_t ixgbe_read_analog_reg8_82599(str
  *
  *  Performs write operation to Omer analog register specified.
  **/
-int32_t ixgbe_write_analog_reg8_82599(struct ixgbe_hw *hw, uint32_t reg,
-				      uint8_t val)
+int32_t ixgbe_write_analog_reg8_82599(struct ixgbe_hw *hw, uint32_t reg, uint8_t val)
 {
 	uint32_t  core_ctl;
 
@@ -1317,9 +2208,9 @@ int32_t ixgbe_identify_phy_82599(struct 
  *
  *  Determines physical layer capabilities of the current configuration.
  **/
-uint32_t ixgbe_get_supported_physical_layer_82599(struct ixgbe_hw *hw)
+uint64_t ixgbe_get_supported_physical_layer_82599(struct ixgbe_hw *hw)
 {
-	uint32_t physical_layer = IXGBE_PHYSICAL_LAYER_UNKNOWN;
+	uint64_t physical_layer = IXGBE_PHYSICAL_LAYER_UNKNOWN;
 	uint32_t autoc = IXGBE_READ_REG(hw, IXGBE_AUTOC);
 	uint32_t autoc2 = IXGBE_READ_REG(hw, IXGBE_AUTOC2);
 	uint32_t pma_pmd_10g_serial = autoc2 & IXGBE_AUTOC2_10G_SERIAL_PMA_PMD_MASK;
@@ -1439,7 +2330,7 @@ int32_t ixgbe_enable_rx_dma_82599(struct
  *  Returns IXGBE_ERR_EEPROM_VERSION if the FW is not present or
  *  if the FW version is not supported.
  **/
-int32_t ixgbe_verify_fw_version_82599(struct ixgbe_hw *hw)
+static int32_t ixgbe_verify_fw_version_82599(struct ixgbe_hw *hw)
 {
 	int32_t status = IXGBE_ERR_EEPROM_VERSION;
 	uint16_t fw_offset, fw_ptp_cfg_offset;
@@ -1538,6 +2429,41 @@ out:
 }
 
 /**
+ *  ixgbe_read_eeprom_buffer_82599 - Read EEPROM word(s) using
+ *  fastest available method
+ *
+ *  @hw: pointer to hardware structure
+ *  @offset: offset of  word in EEPROM to read
+ *  @words: number of words
+ *  @data: word(s) read from the EEPROM
+ *
+ *  Retrieves 16 bit word(s) read from EEPROM
+ **/
+static int32_t ixgbe_read_eeprom_buffer_82599(struct ixgbe_hw *hw, uint16_t offset,
+					  uint16_t words, uint16_t *data)
+{
+	struct ixgbe_eeprom_info *eeprom = &hw->eeprom;
+	int32_t ret_val = IXGBE_ERR_CONFIG;
+
+	DEBUGFUNC("ixgbe_read_eeprom_buffer_82599");
+
+	/*
+	 * If EEPROM is detected and can be addressed using 14 bits,
+	 * use EERD otherwise use bit bang
+	 */
+	if ((eeprom->type == ixgbe_eeprom_spi) &&
+	    (offset + (words - 1) <= IXGBE_EERD_MAX_ADDR))
+		ret_val = ixgbe_read_eerd_buffer_generic(hw, offset, words,
+							 data);
+	else
+		ret_val = ixgbe_read_eeprom_buffer_bit_bang_generic(hw, offset,
+								    words,
+								    data);
+
+	return ret_val;
+}
+
+/**
  *  ixgbe_read_eeprom_82599 - Read EEPROM word using
  *  fastest available method
  *
@@ -1547,8 +2473,8 @@ out:
  *
  *  Reads a 16 bit word from the EEPROM
  **/
-int32_t ixgbe_read_eeprom_82599(struct ixgbe_hw *hw,
-				uint16_t offset, uint16_t *data)
+static int32_t ixgbe_read_eeprom_82599(struct ixgbe_hw *hw,
+				   uint16_t offset, uint16_t *data)
 {
 	struct ixgbe_eeprom_info *eeprom = &hw->eeprom;
 	int32_t ret_val = IXGBE_ERR_CONFIG;
@@ -1623,13 +2549,14 @@ reset_pipeline_out:
  *  ixgbe_read_i2c_byte_82599 - Reads 8 bit word over I2C
  *  @hw: pointer to hardware structure
  *  @byte_offset: byte offset to read
+ *  @dev_addr: address to read from
  *  @data: value read
  *
  *  Performs byte read operation to SFP module's EEPROM over I2C interface at
  *  a specified device address.
  **/
-int32_t ixgbe_read_i2c_byte_82599(struct ixgbe_hw *hw, uint8_t byte_offset,
-				  uint8_t dev_addr, uint8_t *data)
+static int32_t ixgbe_read_i2c_byte_82599(struct ixgbe_hw *hw, uint8_t byte_offset,
+				uint8_t dev_addr, uint8_t *data)
 {
 	uint32_t esdp;
 	int32_t status;
@@ -1680,13 +2607,14 @@ release_i2c_access:
  *  ixgbe_write_i2c_byte_82599 - Writes 8 bit word over I2C
  *  @hw: pointer to hardware structure
  *  @byte_offset: byte offset to write
+ *  @dev_addr: address to read from
  *  @data: value to write
  *
  *  Performs byte write operation to SFP module's EEPROM over I2C interface at
  *  a specified device address.
  **/
-int32_t ixgbe_write_i2c_byte_82599(struct ixgbe_hw *hw, uint8_t byte_offset,
-				   uint8_t dev_addr, uint8_t data)
+static int32_t ixgbe_write_i2c_byte_82599(struct ixgbe_hw *hw, uint8_t byte_offset,
+				 uint8_t dev_addr, uint8_t data)
 {
 	uint32_t esdp;
 	int32_t status;
Index: ./dev/pci/ixgbe_api.c
===================================================================
RCS file: ./dev/pci/ixgbe_api.c
diff -N ./dev/pci/ixgbe_api.c
--- /dev/null	1 Jan 1970 00:00:00 -0000
+++ ./dev/pci/ixgbe_api.c	17 Sep 2018 19:59:55 -0000
@@ -0,0 +1,1719 @@
+/******************************************************************************
+  SPDX-License-Identifier: BSD-3-Clause
+
+  Copyright (c) 2001-2017, Intel Corporation
+  All rights reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions are met:
+
+   1. Redistributions of source code must retain the above copyright notice,
+      this list of conditions and the following disclaimer.
+
+   2. Redistributions in binary form must reproduce the above copyright
+      notice, this list of conditions and the following disclaimer in the
+      documentation and/or other materials provided with the distribution.
+
+   3. Neither the name of the Intel Corporation nor the names of its
+      contributors may be used to endorse or promote products derived from
+      this software without specific prior written permission.
+
+  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
+  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+  POSSIBILITY OF SUCH DAMAGE.
+
+******************************************************************************/
+/*$FreeBSD$*/
+
+#include <dev/pci/ixgbe.h>
+#include <dev/pci/ixgbe_type.h>
+#include <dev/pci/ixgbe_api.h>
+
+#define IXGBE_EMPTY_PARAM
+
+static const uint32_t ixgbe_mvals_base[IXGBE_MVALS_IDX_LIMIT] = {
+	IXGBE_MVALS_INIT(IXGBE_EMPTY_PARAM)
+};
+
+static const uint32_t ixgbe_mvals_X540[IXGBE_MVALS_IDX_LIMIT] = {
+	IXGBE_MVALS_INIT(_X540)
+};
+
+static const uint32_t ixgbe_mvals_X550[IXGBE_MVALS_IDX_LIMIT] = {
+	IXGBE_MVALS_INIT(_X550)
+};
+
+static const uint32_t ixgbe_mvals_X550EM_x[IXGBE_MVALS_IDX_LIMIT] = {
+	IXGBE_MVALS_INIT(_X550EM_x)
+};
+
+static const uint32_t ixgbe_mvals_X550EM_a[IXGBE_MVALS_IDX_LIMIT] = {
+	IXGBE_MVALS_INIT(_X550EM_a)
+};
+
+/**
+ * ixgbe_dcb_get_rtrup2tc - read rtrup2tc reg
+ * @hw: pointer to hardware structure
+ * @map: pointer to uint8_t arr for returning map
+ *
+ * Read the rtrup2tc HW register and resolve its content into map
+ **/
+void ixgbe_dcb_get_rtrup2tc(struct ixgbe_hw *hw, uint8_t *map)
+{
+	if (hw->mac.ops.get_rtrup2tc)
+		hw->mac.ops.get_rtrup2tc(hw, map);
+}
+
+/**
+ *  ixgbe_init_shared_code - Initialize the shared code
+ *  @hw: pointer to hardware structure
+ *
+ *  This will assign function pointers and assign the MAC type and PHY code.
+ *  Does not touch the hardware. This function must be called prior to any
+ *  other function in the shared code. The ixgbe_hw structure should be
+ *  memset to 0 prior to calling this function.  The following fields in
+ *  hw structure should be filled in prior to calling this function:
+ *  hw_addr, back, device_id, vendor_id, subsystem_device_id,
+ *  subsystem_vendor_id, and revision_id
+ **/
+int32_t ixgbe_init_shared_code(struct ixgbe_hw *hw)
+{
+	int32_t status;
+
+	DEBUGFUNC("ixgbe_init_shared_code");
+
+	/*
+	 * Set the mac type
+	 */
+	ixgbe_set_mac_type(hw);
+
+	switch (hw->mac.type) {
+	case ixgbe_mac_82598EB:
+		status = ixgbe_init_ops_82598(hw);
+		break;
+	case ixgbe_mac_82599EB:
+		status = ixgbe_init_ops_82599(hw);
+		break;
+	case ixgbe_mac_X540:
+		status = ixgbe_init_ops_X540(hw);
+		break;
+	case ixgbe_mac_X550:
+		status = ixgbe_init_ops_X550(hw);
+		break;
+	case ixgbe_mac_X550EM_x:
+		status = ixgbe_init_ops_X550EM_x(hw);
+		break;
+	case ixgbe_mac_X550EM_a:
+		status = ixgbe_init_ops_X550EM_a(hw);
+		break;
+	default:
+		status = IXGBE_ERR_DEVICE_NOT_SUPPORTED;
+		break;
+	}
+	hw->mac.max_link_up_time = IXGBE_LINK_UP_TIME;
+
+	return status;
+}
+
+/**
+ *  ixgbe_set_mac_type - Sets MAC type
+ *  @hw: pointer to the HW structure
+ *
+ *  This function sets the mac type of the adapter based on the
+ *  vendor ID and device ID stored in the hw structure.
+ **/
+int32_t ixgbe_set_mac_type(struct ixgbe_hw *hw)
+{
+	int32_t ret_val = IXGBE_SUCCESS;
+
+	DEBUGFUNC("ixgbe_set_mac_type\n");
+
+	if (hw->vendor_id != IXGBE_INTEL_VENDOR_ID) {
+		ERROR_REPORT2(IXGBE_ERROR_UNSUPPORTED,
+			     "Unsupported vendor id: %x", hw->vendor_id);
+		return IXGBE_ERR_DEVICE_NOT_SUPPORTED;
+	}
+
+	hw->mvals = ixgbe_mvals_base;
+
+	switch (hw->device_id) {
+	case IXGBE_DEV_ID_82598:
+	case IXGBE_DEV_ID_82598_BX:
+	case IXGBE_DEV_ID_82598AF_SINGLE_PORT:
+	case IXGBE_DEV_ID_82598AF_DUAL_PORT:
+	case IXGBE_DEV_ID_82598AT:
+	case IXGBE_DEV_ID_82598AT2:
+	case IXGBE_DEV_ID_82598EB_CX4:
+	case IXGBE_DEV_ID_82598_CX4_DUAL_PORT:
+	case IXGBE_DEV_ID_82598_DA_DUAL_PORT:
+	case IXGBE_DEV_ID_82598_SR_DUAL_PORT_EM:
+	case IXGBE_DEV_ID_82598EB_XF_LR:
+	case IXGBE_DEV_ID_82598EB_SFP_LOM:
+		hw->mac.type = ixgbe_mac_82598EB;
+		break;
+	case IXGBE_DEV_ID_82599_KX4:
+	case IXGBE_DEV_ID_82599_KX4_MEZZ:
+	case IXGBE_DEV_ID_82599_XAUI_LOM:
+	case IXGBE_DEV_ID_82599_COMBO_BACKPLANE:
+	case IXGBE_DEV_ID_82599_KR:
+	case IXGBE_DEV_ID_82599_SFP:
+	case IXGBE_DEV_ID_82599_BACKPLANE_FCOE:
+	case IXGBE_DEV_ID_82599_SFP_FCOE:
+	case IXGBE_DEV_ID_82599_SFP_EM:
+	case IXGBE_DEV_ID_82599_SFP_SF2:
+	case IXGBE_DEV_ID_82599_SFP_SF_QP:
+	case IXGBE_DEV_ID_82599_QSFP_SF_QP:
+	case IXGBE_DEV_ID_82599EN_SFP:
+	case IXGBE_DEV_ID_82599_CX4:
+	case IXGBE_DEV_ID_82599_BYPASS:
+	case IXGBE_DEV_ID_82599_T3_LOM:
+		hw->mac.type = ixgbe_mac_82599EB;
+		break;
+	case IXGBE_DEV_ID_X540T:
+	case IXGBE_DEV_ID_X540T1:
+	case IXGBE_DEV_ID_X540_BYPASS:
+		hw->mac.type = ixgbe_mac_X540;
+		hw->mvals = ixgbe_mvals_X540;
+		break;
+	case IXGBE_DEV_ID_X550T:
+	case IXGBE_DEV_ID_X550T1:
+		hw->mac.type = ixgbe_mac_X550;
+		hw->mvals = ixgbe_mvals_X550;
+		break;
+	case IXGBE_DEV_ID_X550EM_X_KX4:
+	case IXGBE_DEV_ID_X550EM_X_KR:
+	case IXGBE_DEV_ID_X550EM_X_10G_T:
+	case IXGBE_DEV_ID_X550EM_X_1G_T:
+	case IXGBE_DEV_ID_X550EM_X_SFP:
+	case IXGBE_DEV_ID_X550EM_X_XFI:
+		hw->mac.type = ixgbe_mac_X550EM_x;
+		hw->mvals = ixgbe_mvals_X550EM_x;
+		break;
+	case IXGBE_DEV_ID_X550EM_A_KR:
+	case IXGBE_DEV_ID_X550EM_A_KR_L:
+	case IXGBE_DEV_ID_X550EM_A_SFP_N:
+	case IXGBE_DEV_ID_X550EM_A_SGMII:
+	case IXGBE_DEV_ID_X550EM_A_SGMII_L:
+	case IXGBE_DEV_ID_X550EM_A_1G_T:
+	case IXGBE_DEV_ID_X550EM_A_1G_T_L:
+	case IXGBE_DEV_ID_X550EM_A_10G_T:
+	case IXGBE_DEV_ID_X550EM_A_QSFP:
+	case IXGBE_DEV_ID_X550EM_A_QSFP_N:
+	case IXGBE_DEV_ID_X550EM_A_SFP:
+		hw->mac.type = ixgbe_mac_X550EM_a;
+		hw->mvals = ixgbe_mvals_X550EM_a;
+		break;
+	default:
+		ret_val = IXGBE_ERR_DEVICE_NOT_SUPPORTED;
+		ERROR_REPORT2(IXGBE_ERROR_UNSUPPORTED,
+			     "Unsupported device id: %x",
+			     hw->device_id);
+		break;
+	}
+
+	DEBUGOUT2("ixgbe_set_mac_type found mac: %d, returns: %d\n",
+		  hw->mac.type, ret_val);
+	return ret_val;
+}
+
+/**
+ *  ixgbe_init_hw - Initialize the hardware
+ *  @hw: pointer to hardware structure
+ *
+ *  Initialize the hardware by resetting and then starting the hardware
+ **/
+int32_t ixgbe_init_hw(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.init_hw, (hw),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_reset_hw - Performs a hardware reset
+ *  @hw: pointer to hardware structure
+ *
+ *  Resets the hardware by resetting the transmit and receive units, masks and
+ *  clears all interrupts, performs a PHY reset, and performs a MAC reset
+ **/
+int32_t ixgbe_reset_hw(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.reset_hw, (hw),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_start_hw - Prepares hardware for Rx/Tx
+ *  @hw: pointer to hardware structure
+ *
+ *  Starts the hardware by filling the bus info structure and media type,
+ *  clears all on chip counters, initializes receive address registers,
+ *  multicast table, VLAN filter table, calls routine to setup link and
+ *  flow control settings, and leaves transmit and receive units disabled
+ *  and uninitialized.
+ **/
+int32_t ixgbe_start_hw(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.start_hw, (hw),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_enable_relaxed_ordering - Enables tx relaxed ordering,
+ *  which is disabled by default in ixgbe_start_hw();
+ *
+ *  @hw: pointer to hardware structure
+ *
+ *   Enable relaxed ordering;
+ **/
+void ixgbe_enable_relaxed_ordering(struct ixgbe_hw *hw)
+{
+	if (hw->mac.ops.enable_relaxed_ordering)
+		hw->mac.ops.enable_relaxed_ordering(hw);
+}
+
+/**
+ *  ixgbe_clear_hw_cntrs - Clear hardware counters
+ *  @hw: pointer to hardware structure
+ *
+ *  Clears all hardware statistics counters by reading them from the hardware
+ *  Statistics counters are clear on read.
+ **/
+int32_t ixgbe_clear_hw_cntrs(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.clear_hw_cntrs, (hw),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_get_media_type - Get media type
+ *  @hw: pointer to hardware structure
+ *
+ *  Returns the media type (fiber, copper, backplane)
+ **/
+enum ixgbe_media_type ixgbe_get_media_type(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.get_media_type, (hw),
+			       ixgbe_media_type_unknown);
+}
+
+/**
+ *  ixgbe_get_mac_addr - Get MAC address
+ *  @hw: pointer to hardware structure
+ *  @mac_addr: Adapter MAC address
+ *
+ *  Reads the adapter's MAC address from the first Receive Address Register
+ *  (RAR0) A reset of the adapter must have been performed prior to calling
+ *  this function in order for the MAC address to have been loaded from the
+ *  EEPROM into RAR0
+ **/
+int32_t ixgbe_get_mac_addr(struct ixgbe_hw *hw, uint8_t *mac_addr)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.get_mac_addr,
+			       (hw, mac_addr), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_get_san_mac_addr - Get SAN MAC address
+ *  @hw: pointer to hardware structure
+ *  @san_mac_addr: SAN MAC address
+ *
+ *  Reads the SAN MAC address from the EEPROM, if it's available.  This is
+ *  per-port, so set_lan_id() must be called before reading the addresses.
+ **/
+int32_t ixgbe_get_san_mac_addr(struct ixgbe_hw *hw, uint8_t *san_mac_addr)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.get_san_mac_addr,
+			       (hw, san_mac_addr), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_set_san_mac_addr - Write a SAN MAC address
+ *  @hw: pointer to hardware structure
+ *  @san_mac_addr: SAN MAC address
+ *
+ *  Writes A SAN MAC address to the EEPROM.
+ **/
+int32_t ixgbe_set_san_mac_addr(struct ixgbe_hw *hw, uint8_t *san_mac_addr)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.set_san_mac_addr,
+			       (hw, san_mac_addr), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_get_device_caps - Get additional device capabilities
+ *  @hw: pointer to hardware structure
+ *  @device_caps: the EEPROM word for device capabilities
+ *
+ *  Reads the extra device capabilities from the EEPROM
+ **/
+int32_t ixgbe_get_device_caps(struct ixgbe_hw *hw, uint16_t *device_caps)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.get_device_caps,
+			       (hw, device_caps), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_get_wwn_prefix - Get alternative WWNN/WWPN prefix from the EEPROM
+ *  @hw: pointer to hardware structure
+ *  @wwnn_prefix: the alternative WWNN prefix
+ *  @wwpn_prefix: the alternative WWPN prefix
+ *
+ *  This function will read the EEPROM from the alternative SAN MAC address
+ *  block to check the support for the alternative WWNN/WWPN prefix support.
+ **/
+int32_t ixgbe_get_wwn_prefix(struct ixgbe_hw *hw, uint16_t *wwnn_prefix,
+			 uint16_t *wwpn_prefix)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.get_wwn_prefix,
+			       (hw, wwnn_prefix, wwpn_prefix),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_get_fcoe_boot_status -  Get FCOE boot status from EEPROM
+ *  @hw: pointer to hardware structure
+ *  @bs: the fcoe boot status
+ *
+ *  This function will read the FCOE boot status from the iSCSI FCOE block
+ **/
+int32_t ixgbe_get_fcoe_boot_status(struct ixgbe_hw *hw, uint16_t *bs)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.get_fcoe_boot_status,
+			       (hw, bs),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_get_bus_info - Set PCI bus info
+ *  @hw: pointer to hardware structure
+ *
+ *  Sets the PCI bus info (speed, width, type) within the ixgbe_hw structure
+ **/
+int32_t ixgbe_get_bus_info(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.get_bus_info, (hw),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_get_num_of_tx_queues - Get Tx queues
+ *  @hw: pointer to hardware structure
+ *
+ *  Returns the number of transmit queues for the given adapter.
+ **/
+uint32_t ixgbe_get_num_of_tx_queues(struct ixgbe_hw *hw)
+{
+	return hw->mac.max_tx_queues;
+}
+
+/**
+ *  ixgbe_get_num_of_rx_queues - Get Rx queues
+ *  @hw: pointer to hardware structure
+ *
+ *  Returns the number of receive queues for the given adapter.
+ **/
+uint32_t ixgbe_get_num_of_rx_queues(struct ixgbe_hw *hw)
+{
+	return hw->mac.max_rx_queues;
+}
+
+/**
+ *  ixgbe_stop_adapter - Disable Rx/Tx units
+ *  @hw: pointer to hardware structure
+ *
+ *  Sets the adapter_stopped flag within ixgbe_hw struct. Clears interrupts,
+ *  disables transmit and receive units. The adapter_stopped flag is used by
+ *  the shared code and drivers to determine if the adapter is in a stopped
+ *  state and should not touch the hardware.
+ **/
+int32_t ixgbe_stop_adapter(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.stop_adapter, (hw),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_read_pba_string - Reads part number string from EEPROM
+ *  @hw: pointer to hardware structure
+ *  @pba_num: stores the part number string from the EEPROM
+ *  @pba_num_size: part number string buffer length
+ *
+ *  Reads the part number string from the EEPROM.
+ **/
+int32_t ixgbe_read_pba_string(struct ixgbe_hw *hw, uint8_t *pba_num, uint32_t pba_num_size)
+{
+	return ixgbe_read_pba_string_generic(hw, pba_num, pba_num_size);
+}
+
+/**
+ *  ixgbe_read_pba_num - Reads part number from EEPROM
+ *  @hw: pointer to hardware structure
+ *  @pba_num: stores the part number from the EEPROM
+ *
+ *  Reads the part number from the EEPROM.
+ **/
+int32_t ixgbe_read_pba_num(struct ixgbe_hw *hw, uint32_t *pba_num)
+{
+	return ixgbe_read_pba_num_generic(hw, pba_num);
+}
+
+/**
+ *  ixgbe_identify_phy - Get PHY type
+ *  @hw: pointer to hardware structure
+ *
+ *  Determines the physical layer module found on the current adapter.
+ **/
+int32_t ixgbe_identify_phy(struct ixgbe_hw *hw)
+{
+	int32_t status = IXGBE_SUCCESS;
+
+	if (hw->phy.type == ixgbe_phy_unknown) {
+		status = ixgbe_call_func(hw, hw->phy.ops.identify, (hw),
+					 IXGBE_NOT_IMPLEMENTED);
+	}
+
+	return status;
+}
+
+/**
+ *  ixgbe_reset_phy - Perform a PHY reset
+ *  @hw: pointer to hardware structure
+ **/
+int32_t ixgbe_reset_phy(struct ixgbe_hw *hw)
+{
+	int32_t status = IXGBE_SUCCESS;
+
+	if (hw->phy.type == ixgbe_phy_unknown) {
+		if (ixgbe_identify_phy(hw) != IXGBE_SUCCESS)
+			status = IXGBE_ERR_PHY;
+	}
+
+	if (status == IXGBE_SUCCESS) {
+		status = ixgbe_call_func(hw, hw->phy.ops.reset, (hw),
+					 IXGBE_NOT_IMPLEMENTED);
+	}
+	return status;
+}
+
+/**
+ *  ixgbe_get_phy_firmware_version -
+ *  @hw: pointer to hardware structure
+ *  @firmware_version: pointer to firmware version
+ **/
+int32_t ixgbe_get_phy_firmware_version(struct ixgbe_hw *hw, uint16_t *firmware_version)
+{
+	int32_t status = IXGBE_SUCCESS;
+
+	status = ixgbe_call_func(hw, hw->phy.ops.get_firmware_version,
+				 (hw, firmware_version),
+				 IXGBE_NOT_IMPLEMENTED);
+	return status;
+}
+
+/**
+ *  ixgbe_read_phy_reg - Read PHY register
+ *  @hw: pointer to hardware structure
+ *  @reg_addr: 32 bit address of PHY register to read
+ *  @device_type: type of device you want to communicate with
+ *  @phy_data: Pointer to read data from PHY register
+ *
+ *  Reads a value from a specified PHY register
+ **/
+int32_t ixgbe_read_phy_reg(struct ixgbe_hw *hw, uint32_t reg_addr, uint32_t device_type,
+		       uint16_t *phy_data)
+{
+	if (hw->phy.id == 0)
+		ixgbe_identify_phy(hw);
+
+	return ixgbe_call_func(hw, hw->phy.ops.read_reg, (hw, reg_addr,
+			       device_type, phy_data), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_write_phy_reg - Write PHY register
+ *  @hw: pointer to hardware structure
+ *  @reg_addr: 32 bit PHY register to write
+ *  @device_type: type of device you want to communicate with
+ *  @phy_data: Data to write to the PHY register
+ *
+ *  Writes a value to specified PHY register
+ **/
+int32_t ixgbe_write_phy_reg(struct ixgbe_hw *hw, uint32_t reg_addr, uint32_t device_type,
+			uint16_t phy_data)
+{
+	if (hw->phy.id == 0)
+		ixgbe_identify_phy(hw);
+
+	return ixgbe_call_func(hw, hw->phy.ops.write_reg, (hw, reg_addr,
+			       device_type, phy_data), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_setup_phy_link - Restart PHY autoneg
+ *  @hw: pointer to hardware structure
+ *
+ *  Restart autonegotiation and PHY and waits for completion.
+ **/
+int32_t ixgbe_setup_phy_link(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->phy.ops.setup_link, (hw),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ * ixgbe_setup_internal_phy - Configure integrated PHY
+ * @hw: pointer to hardware structure
+ *
+ * Reconfigure the integrated PHY in order to enable talk to the external PHY.
+ * Returns success if not implemented, since nothing needs to be done in this
+ * case.
+ */
+int32_t ixgbe_setup_internal_phy(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->phy.ops.setup_internal_link, (hw),
+			       IXGBE_SUCCESS);
+}
+
+/**
+ *  ixgbe_check_phy_link - Determine link and speed status
+ *  @hw: pointer to hardware structure
+ *  @speed: link speed
+ *  @link_up: TRUE when link is up
+ *
+ *  Reads a PHY register to determine if link is up and the current speed for
+ *  the PHY.
+ **/
+int32_t ixgbe_check_phy_link(struct ixgbe_hw *hw, ixgbe_link_speed *speed,
+			 bool *link_up)
+{
+	return ixgbe_call_func(hw, hw->phy.ops.check_link, (hw, speed,
+			       link_up), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_setup_phy_link_speed - Set auto advertise
+ *  @hw: pointer to hardware structure
+ *  @speed: new link speed
+ *  @autoneg_wait_to_complete: TRUE when waiting for completion is needed
+ *
+ *  Sets the auto advertised capabilities
+ **/
+int32_t ixgbe_setup_phy_link_speed(struct ixgbe_hw *hw, ixgbe_link_speed speed,
+			       bool autoneg_wait_to_complete)
+{
+	return ixgbe_call_func(hw, hw->phy.ops.setup_link_speed, (hw, speed,
+			       autoneg_wait_to_complete),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ * ixgbe_set_phy_power - Control the phy power state
+ * @hw: pointer to hardware structure
+ * @on: TRUE for on, FALSE for off
+ */
+int32_t ixgbe_set_phy_power(struct ixgbe_hw *hw, bool on)
+{
+	return ixgbe_call_func(hw, hw->phy.ops.set_phy_power, (hw, on),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_check_link - Get link and speed status
+ *  @hw: pointer to hardware structure
+ *  @speed: pointer to link speed
+ *  @link_up: TRUE when link is up
+ *  @link_up_wait_to_complete: bool used to wait for link up or not
+ *
+ *  Reads the links register to determine if link is up and the current speed
+ **/
+int32_t ixgbe_check_link(struct ixgbe_hw *hw, ixgbe_link_speed *speed,
+		     bool *link_up, bool link_up_wait_to_complete)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.check_link, (hw, speed,
+			       link_up, link_up_wait_to_complete),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_disable_tx_laser - Disable Tx laser
+ *  @hw: pointer to hardware structure
+ *
+ *  If the driver needs to disable the laser on SFI optics.
+ **/
+void ixgbe_disable_tx_laser(struct ixgbe_hw *hw)
+{
+	if (hw->mac.ops.disable_tx_laser)
+		hw->mac.ops.disable_tx_laser(hw);
+}
+
+/**
+ *  ixgbe_enable_tx_laser - Enable Tx laser
+ *  @hw: pointer to hardware structure
+ *
+ *  If the driver needs to enable the laser on SFI optics.
+ **/
+void ixgbe_enable_tx_laser(struct ixgbe_hw *hw)
+{
+	if (hw->mac.ops.enable_tx_laser)
+		hw->mac.ops.enable_tx_laser(hw);
+}
+
+/**
+ *  ixgbe_flap_tx_laser - flap Tx laser to start autotry process
+ *  @hw: pointer to hardware structure
+ *
+ *  When the driver changes the link speeds that it can support then
+ *  flap the tx laser to alert the link partner to start autotry
+ *  process on its end.
+ **/
+void ixgbe_flap_tx_laser(struct ixgbe_hw *hw)
+{
+	if (hw->mac.ops.flap_tx_laser)
+		hw->mac.ops.flap_tx_laser(hw);
+}
+
+/**
+ *  ixgbe_setup_link - Set link speed
+ *  @hw: pointer to hardware structure
+ *  @speed: new link speed
+ *  @autoneg_wait_to_complete: TRUE when waiting for completion is needed
+ *
+ *  Configures link settings.  Restarts the link.
+ *  Performs autonegotiation if needed.
+ **/
+int32_t ixgbe_setup_link(struct ixgbe_hw *hw, ixgbe_link_speed speed,
+		     bool autoneg_wait_to_complete)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.setup_link, (hw, speed,
+			       autoneg_wait_to_complete),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_setup_mac_link - Set link speed
+ *  @hw: pointer to hardware structure
+ *  @speed: new link speed
+ *  @autoneg_wait_to_complete: TRUE when waiting for completion is needed
+ *
+ *  Configures link settings.  Restarts the link.
+ *  Performs autonegotiation if needed.
+ **/
+int32_t ixgbe_setup_mac_link(struct ixgbe_hw *hw, ixgbe_link_speed speed,
+			 bool autoneg_wait_to_complete)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.setup_mac_link, (hw, speed,
+			       autoneg_wait_to_complete),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_get_link_capabilities - Returns link capabilities
+ *  @hw: pointer to hardware structure
+ *  @speed: link speed capabilities
+ *  @autoneg: TRUE when autoneg or autotry is enabled
+ *
+ *  Determines the link capabilities of the current configuration.
+ **/
+int32_t ixgbe_get_link_capabilities(struct ixgbe_hw *hw, ixgbe_link_speed *speed,
+				bool *autoneg)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.get_link_capabilities, (hw,
+			       speed, autoneg), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_led_on - Turn on LEDs
+ *  @hw: pointer to hardware structure
+ *  @index: led number to turn on
+ *
+ *  Turns on the software controllable LEDs.
+ **/
+int32_t ixgbe_led_on(struct ixgbe_hw *hw, uint32_t index)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.led_on, (hw, index),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_led_off - Turn off LEDs
+ *  @hw: pointer to hardware structure
+ *  @index: led number to turn off
+ *
+ *  Turns off the software controllable LEDs.
+ **/
+int32_t ixgbe_led_off(struct ixgbe_hw *hw, uint32_t index)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.led_off, (hw, index),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_blink_led_start - Blink LEDs
+ *  @hw: pointer to hardware structure
+ *  @index: led number to blink
+ *
+ *  Blink LED based on index.
+ **/
+int32_t ixgbe_blink_led_start(struct ixgbe_hw *hw, uint32_t index)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.blink_led_start, (hw, index),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_blink_led_stop - Stop blinking LEDs
+ *  @hw: pointer to hardware structure
+ *  @index: led number to stop
+ *
+ *  Stop blinking LED based on index.
+ **/
+int32_t ixgbe_blink_led_stop(struct ixgbe_hw *hw, uint32_t index)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.blink_led_stop, (hw, index),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_init_eeprom_params - Initialize EEPROM parameters
+ *  @hw: pointer to hardware structure
+ *
+ *  Initializes the EEPROM parameters ixgbe_eeprom_info within the
+ *  ixgbe_hw struct in order to set up EEPROM access.
+ **/
+int32_t ixgbe_init_eeprom_params(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->eeprom.ops.init_params, (hw),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+
+/**
+ *  ixgbe_write_eeprom - Write word to EEPROM
+ *  @hw: pointer to hardware structure
+ *  @offset: offset within the EEPROM to be written to
+ *  @data: 16 bit word to be written to the EEPROM
+ *
+ *  Writes 16 bit value to EEPROM. If ixgbe_eeprom_update_checksum is not
+ *  called after this function, the EEPROM will most likely contain an
+ *  invalid checksum.
+ **/
+int32_t ixgbe_write_eeprom(struct ixgbe_hw *hw, uint16_t offset, uint16_t data)
+{
+	return ixgbe_call_func(hw, hw->eeprom.ops.write, (hw, offset, data),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_write_eeprom_buffer - Write word(s) to EEPROM
+ *  @hw: pointer to hardware structure
+ *  @offset: offset within the EEPROM to be written to
+ *  @data: 16 bit word(s) to be written to the EEPROM
+ *  @words: number of words
+ *
+ *  Writes 16 bit word(s) to EEPROM. If ixgbe_eeprom_update_checksum is not
+ *  called after this function, the EEPROM will most likely contain an
+ *  invalid checksum.
+ **/
+int32_t ixgbe_write_eeprom_buffer(struct ixgbe_hw *hw, uint16_t offset, uint16_t words,
+			      uint16_t *data)
+{
+	return ixgbe_call_func(hw, hw->eeprom.ops.write_buffer,
+			       (hw, offset, words, data),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_read_eeprom - Read word from EEPROM
+ *  @hw: pointer to hardware structure
+ *  @offset: offset within the EEPROM to be read
+ *  @data: read 16 bit value from EEPROM
+ *
+ *  Reads 16 bit value from EEPROM
+ **/
+int32_t ixgbe_read_eeprom(struct ixgbe_hw *hw, uint16_t offset, uint16_t *data)
+{
+	return ixgbe_call_func(hw, hw->eeprom.ops.read, (hw, offset, data),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_read_eeprom_buffer - Read word(s) from EEPROM
+ *  @hw: pointer to hardware structure
+ *  @offset: offset within the EEPROM to be read
+ *  @data: read 16 bit word(s) from EEPROM
+ *  @words: number of words
+ *
+ *  Reads 16 bit word(s) from EEPROM
+ **/
+int32_t ixgbe_read_eeprom_buffer(struct ixgbe_hw *hw, uint16_t offset,
+			     uint16_t words, uint16_t *data)
+{
+	return ixgbe_call_func(hw, hw->eeprom.ops.read_buffer,
+			       (hw, offset, words, data),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_validate_eeprom_checksum - Validate EEPROM checksum
+ *  @hw: pointer to hardware structure
+ *  @checksum_val: calculated checksum
+ *
+ *  Performs checksum calculation and validates the EEPROM checksum
+ **/
+int32_t ixgbe_validate_eeprom_checksum(struct ixgbe_hw *hw, uint16_t *checksum_val)
+{
+	return ixgbe_call_func(hw, hw->eeprom.ops.validate_checksum,
+			       (hw, checksum_val), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_eeprom_update_checksum - Updates the EEPROM checksum
+ *  @hw: pointer to hardware structure
+ **/
+int32_t ixgbe_update_eeprom_checksum(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->eeprom.ops.update_checksum, (hw),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_insert_mac_addr - Find a RAR for this mac address
+ *  @hw: pointer to hardware structure
+ *  @addr: Address to put into receive address register
+ *  @vmdq: VMDq pool to assign
+ *
+ *  Puts an ethernet address into a receive address register, or
+ *  finds the rar that it is already in; adds to the pool list
+ **/
+int32_t ixgbe_insert_mac_addr(struct ixgbe_hw *hw, uint8_t *addr, uint32_t vmdq)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.insert_mac_addr,
+			       (hw, addr, vmdq),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_set_rar - Set Rx address register
+ *  @hw: pointer to hardware structure
+ *  @index: Receive address register to write
+ *  @addr: Address to put into receive address register
+ *  @vmdq: VMDq "set"
+ *  @enable_addr: set flag that address is active
+ *
+ *  Puts an ethernet address into a receive address register.
+ **/
+int32_t ixgbe_set_rar(struct ixgbe_hw *hw, uint32_t index, uint8_t *addr, uint32_t vmdq,
+		  uint32_t enable_addr)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.set_rar, (hw, index, addr, vmdq,
+			       enable_addr), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_clear_rar - Clear Rx address register
+ *  @hw: pointer to hardware structure
+ *  @index: Receive address register to write
+ *
+ *  Puts an ethernet address into a receive address register.
+ **/
+int32_t ixgbe_clear_rar(struct ixgbe_hw *hw, uint32_t index)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.clear_rar, (hw, index),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_set_vmdq - Associate a VMDq index with a receive address
+ *  @hw: pointer to hardware structure
+ *  @rar: receive address register index to associate with VMDq index
+ *  @vmdq: VMDq set or pool index
+ **/
+int32_t ixgbe_set_vmdq(struct ixgbe_hw *hw, uint32_t rar, uint32_t vmdq)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.set_vmdq, (hw, rar, vmdq),
+			       IXGBE_NOT_IMPLEMENTED);
+
+}
+
+/**
+ *  ixgbe_set_vmdq_san_mac - Associate VMDq index 127 with a receive address
+ *  @hw: pointer to hardware structure
+ *  @vmdq: VMDq default pool index
+ **/
+int32_t ixgbe_set_vmdq_san_mac(struct ixgbe_hw *hw, uint32_t vmdq)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.set_vmdq_san_mac,
+			       (hw, vmdq), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_clear_vmdq - Disassociate a VMDq index from a receive address
+ *  @hw: pointer to hardware structure
+ *  @rar: receive address register index to disassociate with VMDq index
+ *  @vmdq: VMDq set or pool index
+ **/
+int32_t ixgbe_clear_vmdq(struct ixgbe_hw *hw, uint32_t rar, uint32_t vmdq)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.clear_vmdq, (hw, rar, vmdq),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_init_rx_addrs - Initializes receive address filters.
+ *  @hw: pointer to hardware structure
+ *
+ *  Places the MAC address in receive address register 0 and clears the rest
+ *  of the receive address registers. Clears the multicast table. Assumes
+ *  the receiver is in reset when the routine is called.
+ **/
+int32_t ixgbe_init_rx_addrs(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.init_rx_addrs, (hw),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_get_num_rx_addrs - Returns the number of RAR entries.
+ *  @hw: pointer to hardware structure
+ **/
+uint32_t ixgbe_get_num_rx_addrs(struct ixgbe_hw *hw)
+{
+	return hw->mac.num_rar_entries;
+}
+
+/**
+ *  ixgbe_update_uc_addr_list - Updates the MAC's list of secondary addresses
+ *  @hw: pointer to hardware structure
+ *  @addr_list: the list of new multicast addresses
+ *  @addr_count: number of addresses
+ *  @func: iterator function to walk the multicast address list
+ *
+ *  The given list replaces any existing list. Clears the secondary addrs from
+ *  receive address registers. Uses unused receive address registers for the
+ *  first secondary addresses, and falls back to promiscuous mode as needed.
+ **/
+int32_t ixgbe_update_uc_addr_list(struct ixgbe_hw *hw, uint8_t *addr_list,
+			      uint32_t addr_count, ixgbe_mc_addr_itr func)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.update_uc_addr_list, (hw,
+			       addr_list, addr_count, func),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_update_mc_addr_list - Updates the MAC's list of multicast addresses
+ *  @hw: pointer to hardware structure
+ *  @mc_addr_list: the list of new multicast addresses
+ *  @mc_addr_count: number of addresses
+ *  @func: iterator function to walk the multicast address list
+ *  @clear: flag, when set clears the table beforehand
+ *
+ *  The given list replaces any existing list. Clears the MC addrs from receive
+ *  address registers and the multicast table. Uses unused receive address
+ *  registers for the first multicast addresses, and hashes the rest into the
+ *  multicast table.
+ **/
+int32_t ixgbe_update_mc_addr_list(struct ixgbe_hw *hw, uint8_t *mc_addr_list,
+			      uint32_t mc_addr_count, ixgbe_mc_addr_itr func,
+			      bool clear)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.update_mc_addr_list, (hw,
+			       mc_addr_list, mc_addr_count, func, clear),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_enable_mc - Enable multicast address in RAR
+ *  @hw: pointer to hardware structure
+ *
+ *  Enables multicast address in RAR and the use of the multicast hash table.
+ **/
+int32_t ixgbe_enable_mc(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.enable_mc, (hw),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_disable_mc - Disable multicast address in RAR
+ *  @hw: pointer to hardware structure
+ *
+ *  Disables multicast address in RAR and the use of the multicast hash table.
+ **/
+int32_t ixgbe_disable_mc(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.disable_mc, (hw),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_clear_vfta - Clear VLAN filter table
+ *  @hw: pointer to hardware structure
+ *
+ *  Clears the VLAN filer table, and the VMDq index associated with the filter
+ **/
+int32_t ixgbe_clear_vfta(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.clear_vfta, (hw),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_set_vfta - Set VLAN filter table
+ *  @hw: pointer to hardware structure
+ *  @vlan: VLAN id to write to VLAN filter
+ *  @vind: VMDq output index that maps queue to VLAN id in VLVFB
+ *  @vlan_on: boolean flag to turn on/off VLAN
+ *  @vlvf_bypass: boolean flag indicating updating the default pool is okay
+ *
+ *  Turn on/off specified VLAN in the VLAN filter table.
+ **/
+int32_t ixgbe_set_vfta(struct ixgbe_hw *hw, uint32_t vlan, uint32_t vind, bool vlan_on,
+		   bool vlvf_bypass)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.set_vfta, (hw, vlan, vind,
+			       vlan_on, vlvf_bypass), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_set_vlvf - Set VLAN Pool Filter
+ *  @hw: pointer to hardware structure
+ *  @vlan: VLAN id to write to VLAN filter
+ *  @vind: VMDq output index that maps queue to VLAN id in VLVFB
+ *  @vlan_on: boolean flag to turn on/off VLAN in VLVF
+ *  @vfta_delta: pointer to the difference between the current value of VFTA
+ *		 and the desired value
+ *  @vfta: the desired value of the VFTA
+ *  @vlvf_bypass: boolean flag indicating updating the default pool is okay
+ *
+ *  Turn on/off specified bit in VLVF table.
+ **/
+int32_t ixgbe_set_vlvf(struct ixgbe_hw *hw, uint32_t vlan, uint32_t vind, bool vlan_on,
+		   uint32_t *vfta_delta, uint32_t vfta, bool vlvf_bypass)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.set_vlvf, (hw, vlan, vind,
+			       vlan_on, vfta_delta, vfta, vlvf_bypass),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_fc_enable - Enable flow control
+ *  @hw: pointer to hardware structure
+ *
+ *  Configures the flow control settings based on SW configuration.
+ **/
+int32_t ixgbe_fc_enable(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.fc_enable, (hw),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_setup_fc - Set up flow control
+ *  @hw: pointer to hardware structure
+ *
+ *  Called at init time to set up flow control.
+ **/
+int32_t ixgbe_setup_fc(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.setup_fc, (hw),
+		IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ * ixgbe_set_fw_drv_ver - Try to send the driver version number FW
+ * @hw: pointer to hardware structure
+ * @maj: driver major number to be sent to firmware
+ * @min: driver minor number to be sent to firmware
+ * @build: driver build number to be sent to firmware
+ * @ver: driver version number to be sent to firmware
+ * @len: length of driver_ver string
+ * @driver_ver: driver string
+ **/
+int32_t ixgbe_set_fw_drv_ver(struct ixgbe_hw *hw, uint8_t maj, uint8_t min, uint8_t build,
+			 uint8_t ver, uint16_t len, char *driver_ver)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.set_fw_drv_ver, (hw, maj, min,
+			       build, ver, len, driver_ver),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+
+
+/**
+ *  ixgbe_dmac_config - Configure DMA Coalescing registers.
+ *  @hw: pointer to hardware structure
+ *
+ *  Configure DMA coalescing. If enabling dmac, dmac is activated.
+ *  When disabling dmac, dmac enable dmac bit is cleared.
+ **/
+int32_t ixgbe_dmac_config(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.dmac_config, (hw),
+				IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_dmac_update_tcs - Configure DMA Coalescing registers.
+ *  @hw: pointer to hardware structure
+ *
+ *  Disables dmac, updates per TC settings, and then enable dmac.
+ **/
+int32_t ixgbe_dmac_update_tcs(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.dmac_update_tcs, (hw),
+				IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_dmac_config_tcs - Configure DMA Coalescing registers.
+ *  @hw: pointer to hardware structure
+ *
+ *  Configure DMA coalescing threshold per TC and set high priority bit for
+ *  FCOE TC. The dmac enable bit must be cleared before configuring.
+ **/
+int32_t ixgbe_dmac_config_tcs(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.dmac_config_tcs, (hw),
+				IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_setup_eee - Enable/disable EEE support
+ *  @hw: pointer to the HW structure
+ *  @enable_eee: boolean flag to enable EEE
+ *
+ *  Enable/disable EEE based on enable_ee flag.
+ *  Auto-negotiation must be started after BASE-T EEE bits in PHY register 7.3C
+ *  are modified.
+ *
+ **/
+int32_t ixgbe_setup_eee(struct ixgbe_hw *hw, bool enable_eee)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.setup_eee, (hw, enable_eee),
+			IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ * ixgbe_set_source_address_pruning - Enable/Disable source address pruning
+ * @hw: pointer to hardware structure
+ * @enable: enable or disable source address pruning
+ * @pool: Rx pool - Rx pool to toggle source address pruning
+ **/
+void ixgbe_set_source_address_pruning(struct ixgbe_hw *hw, bool enable,
+				      unsigned int pool)
+{
+	if (hw->mac.ops.set_source_address_pruning)
+		hw->mac.ops.set_source_address_pruning(hw, enable, pool);
+}
+
+/**
+ *  ixgbe_set_ethertype_anti_spoofing - Enable/Disable Ethertype anti-spoofing
+ *  @hw: pointer to hardware structure
+ *  @enable: enable or disable switch for Ethertype anti-spoofing
+ *  @vf: Virtual Function pool - VF Pool to set for Ethertype anti-spoofing
+ *
+ **/
+void ixgbe_set_ethertype_anti_spoofing(struct ixgbe_hw *hw, bool enable, int vf)
+{
+	if (hw->mac.ops.set_ethertype_anti_spoofing)
+		hw->mac.ops.set_ethertype_anti_spoofing(hw, enable, vf);
+}
+
+/**
+ *  ixgbe_read_iosf_sb_reg - Read 32 bit PHY register
+ *  @hw: pointer to hardware structure
+ *  @reg_addr: 32 bit address of PHY register to read
+ *  @device_type: type of device you want to communicate with
+ *  @phy_data: Pointer to read data from PHY register
+ *
+ *  Reads a value from a specified PHY register
+ **/
+int32_t ixgbe_read_iosf_sb_reg(struct ixgbe_hw *hw, uint32_t reg_addr,
+			   uint32_t device_type, uint32_t *phy_data)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.read_iosf_sb_reg, (hw, reg_addr,
+			       device_type, phy_data), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_write_iosf_sb_reg - Write 32 bit register through IOSF Sideband
+ *  @hw: pointer to hardware structure
+ *  @reg_addr: 32 bit PHY register to write
+ *  @device_type: type of device you want to communicate with
+ *  @phy_data: Data to write to the PHY register
+ *
+ *  Writes a value to specified PHY register
+ **/
+int32_t ixgbe_write_iosf_sb_reg(struct ixgbe_hw *hw, uint32_t reg_addr,
+			    uint32_t device_type, uint32_t phy_data)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.write_iosf_sb_reg, (hw, reg_addr,
+			       device_type, phy_data), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_disable_mdd - Disable malicious driver detection
+ *  @hw: pointer to hardware structure
+ *
+ **/
+void ixgbe_disable_mdd(struct ixgbe_hw *hw)
+{
+	if (hw->mac.ops.disable_mdd)
+		hw->mac.ops.disable_mdd(hw);
+}
+
+/**
+ *  ixgbe_enable_mdd - Enable malicious driver detection
+ *  @hw: pointer to hardware structure
+ *
+ **/
+void ixgbe_enable_mdd(struct ixgbe_hw *hw)
+{
+	if (hw->mac.ops.enable_mdd)
+		hw->mac.ops.enable_mdd(hw);
+}
+
+/**
+ *  ixgbe_mdd_event - Handle malicious driver detection event
+ *  @hw: pointer to hardware structure
+ *  @vf_bitmap: vf bitmap of malicious vfs
+ *
+ **/
+void ixgbe_mdd_event(struct ixgbe_hw *hw, uint32_t *vf_bitmap)
+{
+	if (hw->mac.ops.mdd_event)
+		hw->mac.ops.mdd_event(hw, vf_bitmap);
+}
+
+/**
+ *  ixgbe_restore_mdd_vf - Restore VF that was disabled during malicious driver
+ *  detection event
+ *  @hw: pointer to hardware structure
+ *  @vf: vf index
+ *
+ **/
+void ixgbe_restore_mdd_vf(struct ixgbe_hw *hw, uint32_t vf)
+{
+	if (hw->mac.ops.restore_mdd_vf)
+		hw->mac.ops.restore_mdd_vf(hw, vf);
+}
+
+/**
+ *  ixgbe_enter_lplu - Transition to low power states
+ *  @hw: pointer to hardware structure
+ *
+ * Configures Low Power Link Up on transition to low power states
+ * (from D0 to non-D0).
+ **/
+int32_t ixgbe_enter_lplu(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->phy.ops.enter_lplu, (hw),
+				IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ * ixgbe_handle_lasi - Handle external Base T PHY interrupt
+ * @hw: pointer to hardware structure
+ *
+ * Handle external Base T PHY interrupt. If high temperature
+ * failure alarm then return error, else if link status change
+ * then setup internal/external PHY link
+ *
+ * Return IXGBE_ERR_OVERTEMP if interrupt is high temperature
+ * failure alarm, else return PHY access status.
+ */
+int32_t ixgbe_handle_lasi(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->phy.ops.handle_lasi, (hw),
+				IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_bypass_rw - Bit bang data into by_pass FW
+ *  @hw: pointer to hardware structure
+ *  @cmd: Command we send to the FW
+ *  @status: The reply from the FW
+ *
+ *  Bit-bangs the cmd to the by_pass FW status points to what is returned.
+ **/
+int32_t ixgbe_bypass_rw(struct ixgbe_hw *hw, uint32_t cmd, uint32_t *status)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.bypass_rw, (hw, cmd, status),
+				IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ * ixgbe_bypass_valid_rd - Verify valid return from bit-bang.
+ *
+ * If we send a write we can't be sure it took until we can read back
+ * that same register.  It can be a problem as some of the feilds may
+ * for valid reasons change inbetween the time wrote the register and
+ * we read it again to verify.  So this function check everything we
+ * can check and then assumes it worked.
+ *
+ * @uint32_t in_reg - The register cmd for the bit-bang read.
+ * @uint32_t out_reg - The register returned from a bit-bang read.
+ **/
+bool ixgbe_bypass_valid_rd(struct ixgbe_hw *hw, uint32_t in_reg, uint32_t out_reg)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.bypass_valid_rd,
+			       (in_reg, out_reg), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_bypass_set - Set a bypass field in the FW CTRL Regiter.
+ *  @hw: pointer to hardware structure
+ *  @cmd: The control word we are setting.
+ *  @event: The event we are setting in the FW.  This also happens to
+ *          be the mask for the event we are setting (handy)
+ *  @action: The action we set the event to in the FW. This is in a
+ *           bit field that happens to be what we want to put in
+ *           the event spot (also handy)
+ *
+ *  Writes to the cmd control the bits in actions.
+ **/
+int32_t ixgbe_bypass_set(struct ixgbe_hw *hw, uint32_t cmd, uint32_t event, uint32_t action)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.bypass_set,
+			       (hw, cmd, event, action),
+				IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_bypass_rd_eep - Read the bypass FW eeprom address
+ *  @hw: pointer to hardware structure
+ *  @addr: The bypass eeprom address to read.
+ *  @value: The 8b of data at the address above.
+ **/
+int32_t ixgbe_bypass_rd_eep(struct ixgbe_hw *hw, uint32_t addr, uint8_t *value)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.bypass_rd_eep,
+			       (hw, addr, value), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_read_analog_reg8 - Reads 8 bit analog register
+ *  @hw: pointer to hardware structure
+ *  @reg: analog register to read
+ *  @val: read value
+ *
+ *  Performs write operation to analog register specified.
+ **/
+int32_t ixgbe_read_analog_reg8(struct ixgbe_hw *hw, uint32_t reg, uint8_t *val)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.read_analog_reg8, (hw, reg,
+			       val), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_write_analog_reg8 - Writes 8 bit analog register
+ *  @hw: pointer to hardware structure
+ *  @reg: analog register to write
+ *  @val: value to write
+ *
+ *  Performs write operation to Atlas analog register specified.
+ **/
+int32_t ixgbe_write_analog_reg8(struct ixgbe_hw *hw, uint32_t reg, uint8_t val)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.write_analog_reg8, (hw, reg,
+			       val), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_init_uta_tables - Initializes Unicast Table Arrays.
+ *  @hw: pointer to hardware structure
+ *
+ *  Initializes the Unicast Table Arrays to zero on device load.  This
+ *  is part of the Rx init addr execution path.
+ **/
+int32_t ixgbe_init_uta_tables(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.init_uta_tables, (hw),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_read_i2c_byte - Reads 8 bit word over I2C at specified device address
+ *  @hw: pointer to hardware structure
+ *  @byte_offset: byte offset to read
+ *  @dev_addr: I2C bus address to read from
+ *  @data: value read
+ *
+ *  Performs byte read operation to SFP module's EEPROM over I2C interface.
+ **/
+int32_t ixgbe_read_i2c_byte(struct ixgbe_hw *hw, uint8_t byte_offset, uint8_t dev_addr,
+			uint8_t *data)
+{
+	return ixgbe_call_func(hw, hw->phy.ops.read_i2c_byte, (hw, byte_offset,
+			       dev_addr, data), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_read_i2c_byte_unlocked - Reads 8 bit word via I2C from device address
+ *  @hw: pointer to hardware structure
+ *  @byte_offset: byte offset to read
+ *  @dev_addr: I2C bus address to read from
+ *  @data: value read
+ *
+ *  Performs byte read operation to SFP module's EEPROM over I2C interface.
+ **/
+int32_t ixgbe_read_i2c_byte_unlocked(struct ixgbe_hw *hw, uint8_t byte_offset,
+				 uint8_t dev_addr, uint8_t *data)
+{
+	return ixgbe_call_func(hw, hw->phy.ops.read_i2c_byte_unlocked,
+			       (hw, byte_offset, dev_addr, data),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ * ixgbe_read_link - Perform read operation on link device
+ * @hw: pointer to the hardware structure
+ * @addr: bus address to read from
+ * @reg: device register to read from
+ * @val: pointer to location to receive read value
+ *
+ * Returns an error code on error.
+ */
+int32_t ixgbe_read_link(struct ixgbe_hw *hw, uint8_t addr, uint16_t reg, uint16_t *val)
+{
+	return ixgbe_call_func(hw, hw->link.ops.read_link, (hw, addr,
+			       reg, val), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ * ixgbe_read_link_unlocked - Perform read operation on link device
+ * @hw: pointer to the hardware structure
+ * @addr: bus address to read from
+ * @reg: device register to read from
+ * @val: pointer to location to receive read value
+ *
+ * Returns an error code on error.
+ **/
+int32_t ixgbe_read_link_unlocked(struct ixgbe_hw *hw, uint8_t addr, uint16_t reg, uint16_t *val)
+{
+	return ixgbe_call_func(hw, hw->link.ops.read_link_unlocked,
+			       (hw, addr, reg, val), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_write_i2c_byte - Writes 8 bit word over I2C
+ *  @hw: pointer to hardware structure
+ *  @byte_offset: byte offset to write
+ *  @dev_addr: I2C bus address to write to
+ *  @data: value to write
+ *
+ *  Performs byte write operation to SFP module's EEPROM over I2C interface
+ *  at a specified device address.
+ **/
+int32_t ixgbe_write_i2c_byte(struct ixgbe_hw *hw, uint8_t byte_offset, uint8_t dev_addr,
+			 uint8_t data)
+{
+	return ixgbe_call_func(hw, hw->phy.ops.write_i2c_byte, (hw, byte_offset,
+			       dev_addr, data), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_write_i2c_byte_unlocked - Writes 8 bit word over I2C
+ *  @hw: pointer to hardware structure
+ *  @byte_offset: byte offset to write
+ *  @dev_addr: I2C bus address to write to
+ *  @data: value to write
+ *
+ *  Performs byte write operation to SFP module's EEPROM over I2C interface
+ *  at a specified device address.
+ **/
+int32_t ixgbe_write_i2c_byte_unlocked(struct ixgbe_hw *hw, uint8_t byte_offset,
+				  uint8_t dev_addr, uint8_t data)
+{
+	return ixgbe_call_func(hw, hw->phy.ops.write_i2c_byte_unlocked,
+			       (hw, byte_offset, dev_addr, data),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ * ixgbe_write_link - Perform write operation on link device
+ * @hw: pointer to the hardware structure
+ * @addr: bus address to write to
+ * @reg: device register to write to
+ * @val: value to write
+ *
+ * Returns an error code on error.
+ */
+int32_t ixgbe_write_link(struct ixgbe_hw *hw, uint8_t addr, uint16_t reg, uint16_t val)
+{
+	return ixgbe_call_func(hw, hw->link.ops.write_link,
+			       (hw, addr, reg, val), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ * ixgbe_write_link_unlocked - Perform write operation on link device
+ * @hw: pointer to the hardware structure
+ * @addr: bus address to write to
+ * @reg: device register to write to
+ * @val: value to write
+ *
+ * Returns an error code on error.
+ **/
+int32_t ixgbe_write_link_unlocked(struct ixgbe_hw *hw, uint8_t addr, uint16_t reg, uint16_t val)
+{
+	return ixgbe_call_func(hw, hw->link.ops.write_link_unlocked,
+			       (hw, addr, reg, val), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_write_i2c_eeprom - Writes 8 bit EEPROM word over I2C interface
+ *  @hw: pointer to hardware structure
+ *  @byte_offset: EEPROM byte offset to write
+ *  @eeprom_data: value to write
+ *
+ *  Performs byte write operation to SFP module's EEPROM over I2C interface.
+ **/
+int32_t ixgbe_write_i2c_eeprom(struct ixgbe_hw *hw,
+			   uint8_t byte_offset, uint8_t eeprom_data)
+{
+	return ixgbe_call_func(hw, hw->phy.ops.write_i2c_eeprom,
+			       (hw, byte_offset, eeprom_data),
+			       IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_read_i2c_eeprom - Reads 8 bit EEPROM word over I2C interface
+ *  @hw: pointer to hardware structure
+ *  @byte_offset: EEPROM byte offset to read
+ *  @eeprom_data: value read
+ *
+ *  Performs byte read operation to SFP module's EEPROM over I2C interface.
+ **/
+int32_t ixgbe_read_i2c_eeprom(struct ixgbe_hw *hw, uint8_t byte_offset, uint8_t *eeprom_data)
+{
+	return ixgbe_call_func(hw, hw->phy.ops.read_i2c_eeprom,
+			      (hw, byte_offset, eeprom_data),
+			      IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_get_supported_physical_layer - Returns physical layer type
+ *  @hw: pointer to hardware structure
+ *
+ *  Determines physical layer capabilities of the current configuration.
+ **/
+uint64_t ixgbe_get_supported_physical_layer(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.get_supported_physical_layer,
+			       (hw), IXGBE_PHYSICAL_LAYER_UNKNOWN);
+}
+
+/**
+ *  ixgbe_enable_rx_dma - Enables Rx DMA unit, dependent on device specifics
+ *  @hw: pointer to hardware structure
+ *  @regval: bitfield to write to the Rx DMA register
+ *
+ *  Enables the Rx DMA unit of the device.
+ **/
+int32_t ixgbe_enable_rx_dma(struct ixgbe_hw *hw, uint32_t regval)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.enable_rx_dma,
+			       (hw, regval), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_disable_sec_rx_path - Stops the receive data path
+ *  @hw: pointer to hardware structure
+ *
+ *  Stops the receive data path.
+ **/
+int32_t ixgbe_disable_sec_rx_path(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.disable_sec_rx_path,
+				(hw), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_enable_sec_rx_path - Enables the receive data path
+ *  @hw: pointer to hardware structure
+ *
+ *  Enables the receive data path.
+ **/
+int32_t ixgbe_enable_sec_rx_path(struct ixgbe_hw *hw)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.enable_sec_rx_path,
+				(hw), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_acquire_swfw_semaphore - Acquire SWFW semaphore
+ *  @hw: pointer to hardware structure
+ *  @mask: Mask to specify which semaphore to acquire
+ *
+ *  Acquires the SWFW semaphore through SW_FW_SYNC register for the specified
+ *  function (CSR, PHY0, PHY1, EEPROM, Flash)
+ **/
+int32_t ixgbe_acquire_swfw_semaphore(struct ixgbe_hw *hw, uint32_t mask)
+{
+	return ixgbe_call_func(hw, hw->mac.ops.acquire_swfw_sync,
+			       (hw, mask), IXGBE_NOT_IMPLEMENTED);
+}
+
+/**
+ *  ixgbe_release_swfw_semaphore - Release SWFW semaphore
+ *  @hw: pointer to hardware structure
+ *  @mask: Mask to specify which semaphore to release
+ *
+ *  Releases the SWFW semaphore through SW_FW_SYNC register for the specified
+ *  function (CSR, PHY0, PHY1, EEPROM, Flash)
+ **/
+void ixgbe_release_swfw_semaphore(struct ixgbe_hw *hw, uint32_t mask)
+{
+	if (hw->mac.ops.release_swfw_sync)
+		hw->mac.ops.release_swfw_sync(hw, mask);
+}
+
+/**
+ *  ixgbe_init_swfw_semaphore - Clean up SWFW semaphore
+ *  @hw: pointer to hardware structure
+ *
+ *  Attempts to acquire the SWFW semaphore through SW_FW_SYNC register.
+ *  Regardless of whether is succeeds or not it then release the semaphore.
+ *  This is function is called to recover from catastrophic failures that
+ *  may have left the semaphore locked.
+ **/
+void ixgbe_init_swfw_semaphore(struct ixgbe_hw *hw)
+{
+	if (hw->mac.ops.init_swfw_sync)
+		hw->mac.ops.init_swfw_sync(hw);
+}
+
+
+void ixgbe_disable_rx(struct ixgbe_hw *hw)
+{
+	if (hw->mac.ops.disable_rx)
+		hw->mac.ops.disable_rx(hw);
+}
+
+void ixgbe_enable_rx(struct ixgbe_hw *hw)
+{
+	if (hw->mac.ops.enable_rx)
+		hw->mac.ops.enable_rx(hw);
+}
+
+/**
+ *  ixgbe_set_rate_select_speed - Set module link speed
+ *  @hw: pointer to hardware structure
+ *  @speed: link speed to set
+ *
+ *  Set module link speed via the rate select.
+ */
+void ixgbe_set_rate_select_speed(struct ixgbe_hw *hw, ixgbe_link_speed speed)
+{
+	if (hw->mac.ops.set_rate_select_speed)
+		hw->mac.ops.set_rate_select_speed(hw, speed);
+}
Index: ./dev/pci/ixgbe_api.h
===================================================================
RCS file: ./dev/pci/ixgbe_api.h
diff -N ./dev/pci/ixgbe_api.h
--- /dev/null	1 Jan 1970 00:00:00 -0000
+++ ./dev/pci/ixgbe_api.h	17 Sep 2018 19:59:55 -0000
@@ -0,0 +1,228 @@
+/******************************************************************************
+  SPDX-License-Identifier: BSD-3-Clause
+
+  Copyright (c) 2001-2017, Intel Corporation
+  All rights reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions are met:
+
+   1. Redistributions of source code must retain the above copyright notice,
+      this list of conditions and the following disclaimer.
+
+   2. Redistributions in binary form must reproduce the above copyright
+      notice, this list of conditions and the following disclaimer in the
+      documentation and/or other materials provided with the distribution.
+
+   3. Neither the name of the Intel Corporation nor the names of its
+      contributors may be used to endorse or promote products derived from
+      this software without specific prior written permission.
+
+  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
+  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+  POSSIBILITY OF SUCH DAMAGE.
+
+******************************************************************************/
+/*$FreeBSD$*/
+
+#ifndef _IXGBE_API_H_
+#define _IXGBE_API_H_
+
+#include "ixgbe_type.h"
+
+void ixgbe_dcb_get_rtrup2tc(struct ixgbe_hw *hw, uint8_t *map);
+
+int32_t ixgbe_init_shared_code(struct ixgbe_hw *hw);
+
+extern int32_t ixgbe_init_ops_82598(struct ixgbe_hw *hw);
+extern int32_t ixgbe_init_ops_82599(struct ixgbe_hw *hw);
+extern int32_t ixgbe_init_ops_X540(struct ixgbe_hw *hw);
+extern int32_t ixgbe_init_ops_X550(struct ixgbe_hw *hw);
+extern int32_t ixgbe_init_ops_X550EM(struct ixgbe_hw *hw);
+extern int32_t ixgbe_init_ops_X550EM_x(struct ixgbe_hw *hw);
+extern int32_t ixgbe_init_ops_X550EM_a(struct ixgbe_hw *hw);
+
+int32_t ixgbe_set_mac_type(struct ixgbe_hw *hw);
+int32_t ixgbe_init_hw(struct ixgbe_hw *hw);
+int32_t ixgbe_reset_hw(struct ixgbe_hw *hw);
+int32_t ixgbe_start_hw(struct ixgbe_hw *hw);
+void ixgbe_enable_relaxed_ordering(struct ixgbe_hw *hw);
+int32_t ixgbe_clear_hw_cntrs(struct ixgbe_hw *hw);
+enum ixgbe_media_type ixgbe_get_media_type(struct ixgbe_hw *hw);
+int32_t ixgbe_get_mac_addr(struct ixgbe_hw *hw, uint8_t *mac_addr);
+int32_t ixgbe_get_bus_info(struct ixgbe_hw *hw);
+uint32_t ixgbe_get_num_of_tx_queues(struct ixgbe_hw *hw);
+uint32_t ixgbe_get_num_of_rx_queues(struct ixgbe_hw *hw);
+int32_t ixgbe_stop_adapter(struct ixgbe_hw *hw);
+int32_t ixgbe_read_pba_num(struct ixgbe_hw *hw, uint32_t *pba_num);
+int32_t ixgbe_read_pba_string(struct ixgbe_hw *hw, uint8_t *pba_num, uint32_t pba_num_size);
+
+int32_t ixgbe_identify_phy(struct ixgbe_hw *hw);
+int32_t ixgbe_reset_phy(struct ixgbe_hw *hw);
+int32_t ixgbe_read_phy_reg(struct ixgbe_hw *hw, uint32_t reg_addr, uint32_t device_type,
+		       uint16_t *phy_data);
+int32_t ixgbe_write_phy_reg(struct ixgbe_hw *hw, uint32_t reg_addr, uint32_t device_type,
+			uint16_t phy_data);
+
+int32_t ixgbe_setup_phy_link(struct ixgbe_hw *hw);
+int32_t ixgbe_setup_internal_phy(struct ixgbe_hw *hw);
+int32_t ixgbe_check_phy_link(struct ixgbe_hw *hw,
+			 ixgbe_link_speed *speed,
+			 bool *link_up);
+int32_t ixgbe_setup_phy_link_speed(struct ixgbe_hw *hw,
+			       ixgbe_link_speed speed,
+			       bool autoneg_wait_to_complete);
+int32_t ixgbe_set_phy_power(struct ixgbe_hw *, bool on);
+void ixgbe_disable_tx_laser(struct ixgbe_hw *hw);
+void ixgbe_enable_tx_laser(struct ixgbe_hw *hw);
+void ixgbe_flap_tx_laser(struct ixgbe_hw *hw);
+int32_t ixgbe_setup_link(struct ixgbe_hw *hw, ixgbe_link_speed speed,
+		     bool autoneg_wait_to_complete);
+int32_t ixgbe_setup_mac_link(struct ixgbe_hw *hw, ixgbe_link_speed speed,
+			 bool autoneg_wait_to_complete);
+int32_t ixgbe_check_link(struct ixgbe_hw *hw, ixgbe_link_speed *speed,
+		     bool *link_up, bool link_up_wait_to_complete);
+int32_t ixgbe_get_link_capabilities(struct ixgbe_hw *hw, ixgbe_link_speed *speed,
+				bool *autoneg);
+int32_t ixgbe_led_on(struct ixgbe_hw *hw, uint32_t index);
+int32_t ixgbe_led_off(struct ixgbe_hw *hw, uint32_t index);
+int32_t ixgbe_blink_led_start(struct ixgbe_hw *hw, uint32_t index);
+int32_t ixgbe_blink_led_stop(struct ixgbe_hw *hw, uint32_t index);
+
+int32_t ixgbe_init_eeprom_params(struct ixgbe_hw *hw);
+int32_t ixgbe_write_eeprom(struct ixgbe_hw *hw, uint16_t offset, uint16_t data);
+int32_t ixgbe_write_eeprom_buffer(struct ixgbe_hw *hw, uint16_t offset,
+			      uint16_t words, uint16_t *data);
+int32_t ixgbe_read_eeprom(struct ixgbe_hw *hw, uint16_t offset, uint16_t *data);
+int32_t ixgbe_read_eeprom_buffer(struct ixgbe_hw *hw, uint16_t offset,
+			     uint16_t words, uint16_t *data);
+
+int32_t ixgbe_validate_eeprom_checksum(struct ixgbe_hw *hw, uint16_t *checksum_val);
+int32_t ixgbe_update_eeprom_checksum(struct ixgbe_hw *hw);
+
+int32_t ixgbe_insert_mac_addr(struct ixgbe_hw *hw, uint8_t *addr, uint32_t vmdq);
+int32_t ixgbe_set_rar(struct ixgbe_hw *hw, uint32_t index, uint8_t *addr, uint32_t vmdq,
+		  uint32_t enable_addr);
+int32_t ixgbe_clear_rar(struct ixgbe_hw *hw, uint32_t index);
+int32_t ixgbe_set_vmdq(struct ixgbe_hw *hw, uint32_t rar, uint32_t vmdq);
+int32_t ixgbe_set_vmdq_san_mac(struct ixgbe_hw *hw, uint32_t vmdq);
+int32_t ixgbe_clear_vmdq(struct ixgbe_hw *hw, uint32_t rar, uint32_t vmdq);
+int32_t ixgbe_init_rx_addrs(struct ixgbe_hw *hw);
+uint32_t ixgbe_get_num_rx_addrs(struct ixgbe_hw *hw);
+int32_t ixgbe_update_uc_addr_list(struct ixgbe_hw *hw, uint8_t *addr_list,
+			      uint32_t addr_count, ixgbe_mc_addr_itr func);
+int32_t ixgbe_update_mc_addr_list(struct ixgbe_hw *hw, uint8_t *mc_addr_list,
+			      uint32_t mc_addr_count, ixgbe_mc_addr_itr func,
+			      bool clear);
+void ixgbe_add_uc_addr(struct ixgbe_hw *hw, uint8_t *addr_list, uint32_t vmdq);
+int32_t ixgbe_enable_mc(struct ixgbe_hw *hw);
+int32_t ixgbe_disable_mc(struct ixgbe_hw *hw);
+int32_t ixgbe_clear_vfta(struct ixgbe_hw *hw);
+int32_t ixgbe_set_vfta(struct ixgbe_hw *hw, uint32_t vlan,
+		   uint32_t vind, bool vlan_on, bool vlvf_bypass);
+int32_t ixgbe_set_vlvf(struct ixgbe_hw *hw, uint32_t vlan, uint32_t vind,
+		   bool vlan_on, uint32_t *vfta_delta, uint32_t vfta,
+		   bool vlvf_bypass);
+int32_t ixgbe_fc_enable(struct ixgbe_hw *hw);
+int32_t ixgbe_setup_fc(struct ixgbe_hw *hw);
+int32_t ixgbe_set_fw_drv_ver(struct ixgbe_hw *hw, uint8_t maj, uint8_t min, uint8_t build,
+			 uint8_t ver, uint16_t len, char *driver_ver);
+void ixgbe_set_mta(struct ixgbe_hw *hw, uint8_t *mc_addr);
+int32_t ixgbe_get_phy_firmware_version(struct ixgbe_hw *hw,
+				   uint16_t *firmware_version);
+int32_t ixgbe_read_analog_reg8(struct ixgbe_hw *hw, uint32_t reg, uint8_t *val);
+int32_t ixgbe_write_analog_reg8(struct ixgbe_hw *hw, uint32_t reg, uint8_t val);
+int32_t ixgbe_init_uta_tables(struct ixgbe_hw *hw);
+int32_t ixgbe_read_i2c_eeprom(struct ixgbe_hw *hw, uint8_t byte_offset, uint8_t *eeprom_data);
+uint64_t ixgbe_get_supported_physical_layer(struct ixgbe_hw *hw);
+int32_t ixgbe_enable_rx_dma(struct ixgbe_hw *hw, uint32_t regval);
+int32_t ixgbe_disable_sec_rx_path(struct ixgbe_hw *hw);
+int32_t ixgbe_enable_sec_rx_path(struct ixgbe_hw *hw);
+int32_t ixgbe_mng_fw_enabled(struct ixgbe_hw *hw);
+int32_t ixgbe_reinit_fdir_tables_82599(struct ixgbe_hw *hw);
+int32_t ixgbe_init_fdir_signature_82599(struct ixgbe_hw *hw, uint32_t fdirctrl);
+int32_t ixgbe_init_fdir_perfect_82599(struct ixgbe_hw *hw, uint32_t fdirctrl,
+					bool cloud_mode);
+void ixgbe_fdir_add_signature_filter_82599(struct ixgbe_hw *hw,
+					   union ixgbe_atr_hash_dword input,
+					   union ixgbe_atr_hash_dword common,
+					   uint8_t queue);
+int32_t ixgbe_fdir_set_input_mask_82599(struct ixgbe_hw *hw,
+				    union ixgbe_atr_input *input_mask, bool cloud_mode);
+int32_t ixgbe_fdir_write_perfect_filter_82599(struct ixgbe_hw *hw,
+					  union ixgbe_atr_input *input,
+					  uint16_t soft_id, uint8_t queue, bool cloud_mode);
+int32_t ixgbe_fdir_erase_perfect_filter_82599(struct ixgbe_hw *hw,
+					  union ixgbe_atr_input *input,
+					  uint16_t soft_id);
+int32_t ixgbe_fdir_add_perfect_filter_82599(struct ixgbe_hw *hw,
+					union ixgbe_atr_input *input,
+					union ixgbe_atr_input *mask,
+					uint16_t soft_id,
+					uint8_t queue,
+					bool cloud_mode);
+void ixgbe_atr_compute_perfect_hash_82599(union ixgbe_atr_input *input,
+					  union ixgbe_atr_input *mask);
+uint32_t ixgbe_atr_compute_sig_hash_82599(union ixgbe_atr_hash_dword input,
+				     union ixgbe_atr_hash_dword common);
+bool ixgbe_verify_lesm_fw_enabled_82599(struct ixgbe_hw *hw);
+int32_t ixgbe_read_i2c_byte(struct ixgbe_hw *hw, uint8_t byte_offset, uint8_t dev_addr,
+			uint8_t *data);
+int32_t ixgbe_read_i2c_byte_unlocked(struct ixgbe_hw *hw, uint8_t byte_offset,
+				 uint8_t dev_addr, uint8_t *data);
+int32_t ixgbe_read_link(struct ixgbe_hw *hw, uint8_t addr, uint16_t reg, uint16_t *val);
+int32_t ixgbe_read_link_unlocked(struct ixgbe_hw *hw, uint8_t addr, uint16_t reg, uint16_t *val);
+int32_t ixgbe_write_i2c_byte(struct ixgbe_hw *hw, uint8_t byte_offset, uint8_t dev_addr,
+			 uint8_t data);
+void ixgbe_set_fdir_drop_queue_82599(struct ixgbe_hw *hw, uint8_t dropqueue);
+int32_t ixgbe_write_i2c_byte_unlocked(struct ixgbe_hw *hw, uint8_t byte_offset,
+				  uint8_t dev_addr, uint8_t data);
+int32_t ixgbe_write_link(struct ixgbe_hw *hw, uint8_t addr, uint16_t reg, uint16_t val);
+int32_t ixgbe_write_link_unlocked(struct ixgbe_hw *hw, uint8_t addr, uint16_t reg, uint16_t val);
+int32_t ixgbe_write_i2c_eeprom(struct ixgbe_hw *hw, uint8_t byte_offset, uint8_t eeprom_data);
+int32_t ixgbe_get_san_mac_addr(struct ixgbe_hw *hw, uint8_t *san_mac_addr);
+int32_t ixgbe_set_san_mac_addr(struct ixgbe_hw *hw, uint8_t *san_mac_addr);
+int32_t ixgbe_get_device_caps(struct ixgbe_hw *hw, uint16_t *device_caps);
+int32_t ixgbe_acquire_swfw_semaphore(struct ixgbe_hw *hw, uint32_t mask);
+void ixgbe_release_swfw_semaphore(struct ixgbe_hw *hw, uint32_t mask);
+void ixgbe_init_swfw_semaphore(struct ixgbe_hw *hw);
+int32_t ixgbe_get_wwn_prefix(struct ixgbe_hw *hw, uint16_t *wwnn_prefix,
+			 uint16_t *wwpn_prefix);
+int32_t ixgbe_get_fcoe_boot_status(struct ixgbe_hw *hw, uint16_t *bs);
+int32_t ixgbe_bypass_rw(struct ixgbe_hw *hw, uint32_t cmd, uint32_t *status);
+int32_t ixgbe_bypass_set(struct ixgbe_hw *hw, uint32_t cmd, uint32_t event, uint32_t action);
+int32_t ixgbe_bypass_rd_eep(struct ixgbe_hw *hw, uint32_t addr, uint8_t *value);
+bool ixgbe_bypass_valid_rd(struct ixgbe_hw *hw, uint32_t in_reg, uint32_t out_reg);
+int32_t ixgbe_dmac_config(struct ixgbe_hw *hw);
+int32_t ixgbe_dmac_update_tcs(struct ixgbe_hw *hw);
+int32_t ixgbe_dmac_config_tcs(struct ixgbe_hw *hw);
+int32_t ixgbe_setup_eee(struct ixgbe_hw *hw, bool enable_eee);
+void ixgbe_set_source_address_pruning(struct ixgbe_hw *hw, bool enable,
+				      unsigned int vf);
+void ixgbe_set_ethertype_anti_spoofing(struct ixgbe_hw *hw, bool enable,
+				       int vf);
+int32_t ixgbe_read_iosf_sb_reg(struct ixgbe_hw *hw, uint32_t reg_addr,
+			uint32_t device_type, uint32_t *phy_data);
+int32_t ixgbe_write_iosf_sb_reg(struct ixgbe_hw *hw, uint32_t reg_addr,
+			uint32_t device_type, uint32_t phy_data);
+void ixgbe_disable_mdd(struct ixgbe_hw *hw);
+void ixgbe_enable_mdd(struct ixgbe_hw *hw);
+void ixgbe_mdd_event(struct ixgbe_hw *hw, uint32_t *vf_bitmap);
+void ixgbe_restore_mdd_vf(struct ixgbe_hw *hw, uint32_t vf);
+int32_t ixgbe_enter_lplu(struct ixgbe_hw *hw);
+int32_t ixgbe_handle_lasi(struct ixgbe_hw *hw);
+void ixgbe_set_rate_select_speed(struct ixgbe_hw *hw, ixgbe_link_speed speed);
+void ixgbe_disable_rx(struct ixgbe_hw *hw);
+void ixgbe_enable_rx(struct ixgbe_hw *hw);
+int32_t ixgbe_negotiate_fc(struct ixgbe_hw *hw, uint32_t adv_reg, uint32_t lp_reg,
+			uint32_t adv_sym, uint32_t adv_asm, uint32_t lp_sym, uint32_t lp_asm);
+
+#endif /* _IXGBE_API_H_ */
Index: ./dev/pci/ixgbe_common.h
===================================================================
RCS file: ./dev/pci/ixgbe_common.h
diff -N ./dev/pci/ixgbe_common.h
--- /dev/null	1 Jan 1970 00:00:00 -0000
+++ ./dev/pci/ixgbe_common.h	17 Sep 2018 19:59:55 -0000
@@ -0,0 +1,198 @@
+/******************************************************************************
+  SPDX-License-Identifier: BSD-3-Clause
+
+  Copyright (c) 2001-2017, Intel Corporation
+  All rights reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions are met:
+
+   1. Redistributions of source code must retain the above copyright notice,
+      this list of conditions and the following disclaimer.
+
+   2. Redistributions in binary form must reproduce the above copyright
+      notice, this list of conditions and the following disclaimer in the
+      documentation and/or other materials provided with the distribution.
+
+   3. Neither the name of the Intel Corporation nor the names of its
+      contributors may be used to endorse or promote products derived from
+      this software without specific prior written permission.
+
+  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
+  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+  POSSIBILITY OF SUCH DAMAGE.
+
+******************************************************************************/
+/*$FreeBSD$*/
+
+#ifndef _IXGBE_COMMON_H_
+#define _IXGBE_COMMON_H_
+
+
+#include <dev/pci/ixgbe_type.h>
+
+#define IXGBE_WRITE_REG64(hw, reg, value) \
+	do { \
+		IXGBE_WRITE_REG(hw, reg, (uint32_t) value); \
+		IXGBE_WRITE_REG(hw, reg + 4, (uint32_t) (value >> 32)); \
+	} while (0)
+#define IXGBE_REMOVED(a) (0)
+#if !defined(NO_READ_PBA_RAW) || !defined(NO_WRITE_PBA_RAW)
+struct ixgbe_pba {
+	uint16_t word[2];
+	uint16_t *pba_block;
+};
+#endif
+
+void ixgbe_dcb_get_rtrup2tc_generic(struct ixgbe_hw *hw, uint8_t *map);
+
+uint16_t ixgbe_get_pcie_msix_count_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_init_ops_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_init_hw_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_start_hw_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_start_hw_gen2(struct ixgbe_hw *hw);
+int32_t ixgbe_clear_hw_cntrs_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_read_pba_num_generic(struct ixgbe_hw *hw, uint32_t *pba_num);
+int32_t ixgbe_read_pba_string_generic(struct ixgbe_hw *hw, uint8_t *pba_num,
+				  uint32_t pba_num_size);
+int32_t ixgbe_read_pba_raw(struct ixgbe_hw *hw, uint16_t *eeprom_buf,
+		       uint32_t eeprom_buf_size, uint16_t max_pba_block_size,
+		       struct ixgbe_pba *pba);
+int32_t ixgbe_write_pba_raw(struct ixgbe_hw *hw, uint16_t *eeprom_buf,
+			uint32_t eeprom_buf_size, struct ixgbe_pba *pba);
+int32_t ixgbe_get_pba_block_size(struct ixgbe_hw *hw, uint16_t *eeprom_buf,
+			     uint32_t eeprom_buf_size, uint16_t *pba_block_size);
+int32_t ixgbe_get_mac_addr_generic(struct ixgbe_hw *hw, uint8_t *mac_addr);
+int32_t ixgbe_get_bus_info_generic(struct ixgbe_hw *hw);
+void ixgbe_set_pci_config_data_generic(struct ixgbe_hw *hw, uint16_t link_status);
+void ixgbe_set_lan_id_multi_port_pcie(struct ixgbe_hw *hw);
+int32_t ixgbe_stop_adapter_generic(struct ixgbe_hw *hw);
+
+int32_t ixgbe_led_on_generic(struct ixgbe_hw *hw, uint32_t index);
+int32_t ixgbe_led_off_generic(struct ixgbe_hw *hw, uint32_t index);
+int32_t ixgbe_init_led_link_act_generic(struct ixgbe_hw *hw);
+
+int32_t ixgbe_init_eeprom_params_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_write_eeprom_generic(struct ixgbe_hw *hw, uint16_t offset, uint16_t data);
+int32_t ixgbe_write_eeprom_buffer_bit_bang_generic(struct ixgbe_hw *hw, uint16_t offset,
+					       uint16_t words, uint16_t *data);
+int32_t ixgbe_read_eerd_generic(struct ixgbe_hw *hw, uint16_t offset, uint16_t *data);
+int32_t ixgbe_read_eerd_buffer_generic(struct ixgbe_hw *hw, uint16_t offset,
+				   uint16_t words, uint16_t *data);
+int32_t ixgbe_write_eewr_generic(struct ixgbe_hw *hw, uint16_t offset, uint16_t data);
+int32_t ixgbe_write_eewr_buffer_generic(struct ixgbe_hw *hw, uint16_t offset,
+				    uint16_t words, uint16_t *data);
+int32_t ixgbe_read_eeprom_bit_bang_generic(struct ixgbe_hw *hw, uint16_t offset,
+				       uint16_t *data);
+int32_t ixgbe_read_eeprom_buffer_bit_bang_generic(struct ixgbe_hw *hw, uint16_t offset,
+					      uint16_t words, uint16_t *data);
+int32_t ixgbe_calc_eeprom_checksum_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_validate_eeprom_checksum_generic(struct ixgbe_hw *hw,
+					   uint16_t *checksum_val);
+int32_t ixgbe_update_eeprom_checksum_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_poll_eerd_eewr_done(struct ixgbe_hw *hw, uint32_t ee_reg);
+
+int32_t ixgbe_set_rar_generic(struct ixgbe_hw *hw, uint32_t index, uint8_t *addr, uint32_t vmdq,
+			  uint32_t enable_addr);
+int32_t ixgbe_clear_rar_generic(struct ixgbe_hw *hw, uint32_t index);
+int32_t ixgbe_init_rx_addrs_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_update_mc_addr_list_generic(struct ixgbe_hw *hw, uint8_t *mc_addr_list,
+				      uint32_t mc_addr_count,
+				      ixgbe_mc_addr_itr func, bool clear);
+int32_t ixgbe_update_uc_addr_list_generic(struct ixgbe_hw *hw, uint8_t *addr_list,
+				      uint32_t addr_count, ixgbe_mc_addr_itr func);
+int32_t ixgbe_enable_mc_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_disable_mc_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_enable_rx_dma_generic(struct ixgbe_hw *hw, uint32_t regval);
+int32_t ixgbe_disable_sec_rx_path_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_enable_sec_rx_path_generic(struct ixgbe_hw *hw);
+
+int32_t ixgbe_fc_enable_generic(struct ixgbe_hw *hw);
+bool ixgbe_device_supports_autoneg_fc(struct ixgbe_hw *hw);
+void ixgbe_fc_autoneg(struct ixgbe_hw *hw);
+int32_t ixgbe_setup_fc_generic(struct ixgbe_hw *hw);
+
+int32_t ixgbe_validate_mac_addr(uint8_t *mac_addr);
+int32_t ixgbe_acquire_swfw_sync(struct ixgbe_hw *hw, uint32_t mask);
+void ixgbe_release_swfw_sync(struct ixgbe_hw *hw, uint32_t mask);
+int32_t ixgbe_disable_pcie_master(struct ixgbe_hw *hw);
+
+int32_t prot_autoc_read_generic(struct ixgbe_hw *hw, bool *, uint32_t *reg_val);
+int32_t prot_autoc_write_generic(struct ixgbe_hw *hw, uint32_t reg_val, bool locked);
+
+int32_t ixgbe_blink_led_start_generic(struct ixgbe_hw *hw, uint32_t index);
+int32_t ixgbe_blink_led_stop_generic(struct ixgbe_hw *hw, uint32_t index);
+
+int32_t ixgbe_get_san_mac_addr_generic(struct ixgbe_hw *hw, uint8_t *san_mac_addr);
+int32_t ixgbe_set_san_mac_addr_generic(struct ixgbe_hw *hw, uint8_t *san_mac_addr);
+
+int32_t ixgbe_set_vmdq_generic(struct ixgbe_hw *hw, uint32_t rar, uint32_t vmdq);
+int32_t ixgbe_set_vmdq_san_mac_generic(struct ixgbe_hw *hw, uint32_t vmdq);
+int32_t ixgbe_clear_vmdq_generic(struct ixgbe_hw *hw, uint32_t rar, uint32_t vmdq);
+int32_t ixgbe_insert_mac_addr_generic(struct ixgbe_hw *hw, uint8_t *addr, uint32_t vmdq);
+int32_t ixgbe_init_uta_tables_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_set_vfta_generic(struct ixgbe_hw *hw, uint32_t vlan,
+			 uint32_t vind, bool vlan_on, bool vlvf_bypass);
+int32_t ixgbe_set_vlvf_generic(struct ixgbe_hw *hw, uint32_t vlan, uint32_t vind,
+			   bool vlan_on, uint32_t *vfta_delta, uint32_t vfta,
+			   bool vlvf_bypass);
+int32_t ixgbe_clear_vfta_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_find_vlvf_slot(struct ixgbe_hw *hw, uint32_t vlan, bool vlvf_bypass);
+
+int32_t ixgbe_check_mac_link_generic(struct ixgbe_hw *hw,
+			       ixgbe_link_speed *speed,
+			       bool *link_up, bool link_up_wait_to_complete);
+
+int32_t ixgbe_get_wwn_prefix_generic(struct ixgbe_hw *hw, uint16_t *wwnn_prefix,
+				 uint16_t *wwpn_prefix);
+
+int32_t ixgbe_get_fcoe_boot_status_generic(struct ixgbe_hw *hw, uint16_t *bs);
+void ixgbe_set_mac_anti_spoofing(struct ixgbe_hw *hw, bool enable, int vf);
+void ixgbe_set_vlan_anti_spoofing(struct ixgbe_hw *hw, bool enable, int vf);
+int32_t ixgbe_get_device_caps_generic(struct ixgbe_hw *hw, uint16_t *device_caps);
+void ixgbe_set_rxpba_generic(struct ixgbe_hw *hw, int num_pb, uint32_t headroom,
+			     int strategy);
+void ixgbe_enable_relaxed_ordering_gen2(struct ixgbe_hw *hw);
+int32_t ixgbe_set_fw_drv_ver_generic(struct ixgbe_hw *hw, uint8_t maj, uint8_t min,
+				 uint8_t build, uint8_t ver, uint16_t len, const char *str);
+uint8_t ixgbe_calculate_checksum(uint8_t *buffer, uint32_t length);
+int32_t ixgbe_host_interface_command(struct ixgbe_hw *hw, uint32_t *buffer,
+				 uint32_t length, uint32_t timeout, bool return_data);
+int32_t ixgbe_hic_unlocked(struct ixgbe_hw *, uint32_t *buffer, uint32_t length, uint32_t timeout);
+int32_t ixgbe_shutdown_fw_phy(struct ixgbe_hw *);
+int32_t ixgbe_fw_phy_activity(struct ixgbe_hw *, uint16_t activity,
+			  uint32_t (*data)[FW_PHY_ACT_DATA_COUNT]);
+void ixgbe_clear_tx_pending(struct ixgbe_hw *hw);
+int32_t ixgbe_bypass_rw_generic(struct ixgbe_hw *hw, uint32_t cmd, uint32_t *status);
+bool ixgbe_bypass_valid_rd_generic(uint32_t in_reg, uint32_t out_reg);
+int32_t ixgbe_bypass_set_generic(struct ixgbe_hw *hw, uint32_t ctrl, uint32_t event,
+			     uint32_t action);
+int32_t ixgbe_bypass_rd_eep_generic(struct ixgbe_hw *hw, uint32_t addr, uint8_t *value);
+
+extern int32_t ixgbe_reset_pipeline_82599(struct ixgbe_hw *hw);
+extern void ixgbe_stop_mac_link_on_d3_82599(struct ixgbe_hw *hw);
+bool ixgbe_mng_present(struct ixgbe_hw *hw);
+bool ixgbe_mng_enabled(struct ixgbe_hw *hw);
+
+
+void ixgbe_get_etk_id(struct ixgbe_hw *hw, struct ixgbe_nvm_version *nvm_ver);
+void ixgbe_get_oem_prod_version(struct ixgbe_hw *hw,
+				struct ixgbe_nvm_version *nvm_ver);
+void ixgbe_get_orom_version(struct ixgbe_hw *hw,
+			    struct ixgbe_nvm_version *nvm_ver);
+void ixgbe_disable_rx_generic(struct ixgbe_hw *hw);
+void ixgbe_enable_rx_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_setup_mac_link_multispeed_fiber(struct ixgbe_hw *hw,
+					  ixgbe_link_speed speed,
+					  bool autoneg_wait_to_complete);
+void ixgbe_set_soft_rate_select_speed(struct ixgbe_hw *hw,
+				      ixgbe_link_speed speed);
+#endif /* IXGBE_COMMON */
Index: ./dev/pci/ixgbe_dcb.h
===================================================================
RCS file: ./dev/pci/ixgbe_dcb.h
diff -N ./dev/pci/ixgbe_dcb.h
--- /dev/null	1 Jan 1970 00:00:00 -0000
+++ ./dev/pci/ixgbe_dcb.h	17 Sep 2018 19:59:55 -0000
@@ -0,0 +1,176 @@
+/******************************************************************************
+  SPDX-License-Identifier: BSD-3-Clause
+
+  Copyright (c) 2001-2017, Intel Corporation
+  All rights reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions are met:
+
+   1. Redistributions of source code must retain the above copyright notice,
+      this list of conditions and the following disclaimer.
+
+   2. Redistributions in binary form must reproduce the above copyright
+      notice, this list of conditions and the following disclaimer in the
+      documentation and/or other materials provided with the distribution.
+
+   3. Neither the name of the Intel Corporation nor the names of its
+      contributors may be used to endorse or promote products derived from
+      this software without specific prior written permission.
+
+  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
+  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+  POSSIBILITY OF SUCH DAMAGE.
+
+******************************************************************************/
+/*$FreeBSD$*/
+
+#ifndef _IXGBE_DCB_H_
+#define _IXGBE_DCB_H_
+
+#include "ixgbe_type.h"
+
+/* DCB defines */
+/* DCB credit calculation defines */
+#define IXGBE_DCB_CREDIT_QUANTUM	64
+#define IXGBE_DCB_MAX_CREDIT_REFILL	200   /* 200 * 64B = 12800B */
+#define IXGBE_DCB_MAX_TSO_SIZE		(32 * 1024) /* Max TSO pkt size in DCB*/
+#define IXGBE_DCB_MAX_CREDIT		(2 * IXGBE_DCB_MAX_CREDIT_REFILL)
+
+/* 513 for 32KB TSO packet */
+#define IXGBE_DCB_MIN_TSO_CREDIT	\
+	((IXGBE_DCB_MAX_TSO_SIZE / IXGBE_DCB_CREDIT_QUANTUM) + 1)
+
+/* DCB configuration defines */
+#define IXGBE_DCB_MAX_USER_PRIORITY	8
+#define IXGBE_DCB_MAX_BW_GROUP		8
+#define IXGBE_DCB_BW_PERCENT		100
+
+#define IXGBE_DCB_TX_CONFIG		0
+#define IXGBE_DCB_RX_CONFIG		1
+
+/* DCB capability defines */
+#define IXGBE_DCB_PG_SUPPORT	0x00000001
+#define IXGBE_DCB_PFC_SUPPORT	0x00000002
+#define IXGBE_DCB_BCN_SUPPORT	0x00000004
+#define IXGBE_DCB_UP2TC_SUPPORT	0x00000008
+#define IXGBE_DCB_GSP_SUPPORT	0x00000010
+
+struct ixgbe_dcb_support {
+	uint32_t capabilities; /* DCB capabilities */
+
+	/* Each bit represents a number of TCs configurable in the hw.
+	 * If 8 traffic classes can be configured, the value is 0x80. */
+	uint8_t traffic_classes;
+	uint8_t pfc_traffic_classes;
+};
+
+enum ixgbe_dcb_tsa {
+	ixgbe_dcb_tsa_ets = 0,
+	ixgbe_dcb_tsa_group_strict_cee,
+	ixgbe_dcb_tsa_strict
+};
+
+/* Traffic class bandwidth allocation per direction */
+struct ixgbe_dcb_tc_path {
+	uint8_t bwg_id; /* Bandwidth Group (BWG) ID */
+	uint8_t bwg_percent; /* % of BWG's bandwidth */
+	uint8_t link_percent; /* % of link bandwidth */
+	uint8_t up_to_tc_bitmap; /* User Priority to Traffic Class mapping */
+	uint16_t data_credits_refill; /* Credit refill amount in 64B granularity */
+	uint16_t data_credits_max; /* Max credits for a configured packet buffer
+			       * in 64B granularity.*/
+	enum ixgbe_dcb_tsa tsa; /* Link or Group Strict Priority */
+};
+
+enum ixgbe_dcb_pfc {
+	ixgbe_dcb_pfc_disabled = 0,
+	ixgbe_dcb_pfc_enabled,
+	ixgbe_dcb_pfc_enabled_txonly,
+	ixgbe_dcb_pfc_enabled_rxonly
+};
+
+/* Traffic class configuration */
+struct ixgbe_dcb_tc_config {
+	struct ixgbe_dcb_tc_path path[2]; /* One each for Tx/Rx */
+	enum ixgbe_dcb_pfc pfc; /* Class based flow control setting */
+
+	uint16_t desc_credits_max; /* For Tx Descriptor arbitration */
+	uint8_t tc; /* Traffic class (TC) */
+};
+
+enum ixgbe_dcb_pba {
+	/* PBA[0-7] each use 64KB FIFO */
+	ixgbe_dcb_pba_equal = PBA_STRATEGY_EQUAL,
+	/* PBA[0-3] each use 80KB, PBA[4-7] each use 48KB */
+	ixgbe_dcb_pba_80_48 = PBA_STRATEGY_WEIGHTED
+};
+
+struct ixgbe_dcb_num_tcs {
+	uint8_t pg_tcs;
+	uint8_t pfc_tcs;
+};
+
+struct ixgbe_dcb_config {
+	struct ixgbe_dcb_tc_config tc_config[IXGBE_DCB_MAX_TRAFFIC_CLASS];
+	struct ixgbe_dcb_support support;
+	struct ixgbe_dcb_num_tcs num_tcs;
+	uint8_t bw_percentage[2][IXGBE_DCB_MAX_BW_GROUP]; /* One each for Tx/Rx */
+	bool pfc_mode_enable;
+	bool round_robin_enable;
+
+	enum ixgbe_dcb_pba rx_pba_cfg;
+
+	uint32_t dcb_cfg_version; /* Not used...OS-specific? */
+	uint32_t link_speed; /* For bandwidth allocation validation purpose */
+	bool vt_mode;
+};
+
+/* DCB driver APIs */
+
+/* DCB rule checking */
+int32_t ixgbe_dcb_check_config_cee(struct ixgbe_dcb_config *);
+
+/* DCB credits calculation */
+int32_t ixgbe_dcb_calculate_tc_credits(uint8_t *, uint16_t *, uint16_t *, int);
+int32_t ixgbe_dcb_calculate_tc_credits_cee(struct ixgbe_hw *,
+				       struct ixgbe_dcb_config *, uint32_t, uint8_t);
+
+/* DCB PFC */
+int32_t ixgbe_dcb_config_pfc(struct ixgbe_hw *, uint8_t, uint8_t *);
+int32_t ixgbe_dcb_config_pfc_cee(struct ixgbe_hw *, struct ixgbe_dcb_config *);
+
+/* DCB stats */
+int32_t ixgbe_dcb_config_tc_stats(struct ixgbe_hw *);
+int32_t ixgbe_dcb_get_tc_stats(struct ixgbe_hw *, struct ixgbe_hw_stats *, uint8_t);
+int32_t ixgbe_dcb_get_pfc_stats(struct ixgbe_hw *, struct ixgbe_hw_stats *, uint8_t);
+
+/* DCB config arbiters */
+int32_t ixgbe_dcb_config_tx_desc_arbiter_cee(struct ixgbe_hw *,
+					 struct ixgbe_dcb_config *);
+int32_t ixgbe_dcb_config_tx_data_arbiter_cee(struct ixgbe_hw *,
+					 struct ixgbe_dcb_config *);
+int32_t ixgbe_dcb_config_rx_arbiter_cee(struct ixgbe_hw *,
+				    struct ixgbe_dcb_config *);
+
+/* DCB unpack routines */
+void ixgbe_dcb_unpack_pfc_cee(struct ixgbe_dcb_config *, uint8_t *, uint8_t *);
+void ixgbe_dcb_unpack_refill_cee(struct ixgbe_dcb_config *, int, uint16_t *);
+void ixgbe_dcb_unpack_max_cee(struct ixgbe_dcb_config *, uint16_t *);
+void ixgbe_dcb_unpack_bwgid_cee(struct ixgbe_dcb_config *, int, uint8_t *);
+void ixgbe_dcb_unpack_tsa_cee(struct ixgbe_dcb_config *, int, uint8_t *);
+void ixgbe_dcb_unpack_map_cee(struct ixgbe_dcb_config *, int, uint8_t *);
+uint8_t ixgbe_dcb_get_tc_from_up(struct ixgbe_dcb_config *, int, uint8_t);
+
+/* DCB initialization */
+int32_t ixgbe_dcb_hw_config(struct ixgbe_hw *, uint16_t *, uint16_t *, uint8_t *, uint8_t *, uint8_t *);
+int32_t ixgbe_dcb_hw_config_cee(struct ixgbe_hw *, struct ixgbe_dcb_config *);
+#endif /* _IXGBE_DCB_H_ */
Index: ./dev/pci/ixgbe_dcb_82599.h
===================================================================
RCS file: ./dev/pci/ixgbe_dcb_82599.h
diff -N ./dev/pci/ixgbe_dcb_82599.h
--- /dev/null	1 Jan 1970 00:00:00 -0000
+++ ./dev/pci/ixgbe_dcb_82599.h	17 Sep 2018 19:59:55 -0000
@@ -0,0 +1,155 @@
+/******************************************************************************
+  SPDX-License-Identifier: BSD-3-Clause
+
+  Copyright (c) 2001-2017, Intel Corporation
+  All rights reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions are met:
+
+   1. Redistributions of source code must retain the above copyright notice,
+      this list of conditions and the following disclaimer.
+
+   2. Redistributions in binary form must reproduce the above copyright
+      notice, this list of conditions and the following disclaimer in the
+      documentation and/or other materials provided with the distribution.
+
+   3. Neither the name of the Intel Corporation nor the names of its
+      contributors may be used to endorse or promote products derived from
+      this software without specific prior written permission.
+
+  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
+  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+  POSSIBILITY OF SUCH DAMAGE.
+
+******************************************************************************/
+/*$FreeBSD$*/
+
+#ifndef _IXGBE_DCB_82599_H_
+#define _IXGBE_DCB_82599_H_
+
+/* DCB register definitions */
+#define IXGBE_RTTDCS_TDPAC	0x00000001 /* 0 Round Robin,
+					    * 1 WSP - Weighted Strict Priority
+					    */
+#define IXGBE_RTTDCS_VMPAC	0x00000002 /* 0 Round Robin,
+					    * 1 WRR - Weighted Round Robin
+					    */
+#define IXGBE_RTTDCS_TDRM	0x00000010 /* Transmit Recycle Mode */
+#define IXGBE_RTTDCS_BDPM	0x00400000 /* Bypass Data Pipe - must clear! */
+#define IXGBE_RTTDCS_BPBFSM	0x00800000 /* Bypass PB Free Space - must
+					     * clear!
+					     */
+#define IXGBE_RTTDCS_SPEED_CHG	0x80000000 /* Link speed change */
+
+/* Receive UP2TC mapping */
+#define IXGBE_RTRUP2TC_UP_SHIFT	3
+#define IXGBE_RTRUP2TC_UP_MASK	7
+/* Transmit UP2TC mapping */
+#define IXGBE_RTTUP2TC_UP_SHIFT	3
+
+#define IXGBE_RTRPT4C_MCL_SHIFT	12 /* Offset to Max Credit Limit setting */
+#define IXGBE_RTRPT4C_BWG_SHIFT	9  /* Offset to BWG index */
+#define IXGBE_RTRPT4C_GSP	0x40000000 /* GSP enable bit */
+#define IXGBE_RTRPT4C_LSP	0x80000000 /* LSP enable bit */
+
+#define IXGBE_RDRXCTL_MPBEN	0x00000010 /* DMA config for multiple packet
+					    * buffers enable
+					    */
+#define IXGBE_RDRXCTL_MCEN	0x00000040 /* DMA config for multiple cores
+					    * (RSS) enable
+					    */
+
+/* RTRPCS Bit Masks */
+#define IXGBE_RTRPCS_RRM	0x00000002 /* Receive Recycle Mode enable */
+/* Receive Arbitration Control: 0 Round Robin, 1 DFP */
+#define IXGBE_RTRPCS_RAC	0x00000004
+#define IXGBE_RTRPCS_ARBDIS	0x00000040 /* Arbitration disable bit */
+
+/* RTTDT2C Bit Masks */
+#define IXGBE_RTTDT2C_MCL_SHIFT	12
+#define IXGBE_RTTDT2C_BWG_SHIFT	9
+#define IXGBE_RTTDT2C_GSP	0x40000000
+#define IXGBE_RTTDT2C_LSP	0x80000000
+
+#define IXGBE_RTTPT2C_MCL_SHIFT	12
+#define IXGBE_RTTPT2C_BWG_SHIFT	9
+#define IXGBE_RTTPT2C_GSP	0x40000000
+#define IXGBE_RTTPT2C_LSP	0x80000000
+
+/* RTTPCS Bit Masks */
+#define IXGBE_RTTPCS_TPPAC	0x00000020 /* 0 Round Robin,
+					    * 1 SP - Strict Priority
+					    */
+#define IXGBE_RTTPCS_ARBDIS	0x00000040 /* Arbiter disable */
+#define IXGBE_RTTPCS_TPRM	0x00000100 /* Transmit Recycle Mode enable */
+#define IXGBE_RTTPCS_ARBD_SHIFT	22
+#define IXGBE_RTTPCS_ARBD_DCB	0x4 /* Arbitration delay in DCB mode */
+
+#define IXGBE_TXPBTHRESH_DCB	0xA /* THRESH value for DCB mode */
+
+/* SECTXMINIFG DCB */
+#define IXGBE_SECTX_DCB		0x00001F00 /* DCB TX Buffer SEC IFG */
+
+/* BCN register definitions */
+#define IXGBE_RTTBCNRC_RF_INT_SHIFT	14
+#define IXGBE_RTTBCNRC_RS_ENA		0x80000000
+
+#define IXGBE_RTTBCNCR_MNG_CMTGI	0x00000001
+#define IXGBE_RTTBCNCR_MGN_BCNA_MODE	0x00000002
+#define IXGBE_RTTBCNCR_RSV7_11_SHIFT	5
+#define IXGBE_RTTBCNCR_G		0x00000400
+#define IXGBE_RTTBCNCR_I		0x00000800
+#define IXGBE_RTTBCNCR_H		0x00001000
+#define IXGBE_RTTBCNCR_VER_SHIFT	14
+#define IXGBE_RTTBCNCR_CMT_ETH_SHIFT	16
+
+#define IXGBE_RTTBCNACL_SMAC_L_SHIFT	16
+
+#define IXGBE_RTTBCNTG_BCNA_MODE	0x80000000
+
+#define IXGBE_RTTBCNRTT_TS_SHIFT	3
+#define IXGBE_RTTBCNRTT_TXQ_IDX_SHIFT	16
+
+#define IXGBE_RTTBCNRD_BCN_CLEAR_ALL	0x00000002
+#define IXGBE_RTTBCNRD_DRIFT_FAC_SHIFT	2
+#define IXGBE_RTTBCNRD_DRIFT_INT_SHIFT	16
+#define IXGBE_RTTBCNRD_DRIFT_ENA	0x80000000
+
+
+/* DCB driver APIs */
+
+/* DCB PFC */
+int32_t ixgbe_dcb_config_pfc_82599(struct ixgbe_hw *, uint8_t, uint8_t *);
+
+/* DCB stats */
+int32_t ixgbe_dcb_config_tc_stats_82599(struct ixgbe_hw *,
+				    struct ixgbe_dcb_config *);
+int32_t ixgbe_dcb_get_tc_stats_82599(struct ixgbe_hw *,
+				 struct ixgbe_hw_stats *, uint8_t);
+int32_t ixgbe_dcb_get_pfc_stats_82599(struct ixgbe_hw *,
+				  struct ixgbe_hw_stats *, uint8_t);
+
+/* DCB config arbiters */
+int32_t ixgbe_dcb_config_tx_desc_arbiter_82599(struct ixgbe_hw *, uint16_t *, uint16_t *,
+					   uint8_t *, uint8_t *);
+int32_t ixgbe_dcb_config_tx_data_arbiter_82599(struct ixgbe_hw *, uint16_t *, uint16_t *,
+					   uint8_t *, uint8_t *, uint8_t *);
+int32_t ixgbe_dcb_config_rx_arbiter_82599(struct ixgbe_hw *, uint16_t *, uint16_t *, uint8_t *,
+				      uint8_t *, uint8_t *);
+
+/* DCB initialization */
+int32_t ixgbe_dcb_config_82599(struct ixgbe_hw *,
+			   struct ixgbe_dcb_config *);
+
+int32_t ixgbe_dcb_hw_config_82599(struct ixgbe_hw *, int, uint16_t *, uint16_t *, uint8_t *,
+			      uint8_t *, uint8_t *);
+#endif /* _IXGBE_DCB_82959_H_ */
Index: ./dev/pci/ixgbe_phy.c
===================================================================
RCS file: /cvs/src/sys/dev/pci/ixgbe_phy.c,v
retrieving revision 1.19
diff -u -p -r1.19 ixgbe_phy.c
--- ./dev/pci/ixgbe_phy.c	18 Nov 2016 12:36:41 -0000	1.19
+++ ./dev/pci/ixgbe_phy.c	17 Sep 2018 19:59:55 -0000
@@ -1,8 +1,7 @@
-/*	$OpenBSD: ixgbe_phy.c,v 1.19 2016/11/18 12:36:41 mikeb Exp $	*/
-
 /******************************************************************************
+  SPDX-License-Identifier: BSD-3-Clause
 
-  Copyright (c) 2001-2015, Intel Corporation
+  Copyright (c) 2001-2017, Intel Corporation
   All rights reserved.
 
   Redistribution and use in source and binary forms, with or without
@@ -32,22 +31,26 @@
   POSSIBILITY OF SUCH DAMAGE.
 
 ******************************************************************************/
-/*$FreeBSD: head/sys/dev/ixgbe/ixgbe_phy.c 303032 2016-07-19 17:31:48Z sbruno $*/
+/*$FreeBSD$*/
 
 #include <dev/pci/ixgbe.h>
-
-void ixgbe_i2c_start(struct ixgbe_hw *hw);
-void ixgbe_i2c_stop(struct ixgbe_hw *hw);
-int32_t ixgbe_clock_in_i2c_byte(struct ixgbe_hw *hw, uint8_t *data);
-int32_t ixgbe_clock_out_i2c_byte(struct ixgbe_hw *hw, uint8_t data);
-int32_t ixgbe_get_i2c_ack(struct ixgbe_hw *hw);
-int32_t ixgbe_clock_in_i2c_bit(struct ixgbe_hw *hw, bool *data);
-int32_t ixgbe_clock_out_i2c_bit(struct ixgbe_hw *hw, bool data);
-void ixgbe_raise_i2c_clk(struct ixgbe_hw *hw, uint32_t *i2cctl);
-void ixgbe_lower_i2c_clk(struct ixgbe_hw *hw, uint32_t *i2cctl);
-int32_t ixgbe_set_i2c_data(struct ixgbe_hw *hw, uint32_t *i2cctl, bool data);
-bool ixgbe_get_i2c_data(struct ixgbe_hw *hw, uint32_t *i2cctl);
-void ixgbe_i2c_bus_clear(struct ixgbe_hw *hw);
+#include <dev/pci/ixgbe_type.h>
+#include <dev/pci/ixgbe_api.h>
+#include <dev/pci/ixgbe_phy.h>
+
+static void ixgbe_i2c_start(struct ixgbe_hw *hw);
+static void ixgbe_i2c_stop(struct ixgbe_hw *hw);
+static int32_t ixgbe_clock_in_i2c_byte(struct ixgbe_hw *hw, uint8_t *data);
+static int32_t ixgbe_clock_out_i2c_byte(struct ixgbe_hw *hw, uint8_t data);
+static int32_t ixgbe_get_i2c_ack(struct ixgbe_hw *hw);
+static int32_t ixgbe_clock_in_i2c_bit(struct ixgbe_hw *hw, bool *data);
+static int32_t ixgbe_clock_out_i2c_bit(struct ixgbe_hw *hw, bool data);
+static void ixgbe_raise_i2c_clk(struct ixgbe_hw *hw, uint32_t *i2cctl);
+static void ixgbe_lower_i2c_clk(struct ixgbe_hw *hw, uint32_t *i2cctl);
+static int32_t ixgbe_set_i2c_data(struct ixgbe_hw *hw, uint32_t *i2cctl, bool data);
+static bool ixgbe_get_i2c_data(struct ixgbe_hw *hw, uint32_t *i2cctl);
+static int32_t ixgbe_read_i2c_sff8472_generic(struct ixgbe_hw *hw, uint8_t byte_offset,
+					  uint8_t *sff8472_data);
 
 /**
  * ixgbe_out_i2c_byte_ack - Send I2C byte with ack
@@ -86,8 +89,8 @@ static int32_t ixgbe_in_i2c_byte_ack(str
 
 /**
  * ixgbe_ones_comp_byte_add - Perform one's complement addition
- * @add1 - addend 1
- * @add2 - addend 2
+ * @add1: addend 1
+ * @add2: addend 2
  *
  * Returns one's complement 8-bit sum.
  */
@@ -109,12 +112,11 @@ static uint8_t ixgbe_ones_comp_byte_add(
  *
  * Returns an error code on error.
  */
-int32_t ixgbe_read_i2c_combined_generic_int(struct ixgbe_hw *hw, uint8_t addr,
-					    uint16_t reg, uint16_t *val,
-					    bool lock)
+int32_t ixgbe_read_i2c_combined_generic_int(struct ixgbe_hw *hw, uint8_t addr, uint16_t reg,
+					uint16_t *val, bool lock)
 {
 	uint32_t swfw_mask = hw->phy.phy_semaphore_mask;
-	int max_retry = 10;
+	int max_retry = 3;
 	int retry = 0;
 	uint8_t csum_byte;
 	uint8_t high_bits;
@@ -122,8 +124,6 @@ int32_t ixgbe_read_i2c_combined_generic_
 	uint8_t reg_high;
 	uint8_t csum;
 
-	if (hw->mac.type >= ixgbe_mac_X550)
-		max_retry = 3;
 	reg_high = ((reg >> 7) & 0xFE) | 1;	/* Indicate read combined */
 	csum = ixgbe_ones_comp_byte_add(reg_high, reg & 0xFF);
 	csum = ~csum;
@@ -181,36 +181,6 @@ fail:
 }
 
 /**
- * ixgbe_read_i2c_combined_generic - Perform I2C read combined operation
- * @hw: pointer to the hardware structure
- * @addr: I2C bus address to read from
- * @reg: I2C device register to read from
- * @val: pointer to location to receive read value
- *
- * Returns an error code on error.
- **/
-int32_t ixgbe_read_i2c_combined_generic(struct ixgbe_hw *hw, uint8_t addr,
-					uint16_t reg, uint16_t *val)
-{
-	return ixgbe_read_i2c_combined_generic_int(hw, addr, reg, val, TRUE);
-}
-
-/**
- * ixgbe_read_i2c_combined_generic_unlocked - Do I2C read combined operation
- * @hw: pointer to the hardware structure
- * @addr: I2C bus address to read from
- * @reg: I2C device register to read from
- * @val: pointer to location to receive read value
- *
- * Returns an error code on error.
- **/
-int32_t ixgbe_read_i2c_combined_generic_unlocked(struct ixgbe_hw *hw, uint8_t addr,
-						 uint16_t reg, uint16_t *val)
-{
-	return ixgbe_read_i2c_combined_generic_int(hw, addr, reg, val, FALSE);
-}
-
-/**
  * ixgbe_write_i2c_combined_generic_int - Perform I2C write combined operation
  * @hw: pointer to the hardware structure
  * @addr: I2C bus address to write to
@@ -220,8 +190,8 @@ int32_t ixgbe_read_i2c_combined_generic_
  *
  * Returns an error code on error.
  */
-int32_t ixgbe_write_i2c_combined_generic_int(struct ixgbe_hw *hw, uint8_t addr,
-					     uint16_t reg, uint16_t val, bool lock)
+int32_t ixgbe_write_i2c_combined_generic_int(struct ixgbe_hw *hw, uint8_t addr, uint16_t reg,
+					 uint16_t val, bool lock)
 {
 	uint32_t swfw_mask = hw->phy.phy_semaphore_mask;
 	int max_retry = 1;
@@ -276,37 +246,6 @@ fail:
 }
 
 /**
- * ixgbe_write_i2c_combined_generic - Perform I2C write combined operation
- * @hw: pointer to the hardware structure
- * @addr: I2C bus address to write to
- * @reg: I2C device register to write to
- * @val: value to write
- *
- * Returns an error code on error.
- **/
-int32_t ixgbe_write_i2c_combined_generic(struct ixgbe_hw *hw,
-					 uint8_t addr, uint16_t reg, uint16_t val)
-{
-	return ixgbe_write_i2c_combined_generic_int(hw, addr, reg, val, TRUE);
-}
-
-/**
- * ixgbe_write_i2c_combined_generic_unlocked - Do I2C write combined operation
- * @hw: pointer to the hardware structure
- * @addr: I2C bus address to write to
- * @reg: I2C device register to write to
- * @val: value to write
- *
- * Returns an error code on error.
- **/
-int32_t
-ixgbe_write_i2c_combined_generic_unlocked(struct ixgbe_hw *hw,
-					  uint8_t addr, uint16_t reg, uint16_t val)
-{
-	return ixgbe_write_i2c_combined_generic_int(hw, addr, reg, val, FALSE);
-}
-
-/**
  *  ixgbe_init_phy_ops_generic - Inits PHY function ptrs
  *  @hw: pointer to the hardware structure
  *
@@ -331,17 +270,12 @@ int32_t ixgbe_init_phy_ops_generic(struc
 	phy->ops.get_firmware_version = ixgbe_get_phy_firmware_version_generic;
 	phy->ops.read_i2c_byte = ixgbe_read_i2c_byte_generic;
 	phy->ops.write_i2c_byte = ixgbe_write_i2c_byte_generic;
+	phy->ops.read_i2c_sff8472 = ixgbe_read_i2c_sff8472_generic;
 	phy->ops.read_i2c_eeprom = ixgbe_read_i2c_eeprom_generic;
 	phy->ops.write_i2c_eeprom = ixgbe_write_i2c_eeprom_generic;
 	phy->ops.i2c_bus_clear = ixgbe_i2c_bus_clear;
 	phy->ops.identify_sfp = ixgbe_identify_module_generic;
 	phy->sfp_type = ixgbe_sfp_type_unknown;
-	phy->ops.read_i2c_combined = ixgbe_read_i2c_combined_generic;
-	phy->ops.write_i2c_combined = ixgbe_write_i2c_combined_generic;
-	phy->ops.read_i2c_combined_unlocked =
-				ixgbe_read_i2c_combined_generic_unlocked;
-	phy->ops.write_i2c_combined_unlocked =
-				ixgbe_write_i2c_combined_generic_unlocked;
 	phy->ops.read_i2c_byte_unlocked = ixgbe_read_i2c_byte_generic_unlocked;
 	phy->ops.write_i2c_byte_unlocked =
 				ixgbe_write_i2c_byte_generic_unlocked;
@@ -350,6 +284,42 @@ int32_t ixgbe_init_phy_ops_generic(struc
 }
 
 /**
+ * ixgbe_probe_phy - Probe a single address for a PHY
+ * @hw: pointer to hardware structure
+ * @phy_addr: PHY address to probe
+ *
+ * Returns TRUE if PHY found
+ */
+static bool ixgbe_probe_phy(struct ixgbe_hw *hw, uint16_t phy_addr)
+{
+	uint16_t ext_ability = 0;
+
+	if (!ixgbe_validate_phy_addr(hw, phy_addr)) {
+		DEBUGOUT1("Unable to validate PHY address 0x%04X\n",
+			phy_addr);
+		return FALSE;
+	}
+
+	if (ixgbe_get_phy_id(hw))
+		return FALSE;
+
+	hw->phy.type = ixgbe_get_phy_type_from_id(hw->phy.id);
+
+	if (hw->phy.type == ixgbe_phy_unknown) {
+		hw->phy.ops.read_reg(hw, IXGBE_MDIO_PHY_EXT_ABILITY,
+				     IXGBE_MDIO_PMA_PMD_DEV_TYPE, &ext_ability);
+		if (ext_ability &
+		    (IXGBE_MDIO_PHY_10GBASET_ABILITY |
+		     IXGBE_MDIO_PHY_1000BASET_ABILITY))
+			hw->phy.type = ixgbe_phy_cu_unknown;
+		else
+			hw->phy.type = ixgbe_phy_generic;
+	}
+
+	return TRUE;
+}
+
+/**
  *  ixgbe_identify_phy_generic - Get physical layer module
  *  @hw: pointer to hardware structure
  *
@@ -358,8 +328,7 @@ int32_t ixgbe_init_phy_ops_generic(struc
 int32_t ixgbe_identify_phy_generic(struct ixgbe_hw *hw)
 {
 	int32_t status = IXGBE_ERR_PHY_ADDR_INVALID;
-	uint32_t phy_addr;
-	uint16_t ext_ability = 0;
+	uint16_t phy_addr;
 
 	DEBUGFUNC("ixgbe_identify_phy_generic");
 
@@ -370,45 +339,33 @@ int32_t ixgbe_identify_phy_generic(struc
 			hw->phy.phy_semaphore_mask = IXGBE_GSSR_PHY0_SM;
 	}
 
-	if (hw->phy.type == ixgbe_phy_unknown) {
-		for (phy_addr = 0; phy_addr < IXGBE_MAX_PHY_ADDR; phy_addr++) {
-			if (ixgbe_validate_phy_addr(hw, phy_addr)) {
-				hw->phy.addr = phy_addr;
-				ixgbe_get_phy_id(hw);
-				hw->phy.type =
-					ixgbe_get_phy_type_from_id(hw->phy.id);
-
-				if (hw->phy.type == ixgbe_phy_unknown) {
-					hw->phy.ops.read_reg(hw,
-						  IXGBE_MDIO_PHY_EXT_ABILITY,
-						  IXGBE_MDIO_PMA_PMD_DEV_TYPE,
-						  &ext_ability);
-					if (ext_ability &
-					    (IXGBE_MDIO_PHY_10GBASET_ABILITY |
-					     IXGBE_MDIO_PHY_1000BASET_ABILITY))
-						hw->phy.type =
-							 ixgbe_phy_cu_unknown;
-					else
-						hw->phy.type =
-							 ixgbe_phy_generic;
-				}
+	if (hw->phy.type != ixgbe_phy_unknown)
+		return IXGBE_SUCCESS;
 
-				status = IXGBE_SUCCESS;
-				break;
-			}
-		}
+	if (hw->phy.nw_mng_if_sel) {
+		phy_addr = (hw->phy.nw_mng_if_sel &
+			    IXGBE_NW_MNG_IF_SEL_MDIO_PHY_ADD) >>
+			   IXGBE_NW_MNG_IF_SEL_MDIO_PHY_ADD_SHIFT;
+		if (ixgbe_probe_phy(hw, phy_addr))
+			return IXGBE_SUCCESS;
+		else
+			return IXGBE_ERR_PHY_ADDR_INVALID;
+	}
 
-		/* Certain media types do not have a phy so an address will not
-		 * be found and the code will take this path.  Caller has to
-		 * decide if it is an error or not.
-		 */
-		if (status != IXGBE_SUCCESS) {
-			hw->phy.addr = 0;
+	for (phy_addr = 0; phy_addr < IXGBE_MAX_PHY_ADDR; phy_addr++) {
+		if (ixgbe_probe_phy(hw, phy_addr)) {
+			status = IXGBE_SUCCESS;
+			break;
 		}
-	} else {
-		status = IXGBE_SUCCESS;
 	}
 
+	/* Certain media types do not have a phy so an address will not
+	 * be found and the code will take this path.  Caller has to
+	 * decide if it is an error or not.
+	 */
+	if (status != IXGBE_SUCCESS)
+		hw->phy.addr = 0;
+
 	return status;
 }
 
@@ -444,6 +401,7 @@ int32_t ixgbe_check_reset_blocked(struct
 /**
  *  ixgbe_validate_phy_addr - Determines phy address is valid
  *  @hw: pointer to hardware structure
+ *  @phy_addr: PHY address
  *
  **/
 bool ixgbe_validate_phy_addr(struct ixgbe_hw *hw, uint32_t phy_addr)
@@ -460,6 +418,8 @@ bool ixgbe_validate_phy_addr(struct ixgb
 	if (phy_id != 0xFFFF && phy_id != 0x0)
 		valid = TRUE;
 
+	DEBUGOUT1("PHY ID HIGH is 0x%04X\n", phy_id);
+
 	return valid;
 }
 
@@ -486,15 +446,17 @@ int32_t ixgbe_get_phy_id(struct ixgbe_hw
 					      IXGBE_MDIO_PMA_PMD_DEV_TYPE,
 					      &phy_id_low);
 		hw->phy.id |= (uint32_t)(phy_id_low & IXGBE_PHY_REVISION_MASK);
-		hw->phy.revision =
-		    (uint32_t)(phy_id_low & ~IXGBE_PHY_REVISION_MASK);
+		hw->phy.revision = (uint32_t)(phy_id_low & ~IXGBE_PHY_REVISION_MASK);
 	}
+	DEBUGOUT2("PHY_ID_HIGH 0x%04X, PHY_ID_LOW 0x%04X\n",
+		  phy_id_high, phy_id_low);
+
 	return status;
 }
 
 /**
  *  ixgbe_get_phy_type_from_id - Get the phy type
- *  @hw: pointer to hardware structure
+ *  @phy_id: PHY ID information
  *
  **/
 enum ixgbe_phy_type ixgbe_get_phy_type_from_id(uint32_t phy_id)
@@ -507,7 +469,6 @@ enum ixgbe_phy_type ixgbe_get_phy_type_f
 	case TN1010_PHY_ID:
 		phy_type = ixgbe_phy_tn;
 		break;
-	case X550_PHY_ID1:
 	case X550_PHY_ID2:
 	case X550_PHY_ID3:
 	case X540_PHY_ID:
@@ -520,14 +481,17 @@ enum ixgbe_phy_type ixgbe_get_phy_type_f
 		phy_type = ixgbe_phy_nl;
 		break;
 	case X557_PHY_ID:
+	case X557_PHY_ID2:
 		phy_type = ixgbe_phy_x550em_ext_t;
 		break;
+	case IXGBE_M88E1500_E_PHY_ID:
+	case IXGBE_M88E1543_E_PHY_ID:
+		phy_type = ixgbe_phy_ext_1g_t;
+		break;
 	default:
 		phy_type = ixgbe_phy_unknown;
 		break;
 	}
-
-	DEBUGOUT1("phy type found is %d\n", phy_type);
 	return phy_type;
 }
 
@@ -573,11 +537,30 @@ int32_t ixgbe_reset_phy_generic(struct i
 	 */
 	for (i = 0; i < 30; i++) {
 		msec_delay(100);
-		hw->phy.ops.read_reg(hw, IXGBE_MDIO_PHY_XS_CONTROL,
-				     IXGBE_MDIO_PHY_XS_DEV_TYPE, &ctrl);
-		if (!(ctrl & IXGBE_MDIO_PHY_XS_RESET)) {
-			usec_delay(2);
-			break;
+		if (hw->phy.type == ixgbe_phy_x550em_ext_t) {
+			status = hw->phy.ops.read_reg(hw,
+						  IXGBE_MDIO_TX_VENDOR_ALARMS_3,
+						  IXGBE_MDIO_PMA_PMD_DEV_TYPE,
+						  &ctrl);
+			if (status != IXGBE_SUCCESS)
+				return status;
+
+			if (ctrl & IXGBE_MDIO_TX_VENDOR_ALARMS_3_RST_MASK) {
+				usec_delay(2);
+				break;
+			}
+		} else {
+			status = hw->phy.ops.read_reg(hw,
+						     IXGBE_MDIO_PHY_XS_CONTROL,
+						     IXGBE_MDIO_PHY_XS_DEV_TYPE,
+						     &ctrl);
+			if (status != IXGBE_SUCCESS)
+				return status;
+
+			if (!(ctrl & IXGBE_MDIO_PHY_XS_RESET)) {
+				usec_delay(2);
+				break;
+			}
 		}
 	}
 
@@ -596,10 +579,11 @@ out:
  *  the SWFW lock
  *  @hw: pointer to hardware structure
  *  @reg_addr: 32 bit address of PHY register to read
+ *  @device_type: 5 bit device type
  *  @phy_data: Pointer to read data from PHY register
  **/
-int32_t ixgbe_read_phy_reg_mdi(struct ixgbe_hw *hw, uint32_t reg_addr,
-			       uint32_t device_type, uint16_t *phy_data)
+int32_t ixgbe_read_phy_reg_mdi(struct ixgbe_hw *hw, uint32_t reg_addr, uint32_t device_type,
+			   uint16_t *phy_data)
 {
 	uint32_t i, data, command;
 
@@ -621,12 +605,13 @@ int32_t ixgbe_read_phy_reg_mdi(struct ix
 
 		command = IXGBE_READ_REG(hw, IXGBE_MSCA);
 		if ((command & IXGBE_MSCA_MDI_COMMAND) == 0)
-				break;
+			break;
 	}
 
 
 	if ((command & IXGBE_MSCA_MDI_COMMAND) != 0) {
 		ERROR_REPORT1(IXGBE_ERROR_POLLING, "PHY address command did not complete.\n");
+		DEBUGOUT("PHY address command did not complete, returning IXGBE_ERR_PHY\n");
 		return IXGBE_ERR_PHY;
 	}
 
@@ -656,6 +641,7 @@ int32_t ixgbe_read_phy_reg_mdi(struct ix
 
 	if ((command & IXGBE_MSCA_MDI_COMMAND) != 0) {
 		ERROR_REPORT1(IXGBE_ERROR_POLLING, "PHY read command didn't complete\n");
+		DEBUGOUT("PHY read command didn't complete, returning IXGBE_ERR_PHY\n");
 		return IXGBE_ERR_PHY;
 	}
 
@@ -675,23 +661,23 @@ int32_t ixgbe_read_phy_reg_mdi(struct ix
  *  using the SWFW lock - this function is needed in most cases
  *  @hw: pointer to hardware structure
  *  @reg_addr: 32 bit address of PHY register to read
+ *  @device_type: 5 bit device type
  *  @phy_data: Pointer to read data from PHY register
  **/
 int32_t ixgbe_read_phy_reg_generic(struct ixgbe_hw *hw, uint32_t reg_addr,
-				   uint32_t device_type, uint16_t *phy_data)
+			       uint32_t device_type, uint16_t *phy_data)
 {
 	int32_t status;
 	uint32_t gssr = hw->phy.phy_semaphore_mask;
 
 	DEBUGFUNC("ixgbe_read_phy_reg_generic");
 
-	if (hw->mac.ops.acquire_swfw_sync(hw, gssr) == IXGBE_SUCCESS) {
-		status = ixgbe_read_phy_reg_mdi(hw, reg_addr, device_type,
-						phy_data);
-		hw->mac.ops.release_swfw_sync(hw, gssr);
-	} else {
-		status = IXGBE_ERR_SWFW_SYNC;
-	}
+	if (hw->mac.ops.acquire_swfw_sync(hw, gssr))
+		return IXGBE_ERR_SWFW_SYNC;
+
+	status = hw->phy.ops.read_reg_mdi(hw, reg_addr, device_type, phy_data);
+
+	hw->mac.ops.release_swfw_sync(hw, gssr);
 
 	return status;
 }
@@ -779,7 +765,7 @@ int32_t ixgbe_write_phy_reg_mdi(struct i
  *  @phy_data: Data to write to the PHY register
  **/
 int32_t ixgbe_write_phy_reg_generic(struct ixgbe_hw *hw, uint32_t reg_addr,
-				    uint32_t device_type, uint16_t phy_data)
+				uint32_t device_type, uint16_t phy_data)
 {
 	int32_t status;
 	uint32_t gssr = hw->phy.phy_semaphore_mask;
@@ -787,7 +773,7 @@ int32_t ixgbe_write_phy_reg_generic(stru
 	DEBUGFUNC("ixgbe_write_phy_reg_generic");
 
 	if (hw->mac.ops.acquire_swfw_sync(hw, gssr) == IXGBE_SUCCESS) {
-		status = ixgbe_write_phy_reg_mdi(hw, reg_addr, device_type,
+		status = hw->phy.ops.write_reg_mdi(hw, reg_addr, device_type,
 						 phy_data);
 		hw->mac.ops.release_swfw_sync(hw, gssr);
 	} else {
@@ -814,91 +800,63 @@ int32_t ixgbe_setup_phy_link_generic(str
 
 	ixgbe_get_copper_link_capabilities_generic(hw, &speed, &autoneg);
 
-	if (speed & IXGBE_LINK_SPEED_10GB_FULL) {
-		/* Set or unset auto-negotiation 10G advertisement */
-		hw->phy.ops.read_reg(hw, IXGBE_MII_10GBASE_T_AUTONEG_CTRL_REG,
-				     IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
-				     &autoneg_reg);
-
-		autoneg_reg &= ~IXGBE_MII_10GBASE_T_ADVERTISE;
-		if (hw->phy.autoneg_advertised & IXGBE_LINK_SPEED_10GB_FULL)
-			autoneg_reg |= IXGBE_MII_10GBASE_T_ADVERTISE;
-
-		hw->phy.ops.write_reg(hw, IXGBE_MII_10GBASE_T_AUTONEG_CTRL_REG,
-				      IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
-				      autoneg_reg);
-	}
+	/* Set or unset auto-negotiation 10G advertisement */
+	hw->phy.ops.read_reg(hw, IXGBE_MII_10GBASE_T_AUTONEG_CTRL_REG,
+			     IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
+			     &autoneg_reg);
+
+	autoneg_reg &= ~IXGBE_MII_10GBASE_T_ADVERTISE;
+	if ((hw->phy.autoneg_advertised & IXGBE_LINK_SPEED_10GB_FULL) &&
+	    (speed & IXGBE_LINK_SPEED_10GB_FULL))
+		autoneg_reg |= IXGBE_MII_10GBASE_T_ADVERTISE;
+
+	hw->phy.ops.write_reg(hw, IXGBE_MII_10GBASE_T_AUTONEG_CTRL_REG,
+			      IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
+			      autoneg_reg);
+
+	hw->phy.ops.read_reg(hw, IXGBE_MII_AUTONEG_VENDOR_PROVISION_1_REG,
+			     IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
+			     &autoneg_reg);
 
 	if (hw->mac.type == ixgbe_mac_X550) {
-		if (speed & IXGBE_LINK_SPEED_5GB_FULL) {
-			/* Set or unset auto-negotiation 5G advertisement */
-			hw->phy.ops.read_reg(hw,
-				IXGBE_MII_AUTONEG_VENDOR_PROVISION_1_REG,
-				IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
-				&autoneg_reg);
-
-			autoneg_reg &= ~IXGBE_MII_5GBASE_T_ADVERTISE;
-			if (hw->phy.autoneg_advertised &
-			     IXGBE_LINK_SPEED_5GB_FULL)
-				autoneg_reg |= IXGBE_MII_5GBASE_T_ADVERTISE;
-
-			hw->phy.ops.write_reg(hw,
-				IXGBE_MII_AUTONEG_VENDOR_PROVISION_1_REG,
-				IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
-				autoneg_reg);
-		}
-
-		if (speed & IXGBE_LINK_SPEED_2_5GB_FULL) {
-			/* Set or unset auto-negotiation 2.5G advertisement */
-			hw->phy.ops.read_reg(hw,
-				IXGBE_MII_AUTONEG_VENDOR_PROVISION_1_REG,
-				IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
-				&autoneg_reg);
-
-			autoneg_reg &= ~IXGBE_MII_2_5GBASE_T_ADVERTISE;
-			if (hw->phy.autoneg_advertised &
-			    IXGBE_LINK_SPEED_2_5GB_FULL)
-				autoneg_reg |= IXGBE_MII_2_5GBASE_T_ADVERTISE;
-
-			hw->phy.ops.write_reg(hw,
-				IXGBE_MII_AUTONEG_VENDOR_PROVISION_1_REG,
-				IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
-				autoneg_reg);
-		}
-	}
-
-	if (speed & IXGBE_LINK_SPEED_1GB_FULL) {
-		/* Set or unset auto-negotiation 1G advertisement */
-		hw->phy.ops.read_reg(hw,
-				     IXGBE_MII_AUTONEG_VENDOR_PROVISION_1_REG,
-				     IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
-				     &autoneg_reg);
-
-		autoneg_reg &= ~IXGBE_MII_1GBASE_T_ADVERTISE;
-		if (hw->phy.autoneg_advertised & IXGBE_LINK_SPEED_1GB_FULL)
-			autoneg_reg |= IXGBE_MII_1GBASE_T_ADVERTISE;
-
-		hw->phy.ops.write_reg(hw,
-				      IXGBE_MII_AUTONEG_VENDOR_PROVISION_1_REG,
-				      IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
-				      autoneg_reg);
-	}
-
-	if (speed & IXGBE_LINK_SPEED_100_FULL) {
-		/* Set or unset auto-negotiation 100M advertisement */
-		hw->phy.ops.read_reg(hw, IXGBE_MII_AUTONEG_ADVERTISE_REG,
-				     IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
-				     &autoneg_reg);
-
-		autoneg_reg &= ~(IXGBE_MII_100BASE_T_ADVERTISE |
-				 IXGBE_MII_100BASE_T_ADVERTISE_HALF);
-		if (hw->phy.autoneg_advertised & IXGBE_LINK_SPEED_100_FULL)
-			autoneg_reg |= IXGBE_MII_100BASE_T_ADVERTISE;
-
-		hw->phy.ops.write_reg(hw, IXGBE_MII_AUTONEG_ADVERTISE_REG,
-				      IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
-				      autoneg_reg);
-	}
+		/* Set or unset auto-negotiation 5G advertisement */
+		autoneg_reg &= ~IXGBE_MII_5GBASE_T_ADVERTISE;
+		if ((hw->phy.autoneg_advertised & IXGBE_LINK_SPEED_5GB_FULL) &&
+		    (speed & IXGBE_LINK_SPEED_5GB_FULL))
+			autoneg_reg |= IXGBE_MII_5GBASE_T_ADVERTISE;
+
+		/* Set or unset auto-negotiation 2.5G advertisement */
+		autoneg_reg &= ~IXGBE_MII_2_5GBASE_T_ADVERTISE;
+		if ((hw->phy.autoneg_advertised &
+		     IXGBE_LINK_SPEED_2_5GB_FULL) &&
+		    (speed & IXGBE_LINK_SPEED_2_5GB_FULL))
+			autoneg_reg |= IXGBE_MII_2_5GBASE_T_ADVERTISE;
+	}
+
+	/* Set or unset auto-negotiation 1G advertisement */
+	autoneg_reg &= ~IXGBE_MII_1GBASE_T_ADVERTISE;
+	if ((hw->phy.autoneg_advertised & IXGBE_LINK_SPEED_1GB_FULL) &&
+	    (speed & IXGBE_LINK_SPEED_1GB_FULL))
+		autoneg_reg |= IXGBE_MII_1GBASE_T_ADVERTISE;
+
+	hw->phy.ops.write_reg(hw, IXGBE_MII_AUTONEG_VENDOR_PROVISION_1_REG,
+			      IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
+			      autoneg_reg);
+
+	/* Set or unset auto-negotiation 100M advertisement */
+	hw->phy.ops.read_reg(hw, IXGBE_MII_AUTONEG_ADVERTISE_REG,
+			     IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
+			     &autoneg_reg);
+
+	autoneg_reg &= ~(IXGBE_MII_100BASE_T_ADVERTISE |
+			 IXGBE_MII_100BASE_T_ADVERTISE_HALF);
+	if ((hw->phy.autoneg_advertised & IXGBE_LINK_SPEED_100_FULL) &&
+	    (speed & IXGBE_LINK_SPEED_100_FULL))
+		autoneg_reg |= IXGBE_MII_100BASE_T_ADVERTISE;
+
+	hw->phy.ops.write_reg(hw, IXGBE_MII_AUTONEG_ADVERTISE_REG,
+			      IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
+			      autoneg_reg);
 
 	/* Blocked by MNG FW so don't reset PHY */
 	if (ixgbe_check_reset_blocked(hw))
@@ -920,10 +878,11 @@ int32_t ixgbe_setup_phy_link_generic(str
  *  ixgbe_setup_phy_link_speed_generic - Sets the auto advertised capabilities
  *  @hw: pointer to hardware structure
  *  @speed: new link speed
+ *  @autoneg_wait_to_complete: unused
  **/
 int32_t ixgbe_setup_phy_link_speed_generic(struct ixgbe_hw *hw,
-					   ixgbe_link_speed speed,
-					   bool autoneg_wait_to_complete)
+				       ixgbe_link_speed speed,
+				       UNUSED bool autoneg_wait_to_complete)
 {
 	DEBUGFUNC("ixgbe_setup_phy_link_speed_generic");
 
@@ -948,8 +907,11 @@ int32_t ixgbe_setup_phy_link_speed_gener
 	if (speed & IXGBE_LINK_SPEED_100_FULL)
 		hw->phy.autoneg_advertised |= IXGBE_LINK_SPEED_100_FULL;
 
+	if (speed & IXGBE_LINK_SPEED_10_FULL)
+		hw->phy.autoneg_advertised |= IXGBE_LINK_SPEED_10_FULL;
+
 	/* Setup link based on the new speed settings */
-	hw->phy.ops.setup_link(hw);
+	ixgbe_setup_phy_link(hw);
 
 	return IXGBE_SUCCESS;
 }
@@ -961,7 +923,7 @@ int32_t ixgbe_setup_phy_link_speed_gener
  * Determines the supported link capabilities by reading the PHY auto
  * negotiation register.
  **/
-int32_t ixgbe_get_copper_speeds_supported(struct ixgbe_hw *hw)
+static int32_t ixgbe_get_copper_speeds_supported(struct ixgbe_hw *hw)
 {
 	int32_t status;
 	uint16_t speed_ability;
@@ -985,6 +947,7 @@ int32_t ixgbe_get_copper_speeds_supporte
 		hw->phy.speeds_supported |= IXGBE_LINK_SPEED_5GB_FULL;
 		break;
 	case ixgbe_mac_X550EM_x:
+	case ixgbe_mac_X550EM_a:
 		hw->phy.speeds_supported &= ~IXGBE_LINK_SPEED_100_FULL;
 		break;
 	default:
@@ -1001,8 +964,8 @@ int32_t ixgbe_get_copper_speeds_supporte
  *  @autoneg: boolean auto-negotiation value
  **/
 int32_t ixgbe_get_copper_link_capabilities_generic(struct ixgbe_hw *hw,
-						   ixgbe_link_speed *speed,
-						   bool *autoneg)
+					       ixgbe_link_speed *speed,
+					       bool *autoneg)
 {
 	int32_t status = IXGBE_SUCCESS;
 
@@ -1019,12 +982,14 @@ int32_t ixgbe_get_copper_link_capabiliti
 /**
  *  ixgbe_check_phy_link_tnx - Determine link and speed status
  *  @hw: pointer to hardware structure
+ *  @speed: current link speed
+ *  @link_up: TRUE is link is up, FALSE otherwise
  *
  *  Reads the VS1 register to determine if link is up and the current speed for
  *  the PHY.
  **/
 int32_t ixgbe_check_phy_link_tnx(struct ixgbe_hw *hw, ixgbe_link_speed *speed,
-				 bool *link_up)
+			     bool *link_up)
 {
 	int32_t status = IXGBE_SUCCESS;
 	uint32_t time_out;
@@ -1149,7 +1114,7 @@ int32_t ixgbe_setup_phy_link_tnx(struct 
  *  @firmware_version: pointer to the PHY Firmware Version
  **/
 int32_t ixgbe_get_phy_firmware_version_tnx(struct ixgbe_hw *hw,
-					   uint16_t *firmware_version)
+				       uint16_t *firmware_version)
 {
 	int32_t status;
 
@@ -1168,7 +1133,7 @@ int32_t ixgbe_get_phy_firmware_version_t
  *  @firmware_version: pointer to the PHY Firmware Version
  **/
 int32_t ixgbe_get_phy_firmware_version_generic(struct ixgbe_hw *hw,
-					       uint16_t *firmware_version)
+					   uint16_t *firmware_version)
 {
 	int32_t status;
 
@@ -1297,26 +1262,6 @@ err_eeprom:
 	return IXGBE_ERR_PHY;
 }
 
-bool
-ixgbe_is_sfp(struct ixgbe_hw *hw)
-{
-	switch (hw->phy.type) {
-	case ixgbe_phy_sfp_avago:
-	case ixgbe_phy_sfp_ftl:
-	case ixgbe_phy_sfp_intel:
-	case ixgbe_phy_sfp_unknown:
-	case ixgbe_phy_sfp_passive_tyco:
-	case ixgbe_phy_sfp_passive_unknown:
-	case ixgbe_phy_qsfp_passive_unknown:
-	case ixgbe_phy_qsfp_active_unknown:
-	case ixgbe_phy_qsfp_intel:
-	case ixgbe_phy_qsfp_unknown:
-		return TRUE;
-	default:
-		return FALSE;
-	}
-}
-
 /**
  *  ixgbe_identify_module_generic - Identifies module type
  *  @hw: pointer to hardware structure
@@ -1364,6 +1309,7 @@ int32_t ixgbe_identify_sfp_module_generi
 	uint8_t oui_bytes[3] = {0, 0, 0};
 	uint8_t cable_tech = 0;
 	uint8_t cable_spec = 0;
+	uint16_t enforce_sfp = 0;
 
 	DEBUGFUNC("ixgbe_identify_sfp_module_generic");
 
@@ -1430,8 +1376,6 @@ int32_t ixgbe_identify_sfp_module_generi
 				hw->phy.sfp_type = ixgbe_sfp_type_sr;
 			else if (comp_codes_10g & IXGBE_SFF_10GBASELR_CAPABLE)
 				hw->phy.sfp_type = ixgbe_sfp_type_lr;
-			else if (comp_codes_10g & IXGBE_SFF_DA_BAD_HP_CABLE)
-				hw->phy.sfp_type = ixgbe_sfp_type_da_cu;
 			else
 				hw->phy.sfp_type = ixgbe_sfp_type_unknown;
 		} else {
@@ -1581,11 +1525,37 @@ int32_t ixgbe_identify_sfp_module_generi
 			goto out;
 		}
 
-		/*
-		 * We do not limit the definition of "supported SPF modules"
-		 * to the vendor/make whitelist.
-		 */
-		status = IXGBE_SUCCESS;
+		/* Anything else 82598-based is supported */
+		if (hw->mac.type == ixgbe_mac_82598EB) {
+			status = IXGBE_SUCCESS;
+			goto out;
+		}
+
+		ixgbe_get_device_caps(hw, &enforce_sfp);
+		if (!(enforce_sfp & IXGBE_DEVICE_CAPS_ALLOW_ANY_SFP) &&
+		    !(hw->phy.sfp_type == ixgbe_sfp_type_1g_cu_core0 ||
+		      hw->phy.sfp_type == ixgbe_sfp_type_1g_cu_core1 ||
+		      hw->phy.sfp_type == ixgbe_sfp_type_1g_lx_core0 ||
+		      hw->phy.sfp_type == ixgbe_sfp_type_1g_lx_core1 ||
+		      hw->phy.sfp_type == ixgbe_sfp_type_1g_sx_core0 ||
+		      hw->phy.sfp_type == ixgbe_sfp_type_1g_sx_core1)) {
+			/* Make sure we're a supported PHY type */
+			if (hw->phy.type == ixgbe_phy_sfp_intel) {
+				status = IXGBE_SUCCESS;
+			} else {
+				if (hw->allow_unsupported_sfp == TRUE) {
+					printf("WARNING: Intel (R) Network Connections are quality tested using Intel (R) Ethernet Optics. Using untested modules is not supported and may cause unstable operation or damage to the module or the adapter. Intel Corporation is not responsible for any harm caused by using untested modules.\n");
+					status = IXGBE_SUCCESS;
+				} else {
+					DEBUGOUT("SFP+ module not supported\n");
+					hw->phy.type =
+						ixgbe_phy_sfp_unsupported;
+					status = IXGBE_ERR_SFP_NOT_SUPPORTED;
+				}
+			}
+		} else {
+			status = IXGBE_SUCCESS;
+		}
 	}
 
 out:
@@ -1606,9 +1576,9 @@ err_read_i2c_eeprom:
  *
  *  Determines physical layer capabilities of the current SFP.
  */
-int32_t ixgbe_get_supported_phy_sfp_layer_generic(struct ixgbe_hw *hw)
+uint64_t ixgbe_get_supported_phy_sfp_layer_generic(struct ixgbe_hw *hw)
 {
-	uint32_t physical_layer = IXGBE_PHYSICAL_LAYER_UNKNOWN;
+	uint64_t physical_layer = IXGBE_PHYSICAL_LAYER_UNKNOWN;
 	uint8_t comp_codes_10g = 0;
 	uint8_t comp_codes_1g = 0;
 
@@ -1641,17 +1611,10 @@ int32_t ixgbe_get_supported_phy_sfp_laye
 			physical_layer = IXGBE_PHYSICAL_LAYER_10GBASE_SR;
 		else if (comp_codes_10g & IXGBE_SFF_10GBASELR_CAPABLE)
 			physical_layer = IXGBE_PHYSICAL_LAYER_10GBASE_LR;
-		else if (comp_codes_10g &
-		    (IXGBE_SFF_DA_PASSIVE_CABLE | IXGBE_SFF_DA_BAD_HP_CABLE))
-			physical_layer = IXGBE_PHYSICAL_LAYER_SFP_PLUS_CU;
-		else if (comp_codes_10g & IXGBE_SFF_DA_ACTIVE_CABLE)
-			physical_layer = IXGBE_PHYSICAL_LAYER_SFP_ACTIVE_DA;
 		else if (comp_codes_1g & IXGBE_SFF_1GBASET_CAPABLE)
 			physical_layer = IXGBE_PHYSICAL_LAYER_1000BASE_T;
 		else if (comp_codes_1g & IXGBE_SFF_1GBASESX_CAPABLE)
 			physical_layer = IXGBE_PHYSICAL_LAYER_1000BASE_SX;
-		else if (comp_codes_1g & IXGBE_SFF_1GBASELX_CAPABLE)
-			physical_layer = IXGBE_PHYSICAL_LAYER_1000BASE_LX;
 		break;
 	case ixgbe_phy_qsfp_intel:
 	case ixgbe_phy_qsfp_unknown:
@@ -1684,6 +1647,7 @@ int32_t ixgbe_identify_qsfp_module_gener
 	uint8_t comp_codes_1g = 0;
 	uint8_t comp_codes_10g = 0;
 	uint8_t oui_bytes[3] = {0, 0, 0};
+	uint16_t enforce_sfp = 0;
 	uint8_t connector = 0;
 	uint8_t cable_length = 0;
 	uint8_t device_tech = 0;
@@ -1826,11 +1790,25 @@ int32_t ixgbe_identify_qsfp_module_gener
 		else
 			hw->phy.type = ixgbe_phy_qsfp_unknown;
 
-		/*
-		 * We do not limit the definition of "supported SPF modules"
-		 * to the vendor/make whitelist.
-		 */
-		status = IXGBE_SUCCESS;
+		ixgbe_get_device_caps(hw, &enforce_sfp);
+		if (!(enforce_sfp & IXGBE_DEVICE_CAPS_ALLOW_ANY_SFP)) {
+			/* Make sure we're a supported PHY type */
+			if (hw->phy.type == ixgbe_phy_qsfp_intel) {
+				status = IXGBE_SUCCESS;
+			} else {
+				if (hw->allow_unsupported_sfp == TRUE) {
+					printf("WARNING: Intel (R) Network Connections are quality tested using Intel (R) Ethernet Optics. Using untested modules is not supported and may cause unstable operation or damage to the module or the adapter. Intel Corporation is not responsible for any harm caused by using untested modules.\n");
+					status = IXGBE_SUCCESS;
+				} else {
+					DEBUGOUT("QSFP module not supported\n");
+					hw->phy.type =
+						ixgbe_phy_sfp_unsupported;
+					status = IXGBE_ERR_SFP_NOT_SUPPORTED;
+				}
+			}
+		} else {
+			status = IXGBE_SUCCESS;
+		}
 	}
 
 out:
@@ -1844,7 +1822,6 @@ err_read_i2c_eeprom:
 	return IXGBE_ERR_SFP_NOT_PRESENT;
 }
 
-
 /**
  *  ixgbe_get_sfp_init_sequence_offsets - Provides offset of PHY init sequence
  *  @hw: pointer to hardware structure
@@ -1855,8 +1832,8 @@ err_read_i2c_eeprom:
  *  so it returns the offsets to the phy init sequence block.
  **/
 int32_t ixgbe_get_sfp_init_sequence_offsets(struct ixgbe_hw *hw,
-					    uint16_t *list_offset,
-					    uint16_t *data_offset)
+					uint16_t *list_offset,
+					uint16_t *data_offset)
 {
 	uint16_t sfp_id;
 	uint16_t sfp_type = hw->phy.sfp_type;
@@ -1927,18 +1904,7 @@ int32_t ixgbe_get_sfp_init_sequence_offs
 		}
 	}
 
-	/*
-	 * the 82598EB SFP+ card offically supports only direct attached cables
-	 * but works fine with optical SFP+ modules as well. Even though the
-	 * EEPROM has no matching ID for them. So just accept the module.
-	 */
-	if (sfp_id == IXGBE_PHY_INIT_END_NL &&
-	    hw->mac.type == ixgbe_mac_82598EB) {
-		/* refetch offset for the first phy entry */
-		hw->eeprom.ops.read(hw, IXGBE_PHY_INIT_OFFSET_NL, list_offset);
-		(*list_offset) += 2;
-		hw->eeprom.ops.read(hw, *list_offset, data_offset);
-	} else if (sfp_id == IXGBE_PHY_INIT_END_NL) {
+	if (sfp_id == IXGBE_PHY_INIT_END_NL) {
 		DEBUGOUT("No matching SFP+ module found\n");
 		return IXGBE_ERR_SFP_NOT_SUPPORTED;
 	}
@@ -1960,7 +1926,7 @@ err_phy:
  *  Performs byte read operation to SFP module's EEPROM over I2C interface.
  **/
 int32_t ixgbe_read_i2c_eeprom_generic(struct ixgbe_hw *hw, uint8_t byte_offset,
-				      uint8_t *eeprom_data)
+				  uint8_t *eeprom_data)
 {
 	DEBUGFUNC("ixgbe_read_i2c_eeprom_generic");
 
@@ -1970,6 +1936,22 @@ int32_t ixgbe_read_i2c_eeprom_generic(st
 }
 
 /**
+ *  ixgbe_read_i2c_sff8472_generic - Reads 8 bit word over I2C interface
+ *  @hw: pointer to hardware structure
+ *  @byte_offset: byte offset at address 0xA2
+ *  @sff8472_data: value read
+ *
+ *  Performs byte read operation to SFP module's SFF-8472 data over I2C
+ **/
+static int32_t ixgbe_read_i2c_sff8472_generic(struct ixgbe_hw *hw, uint8_t byte_offset,
+					  uint8_t *sff8472_data)
+{
+	return hw->phy.ops.read_i2c_byte(hw, byte_offset,
+					 IXGBE_I2C_EEPROM_DEV_ADDR2,
+					 sff8472_data);
+}
+
+/**
  *  ixgbe_write_i2c_eeprom_generic - Writes 8 bit EEPROM word over I2C interface
  *  @hw: pointer to hardware structure
  *  @byte_offset: EEPROM byte offset to write
@@ -1978,7 +1960,7 @@ int32_t ixgbe_read_i2c_eeprom_generic(st
  *  Performs byte write operation to SFP module's EEPROM over I2C interface.
  **/
 int32_t ixgbe_write_i2c_eeprom_generic(struct ixgbe_hw *hw, uint8_t byte_offset,
-				       uint8_t eeprom_data)
+				   uint8_t eeprom_data)
 {
 	DEBUGFUNC("ixgbe_write_i2c_eeprom_generic");
 
@@ -1993,7 +1975,7 @@ int32_t ixgbe_write_i2c_eeprom_generic(s
  * @offset: eeprom offset to be read
  * @addr: I2C address to be read
  */
-bool ixgbe_is_sfp_probe(struct ixgbe_hw *hw, uint8_t offset, uint8_t addr)
+static bool ixgbe_is_sfp_probe(struct ixgbe_hw *hw, uint8_t offset, uint8_t addr)
 {
 	if (addr == IXGBE_I2C_EEPROM_DEV_ADDR &&
 	    offset == IXGBE_SFF_IDENTIFIER &&
@@ -2006,13 +1988,15 @@ bool ixgbe_is_sfp_probe(struct ixgbe_hw 
  *  ixgbe_read_i2c_byte_generic_int - Reads 8 bit word over I2C
  *  @hw: pointer to hardware structure
  *  @byte_offset: byte offset to read
+ *  @dev_addr: address to read from
  *  @data: value read
+ *  @lock: TRUE if to take and release semaphore
  *
  *  Performs byte read operation to SFP module's EEPROM over I2C interface at
  *  a specified device address.
  **/
-int32_t ixgbe_read_i2c_byte_generic_int(struct ixgbe_hw *hw, uint8_t byte_offset,
-					uint8_t dev_addr, uint8_t *data, bool lock)
+static int32_t ixgbe_read_i2c_byte_generic_int(struct ixgbe_hw *hw, uint8_t byte_offset,
+					   uint8_t dev_addr, uint8_t *data, bool lock)
 {
 	int32_t status;
 	uint32_t max_retry = 10;
@@ -2021,7 +2005,7 @@ int32_t ixgbe_read_i2c_byte_generic_int(
 	bool nack = 1;
 	*data = 0;
 
-	DEBUGFUNC("ixgbe_read_i2c_byte_generic_int");
+	DEBUGFUNC("ixgbe_read_i2c_byte_generic");
 
 	if (hw->mac.type >= ixgbe_mac_X550)
 		max_retry = 3;
@@ -2096,13 +2080,14 @@ fail:
  *  ixgbe_read_i2c_byte_generic - Reads 8 bit word over I2C
  *  @hw: pointer to hardware structure
  *  @byte_offset: byte offset to read
+ *  @dev_addr: address to read from
  *  @data: value read
  *
  *  Performs byte read operation to SFP module's EEPROM over I2C interface at
  *  a specified device address.
  **/
 int32_t ixgbe_read_i2c_byte_generic(struct ixgbe_hw *hw, uint8_t byte_offset,
-				    uint8_t dev_addr, uint8_t *data)
+				uint8_t dev_addr, uint8_t *data)
 {
 	return ixgbe_read_i2c_byte_generic_int(hw, byte_offset, dev_addr,
 					       data, TRUE);
@@ -2112,13 +2097,14 @@ int32_t ixgbe_read_i2c_byte_generic(stru
  *  ixgbe_read_i2c_byte_generic_unlocked - Reads 8 bit word over I2C
  *  @hw: pointer to hardware structure
  *  @byte_offset: byte offset to read
+ *  @dev_addr: address to read from
  *  @data: value read
  *
  *  Performs byte read operation to SFP module's EEPROM over I2C interface at
  *  a specified device address.
  **/
 int32_t ixgbe_read_i2c_byte_generic_unlocked(struct ixgbe_hw *hw, uint8_t byte_offset,
-					     uint8_t dev_addr, uint8_t *data)
+					 uint8_t dev_addr, uint8_t *data)
 {
 	return ixgbe_read_i2c_byte_generic_int(hw, byte_offset, dev_addr,
 					       data, FALSE);
@@ -2128,21 +2114,22 @@ int32_t ixgbe_read_i2c_byte_generic_unlo
  *  ixgbe_write_i2c_byte_generic_int - Writes 8 bit word over I2C
  *  @hw: pointer to hardware structure
  *  @byte_offset: byte offset to write
+ *  @dev_addr: address to write to
  *  @data: value to write
  *  @lock: TRUE if to take and release semaphore
  *
  *  Performs byte write operation to SFP module's EEPROM over I2C interface at
  *  a specified device address.
  **/
-int32_t ixgbe_write_i2c_byte_generic_int(struct ixgbe_hw *hw, uint8_t byte_offset,
-					 uint8_t dev_addr, uint8_t data, bool lock)
+static int32_t ixgbe_write_i2c_byte_generic_int(struct ixgbe_hw *hw, uint8_t byte_offset,
+					    uint8_t dev_addr, uint8_t data, bool lock)
 {
 	int32_t status;
 	uint32_t max_retry = 1;
 	uint32_t retry = 0;
 	uint32_t swfw_mask = hw->phy.phy_semaphore_mask;
 
-	DEBUGFUNC("ixgbe_write_i2c_byte_generic_int");
+	DEBUGFUNC("ixgbe_write_i2c_byte_generic");
 
 	if (lock && hw->mac.ops.acquire_swfw_sync(hw, swfw_mask) !=
 	    IXGBE_SUCCESS)
@@ -2199,13 +2186,14 @@ fail:
  *  ixgbe_write_i2c_byte_generic - Writes 8 bit word over I2C
  *  @hw: pointer to hardware structure
  *  @byte_offset: byte offset to write
+ *  @dev_addr: address to write to
  *  @data: value to write
  *
  *  Performs byte write operation to SFP module's EEPROM over I2C interface at
  *  a specified device address.
  **/
 int32_t ixgbe_write_i2c_byte_generic(struct ixgbe_hw *hw, uint8_t byte_offset,
-				     uint8_t dev_addr, uint8_t data)
+				 uint8_t dev_addr, uint8_t data)
 {
 	return ixgbe_write_i2c_byte_generic_int(hw, byte_offset, dev_addr,
 						data, TRUE);
@@ -2215,13 +2203,14 @@ int32_t ixgbe_write_i2c_byte_generic(str
  *  ixgbe_write_i2c_byte_generic_unlocked - Writes 8 bit word over I2C
  *  @hw: pointer to hardware structure
  *  @byte_offset: byte offset to write
+ *  @dev_addr: address to write to
  *  @data: value to write
  *
  *  Performs byte write operation to SFP module's EEPROM over I2C interface at
  *  a specified device address.
  **/
 int32_t ixgbe_write_i2c_byte_generic_unlocked(struct ixgbe_hw *hw, uint8_t byte_offset,
-					      uint8_t dev_addr, uint8_t data)
+					  uint8_t dev_addr, uint8_t data)
 {
 	return ixgbe_write_i2c_byte_generic_int(hw, byte_offset, dev_addr,
 						data, FALSE);
@@ -2234,18 +2223,13 @@ int32_t ixgbe_write_i2c_byte_generic_unl
  *  Sets I2C start condition (High -> Low on SDA while SCL is High)
  *  Set bit-bang mode on X550 hardware.
  **/
-void ixgbe_i2c_start(struct ixgbe_hw *hw)
+static void ixgbe_i2c_start(struct ixgbe_hw *hw)
 {
-	uint32_t i2cctl;
+	uint32_t i2cctl = IXGBE_READ_REG(hw, IXGBE_I2CCTL_BY_MAC(hw));
 
 	DEBUGFUNC("ixgbe_i2c_start");
 
-	if (hw->mac.type == ixgbe_mac_X550 ||
-	    hw->mac.type == ixgbe_mac_X550EM_x) {
-		i2cctl = IXGBE_READ_REG(hw, IXGBE_I2CCTL_X550);
-		i2cctl |= IXGBE_I2C_BB_EN_X550;
-	} else
-		i2cctl = IXGBE_READ_REG(hw, IXGBE_I2CCTL);
+	i2cctl |= IXGBE_I2C_BB_EN_BY_MAC(hw);
 
 	/* Start condition must begin with data and clock high */
 	ixgbe_set_i2c_data(hw, &i2cctl, 1);
@@ -2274,18 +2258,15 @@ void ixgbe_i2c_start(struct ixgbe_hw *hw
  *  Disables bit-bang mode and negates data output enable on X550
  *  hardware.
  **/
-void ixgbe_i2c_stop(struct ixgbe_hw *hw)
+static void ixgbe_i2c_stop(struct ixgbe_hw *hw)
 {
-	uint32_t i2cctl;
+	uint32_t i2cctl = IXGBE_READ_REG(hw, IXGBE_I2CCTL_BY_MAC(hw));
+	uint32_t data_oe_bit = IXGBE_I2C_DATA_OE_N_EN_BY_MAC(hw);
+	uint32_t clk_oe_bit = IXGBE_I2C_CLK_OE_N_EN_BY_MAC(hw);
+	uint32_t bb_en_bit = IXGBE_I2C_BB_EN_BY_MAC(hw);
 
 	DEBUGFUNC("ixgbe_i2c_stop");
 
-	if (hw->mac.type == ixgbe_mac_X550 ||
-	    hw->mac.type == ixgbe_mac_X550EM_x)
-		i2cctl = IXGBE_READ_REG(hw, IXGBE_I2CCTL_X550);
-	else
-		i2cctl = IXGBE_READ_REG(hw, IXGBE_I2CCTL);
-
 	/* Stop condition must begin with data low and clock high */
 	ixgbe_set_i2c_data(hw, &i2cctl, 0);
 	ixgbe_raise_i2c_clk(hw, &i2cctl);
@@ -2298,12 +2279,10 @@ void ixgbe_i2c_stop(struct ixgbe_hw *hw)
 	/* bus free time between stop and start (4.7us)*/
 	usec_delay(IXGBE_I2C_T_BUF);
 
-	if (hw->mac.type == ixgbe_mac_X550 ||
-	    hw->mac.type == ixgbe_mac_X550EM_x) {
-		i2cctl &= ~IXGBE_I2C_BB_EN_X550;
-		i2cctl |= IXGBE_I2C_DATA_OE_N_EN_X550 |
-		    IXGBE_I2C_CLK_OE_N_EN_X550;
-		IXGBE_WRITE_REG(hw, IXGBE_I2CCTL_X550, i2cctl);
+	if (bb_en_bit || data_oe_bit || clk_oe_bit) {
+		i2cctl &= ~bb_en_bit;
+		i2cctl |= data_oe_bit | clk_oe_bit;
+		IXGBE_WRITE_REG(hw, IXGBE_I2CCTL_BY_MAC(hw), i2cctl);
 		IXGBE_WRITE_FLUSH(hw);
 	}
 }
@@ -2315,7 +2294,7 @@ void ixgbe_i2c_stop(struct ixgbe_hw *hw)
  *
  *  Clocks in one byte data via I2C data/clock
  **/
-int32_t ixgbe_clock_in_i2c_byte(struct ixgbe_hw *hw, uint8_t *data)
+static int32_t ixgbe_clock_in_i2c_byte(struct ixgbe_hw *hw, uint8_t *data)
 {
 	int32_t i;
 	bool bit = 0;
@@ -2338,7 +2317,7 @@ int32_t ixgbe_clock_in_i2c_byte(struct i
  *
  *  Clocks out one byte data via I2C data/clock
  **/
-int32_t ixgbe_clock_out_i2c_byte(struct ixgbe_hw *hw, uint8_t data)
+static int32_t ixgbe_clock_out_i2c_byte(struct ixgbe_hw *hw, uint8_t data)
 {
 	int32_t status = IXGBE_SUCCESS;
 	int32_t i;
@@ -2356,16 +2335,10 @@ int32_t ixgbe_clock_out_i2c_byte(struct 
 	}
 
 	/* Release SDA line (set high) */
-	if (hw->mac.type == ixgbe_mac_X550 ||
-	    hw->mac.type == ixgbe_mac_X550EM_x) {
-		i2cctl = IXGBE_READ_REG(hw, IXGBE_I2CCTL_X550);
-		i2cctl |= IXGBE_I2C_DATA_OUT_X550 | IXGBE_I2C_DATA_OE_N_EN_X550;
-		IXGBE_WRITE_REG(hw, IXGBE_I2CCTL_X550, i2cctl);
-	} else {
-		i2cctl = IXGBE_READ_REG(hw, IXGBE_I2CCTL);
-		i2cctl |= IXGBE_I2C_DATA_OUT;
-		IXGBE_WRITE_REG(hw, IXGBE_I2CCTL, i2cctl);
-	}
+	i2cctl = IXGBE_READ_REG(hw, IXGBE_I2CCTL_BY_MAC(hw));
+	i2cctl |= IXGBE_I2C_DATA_OUT_BY_MAC(hw);
+	i2cctl |= IXGBE_I2C_DATA_OE_N_EN_BY_MAC(hw);
+	IXGBE_WRITE_REG(hw, IXGBE_I2CCTL_BY_MAC(hw), i2cctl);
 	IXGBE_WRITE_FLUSH(hw);
 
 	return status;
@@ -2377,26 +2350,22 @@ int32_t ixgbe_clock_out_i2c_byte(struct 
  *
  *  Clocks in/out one bit via I2C data/clock
  **/
-int32_t ixgbe_get_i2c_ack(struct ixgbe_hw *hw)
+static int32_t ixgbe_get_i2c_ack(struct ixgbe_hw *hw)
 {
+	uint32_t data_oe_bit = IXGBE_I2C_DATA_OE_N_EN_BY_MAC(hw);
 	int32_t status = IXGBE_SUCCESS;
 	uint32_t i = 0;
-	uint32_t i2cctl, i2cctl_reg;
+	uint32_t i2cctl = IXGBE_READ_REG(hw, IXGBE_I2CCTL_BY_MAC(hw));
 	uint32_t timeout = 10;
 	bool ack = 1;
 
 	DEBUGFUNC("ixgbe_get_i2c_ack");
 
-	if (hw->mac.type == ixgbe_mac_X550 ||
-	    hw->mac.type == ixgbe_mac_X550EM_x) {
-		i2cctl_reg = IXGBE_I2CCTL_X550;
-		i2cctl = IXGBE_READ_REG(hw, i2cctl_reg);
-		i2cctl |= IXGBE_I2C_DATA_OUT_X550 | IXGBE_I2C_DATA_OE_N_EN_X550;
-		IXGBE_WRITE_REG(hw, i2cctl_reg, i2cctl);
+	if (data_oe_bit) {
+		i2cctl |= IXGBE_I2C_DATA_OUT_BY_MAC(hw);
+		i2cctl |= data_oe_bit;
+		IXGBE_WRITE_REG(hw, IXGBE_I2CCTL_BY_MAC(hw), i2cctl);
 		IXGBE_WRITE_FLUSH(hw);
-	} else {
-		i2cctl_reg = IXGBE_I2CCTL;
-		i2cctl = IXGBE_READ_REG(hw, i2cctl_reg);
 	}
 	ixgbe_raise_i2c_clk(hw, &i2cctl);
 
@@ -2406,7 +2375,7 @@ int32_t ixgbe_get_i2c_ack(struct ixgbe_h
 	/* Poll for ACK.  Note that ACK in I2C spec is
 	 * transition from 1 to 0 */
 	for (i = 0; i < timeout; i++) {
-		i2cctl = IXGBE_READ_REG(hw, i2cctl_reg);
+		i2cctl = IXGBE_READ_REG(hw, IXGBE_I2CCTL_BY_MAC(hw));
 		ack = ixgbe_get_i2c_data(hw, &i2cctl);
 
 		usec_delay(1);
@@ -2434,30 +2403,25 @@ int32_t ixgbe_get_i2c_ack(struct ixgbe_h
  *
  *  Clocks in one bit via I2C data/clock
  **/
-int32_t ixgbe_clock_in_i2c_bit(struct ixgbe_hw *hw, bool *data)
+static int32_t ixgbe_clock_in_i2c_bit(struct ixgbe_hw *hw, bool *data)
 {
-	uint32_t i2cctl, i2cctl_reg;
+	uint32_t i2cctl = IXGBE_READ_REG(hw, IXGBE_I2CCTL_BY_MAC(hw));
+	uint32_t data_oe_bit = IXGBE_I2C_DATA_OE_N_EN_BY_MAC(hw);
 
 	DEBUGFUNC("ixgbe_clock_in_i2c_bit");
 
-	if (hw->mac.type == ixgbe_mac_X550 ||
-	    hw->mac.type == ixgbe_mac_X550EM_x) {
-		i2cctl_reg = IXGBE_I2CCTL_X550;
-		i2cctl = IXGBE_READ_REG(hw, i2cctl_reg);
-		i2cctl |= IXGBE_I2C_DATA_OUT_X550 | IXGBE_I2C_DATA_OE_N_EN_X550;
-		IXGBE_WRITE_REG(hw, i2cctl_reg, i2cctl);
+	if (data_oe_bit) {
+		i2cctl |= IXGBE_I2C_DATA_OUT_BY_MAC(hw);
+		i2cctl |= data_oe_bit;
+		IXGBE_WRITE_REG(hw, IXGBE_I2CCTL_BY_MAC(hw), i2cctl);
 		IXGBE_WRITE_FLUSH(hw);
-	} else {
-		i2cctl_reg = IXGBE_I2CCTL;
-		i2cctl = IXGBE_READ_REG(hw, i2cctl_reg);
 	}
-
 	ixgbe_raise_i2c_clk(hw, &i2cctl);
 
 	/* Minimum high period of clock is 4us */
 	usec_delay(IXGBE_I2C_T_HIGH);
 
-	i2cctl = IXGBE_READ_REG(hw, i2cctl_reg);
+	i2cctl = IXGBE_READ_REG(hw, IXGBE_I2CCTL_BY_MAC(hw));
 	*data = ixgbe_get_i2c_data(hw, &i2cctl);
 
 	ixgbe_lower_i2c_clk(hw, &i2cctl);
@@ -2475,19 +2439,13 @@ int32_t ixgbe_clock_in_i2c_bit(struct ix
  *
  *  Clocks out one bit via I2C data/clock
  **/
-int32_t ixgbe_clock_out_i2c_bit(struct ixgbe_hw *hw, bool data)
+static int32_t ixgbe_clock_out_i2c_bit(struct ixgbe_hw *hw, bool data)
 {
 	int32_t status;
-	uint32_t i2cctl;
+	uint32_t i2cctl = IXGBE_READ_REG(hw, IXGBE_I2CCTL_BY_MAC(hw));
 
 	DEBUGFUNC("ixgbe_clock_out_i2c_bit");
 
-	if (hw->mac.type == ixgbe_mac_X550 ||
-	    hw->mac.type == ixgbe_mac_X550EM_x)
-		i2cctl = IXGBE_READ_REG(hw, IXGBE_I2CCTL_X550);
-	else
-		i2cctl = IXGBE_READ_REG(hw, IXGBE_I2CCTL);
-
 	status = ixgbe_set_i2c_data(hw, &i2cctl, data);
 	if (status == IXGBE_SUCCESS) {
 		ixgbe_raise_i2c_clk(hw, &i2cctl);
@@ -2518,32 +2476,30 @@ int32_t ixgbe_clock_out_i2c_bit(struct i
  *  Raises the I2C clock line '0'->'1'
  *  Negates the I2C clock output enable on X550 hardware.
  **/
-void ixgbe_raise_i2c_clk(struct ixgbe_hw *hw, uint32_t *i2cctl)
+static void ixgbe_raise_i2c_clk(struct ixgbe_hw *hw, uint32_t *i2cctl)
 {
-	uint32_t i2cctl_clk_in, i2cctl_reg;
+	uint32_t clk_oe_bit = IXGBE_I2C_CLK_OE_N_EN_BY_MAC(hw);
 	uint32_t i = 0;
 	uint32_t timeout = IXGBE_I2C_CLOCK_STRETCHING_TIMEOUT;
+	uint32_t i2cctl_r = 0;
 
-	if (hw->mac.type == ixgbe_mac_X550 ||
-	    hw->mac.type == ixgbe_mac_X550EM_x) {
-		i2cctl_reg = IXGBE_I2CCTL_X550;
-		*i2cctl |= IXGBE_I2C_CLK_OE_N_EN_X550;
-		IXGBE_WRITE_REG(hw, i2cctl_reg, *i2cctl);
-		*i2cctl |= IXGBE_I2C_CLK_OUT_X550;
-		i2cctl_clk_in = IXGBE_I2C_CLK_IN_X550;
-	} else {
-		i2cctl_reg = IXGBE_I2CCTL;
-		*i2cctl |= IXGBE_I2C_CLK_OUT;
-		i2cctl_clk_in = IXGBE_I2C_CLK_IN;
+	DEBUGFUNC("ixgbe_raise_i2c_clk");
+
+	if (clk_oe_bit) {
+		*i2cctl |= clk_oe_bit;
+		IXGBE_WRITE_REG(hw, IXGBE_I2CCTL_BY_MAC(hw), *i2cctl);
 	}
 
 	for (i = 0; i < timeout; i++) {
-		IXGBE_WRITE_REG(hw, i2cctl_reg, *i2cctl);
+		*i2cctl |= IXGBE_I2C_CLK_OUT_BY_MAC(hw);
+
+		IXGBE_WRITE_REG(hw, IXGBE_I2CCTL_BY_MAC(hw), *i2cctl);
 		IXGBE_WRITE_FLUSH(hw);
 		/* SCL rise time (1000ns) */
 		usec_delay(IXGBE_I2C_T_RISE);
 
-		if (IXGBE_READ_REG(hw, i2cctl_reg) & i2cctl_clk_in)
+		i2cctl_r = IXGBE_READ_REG(hw, IXGBE_I2CCTL_BY_MAC(hw));
+		if (i2cctl_r & IXGBE_I2C_CLK_IN_BY_MAC(hw))
 			break;
 	}
 }
@@ -2556,19 +2512,14 @@ void ixgbe_raise_i2c_clk(struct ixgbe_hw
  *  Lowers the I2C clock line '1'->'0'
  *  Asserts the I2C clock output enable on X550 hardware.
  **/
-void ixgbe_lower_i2c_clk(struct ixgbe_hw *hw, uint32_t *i2cctl)
+static void ixgbe_lower_i2c_clk(struct ixgbe_hw *hw, uint32_t *i2cctl)
 {
 	DEBUGFUNC("ixgbe_lower_i2c_clk");
 
-	if (hw->mac.type == ixgbe_mac_X550 ||
-	    hw->mac.type == ixgbe_mac_X550EM_x) {
-		*i2cctl &= ~(IXGBE_I2C_CLK_OUT_X550 |
-		    IXGBE_I2C_CLK_OE_N_EN_X550);
-		IXGBE_WRITE_REG(hw, IXGBE_I2CCTL_X550, *i2cctl);
-	} else {
-		*i2cctl &= ~IXGBE_I2C_CLK_OUT;
-		IXGBE_WRITE_REG(hw, IXGBE_I2CCTL, *i2cctl);
-	}
+	*i2cctl &= ~(IXGBE_I2C_CLK_OUT_BY_MAC(hw));
+	*i2cctl &= ~IXGBE_I2C_CLK_OE_N_EN_BY_MAC(hw);
+
+	IXGBE_WRITE_REG(hw, IXGBE_I2CCTL_BY_MAC(hw), *i2cctl);
 	IXGBE_WRITE_FLUSH(hw);
 
 	/* SCL fall time (300ns) */
@@ -2584,30 +2535,20 @@ void ixgbe_lower_i2c_clk(struct ixgbe_hw
  *  Sets the I2C data bit
  *  Asserts the I2C data output enable on X550 hardware.
  **/
-int32_t ixgbe_set_i2c_data(struct ixgbe_hw *hw, uint32_t *i2cctl, bool data)
+static int32_t ixgbe_set_i2c_data(struct ixgbe_hw *hw, uint32_t *i2cctl, bool data)
 {
-	uint32_t i2cctl_reg;
+	uint32_t data_oe_bit = IXGBE_I2C_DATA_OE_N_EN_BY_MAC(hw);
 	int32_t status = IXGBE_SUCCESS;
 
 	DEBUGFUNC("ixgbe_set_i2c_data");
 
-	if (hw->mac.type == ixgbe_mac_X550 ||
-	    hw->mac.type == ixgbe_mac_X550EM_x) {
-		i2cctl_reg = IXGBE_I2CCTL_X550;
-		if (data)
-			*i2cctl |= IXGBE_I2C_DATA_OUT_X550;
-		else
-			*i2cctl &= ~IXGBE_I2C_DATA_OUT_X550;
-		*i2cctl &= ~IXGBE_I2C_DATA_OE_N_EN_X550;
-	} else {
-		i2cctl_reg = IXGBE_I2CCTL;
-		if (data)
-			*i2cctl |= IXGBE_I2C_DATA_OUT;
-		else
-			*i2cctl &= ~IXGBE_I2C_DATA_OUT;
-	}
+	if (data)
+		*i2cctl |= IXGBE_I2C_DATA_OUT_BY_MAC(hw);
+	else
+		*i2cctl &= ~(IXGBE_I2C_DATA_OUT_BY_MAC(hw));
+	*i2cctl &= ~data_oe_bit;
 
-	IXGBE_WRITE_REG(hw, i2cctl_reg, *i2cctl);
+	IXGBE_WRITE_REG(hw, IXGBE_I2CCTL_BY_MAC(hw), *i2cctl);
 	IXGBE_WRITE_FLUSH(hw);
 
 	/* Data rise/fall (1000ns/300ns) and set-up time (250ns) */
@@ -2615,15 +2556,14 @@ int32_t ixgbe_set_i2c_data(struct ixgbe_
 
 	if (!data)	/* Can't verify data in this case */
 		return IXGBE_SUCCESS;
-	if (hw->mac.type == ixgbe_mac_X550 ||
-	    hw->mac.type == ixgbe_mac_X550EM_x) {
-		*i2cctl |= IXGBE_I2C_DATA_OE_N_EN_X550;
-		IXGBE_WRITE_REG(hw, i2cctl_reg, *i2cctl);
+	if (data_oe_bit) {
+		*i2cctl |= data_oe_bit;
+		IXGBE_WRITE_REG(hw, IXGBE_I2CCTL_BY_MAC(hw), *i2cctl);
 		IXGBE_WRITE_FLUSH(hw);
 	}
 
 	/* Verify data was set correctly */
-	*i2cctl = IXGBE_READ_REG(hw, i2cctl_reg);
+	*i2cctl = IXGBE_READ_REG(hw, IXGBE_I2CCTL_BY_MAC(hw));
 	if (data != ixgbe_get_i2c_data(hw, i2cctl)) {
 		status = IXGBE_ERR_I2C;
 		ERROR_REPORT2(IXGBE_ERROR_INVALID_STATE,
@@ -2642,24 +2582,21 @@ int32_t ixgbe_set_i2c_data(struct ixgbe_
  *  Returns the I2C data bit value
  *  Negates the I2C data output enable on X550 hardware.
  **/
-bool ixgbe_get_i2c_data(struct ixgbe_hw *hw, uint32_t *i2cctl)
+static bool ixgbe_get_i2c_data(UNUSED struct ixgbe_hw *hw, uint32_t *i2cctl)
 {
-	uint32_t i2cctl_data_in;
 	bool data;
+	uint32_t data_oe_bit = IXGBE_I2C_DATA_OE_N_EN_BY_MAC(hw);
 
 	DEBUGFUNC("ixgbe_get_i2c_data");
 
-	if (hw->mac.type == ixgbe_mac_X550 ||
-	    hw->mac.type == ixgbe_mac_X550EM_x) {
-		i2cctl_data_in = IXGBE_I2C_DATA_IN_X550;
-		*i2cctl |= IXGBE_I2C_DATA_OE_N_EN_X550;
-		IXGBE_WRITE_REG(hw, IXGBE_I2CCTL_X550, *i2cctl);
+	if (data_oe_bit) {
+		*i2cctl |= data_oe_bit;
+		IXGBE_WRITE_REG(hw, IXGBE_I2CCTL_BY_MAC(hw), *i2cctl);
 		IXGBE_WRITE_FLUSH(hw);
 		usec_delay(IXGBE_I2C_T_FALL);
-	} else
-		i2cctl_data_in = IXGBE_I2C_DATA_IN;
+	}
 
-	if (*i2cctl & i2cctl_data_in)
+	if (*i2cctl & IXGBE_I2C_DATA_IN_BY_MAC(hw))
 		data = 1;
 	else
 		data = 0;
@@ -2682,12 +2619,7 @@ void ixgbe_i2c_bus_clear(struct ixgbe_hw
 	DEBUGFUNC("ixgbe_i2c_bus_clear");
 
 	ixgbe_i2c_start(hw);
-
-	if (hw->mac.type == ixgbe_mac_X550 ||
-	    hw->mac.type == ixgbe_mac_X550EM_x)
-		i2cctl = IXGBE_READ_REG(hw, IXGBE_I2CCTL_X550);
-	else
-		i2cctl = IXGBE_READ_REG(hw, IXGBE_I2CCTL);
+	i2cctl = IXGBE_READ_REG(hw, IXGBE_I2CCTL_BY_MAC(hw));
 
 	ixgbe_set_i2c_data(hw, &i2cctl, 1);
 
Index: ./dev/pci/ixgbe_phy.h
===================================================================
RCS file: ./dev/pci/ixgbe_phy.h
diff -N ./dev/pci/ixgbe_phy.h
--- /dev/null	1 Jan 1970 00:00:00 -0000
+++ ./dev/pci/ixgbe_phy.h	17 Sep 2018 19:59:56 -0000
@@ -0,0 +1,220 @@
+/******************************************************************************
+  SPDX-License-Identifier: BSD-3-Clause
+
+  Copyright (c) 2001-2017, Intel Corporation
+  All rights reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions are met:
+
+   1. Redistributions of source code must retain the above copyright notice,
+      this list of conditions and the following disclaimer.
+
+   2. Redistributions in binary form must reproduce the above copyright
+      notice, this list of conditions and the following disclaimer in the
+      documentation and/or other materials provided with the distribution.
+
+   3. Neither the name of the Intel Corporation nor the names of its
+      contributors may be used to endorse or promote products derived from
+      this software without specific prior written permission.
+
+  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
+  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+  POSSIBILITY OF SUCH DAMAGE.
+
+******************************************************************************/
+/*$FreeBSD$*/
+
+#ifndef _IXGBE_PHY_H_
+#define _IXGBE_PHY_H_
+
+#include "ixgbe_type.h"
+#define IXGBE_I2C_EEPROM_DEV_ADDR	0xA0
+#define IXGBE_I2C_EEPROM_DEV_ADDR2	0xA2
+#define IXGBE_I2C_EEPROM_BANK_LEN	0xFF
+
+/* EEPROM byte offsets */
+#define IXGBE_SFF_IDENTIFIER		0x0
+#define IXGBE_SFF_IDENTIFIER_SFP	0x3
+#define IXGBE_SFF_VENDOR_OUI_BYTE0	0x25
+#define IXGBE_SFF_VENDOR_OUI_BYTE1	0x26
+#define IXGBE_SFF_VENDOR_OUI_BYTE2	0x27
+#define IXGBE_SFF_1GBE_COMP_CODES	0x6
+#define IXGBE_SFF_10GBE_COMP_CODES	0x3
+#define IXGBE_SFF_CABLE_TECHNOLOGY	0x8
+#define IXGBE_SFF_CABLE_SPEC_COMP	0x3C
+#define IXGBE_SFF_SFF_8472_SWAP		0x5C
+#define IXGBE_SFF_SFF_8472_COMP		0x5E
+#define IXGBE_SFF_SFF_8472_OSCB		0x6E
+#define IXGBE_SFF_SFF_8472_ESCB		0x76
+#define IXGBE_SFF_IDENTIFIER_QSFP_PLUS	0xD
+#define IXGBE_SFF_QSFP_VENDOR_OUI_BYTE0	0xA5
+#define IXGBE_SFF_QSFP_VENDOR_OUI_BYTE1	0xA6
+#define IXGBE_SFF_QSFP_VENDOR_OUI_BYTE2	0xA7
+#define IXGBE_SFF_QSFP_CONNECTOR	0x82
+#define IXGBE_SFF_QSFP_10GBE_COMP	0x83
+#define IXGBE_SFF_QSFP_1GBE_COMP	0x86
+#define IXGBE_SFF_QSFP_CABLE_LENGTH	0x92
+#define IXGBE_SFF_QSFP_DEVICE_TECH	0x93
+
+/* Bitmasks */
+#define IXGBE_SFF_DA_PASSIVE_CABLE	0x4
+#define IXGBE_SFF_DA_ACTIVE_CABLE	0x8
+#define IXGBE_SFF_DA_SPEC_ACTIVE_LIMITING	0x4
+#define IXGBE_SFF_1GBASESX_CAPABLE	0x1
+#define IXGBE_SFF_1GBASELX_CAPABLE	0x2
+#define IXGBE_SFF_1GBASET_CAPABLE	0x8
+#define IXGBE_SFF_10GBASESR_CAPABLE	0x10
+#define IXGBE_SFF_10GBASELR_CAPABLE	0x20
+#define IXGBE_SFF_SOFT_RS_SELECT_MASK	0x8
+#define IXGBE_SFF_SOFT_RS_SELECT_10G	0x8
+#define IXGBE_SFF_SOFT_RS_SELECT_1G	0x0
+#define IXGBE_SFF_ADDRESSING_MODE	0x4
+#define IXGBE_SFF_QSFP_DA_ACTIVE_CABLE	0x1
+#define IXGBE_SFF_QSFP_DA_PASSIVE_CABLE	0x8
+#define IXGBE_SFF_QSFP_CONNECTOR_NOT_SEPARABLE	0x23
+#define IXGBE_SFF_QSFP_TRANSMITER_850NM_VCSEL	0x0
+#define IXGBE_I2C_EEPROM_READ_MASK	0x100
+#define IXGBE_I2C_EEPROM_STATUS_MASK	0x3
+#define IXGBE_I2C_EEPROM_STATUS_NO_OPERATION	0x0
+#define IXGBE_I2C_EEPROM_STATUS_PASS	0x1
+#define IXGBE_I2C_EEPROM_STATUS_FAIL	0x2
+#define IXGBE_I2C_EEPROM_STATUS_IN_PROGRESS	0x3
+
+#define IXGBE_CS4227			0xBE	/* CS4227 address */
+#define IXGBE_CS4227_GLOBAL_ID_LSB	0
+#define IXGBE_CS4227_GLOBAL_ID_MSB	1
+#define IXGBE_CS4227_SCRATCH		2
+#define IXGBE_CS4227_GLOBAL_ID_VALUE	0x03E5
+#define IXGBE_CS4227_EFUSE_PDF_SKU	0x19F
+#define IXGBE_CS4223_SKU_ID		0x0010	/* Quad port */
+#define IXGBE_CS4227_SKU_ID		0x0014	/* Dual port */
+#define IXGBE_CS4227_RESET_PENDING	0x1357
+#define IXGBE_CS4227_RESET_COMPLETE	0x5AA5
+#define IXGBE_CS4227_RETRIES		15
+#define IXGBE_CS4227_EFUSE_STATUS	0x0181
+#define IXGBE_CS4227_LINE_SPARE22_MSB	0x12AD	/* Reg to program speed */
+#define IXGBE_CS4227_LINE_SPARE24_LSB	0x12B0	/* Reg to program EDC */
+#define IXGBE_CS4227_HOST_SPARE22_MSB	0x1AAD	/* Reg to program speed */
+#define IXGBE_CS4227_HOST_SPARE24_LSB	0x1AB0	/* Reg to program EDC */
+#define IXGBE_CS4227_EEPROM_STATUS	0x5001
+#define IXGBE_CS4227_EEPROM_LOAD_OK	0x0001
+#define IXGBE_CS4227_SPEED_1G		0x8000
+#define IXGBE_CS4227_SPEED_10G		0
+#define IXGBE_CS4227_EDC_MODE_CX1	0x0002
+#define IXGBE_CS4227_EDC_MODE_SR	0x0004
+#define IXGBE_CS4227_EDC_MODE_DIAG	0x0008
+#define IXGBE_CS4227_RESET_HOLD		500	/* microseconds */
+#define IXGBE_CS4227_RESET_DELAY	450	/* milliseconds */
+#define IXGBE_CS4227_CHECK_DELAY	30	/* milliseconds */
+#define IXGBE_PE			0xE0	/* Port expander address */
+#define IXGBE_PE_OUTPUT			1	/* Output register offset */
+#define IXGBE_PE_CONFIG			3	/* Config register offset */
+#define IXGBE_PE_BIT1			(1 << 1)
+
+/* Flow control defines */
+#define IXGBE_TAF_SYM_PAUSE		0x400
+#define IXGBE_TAF_ASM_PAUSE		0x800
+
+/* Bit-shift macros */
+#define IXGBE_SFF_VENDOR_OUI_BYTE0_SHIFT	24
+#define IXGBE_SFF_VENDOR_OUI_BYTE1_SHIFT	16
+#define IXGBE_SFF_VENDOR_OUI_BYTE2_SHIFT	8
+
+/* Vendor OUIs: format of OUI is 0x[byte0][byte1][byte2][00] */
+#define IXGBE_SFF_VENDOR_OUI_TYCO	0x00407600
+#define IXGBE_SFF_VENDOR_OUI_FTL	0x00906500
+#define IXGBE_SFF_VENDOR_OUI_AVAGO	0x00176A00
+#define IXGBE_SFF_VENDOR_OUI_INTEL	0x001B2100
+
+/* I2C SDA and SCL timing parameters for standard mode */
+#define IXGBE_I2C_T_HD_STA	4
+#define IXGBE_I2C_T_LOW		5
+#define IXGBE_I2C_T_HIGH	4
+#define IXGBE_I2C_T_SU_STA	5
+#define IXGBE_I2C_T_HD_DATA	5
+#define IXGBE_I2C_T_SU_DATA	1
+#define IXGBE_I2C_T_RISE	1
+#define IXGBE_I2C_T_FALL	1
+#define IXGBE_I2C_T_SU_STO	4
+#define IXGBE_I2C_T_BUF		5
+
+#ifndef IXGBE_SFP_DETECT_RETRIES
+#define IXGBE_SFP_DETECT_RETRIES	10
+
+#endif /* IXGBE_SFP_DETECT_RETRIES */
+#define IXGBE_TN_LASI_STATUS_REG	0x9005
+#define IXGBE_TN_LASI_STATUS_TEMP_ALARM	0x0008
+
+/* SFP+ SFF-8472 Compliance */
+#define IXGBE_SFF_SFF_8472_UNSUP	0x00
+
+int32_t ixgbe_init_phy_ops_generic(struct ixgbe_hw *hw);
+bool ixgbe_validate_phy_addr(struct ixgbe_hw *hw, uint32_t phy_addr);
+enum ixgbe_phy_type ixgbe_get_phy_type_from_id(uint32_t phy_id);
+int32_t ixgbe_get_phy_id(struct ixgbe_hw *hw);
+int32_t ixgbe_identify_phy_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_reset_phy_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_read_phy_reg_mdi(struct ixgbe_hw *hw, uint32_t reg_addr, uint32_t device_type,
+			   uint16_t *phy_data);
+int32_t ixgbe_write_phy_reg_mdi(struct ixgbe_hw *hw, uint32_t reg_addr, uint32_t device_type,
+			    uint16_t phy_data);
+int32_t ixgbe_read_phy_reg_generic(struct ixgbe_hw *hw, uint32_t reg_addr,
+			       uint32_t device_type, uint16_t *phy_data);
+int32_t ixgbe_write_phy_reg_generic(struct ixgbe_hw *hw, uint32_t reg_addr,
+				uint32_t device_type, uint16_t phy_data);
+int32_t ixgbe_setup_phy_link_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_setup_phy_link_speed_generic(struct ixgbe_hw *hw,
+				       ixgbe_link_speed speed,
+				       bool autoneg_wait_to_complete);
+int32_t ixgbe_get_copper_link_capabilities_generic(struct ixgbe_hw *hw,
+					       ixgbe_link_speed *speed,
+					       bool *autoneg);
+int32_t ixgbe_check_reset_blocked(struct ixgbe_hw *hw);
+
+/* PHY specific */
+int32_t ixgbe_check_phy_link_tnx(struct ixgbe_hw *hw,
+			     ixgbe_link_speed *speed,
+			     bool *link_up);
+int32_t ixgbe_setup_phy_link_tnx(struct ixgbe_hw *hw);
+int32_t ixgbe_get_phy_firmware_version_tnx(struct ixgbe_hw *hw,
+				       uint16_t *firmware_version);
+int32_t ixgbe_get_phy_firmware_version_generic(struct ixgbe_hw *hw,
+					   uint16_t *firmware_version);
+
+int32_t ixgbe_reset_phy_nl(struct ixgbe_hw *hw);
+int32_t ixgbe_set_copper_phy_power(struct ixgbe_hw *hw, bool on);
+int32_t ixgbe_identify_module_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_identify_sfp_module_generic(struct ixgbe_hw *hw);
+uint64_t ixgbe_get_supported_phy_sfp_layer_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_identify_qsfp_module_generic(struct ixgbe_hw *hw);
+int32_t ixgbe_get_sfp_init_sequence_offsets(struct ixgbe_hw *hw,
+					uint16_t *list_offset,
+					uint16_t *data_offset);
+int32_t ixgbe_tn_check_overtemp(struct ixgbe_hw *hw);
+int32_t ixgbe_read_i2c_byte_generic(struct ixgbe_hw *hw, uint8_t byte_offset,
+				uint8_t dev_addr, uint8_t *data);
+int32_t ixgbe_read_i2c_byte_generic_unlocked(struct ixgbe_hw *hw, uint8_t byte_offset,
+					 uint8_t dev_addr, uint8_t *data);
+int32_t ixgbe_write_i2c_byte_generic(struct ixgbe_hw *hw, uint8_t byte_offset,
+				 uint8_t dev_addr, uint8_t data);
+int32_t ixgbe_write_i2c_byte_generic_unlocked(struct ixgbe_hw *hw, uint8_t byte_offset,
+					  uint8_t dev_addr, uint8_t data);
+int32_t ixgbe_read_i2c_eeprom_generic(struct ixgbe_hw *hw, uint8_t byte_offset,
+				  uint8_t *eeprom_data);
+int32_t ixgbe_write_i2c_eeprom_generic(struct ixgbe_hw *hw, uint8_t byte_offset,
+				   uint8_t eeprom_data);
+void ixgbe_i2c_bus_clear(struct ixgbe_hw *hw);
+int32_t ixgbe_read_i2c_combined_generic_int(struct ixgbe_hw *, uint8_t addr, uint16_t reg,
+					uint16_t *val, bool lock);
+int32_t ixgbe_write_i2c_combined_generic_int(struct ixgbe_hw *, uint8_t addr, uint16_t reg,
+					 uint16_t val, bool lock);
+#endif /* _IXGBE_PHY_H_ */
Index: ./dev/pci/ixgbe_type.h
===================================================================
RCS file: /cvs/src/sys/dev/pci/ixgbe_type.h,v
retrieving revision 1.31
diff -u -p -r1.31 ixgbe_type.h
--- ./dev/pci/ixgbe_type.h	18 Nov 2016 14:16:10 -0000	1.31
+++ ./dev/pci/ixgbe_type.h	17 Sep 2018 19:59:56 -0000
@@ -1,8 +1,8 @@
-/*	$OpenBSD: ixgbe_type.h,v 1.31 2016/11/18 14:16:10 mikeb Exp $	*/
-
+/*  $OpenBSD$ */
 /******************************************************************************
+  SPDX-License-Identifier: BSD-3-Clause
 
-  Copyright (c) 2001-2015, Intel Corporation
+  Copyright (c) 2001-2017, Intel Corporation
   All rights reserved.
 
   Redistribution and use in source and binary forms, with or without
@@ -32,13 +32,53 @@
   POSSIBILITY OF SUCH DAMAGE.
 
 ******************************************************************************/
-/*$FreeBSD: head/sys/dev/ixgbe/ixgbe_type.h 299200 2016-05-06 22:54:56Z pfg $*/
-/*$FreeBSD: head/sys/dev/ixgbe/ixgbe_phy.h 292674 2015-12-23 22:45:17Z sbruno $*/
-/*$FreeBSD: head/sys/dev/ixgbe/ixgbe_mbx.h 283883 2015-06-01 17:43:34Z jfv $*/
+/*$FreeBSD$*/
 
 #ifndef _IXGBE_TYPE_H_
 #define _IXGBE_TYPE_H_
 
+/*
+ * The following is a brief description of the error categories used by the
+ * ERROR_REPORT* macros.
+ *
+ * - IXGBE_ERROR_INVALID_STATE
+ * This category is for errors which represent a serious failure state that is
+ * unexpected, and could be potentially harmful to device operation. It should
+ * not be used for errors relating to issues that can be worked around or
+ * ignored.
+ *
+ * - IXGBE_ERROR_POLLING
+ * This category is for errors related to polling/timeout issues and should be
+ * used in any case where the timeout occurred, or a failure to obtain a lock, or
+ * failure to receive data within the time limit.
+ *
+ * - IXGBE_ERROR_CAUTION
+ * This category should be used for reporting issues that may be the cause of
+ * other errors, such as temperature warnings. It should indicate an event which
+ * could be serious, but hasn't necessarily caused problems yet.
+ *
+ * - IXGBE_ERROR_SOFTWARE
+ * This category is intended for errors due to software state preventing
+ * something. The category is not intended for errors due to bad arguments, or
+ * due to unsupported features. It should be used when a state occurs which
+ * prevents action but is not a serious issue.
+ *
+ * - IXGBE_ERROR_ARGUMENT
+ * This category is for when a bad or invalid argument is passed. It should be
+ * used whenever a function is called and error checking has detected the
+ * argument is wrong or incorrect.
+ *
+ * - IXGBE_ERROR_UNSUPPORTED
+ * This category is for errors which are due to unsupported circumstances or
+ * configuration issues. It should not be used when the issue is due to an
+ * invalid argument, but for when something has occurred that is unsupported
+ * (Ex: Flow control autonegotiation or an unsupported SFP+ module.)
+ */
+
+// #include "ixgbe_osdep.h"
+
+/* Override this by setting IOMEM in your ixgbe_osdep.h header */
+#define IOMEM
 
 /* Vendor ID */
 #define IXGBE_INTEL_VENDOR_ID			0x8086
@@ -50,7 +90,7 @@
 #define IXGBE_DEV_ID_82598AF_SINGLE_PORT	0x10C7
 #define IXGBE_DEV_ID_82598AT			0x10C8
 #define IXGBE_DEV_ID_82598AT2			0x150B
-#define IXGBE_DEV_ID_82598AT_DUAL_PORT		0x10D7
+#define IXGBE_DEV_ID_82598AT_DUAL_PORT    0x10D7
 #define IXGBE_DEV_ID_82598EB_SFP_LOM		0x10DB
 #define IXGBE_DEV_ID_82598EB_CX4		0x10DD
 #define IXGBE_DEV_ID_82598_CX4_DUAL_PORT	0x10EC
@@ -70,11 +110,14 @@
 #define IXGBE_SUBDEV_ID_82599_560FLR		0x17D0
 #define IXGBE_SUBDEV_ID_82599_ECNA_DP		0x0470
 #define IXGBE_SUBDEV_ID_82599_SP_560FLR		0x211B
-#define IXGBE_SUBDEV_ID_82599_LOM_SFP		0x8976
+#define IXGBE_SUBDEV_ID_82599_LOM_SFP   0x8976
 #define IXGBE_SUBDEV_ID_82599_LOM_SNAP6		0x2159
 #define IXGBE_SUBDEV_ID_82599_SFP_1OCP		0x000D
 #define IXGBE_SUBDEV_ID_82599_SFP_2OCP		0x0008
-#define IXGBE_SUBDEV_ID_82599_SFP_LOM		0x06EE
+#define IXGBE_SUBDEV_ID_82599_SFP_LOM_OEM1	0x8976
+#define IXGBE_SUBDEV_ID_82599_SFP_LOM    0x06EE
+#define IXGBE_SUBDEV_ID_82599_SFP_LOM_OEM1 0x8976
+#define IXGBE_SUBDEV_ID_82599_SFP_LOM_OEM2 0x06EE
 #define IXGBE_DEV_ID_82599_BACKPLANE_FCOE	0x152A
 #define IXGBE_DEV_ID_82599_SFP_FCOE		0x1529
 #define IXGBE_DEV_ID_82599_SFP_EM		0x1507
@@ -95,24 +138,67 @@
 #define IXGBE_DEV_ID_X540T1			0x1560
 #define IXGBE_DEV_ID_X550T			0x1563
 #define IXGBE_DEV_ID_X550T1			0x15D1
+#define IXGBE_DEV_ID_X550EM_A_KR		0x15C2
+#define IXGBE_DEV_ID_X550EM_A_KR_L		0x15C3
+#define IXGBE_DEV_ID_X550EM_A_SFP_N		0x15C4
+#define IXGBE_DEV_ID_X550EM_A_SGMII		0x15C6
+#define IXGBE_DEV_ID_X550EM_A_SGMII_L		0x15C7
+#define IXGBE_DEV_ID_X550EM_A_10G_T		0x15C8
+#define IXGBE_DEV_ID_X550EM_A_QSFP		0x15CA
+#define IXGBE_DEV_ID_X550EM_A_QSFP_N		0x15CC
+#define IXGBE_DEV_ID_X550EM_A_SFP		0x15CE
+#define IXGBE_DEV_ID_X550EM_A_1G_T		0x15E4
+#define IXGBE_DEV_ID_X550EM_A_1G_T_L		0x15E5
 #define IXGBE_DEV_ID_X550EM_X_KX4		0x15AA
 #define IXGBE_DEV_ID_X550EM_X_KR		0x15AB
 #define IXGBE_DEV_ID_X550EM_X_SFP		0x15AC
 #define IXGBE_DEV_ID_X550EM_X_10G_T		0x15AD
 #define IXGBE_DEV_ID_X550EM_X_1G_T		0x15AE
+#define IXGBE_DEV_ID_X550EM_X_XFI		0x15B0
 #define IXGBE_DEV_ID_X550_VF_HV			0x1564
 #define IXGBE_DEV_ID_X550_VF			0x1565
+#define IXGBE_DEV_ID_X550EM_A_VF		0x15C5
+#define IXGBE_DEV_ID_X550EM_A_VF_HV		0x15B4
 #define IXGBE_DEV_ID_X550EM_X_VF		0x15A8
 #define IXGBE_DEV_ID_X550EM_X_VF_HV		0x15A9
 
+#define IXGBE_VFMAILBOX		0x002FC
+#define IXGBE_VFMBMEM		0x00200
+
+/* Define mailbox register bits */
+#define IXGBE_VFMAILBOX_REQ	0x00000001 /* Request for PF Ready bit */
+#define IXGBE_VFMAILBOX_ACK	0x00000002 /* Ack PF message received */
+#define IXGBE_VFMAILBOX_VFU	0x00000004 /* VF owns the mailbox buffer */
+#define IXGBE_VFMAILBOX_PFU	0x00000008 /* PF owns the mailbox buffer */
+#define IXGBE_VFMAILBOX_PFSTS	0x00000010 /* PF wrote a message in the MB */
+#define IXGBE_VFMAILBOX_PFACK	0x00000020 /* PF ack the previous VF msg */
+#define IXGBE_VFMAILBOX_RSTI	0x00000040 /* PF has reset indication */
+#define IXGBE_VFMAILBOX_RSTD	0x00000080 /* PF has indicated reset done */
+#define IXGBE_VFMAILBOX_R2C_BITS	0x000000B0 /* All read to clear bits */
+
+/* mailbox API, version 2.0 PF requests */
+#define IXGBE_PF_TRANSPARENT_VLAN	0x0101 /* enable transparent vlan */
+
+#define IXGBE_VF_MBX_INIT_TIMEOUT	2000 /* number of retries on mailbox */
+#define IXGBE_VF_MBX_INIT_DELAY		500  /* microseconds between retries */
+
+#define IXGBE_CAT(r,m) IXGBE_##r##m
+
+#define IXGBE_BY_MAC(_hw, r) ((_hw)->mvals[IXGBE_CAT(r, _IDX)])
+
 /* General Registers */
 #define IXGBE_CTRL		0x00000
 #define IXGBE_STATUS		0x00008
 #define IXGBE_CTRL_EXT		0x00018
 #define IXGBE_ESDP		0x00020
 #define IXGBE_EODSDP		0x00028
-#define IXGBE_I2CCTL		0x00028
+#define IXGBE_I2CCTL_82599	0x00028
+#define IXGBE_I2CCTL		IXGBE_I2CCTL_82599
+#define IXGBE_I2CCTL_X540	IXGBE_I2CCTL_82599
 #define IXGBE_I2CCTL_X550	0x15F5C
+#define IXGBE_I2CCTL_X550EM_x	IXGBE_I2CCTL_X550
+#define IXGBE_I2CCTL_X550EM_a	IXGBE_I2CCTL_X550
+#define IXGBE_I2CCTL_BY_MAC(_hw) IXGBE_BY_MAC((_hw), I2CCTL)
 #define IXGBE_PHY_GPIO		0x00028
 #define IXGBE_MAC_GPIO		0x00030
 #define IXGBE_PHYINT_STATUS0	0x00100
@@ -125,18 +211,44 @@
 #define IXGBE_EXVET		0x05078
 
 /* NVM Registers */
-#define IXGBE_EEC	0x10010
-#define IXGBE_EERD	0x10014
-#define IXGBE_EEWR	0x10018
-#define IXGBE_FLA	0x1001C
+#define IXGBE_EEC		0x10010
+#define IXGBE_EEC_X540		IXGBE_EEC
+#define IXGBE_EEC_X550		IXGBE_EEC
+#define IXGBE_EEC_X550EM_x	IXGBE_EEC
+#define IXGBE_EEC_X550EM_a	0x15FF8
+#define IXGBE_EEC_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), EEC)
+
+#define IXGBE_EERD		0x10014
+#define IXGBE_EEWR		0x10018
+
+#define IXGBE_FLA		0x1001C
+#define IXGBE_FLA_X540		IXGBE_FLA
+#define IXGBE_FLA_X550		IXGBE_FLA
+#define IXGBE_FLA_X550EM_x	IXGBE_FLA
+#define IXGBE_FLA_X550EM_a	0x15F68
+#define IXGBE_FLA_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), FLA)
+
 #define IXGBE_EEMNGCTL	0x10110
 #define IXGBE_EEMNGDATA	0x10114
 #define IXGBE_FLMNGCTL	0x10118
 #define IXGBE_FLMNGDATA	0x1011C
 #define IXGBE_FLMNGCNT	0x10120
 #define IXGBE_FLOP	0x1013C
-#define IXGBE_GRC	0x10200
-#define IXGBE_SRAMREL	0x10210
+
+#define IXGBE_GRC		0x10200
+#define IXGBE_GRC_X540		IXGBE_GRC
+#define IXGBE_GRC_X550		IXGBE_GRC
+#define IXGBE_GRC_X550EM_x	IXGBE_GRC
+#define IXGBE_GRC_X550EM_a	0x15F64
+#define IXGBE_GRC_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), GRC)
+
+#define IXGBE_SRAMREL		0x10210
+#define IXGBE_SRAMREL_X540	IXGBE_SRAMREL
+#define IXGBE_SRAMREL_X550	IXGBE_SRAMREL
+#define IXGBE_SRAMREL_X550EM_x	IXGBE_SRAMREL
+#define IXGBE_SRAMREL_X550EM_a	0x15F6C
+#define IXGBE_SRAMREL_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), SRAMREL)
+
 #define IXGBE_PHYDBG	0x10218
 
 /* General Receive Control */
@@ -148,20 +260,97 @@
 
 /* I2CCTL Bit Masks */
 #define IXGBE_I2C_CLK_IN		0x00000001
+#define IXGBE_I2C_CLK_IN_X540		IXGBE_I2C_CLK_IN
 #define IXGBE_I2C_CLK_IN_X550		0x00004000
+#define IXGBE_I2C_CLK_IN_X550EM_x	IXGBE_I2C_CLK_IN_X550
+#define IXGBE_I2C_CLK_IN_X550EM_a	IXGBE_I2C_CLK_IN_X550
+#define IXGBE_I2C_CLK_IN_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), I2C_CLK_IN)
+
 #define IXGBE_I2C_CLK_OUT		0x00000002
+#define IXGBE_I2C_CLK_OUT_X540		IXGBE_I2C_CLK_OUT
 #define IXGBE_I2C_CLK_OUT_X550		0x00000200
+#define IXGBE_I2C_CLK_OUT_X550EM_x	IXGBE_I2C_CLK_OUT_X550
+#define IXGBE_I2C_CLK_OUT_X550EM_a	IXGBE_I2C_CLK_OUT_X550
+#define IXGBE_I2C_CLK_OUT_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), I2C_CLK_OUT)
+
 #define IXGBE_I2C_DATA_IN		0x00000004
+#define IXGBE_I2C_DATA_IN_X540		IXGBE_I2C_DATA_IN
 #define IXGBE_I2C_DATA_IN_X550		0x00001000
+#define IXGBE_I2C_DATA_IN_X550EM_x	IXGBE_I2C_DATA_IN_X550
+#define IXGBE_I2C_DATA_IN_X550EM_a	IXGBE_I2C_DATA_IN_X550
+#define IXGBE_I2C_DATA_IN_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), I2C_DATA_IN)
+
 #define IXGBE_I2C_DATA_OUT		0x00000008
+#define IXGBE_I2C_DATA_OUT_X540		IXGBE_I2C_DATA_OUT
 #define IXGBE_I2C_DATA_OUT_X550		0x00000400
+#define IXGBE_I2C_DATA_OUT_X550EM_x	IXGBE_I2C_DATA_OUT_X550
+#define IXGBE_I2C_DATA_OUT_X550EM_a	IXGBE_I2C_DATA_OUT_X550
+#define IXGBE_I2C_DATA_OUT_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), I2C_DATA_OUT)
+
+#define IXGBE_I2C_DATA_OE_N_EN		0
+#define IXGBE_I2C_DATA_OE_N_EN_X540	IXGBE_I2C_DATA_OE_N_EN
 #define IXGBE_I2C_DATA_OE_N_EN_X550	0x00000800
+#define IXGBE_I2C_DATA_OE_N_EN_X550EM_x	IXGBE_I2C_DATA_OE_N_EN_X550
+#define IXGBE_I2C_DATA_OE_N_EN_X550EM_a	IXGBE_I2C_DATA_OE_N_EN_X550
+#define IXGBE_I2C_DATA_OE_N_EN_BY_MAC(_hw) IXGBE_BY_MAC((_hw), I2C_DATA_OE_N_EN)
+
+#define IXGBE_I2C_BB_EN			0
+#define IXGBE_I2C_BB_EN_X540		IXGBE_I2C_BB_EN
 #define IXGBE_I2C_BB_EN_X550		0x00000100
-#define IXGBE_I2C_CLK_OE_N_EN_X550	0x00002000
+#define IXGBE_I2C_BB_EN_X550EM_x	IXGBE_I2C_BB_EN_X550
+#define IXGBE_I2C_BB_EN_X550EM_a	IXGBE_I2C_BB_EN_X550
+#define IXGBE_I2C_BB_EN_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), I2C_BB_EN)
 
+#define IXGBE_I2C_CLK_OE_N_EN		0
+#define IXGBE_I2C_CLK_OE_N_EN_X540	IXGBE_I2C_CLK_OE_N_EN
+#define IXGBE_I2C_CLK_OE_N_EN_X550	0x00002000
+#define IXGBE_I2C_CLK_OE_N_EN_X550EM_x	IXGBE_I2C_CLK_OE_N_EN_X550
+#define IXGBE_I2C_CLK_OE_N_EN_X550EM_a	IXGBE_I2C_CLK_OE_N_EN_X550
+#define IXGBE_I2C_CLK_OE_N_EN_BY_MAC(_hw) IXGBE_BY_MAC((_hw), I2C_CLK_OE_N_EN)
 #define IXGBE_I2C_CLOCK_STRETCHING_TIMEOUT	500
 
 
+
+#define NVM_OROM_OFFSET		0x17
+#define NVM_OROM_BLK_LOW	0x83
+#define NVM_OROM_BLK_HI		0x84
+#define NVM_OROM_PATCH_MASK	0xFF
+#define NVM_OROM_SHIFT		8
+
+#define NVM_VER_MASK		0x00FF /* version mask */
+#define NVM_VER_SHIFT		8     /* version bit shift */
+#define NVM_OEM_PROD_VER_PTR	0x1B  /* OEM Product version block pointer */
+#define NVM_OEM_PROD_VER_CAP_OFF 0x1  /* OEM Product version format offset */
+#define NVM_OEM_PROD_VER_OFF_L	0x2   /* OEM Product version offset low */
+#define NVM_OEM_PROD_VER_OFF_H	0x3   /* OEM Product version offset high */
+#define NVM_OEM_PROD_VER_CAP_MASK 0xF /* OEM Product version cap mask */
+#define NVM_OEM_PROD_VER_MOD_LEN 0x3  /* OEM Product version module length */
+#define NVM_ETK_OFF_LOW		0x2D  /* version low order word */
+#define NVM_ETK_OFF_HI		0x2E  /* version high order word */
+#define NVM_ETK_SHIFT		16    /* high version word shift */
+#define NVM_VER_INVALID		0xFFFF
+#define NVM_ETK_VALID		0x8000
+#define NVM_INVALID_PTR		0xFFFF
+#define NVM_VER_SIZE		32    /* version sting size */
+
+struct ixgbe_nvm_version {
+	uint32_t etk_id;
+	uint8_t  nvm_major;
+	uint16_t nvm_minor;
+	uint8_t  nvm_id;
+
+	bool oem_valid;
+	uint8_t   oem_major;
+	uint8_t   oem_minor;
+	uint16_t  oem_release;
+
+	bool or_valid;
+	uint8_t  or_major;
+	uint16_t or_build;
+	uint8_t  or_patch;
+
+};
+
 /* Interrupt Registers */
 #define IXGBE_EICR		0x00800
 #define IXGBE_EICS		0x00808
@@ -328,6 +517,13 @@
 #define IXGBE_ERETA(_i)		(0x0EE80 + ((_i) * 4))  /* 96 of these (0-95) */
 #define IXGBE_RSSRK(_i)		(0x05C80 + ((_i) * 4))  /* 10 of these (0-9) */
 
+/* Registers for setting up RSS on X550 with SRIOV
+ * _p - pool number (0..63)
+ * _i - index (0..10 for PFVFRSSRK, 0..15 for PFVFRETA)
+ */
+#define IXGBE_PFVFMRQC(_p)	(0x03400 + ((_p) * 4))
+#define IXGBE_PFVFRSSRK(_i, _p)	(0x018000 + ((_i) * 4) + ((_p) * 0x40))
+#define IXGBE_PFVFRETA(_i, _p)	(0x019000 + ((_i) * 4) + ((_p) * 0x40))
 
 /* Flow Director registers */
 #define IXGBE_FDIRCTRL	0x0EE00
@@ -418,6 +614,12 @@
 #define IXGBE_PROXYFC	0x05F64 /* Proxying Filter Control Register */
 #define IXGBE_VXLANCTRL	0x0000507C /* Rx filter VXLAN UDPPORT Register */
 
+/* masks for accessing VXLAN and GENEVE UDP ports */
+#define IXGBE_VXLANCTRL_VXLAN_UDPPORT_MASK	0x0000ffff /* VXLAN port */
+#define IXGBE_VXLANCTRL_GENEVE_UDPPORT_MASK	0xffff0000 /* GENEVE port */
+#define IXGBE_VXLANCTRL_ALL_UDPPORT_MASK	0xffffffff /* GENEVE/VXLAN */
+#define IXGBE_VXLANCTRL_GENEVE_UDPPORT_SHIFT	16
+
 #define IXGBE_FHFT(_n)	(0x09000 + ((_n) * 0x100)) /* Flex host filter table */
 /* Ext Flexible Host Filter Table */
 #define IXGBE_FHFT_EXT(_n)	(0x09800 + ((_n) * 0x100))
@@ -425,7 +627,6 @@
 
 /* Four Flexible Filters are supported */
 #define IXGBE_FLEXIBLE_FILTER_COUNT_MAX		4
-
 /* Six Flexible Filters are supported */
 #define IXGBE_FLEXIBLE_FILTER_COUNT_MAX_6	6
 /* Eight Flexible Filters are supported */
@@ -523,6 +724,14 @@
 #define IXGBE_TDPT2TCSR(_i)	(0x0CD40 + ((_i) * 4)) /* 8 of these (0-7) */
 
 /* Power Management */
+/* DMA Coalescing configuration */
+struct ixgbe_dmac_config {
+	uint16_t	watchdog_timer; /* usec units */
+	bool	fcoe_en;
+	uint32_t	link_speed;
+	uint8_t	fcoe_tc;
+	uint8_t	num_tcs;
+};
 
 /*
  * DMA Coalescing threshold Rx PB TC[n] value in Kilobyte by link speed.
@@ -565,8 +774,6 @@
 #define IXGBE_EEE_RX_LPI_STATUS		0x40000000 /* RX Link in LPI status */
 #define IXGBE_EEE_TX_LPI_STATUS		0x80000000 /* TX Link in LPI status */
 
-
-
 /* Security Control Registers */
 #define IXGBE_SECTXCTRL		0x08800
 #define IXGBE_SECTXSTAT		0x08804
@@ -704,7 +911,6 @@
 #define IXGBE_RTTBCNRTT	0x05150
 #define IXGBE_RTTBCNRD	0x0498C
 
-
 /* FCoE DMA Context Registers */
 /* FCoE Direct DMA Context */
 #define IXGBE_FCDDC(_i, _j)	(0x20000 + ((_i) * 0x4) + ((_j) * 0x10))
@@ -883,7 +1089,7 @@
 #define IXGBE_FTFT		0x09400 /* 0x9400-0x97FC */
 #define IXGBE_METF(_i)		(0x05190 + ((_i) * 4)) /* 4 of these (0-3) */
 #define IXGBE_MDEF_EXT(_i)	(0x05160 + ((_i) * 4)) /* 8 of these (0-7) */
-#define IXGBE_LSWFW		0x15014
+#define IXGBE_LSWFW		0x15F14
 #define IXGBE_BMCIP(_i)		(0x05050 + ((_i) * 4)) /* 0x5050-0x505C */
 #define IXGBE_BMCIPVAL		0x05060
 #define IXGBE_BMCIP_IPADDR_TYPE	0x00000001
@@ -925,17 +1131,65 @@
 #define IXGBE_PCIEPIPEDAT	0x11008
 #define IXGBE_GSCL_1		0x11010
 #define IXGBE_GSCL_2		0x11014
+#define IXGBE_GSCL_1_X540	IXGBE_GSCL_1
+#define IXGBE_GSCL_2_X540	IXGBE_GSCL_2
 #define IXGBE_GSCL_3		0x11018
 #define IXGBE_GSCL_4		0x1101C
 #define IXGBE_GSCN_0		0x11020
 #define IXGBE_GSCN_1		0x11024
 #define IXGBE_GSCN_2		0x11028
 #define IXGBE_GSCN_3		0x1102C
+#define IXGBE_GSCN_0_X540	IXGBE_GSCN_0
+#define IXGBE_GSCN_1_X540	IXGBE_GSCN_1
+#define IXGBE_GSCN_2_X540	IXGBE_GSCN_2
+#define IXGBE_GSCN_3_X540	IXGBE_GSCN_3
 #define IXGBE_FACTPS		0x10150
+#define IXGBE_FACTPS_X540	IXGBE_FACTPS
+#define IXGBE_GSCL_1_X550	0x11800
+#define IXGBE_GSCL_2_X550	0x11804
+#define IXGBE_GSCL_1_X550EM_x	IXGBE_GSCL_1_X550
+#define IXGBE_GSCL_2_X550EM_x	IXGBE_GSCL_2_X550
+#define IXGBE_GSCN_0_X550	0x11820
+#define IXGBE_GSCN_1_X550	0x11824
+#define IXGBE_GSCN_2_X550	0x11828
+#define IXGBE_GSCN_3_X550	0x1182C
+#define IXGBE_GSCN_0_X550EM_x	IXGBE_GSCN_0_X550
+#define IXGBE_GSCN_1_X550EM_x	IXGBE_GSCN_1_X550
+#define IXGBE_GSCN_2_X550EM_x	IXGBE_GSCN_2_X550
+#define IXGBE_GSCN_3_X550EM_x	IXGBE_GSCN_3_X550
+#define IXGBE_FACTPS_X550	IXGBE_FACTPS
+#define IXGBE_FACTPS_X550EM_x	IXGBE_FACTPS
+#define IXGBE_GSCL_1_X550EM_a	IXGBE_GSCL_1_X550
+#define IXGBE_GSCL_2_X550EM_a	IXGBE_GSCL_2_X550
+#define IXGBE_GSCN_0_X550EM_a	IXGBE_GSCN_0_X550
+#define IXGBE_GSCN_1_X550EM_a	IXGBE_GSCN_1_X550
+#define IXGBE_GSCN_2_X550EM_a	IXGBE_GSCN_2_X550
+#define IXGBE_GSCN_3_X550EM_a	IXGBE_GSCN_3_X550
+#define IXGBE_FACTPS_X550EM_a	0x15FEC
+#define IXGBE_FACTPS_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), FACTPS)
+
 #define IXGBE_PCIEANACTL	0x11040
 #define IXGBE_SWSM		0x10140
+#define IXGBE_SWSM_X540		IXGBE_SWSM
+#define IXGBE_SWSM_X550		IXGBE_SWSM
+#define IXGBE_SWSM_X550EM_x	IXGBE_SWSM
+#define IXGBE_SWSM_X550EM_a	0x15F70
+#define IXGBE_SWSM_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), SWSM)
+
 #define IXGBE_FWSM		0x10148
+#define IXGBE_FWSM_X540		IXGBE_FWSM
+#define IXGBE_FWSM_X550		IXGBE_FWSM
+#define IXGBE_FWSM_X550EM_x	IXGBE_FWSM
+#define IXGBE_FWSM_X550EM_a	0x15F74
+#define IXGBE_FWSM_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), FWSM)
+
 #define IXGBE_SWFW_SYNC		IXGBE_GSSR
+#define IXGBE_SWFW_SYNC_X540	IXGBE_SWFW_SYNC
+#define IXGBE_SWFW_SYNC_X550	IXGBE_SWFW_SYNC
+#define IXGBE_SWFW_SYNC_X550EM_x	IXGBE_SWFW_SYNC
+#define IXGBE_SWFW_SYNC_X550EM_a	0x15F78
+#define IXGBE_SWFW_SYNC_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), SWFW_SYNC)
+
 #define IXGBE_GSSR		0x10160
 #define IXGBE_MREVID		0x11064
 #define IXGBE_DCA_ID		0x11070
@@ -947,14 +1201,40 @@
 #define IXGBE_GSCL_6_82599	0x11034
 #define IXGBE_GSCL_7_82599	0x11038
 #define IXGBE_GSCL_8_82599	0x1103C
+#define IXGBE_GSCL_5_X540	IXGBE_GSCL_5_82599
+#define IXGBE_GSCL_6_X540	IXGBE_GSCL_6_82599
+#define IXGBE_GSCL_7_X540	IXGBE_GSCL_7_82599
+#define IXGBE_GSCL_8_X540	IXGBE_GSCL_8_82599
 #define IXGBE_PHYADR_82599	0x11040
 #define IXGBE_PHYDAT_82599	0x11044
 #define IXGBE_PHYCTL_82599	0x11048
 #define IXGBE_PBACLR_82599	0x11068
-#define IXGBE_CIAA_82599	0x11088
-#define IXGBE_CIAD_82599	0x1108C
+#define IXGBE_CIAA		0x11088
+#define IXGBE_CIAD		0x1108C
+#define IXGBE_CIAA_82599	IXGBE_CIAA
+#define IXGBE_CIAD_82599	IXGBE_CIAD
+#define IXGBE_CIAA_X540		IXGBE_CIAA
+#define IXGBE_CIAD_X540		IXGBE_CIAD
+#define IXGBE_GSCL_5_X550	0x11810
+#define IXGBE_GSCL_6_X550	0x11814
+#define IXGBE_GSCL_7_X550	0x11818
+#define IXGBE_GSCL_8_X550	0x1181C
+#define IXGBE_GSCL_5_X550EM_x	IXGBE_GSCL_5_X550
+#define IXGBE_GSCL_6_X550EM_x	IXGBE_GSCL_6_X550
+#define IXGBE_GSCL_7_X550EM_x	IXGBE_GSCL_7_X550
+#define IXGBE_GSCL_8_X550EM_x	IXGBE_GSCL_8_X550
 #define IXGBE_CIAA_X550		0x11508
 #define IXGBE_CIAD_X550		0x11510
+#define IXGBE_CIAA_X550EM_x	IXGBE_CIAA_X550
+#define IXGBE_CIAD_X550EM_x	IXGBE_CIAD_X550
+#define IXGBE_GSCL_5_X550EM_a	IXGBE_GSCL_5_X550
+#define IXGBE_GSCL_6_X550EM_a	IXGBE_GSCL_6_X550
+#define IXGBE_GSCL_7_X550EM_a	IXGBE_GSCL_7_X550
+#define IXGBE_GSCL_8_X550EM_a	IXGBE_GSCL_8_X550
+#define IXGBE_CIAA_X550EM_a	IXGBE_CIAA_X550
+#define IXGBE_CIAD_X550EM_a	IXGBE_CIAD_X550
+#define IXGBE_CIAA_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), CIAA)
+#define IXGBE_CIAD_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), CIAD)
 #define IXGBE_PICAUSE		0x110B0
 #define IXGBE_PIENA		0x110B8
 #define IXGBE_CDQ_MBR_82599	0x110B4
@@ -1098,6 +1378,7 @@
 #define IXGBE_XPCSS		0x04290
 #define IXGBE_MFLCN		0x04294
 #define IXGBE_SERDESC		0x04298
+#define IXGBE_MAC_SGMII_BUSY	0x04298
 #define IXGBE_MACS		0x0429C
 #define IXGBE_AUTOC		0x042A0
 #define IXGBE_LINKS		0x042A4
@@ -1284,6 +1565,7 @@
 #define IXGBE_CORECTL_WRITE_CMD		0x00010000
 
 /* Device Type definitions for new protocol MDIO commands */
+#define IXGBE_MDIO_ZERO_DEV_TYPE		0x0
 #define IXGBE_MDIO_PMA_PMD_DEV_TYPE		0x1
 #define IXGBE_MDIO_PCS_DEV_TYPE			0x3
 #define IXGBE_MDIO_PHY_XS_DEV_TYPE		0x4
@@ -1349,6 +1631,7 @@
 #define IXGBE_MDIO_GLOBAL_VEN_ALM_INT_EN	0x1 /* vendor alarm int enable */
 #define IXGBE_MDIO_GLOBAL_STD_ALM2_INT		0x200 /* vendor alarm2 int mask */
 #define IXGBE_MDIO_GLOBAL_INT_HI_TEMP_EN	0x4000 /* int high temp enable */
+#define IXGBE_MDIO_GLOBAL_INT_DEV_FAULT_EN 0x0010 /* int dev fault enable */
 #define IXGBE_MDIO_PMA_PMD_CONTROL_ADDR	0x0000 /* PMA/PMD Control Reg */
 #define IXGBE_MDIO_PMA_PMD_SDA_SCL_ADDR	0xC30A /* PHY_XS SDA/SCL Addr Reg */
 #define IXGBE_MDIO_PMA_PMD_SDA_SCL_DATA	0xC30B /* PHY_XS SDA/SCL Data Reg */
@@ -1408,16 +1691,19 @@
 #define TN1010_PHY_ID	0x00A19410
 #define TNX_FW_REV	0xB
 #define X540_PHY_ID	0x01540200
-#define X550_PHY_ID1	0x01540220
+#define X540_PHY_ID1	0x01540200
+#define X550_PHY_ID1 0x01540220
 #define X550_PHY_ID2	0x01540223
 #define X550_PHY_ID3	0x01540221
 #define X557_PHY_ID	0x01540240
+#define X557_PHY_ID2	0x01540250
 #define AQ_FW_REV	0x20
 #define QT2022_PHY_ID	0x0043A400
 #define ATH_PHY_ID	0x03429050
 
 /* PHY Types */
-#define IXGBE_M88E1145_E_PHY_ID	0x01410CD0
+#define IXGBE_M88E1500_E_PHY_ID	0x01410DD0
+#define IXGBE_M88E1543_E_PHY_ID	0x01410EA0
 
 /* Special PHY Init Routine */
 #define IXGBE_PHY_INIT_OFFSET_NL	0x002B
@@ -1438,13 +1724,26 @@
 #define IXGBE_SDP0_GPIEN_X540	0x00000002 /* SDP0 on X540 and X550 */
 #define IXGBE_SDP1_GPIEN_X540	0x00000004 /* SDP1 on X540 and X550 */
 #define IXGBE_SDP2_GPIEN_X540	0x00000008 /* SDP2 on X540 and X550 */
+#define IXGBE_SDP0_GPIEN_X550	IXGBE_SDP0_GPIEN_X540
+#define IXGBE_SDP1_GPIEN_X550	IXGBE_SDP1_GPIEN_X540
+#define IXGBE_SDP2_GPIEN_X550	IXGBE_SDP2_GPIEN_X540
+#define IXGBE_SDP0_GPIEN_X550EM_x	IXGBE_SDP0_GPIEN_X540
+#define IXGBE_SDP1_GPIEN_X550EM_x	IXGBE_SDP1_GPIEN_X540
+#define IXGBE_SDP2_GPIEN_X550EM_x	IXGBE_SDP2_GPIEN_X540
+#define IXGBE_SDP0_GPIEN_X550EM_a	IXGBE_SDP0_GPIEN_X540
+#define IXGBE_SDP1_GPIEN_X550EM_a	IXGBE_SDP1_GPIEN_X540
+#define IXGBE_SDP2_GPIEN_X550EM_a	IXGBE_SDP2_GPIEN_X540
+#define IXGBE_SDP0_GPIEN_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), SDP0_GPIEN)
+#define IXGBE_SDP1_GPIEN_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), SDP1_GPIEN)
+#define IXGBE_SDP2_GPIEN_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), SDP2_GPIEN)
+
 #define IXGBE_GPIE_MSIX_MODE	0x00000010 /* MSI-X mode */
 #define IXGBE_GPIE_OCD		0x00000020 /* Other Clear Disable */
 #define IXGBE_GPIE_EIMEN	0x00000040 /* Immediate Interrupt Enable */
 #define IXGBE_GPIE_EIAME	0x40000000
 #define IXGBE_GPIE_PBA_SUPPORT	0x80000000
+#define IXGBE_GPIE_LLI_DELAY_SHIFT  7
 #define IXGBE_GPIE_RSC_DELAY_SHIFT	11
-#define IXGBE_GPIE_LLI_DELAY_SHIFT	7
 #define IXGBE_GPIE_VTMODE_MASK	0x0000C000 /* VT Mode Mask */
 #define IXGBE_GPIE_VTMODE_16	0x00004000 /* 16 VFs 8 queues per VF */
 #define IXGBE_GPIE_VTMODE_32	0x00008000 /* 32 VFs 4 queues per VF */
@@ -1474,7 +1773,16 @@ enum {
 };
 
 /* Transmit Flow Control status */
-#define IXGBE_TFCS_TXON		0x00000001
+#define IXGBE_TFCS_TXON  0x00000001
+#define IXGBE_TFCS_TXOFF	0x00000001
+#define IXGBE_TFCS_TXOFF0	0x00000100
+#define IXGBE_TFCS_TXOFF1	0x00000200
+#define IXGBE_TFCS_TXOFF2	0x00000400
+#define IXGBE_TFCS_TXOFF3	0x00000800
+#define IXGBE_TFCS_TXOFF4	0x00001000
+#define IXGBE_TFCS_TXOFF5	0x00002000
+#define IXGBE_TFCS_TXOFF6	0x00004000
+#define IXGBE_TFCS_TXOFF7	0x00008000
 
 /* TCP Timer */
 #define IXGBE_TCPTIMER_KS		0x00000100
@@ -1512,6 +1820,8 @@ enum {
 #define IXGBE_VT_CTL_POOL_MASK		(0x3F << IXGBE_VT_CTL_POOL_SHIFT)
 
 /* VMOLR bitmasks */
+#define IXGBE_VMOLR_UPE		0x00400000 /* unicast promiscuous */
+#define IXGBE_VMOLR_VPE		0x00800000 /* VLAN promiscuous */
 #define IXGBE_VMOLR_AUPE	0x01000000 /* accept untagged packets */
 #define IXGBE_VMOLR_ROMPE	0x02000000 /* accept packets in MTA tbl */
 #define IXGBE_VMOLR_ROPE	0x04000000 /* accept packets in UC tbl */
@@ -1611,6 +1921,22 @@ enum {
 #define IXGBE_EICR_GPI_SDP0_X540 0x02000000 /* Gen Purpose Interrupt on SDP0 */
 #define IXGBE_EICR_GPI_SDP1_X540 0x04000000 /* Gen Purpose Interrupt on SDP1 */
 #define IXGBE_EICR_GPI_SDP2_X540 0x08000000 /* Gen Purpose Interrupt on SDP2 */
+#define IXGBE_EIMS_GPI_SDP0_X540 IXGBE_EICR_GPI_SDP0_X540 /* deprecated */
+#define IXGBE_EIMS_GPI_SDP1_X540 IXGBE_EICR_GPI_SDP1_X540 /* deprecated */
+#define IXGBE_EIMS_GPI_SDP2_X540 IXGBE_EICR_GPI_SDP2_X540 /* deprecated */
+#define IXGBE_EICR_GPI_SDP0_X550	IXGBE_EICR_GPI_SDP0_X540
+#define IXGBE_EICR_GPI_SDP1_X550	IXGBE_EICR_GPI_SDP1_X540
+#define IXGBE_EICR_GPI_SDP2_X550	IXGBE_EICR_GPI_SDP2_X540
+#define IXGBE_EICR_GPI_SDP0_X550EM_x	IXGBE_EICR_GPI_SDP0_X540
+#define IXGBE_EICR_GPI_SDP1_X550EM_x	IXGBE_EICR_GPI_SDP1_X540
+#define IXGBE_EICR_GPI_SDP2_X550EM_x	IXGBE_EICR_GPI_SDP2_X540
+#define IXGBE_EICR_GPI_SDP0_X550EM_a	IXGBE_EICR_GPI_SDP0_X540
+#define IXGBE_EICR_GPI_SDP1_X550EM_a	IXGBE_EICR_GPI_SDP1_X540
+#define IXGBE_EICR_GPI_SDP2_X550EM_a	IXGBE_EICR_GPI_SDP2_X540
+#define IXGBE_EICR_GPI_SDP0_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), EICR_GPI_SDP0)
+#define IXGBE_EICR_GPI_SDP1_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), EICR_GPI_SDP1)
+#define IXGBE_EICR_GPI_SDP2_BY_MAC(_hw)	IXGBE_BY_MAC((_hw), EICR_GPI_SDP2)
+
 #define IXGBE_EICR_PBUR		0x10000000 /* Packet Buffer Handler Error */
 #define IXGBE_EICR_DHER		0x20000000 /* Descriptor Handler Error */
 #define IXGBE_EICR_TCP_TIMER	0x40000000 /* TCP Timer */
@@ -1628,10 +1954,10 @@ enum {
 #define IXGBE_EICS_GPI_SDP0	IXGBE_EICR_GPI_SDP0 /* SDP0 Gen Purpose Int */
 #define IXGBE_EICS_GPI_SDP1	IXGBE_EICR_GPI_SDP1 /* SDP1 Gen Purpose Int */
 #define IXGBE_EICS_GPI_SDP2	IXGBE_EICR_GPI_SDP2 /* SDP2 Gen Purpose Int */
-#define IXGBE_EICS_GPI_SDP0_X540 IXGBE_EICR_GPI_SDP0_X540
-#define IXGBE_EICS_GPI_SDP1_X540 IXGBE_EICR_GPI_SDP1_X540
-#define IXGBE_EICS_GPI_SDP2_X540 IXGBE_EICR_GPI_SDP2_X540
 #define IXGBE_EICS_ECC		IXGBE_EICR_ECC /* ECC Error */
+#define IXGBE_EICS_GPI_SDP0_BY_MAC(_hw)	IXGBE_EICR_GPI_SDP0_BY_MAC(_hw)
+#define IXGBE_EICS_GPI_SDP1_BY_MAC(_hw)	IXGBE_EICR_GPI_SDP1_BY_MAC(_hw)
+#define IXGBE_EICS_GPI_SDP2_BY_MAC(_hw)	IXGBE_EICR_GPI_SDP2_BY_MAC(_hw)
 #define IXGBE_EICS_PBUR		IXGBE_EICR_PBUR /* Pkt Buf Handler Err */
 #define IXGBE_EICS_DHER		IXGBE_EICR_DHER /* Desc Handler Error */
 #define IXGBE_EICS_TCP_TIMER	IXGBE_EICR_TCP_TIMER /* TCP Timer */
@@ -1650,10 +1976,10 @@ enum {
 #define IXGBE_EIMS_GPI_SDP0	IXGBE_EICR_GPI_SDP0 /* SDP0 Gen Purpose Int */
 #define IXGBE_EIMS_GPI_SDP1	IXGBE_EICR_GPI_SDP1 /* SDP1 Gen Purpose Int */
 #define IXGBE_EIMS_GPI_SDP2	IXGBE_EICR_GPI_SDP2 /* SDP2 Gen Purpose Int */
-#define IXGBE_EIMS_GPI_SDP0_X540 IXGBE_EICR_GPI_SDP0_X540
-#define IXGBE_EIMS_GPI_SDP1_X540 IXGBE_EICR_GPI_SDP1_X540
-#define IXGBE_EIMS_GPI_SDP2_X540 IXGBE_EICR_GPI_SDP2_X540
 #define IXGBE_EIMS_ECC		IXGBE_EICR_ECC /* ECC Error */
+#define IXGBE_EIMS_GPI_SDP0_BY_MAC(_hw)	IXGBE_EICR_GPI_SDP0_BY_MAC(_hw)
+#define IXGBE_EIMS_GPI_SDP1_BY_MAC(_hw)	IXGBE_EICR_GPI_SDP1_BY_MAC(_hw)
+#define IXGBE_EIMS_GPI_SDP2_BY_MAC(_hw)	IXGBE_EICR_GPI_SDP2_BY_MAC(_hw)
 #define IXGBE_EIMS_PBUR		IXGBE_EICR_PBUR /* Pkt Buf Handler Err */
 #define IXGBE_EIMS_DHER		IXGBE_EICR_DHER /* Descr Handler Error */
 #define IXGBE_EIMS_TCP_TIMER	IXGBE_EICR_TCP_TIMER /* TCP Timer */
@@ -1670,11 +1996,11 @@ enum {
 #define IXGBE_EIMC_TIMESYNC	IXGBE_EICR_TIMESYNC /* Timesync Event */
 #define IXGBE_EIMC_GPI_SDP0	IXGBE_EICR_GPI_SDP0 /* SDP0 Gen Purpose Int */
 #define IXGBE_EIMC_GPI_SDP1	IXGBE_EICR_GPI_SDP1 /* SDP1 Gen Purpose Int */
-#define IXGBE_EIMC_GPI_SDP2	IXGBE_EICR_GPI_SDP2 /* SDP2 Gen Purpose Int */
-#define IXGBE_EIMC_GPI_SDP0_X540 IXGBE_EICR_GPI_SDP0_X540
-#define IXGBE_EIMC_GPI_SDP1_X540 IXGBE_EICR_GPI_SDP1_X540
-#define IXGBE_EIMC_GPI_SDP2_X540 IXGBE_EICR_GPI_SDP2_X540
+#define IXGBE_EIMC_GPI_SDP2	IXGBE_EICR_GPI_SDP2  /* SDP2 Gen Purpose Int */
 #define IXGBE_EIMC_ECC		IXGBE_EICR_ECC /* ECC Error */
+#define IXGBE_EIMC_GPI_SDP0_BY_MAC(_hw)	IXGBE_EICR_GPI_SDP0_BY_MAC(_hw)
+#define IXGBE_EIMC_GPI_SDP1_BY_MAC(_hw)	IXGBE_EICR_GPI_SDP1_BY_MAC(_hw)
+#define IXGBE_EIMC_GPI_SDP2_BY_MAC(_hw)	IXGBE_EICR_GPI_SDP2_BY_MAC(_hw)
 #define IXGBE_EIMC_PBUR		IXGBE_EICR_PBUR /* Pkt Buf Handler Err */
 #define IXGBE_EIMC_DHER		IXGBE_EICR_DHER /* Desc Handler Err */
 #define IXGBE_EIMC_TCP_TIMER	IXGBE_EICR_TCP_TIMER /* TCP Timer */
@@ -1683,6 +2009,7 @@ enum {
 #define IXGBE_EIMS_ENABLE_MASK ( \
 				IXGBE_EIMS_RTX_QUEUE	| \
 				IXGBE_EIMS_LSC		| \
+				IXGBE_EIMS_TCP_TIMER	| \
 				IXGBE_EIMS_OTHER)
 
 /* Immediate Interrupt Rx (A.K.A. Low Latency Interrupt) */
@@ -1936,6 +2263,7 @@ enum {
 #define IXGBE_LINKS_SPEED_10G_82599	0x30000000
 #define IXGBE_LINKS_SPEED_1G_82599	0x20000000
 #define IXGBE_LINKS_SPEED_100_82599	0x10000000
+#define IXGBE_LINKS_SPEED_10_X550EM_A	0x00000000
 #define IXGBE_LINK_UP_TIME		90 /* 9.0 Seconds */
 #define IXGBE_AUTO_NEG_TIME		45 /* 4.5 Seconds */
 
@@ -1981,6 +2309,7 @@ enum {
 #define IXGBE_GSSR_FLASH_SM		0x0010
 #define IXGBE_GSSR_NVM_UPDATE_SM	0x0200
 #define IXGBE_GSSR_SW_MNG_SM		0x0400
+#define IXGBE_GSSR_TOKEN_SM	0x40000000 /* SW bit for shared access */
 #define IXGBE_GSSR_SHARED_I2C_SM 0x1806 /* Wait for both phys and both I2Cs */
 #define IXGBE_GSSR_I2C_MASK	0x1800
 #define IXGBE_GSSR_NVM_PHY_MASK	0xF
@@ -2023,6 +2352,9 @@ enum {
 #define IXGBE_PBANUM_PTR_GUARD		0xFAFA
 #define IXGBE_EEPROM_CHECKSUM		0x3F
 #define IXGBE_EEPROM_SUM		0xBABA
+#define IXGBE_EEPROM_CTRL_4		0x45
+#define IXGBE_EE_CTRL_4_INST_ID		0x10
+#define IXGBE_EE_CTRL_4_INST_ID_SHIFT	4
 #define IXGBE_PCIE_ANALOG_PTR		0x03
 #define IXGBE_ATLAS0_CONFIG_PTR		0x04
 #define IXGBE_PHY_PTR			0x04
@@ -2050,7 +2382,9 @@ enum {
 
 #define IXGBE_SAN_MAC_ADDR_PTR		0x28
 #define IXGBE_DEVICE_CAPS		0x2C
-#define IXGBE_SERIAL_NUMBER_MAC_ADDR	0x11
+#define IXGBE_82599_SERIAL_NUMBER_MAC_ADDR	0x11
+#define IXGBE_X550_SERIAL_NUMBER_MAC_ADDR	0x04
+
 #define IXGBE_PCIE_MSIX_82599_CAPS	0x72
 #define IXGBE_MAX_MSIX_VECTORS_82599	0x40
 #define IXGBE_PCIE_MSIX_82598_CAPS	0x62
@@ -2120,6 +2454,7 @@ enum {
 #define IXGBE_SAN_MAC_ADDR_PORT1_OFFSET		0x3
 #define IXGBE_DEVICE_CAPS_ALLOW_ANY_SFP		0x1
 #define IXGBE_DEVICE_CAPS_FCOE_OFFLOADS		0x2
+#define IXGBE_DEVICE_CAPS_NO_CROSSTALK_WR	(1 << 7)
 #define IXGBE_FW_LESM_PARAMETERS_PTR		0x2
 #define IXGBE_FW_LESM_STATE_1			0x1
 #define IXGBE_FW_LESM_STATE_ENABLED		0x8000 /* LESM Enable bit */
@@ -2323,6 +2658,7 @@ enum {
 #define IXGBE_MRQC_VMDQRSS64EN	0x0000000B /* VMDq2 64 pools w/ RSS */
 #define IXGBE_MRQC_VMDQRT8TCEN	0x0000000C /* VMDq2/RT 16 pool 8 TC */
 #define IXGBE_MRQC_VMDQRT4TCEN	0x0000000D /* VMDq2/RT 32 pool 4 TC */
+#define IXGBE_MRQC_L3L4TXSWEN	0x00008000 /* Enable L3/L4 Tx switch */
 #define IXGBE_MRQC_RSS_FIELD_MASK	0xFFFF0000
 #define IXGBE_MRQC_RSS_FIELD_IPV4_TCP	0x00010000
 #define IXGBE_MRQC_RSS_FIELD_IPV4	0x00020000
@@ -2494,6 +2830,7 @@ enum {
 #define IXGBE_RXDADV_PKTTYPE_UDP	0x00000200 /* UDP hdr present */
 #define IXGBE_RXDADV_PKTTYPE_SCTP	0x00000400 /* SCTP hdr present */
 #define IXGBE_RXDADV_PKTTYPE_NFS	0x00000800 /* NFS hdr present */
+#define IXGBE_RXDADV_PKTTYPE_GENEVE	0x00000800 /* GENEVE hdr present */
 #define IXGBE_RXDADV_PKTTYPE_VXLAN	0x00000800 /* VXLAN hdr present */
 #define IXGBE_RXDADV_PKTTYPE_TUNNEL	0x00010000 /* Tunnel type */
 #define IXGBE_RXDADV_PKTTYPE_IPSEC_ESP	0x00001000 /* IPSec ESP */
@@ -2546,6 +2883,68 @@ enum {
 #define IXGBE_MBVFICR(_i)		(0x00710 + ((_i) * 4))
 #define IXGBE_VFLRE(_i)			(((_i & 1) ? 0x001C0 : 0x00600))
 #define IXGBE_VFLREC(_i)		 (0x00700 + ((_i) * 4))
+/* Translated register #defines */
+#define IXGBE_PVFCTRL(P)	(0x00300 + (4 * (P)))
+#define IXGBE_PVFSTATUS(P)	(0x00008 + (0 * (P)))
+#define IXGBE_PVFLINKS(P)	(0x042A4 + (0 * (P)))
+#define IXGBE_PVFRTIMER(P)	(0x00048 + (0 * (P)))
+#define IXGBE_PVFMAILBOX(P)	(0x04C00 + (4 * (P)))
+#define IXGBE_PVFRXMEMWRAP(P)	(0x03190 + (0 * (P)))
+#define IXGBE_PVTEICR(P)	(0x00B00 + (4 * (P)))
+#define IXGBE_PVTEICS(P)	(0x00C00 + (4 * (P)))
+#define IXGBE_PVTEIMS(P)	(0x00D00 + (4 * (P)))
+#define IXGBE_PVTEIMC(P)	(0x00E00 + (4 * (P)))
+#define IXGBE_PVTEIAC(P)	(0x00F00 + (4 * (P)))
+#define IXGBE_PVTEIAM(P)	(0x04D00 + (4 * (P)))
+#define IXGBE_PVTEITR(P)	(((P) < 24) ? (0x00820 + ((P) * 4)) : \
+				 (0x012300 + (((P) - 24) * 4)))
+#define IXGBE_PVTIVAR(P)	(0x12500 + (4 * (P)))
+#define IXGBE_PVTIVAR_MISC(P)	(0x04E00 + (4 * (P)))
+#define IXGBE_PVTRSCINT(P)	(0x12000 + (4 * (P)))
+#define IXGBE_VFPBACL(P)	(0x110C8 + (4 * (P)))
+#define IXGBE_PVFRDBAL(P)	((P < 64) ? (0x01000 + (0x40 * (P))) \
+				 : (0x0D000 + (0x40 * ((P) - 64))))
+#define IXGBE_PVFRDBAH(P)	((P < 64) ? (0x01004 + (0x40 * (P))) \
+				 : (0x0D004 + (0x40 * ((P) - 64))))
+#define IXGBE_PVFRDLEN(P)	((P < 64) ? (0x01008 + (0x40 * (P))) \
+				 : (0x0D008 + (0x40 * ((P) - 64))))
+#define IXGBE_PVFRDH(P)		((P < 64) ? (0x01010 + (0x40 * (P))) \
+				 : (0x0D010 + (0x40 * ((P) - 64))))
+#define IXGBE_PVFRDT(P)		((P < 64) ? (0x01018 + (0x40 * (P))) \
+				 : (0x0D018 + (0x40 * ((P) - 64))))
+#define IXGBE_PVFRXDCTL(P)	((P < 64) ? (0x01028 + (0x40 * (P))) \
+				 : (0x0D028 + (0x40 * ((P) - 64))))
+#define IXGBE_PVFSRRCTL(P)	((P < 64) ? (0x01014 + (0x40 * (P))) \
+				 : (0x0D014 + (0x40 * ((P) - 64))))
+#define IXGBE_PVFPSRTYPE(P)	(0x0EA00 + (4 * (P)))
+#define IXGBE_PVFTDBAL(P)	(0x06000 + (0x40 * (P)))
+#define IXGBE_PVFTDBAH(P)	(0x06004 + (0x40 * (P)))
+#define IXGBE_PVFTDLEN(P)	(0x06008 + (0x40 * (P)))
+#define IXGBE_PVFTDH(P)		(0x06010 + (0x40 * (P)))
+#define IXGBE_PVFTDT(P)		(0x06018 + (0x40 * (P)))
+#define IXGBE_PVFTXDCTL(P)	(0x06028 + (0x40 * (P)))
+#define IXGBE_PVFTDWBAL(P)	(0x06038 + (0x40 * (P)))
+#define IXGBE_PVFTDWBAH(P)	(0x0603C + (0x40 * (P)))
+#define IXGBE_PVFDCA_RXCTRL(P)	(((P) < 64) ? (0x0100C + (0x40 * (P))) \
+				 : (0x0D00C + (0x40 * ((P) - 64))))
+#define IXGBE_PVFDCA_TXCTRL(P)	(0x0600C + (0x40 * (P)))
+#define IXGBE_PVFGPRC(x)	(0x0101C + (0x40 * (x)))
+#define IXGBE_PVFGPTC(x)	(0x08300 + (0x04 * (x)))
+#define IXGBE_PVFGORC_LSB(x)	(0x01020 + (0x40 * (x)))
+#define IXGBE_PVFGORC_MSB(x)	(0x0D020 + (0x40 * (x)))
+#define IXGBE_PVFGOTC_LSB(x)	(0x08400 + (0x08 * (x)))
+#define IXGBE_PVFGOTC_MSB(x)	(0x08404 + (0x08 * (x)))
+#define IXGBE_PVFMPRC(x)	(0x0D01C + (0x40 * (x)))
+
+#define IXGBE_PVFTDWBALn(q_per_pool, vf_number, vf_q_index) \
+		(IXGBE_PVFTDWBAL((q_per_pool)*(vf_number) + (vf_q_index)))
+#define IXGBE_PVFTDWBAHn(q_per_pool, vf_number, vf_q_index) \
+		(IXGBE_PVFTDWBAH((q_per_pool)*(vf_number) + (vf_q_index)))
+
+#define IXGBE_PVFTDHn(q_per_pool, vf_number, vf_q_index) \
+		(IXGBE_PVFTDH((q_per_pool)*(vf_number) + (vf_q_index)))
+#define IXGBE_PVFTDTn(q_per_pool, vf_number, vf_q_index) \
+		(IXGBE_PVFTDT((q_per_pool)*(vf_number) + (vf_q_index)))
 
 /* Little Endian defines */
 #ifndef __le16
@@ -2675,6 +3074,7 @@ enum ixgbe_fdir_pballoc_type {
 #define FW_CEM_UNUSED_VER		0x0
 #define FW_CEM_MAX_RETRIES		3
 #define FW_CEM_RESP_STATUS_SUCCESS	0x1
+#define FW_CEM_DRIVER_VERSION_SIZE	39 /* +9 would send 48 bytes to fw */
 #define FW_READ_SHADOW_RAM_CMD		0x31
 #define FW_READ_SHADOW_RAM_LEN		0x6
 #define FW_WRITE_SHADOW_RAM_CMD		0x33
@@ -2687,13 +3087,77 @@ enum ixgbe_fdir_pballoc_type {
 #define FW_DISABLE_RXEN_CMD		0xDE
 #define FW_DISABLE_RXEN_LEN		0x1
 #define FW_PHY_MGMT_REQ_CMD		0x20
+#define FW_PHY_TOKEN_REQ_CMD		0xA
+#define FW_PHY_TOKEN_REQ_LEN		2
+#define FW_PHY_TOKEN_REQ		0
+#define FW_PHY_TOKEN_REL		1
+#define FW_PHY_TOKEN_OK			1
+#define FW_PHY_TOKEN_RETRY		0x80
+#define FW_PHY_TOKEN_DELAY		5	/* milliseconds */
+#define FW_PHY_TOKEN_WAIT		5	/* seconds */
+#define FW_PHY_TOKEN_RETRIES ((FW_PHY_TOKEN_WAIT * 1000) / FW_PHY_TOKEN_DELAY)
 #define FW_INT_PHY_REQ_CMD		0xB
 #define FW_INT_PHY_REQ_LEN		10
 #define FW_INT_PHY_REQ_READ		0
 #define FW_INT_PHY_REQ_WRITE		1
+#define FW_PHY_ACT_REQ_CMD		5
+#define FW_PHY_ACT_DATA_COUNT		4
+#define FW_PHY_ACT_REQ_LEN		(4 + 4 * FW_PHY_ACT_DATA_COUNT)
+#define FW_PHY_ACT_INIT_PHY		1
+#define FW_PHY_ACT_SETUP_LINK		2
+#define FW_PHY_ACT_LINK_SPEED_10	(1u << 0)
+#define FW_PHY_ACT_LINK_SPEED_100	(1u << 1)
+#define FW_PHY_ACT_LINK_SPEED_1G	(1u << 2)
+#define FW_PHY_ACT_LINK_SPEED_2_5G	(1u << 3)
+#define FW_PHY_ACT_LINK_SPEED_5G	(1u << 4)
+#define FW_PHY_ACT_LINK_SPEED_10G	(1u << 5)
+#define FW_PHY_ACT_LINK_SPEED_20G	(1u << 6)
+#define FW_PHY_ACT_LINK_SPEED_25G	(1u << 7)
+#define FW_PHY_ACT_LINK_SPEED_40G	(1u << 8)
+#define FW_PHY_ACT_LINK_SPEED_50G	(1u << 9)
+#define FW_PHY_ACT_LINK_SPEED_100G	(1u << 10)
+#define FW_PHY_ACT_SETUP_LINK_PAUSE_SHIFT 16
+#define FW_PHY_ACT_SETUP_LINK_PAUSE_MASK (3u << \
+					  FW_PHY_ACT_SETUP_LINK_PAUSE_SHIFT)
+#define FW_PHY_ACT_SETUP_LINK_PAUSE_NONE 0u
+#define FW_PHY_ACT_SETUP_LINK_PAUSE_TX	1u
+#define FW_PHY_ACT_SETUP_LINK_PAUSE_RX	2u
+#define FW_PHY_ACT_SETUP_LINK_PAUSE_RXTX 3u
+#define FW_PHY_ACT_SETUP_LINK_LP	(1u << 18)
+#define FW_PHY_ACT_SETUP_LINK_HP	(1u << 19)
+#define FW_PHY_ACT_SETUP_LINK_EEE	(1u << 20)
+#define FW_PHY_ACT_SETUP_LINK_AN	(1u << 22)
+#define FW_PHY_ACT_SETUP_LINK_RSP_DOWN	(1u << 0)
+#define FW_PHY_ACT_GET_LINK_INFO	3
+#define FW_PHY_ACT_GET_LINK_INFO_EEE	(1u << 19)
+#define FW_PHY_ACT_GET_LINK_INFO_FC_TX	(1u << 20)
+#define FW_PHY_ACT_GET_LINK_INFO_FC_RX	(1u << 21)
+#define FW_PHY_ACT_GET_LINK_INFO_POWER	(1u << 22)
+#define FW_PHY_ACT_GET_LINK_INFO_AN_COMPLETE	(1u << 24)
+#define FW_PHY_ACT_GET_LINK_INFO_TEMP	(1u << 25)
+#define FW_PHY_ACT_GET_LINK_INFO_LP_FC_TX	(1u << 28)
+#define FW_PHY_ACT_GET_LINK_INFO_LP_FC_RX	(1u << 29)
+#define FW_PHY_ACT_FORCE_LINK_DOWN	4
+#define FW_PHY_ACT_FORCE_LINK_DOWN_OFF	(1u << 0)
+#define FW_PHY_ACT_PHY_SW_RESET		5
+#define FW_PHY_ACT_PHY_HW_RESET		6
+#define FW_PHY_ACT_GET_PHY_INFO		7
+#define FW_PHY_ACT_UD_2			0x1002
+#define FW_PHY_ACT_UD_2_10G_KR_EEE	(1u << 6)
+#define FW_PHY_ACT_UD_2_10G_KX4_EEE	(1u << 5)
+#define FW_PHY_ACT_UD_2_1G_KX_EEE	(1u << 4)
+#define FW_PHY_ACT_UD_2_10G_T_EEE	(1u << 3)
+#define FW_PHY_ACT_UD_2_1G_T_EEE	(1u << 2)
+#define FW_PHY_ACT_UD_2_100M_TX_EEE	(1u << 1)
+#define FW_PHY_ACT_RETRIES		50
+#define FW_PHY_INFO_SPEED_MASK		0xFFFu
+#define FW_PHY_INFO_ID_HI_MASK		0xFFFF0000u
+#define FW_PHY_INFO_ID_LO_MASK		0x0000FFFFu
 
 /* Host Interface Command Structures */
 
+#pragma pack(push, 1)
+
 struct ixgbe_hic_hdr {
 	uint8_t cmd;
 	uint8_t buf_len;
@@ -2714,7 +3178,7 @@ struct ixgbe_hic_hdr2_req {
 struct ixgbe_hic_hdr2_rsp {
 	uint8_t cmd;
 	uint8_t buf_lenl;
-	uint8_t buf_lenh_status; /* 7-5: high bits of buf_len, 4-0: status */
+	uint8_t buf_lenh_status;	/* 7-5: high bits of buf_len, 4-0: status */
 	uint8_t checksum;
 };
 
@@ -2734,6 +3198,16 @@ struct ixgbe_hic_drv_info {
 	uint16_t pad2; /* end spacing to ensure length is mult. of dword2 */
 };
 
+struct ixgbe_hic_drv_info2 {
+	struct ixgbe_hic_hdr hdr;
+	uint8_t port_num;
+	uint8_t ver_sub;
+	uint8_t ver_build;
+	uint8_t ver_min;
+	uint8_t ver_maj;
+	char driver_string[FW_CEM_DRIVER_VERSION_SIZE];
+};
+
 /* These need to be dword aligned */
 struct ixgbe_hic_read_shadow_ram {
 	union ixgbe_hic_hdr2 hdr;
@@ -2760,37 +3234,59 @@ struct ixgbe_hic_disable_rxen {
 	uint16_t pad3;
 };
 
+struct ixgbe_hic_phy_token_req {
+	struct ixgbe_hic_hdr hdr;
+	uint8_t port_number;
+	uint8_t command_type;
+	uint16_t pad;
+};
+
 struct ixgbe_hic_internal_phy_req {
 	struct ixgbe_hic_hdr hdr;
 	uint8_t port_number;
 	uint8_t command_type;
-	uint16_t address;
+	__be16 address;
 	uint16_t rsv1;
-	uint32_t write_data;
+	__be32 write_data;
 	uint16_t pad;
 };
 
 struct ixgbe_hic_internal_phy_resp {
 	struct ixgbe_hic_hdr hdr;
-	uint32_t read_data;
+	__be32 read_data;
+};
+
+struct ixgbe_hic_phy_activity_req {
+	struct ixgbe_hic_hdr hdr;
+	uint8_t port_number;
+	uint8_t pad;
+	__le16 activity_id;
+	__be32 data[FW_PHY_ACT_DATA_COUNT];
+};
+
+struct ixgbe_hic_phy_activity_resp {
+	struct ixgbe_hic_hdr hdr;
+	__be32 data[FW_PHY_ACT_DATA_COUNT];
 };
 
+#pragma pack(pop)
+
 /* Transmit Descriptor - Legacy */
 struct ixgbe_legacy_tx_desc {
-	uint64_t buffer_addr;     /* Address of the descriptor's data buffer */
+	uint64_t buffer_addr; /* Address of the descriptor's data buffer */
 	union {
 		__le32 data;
 		struct {
-			__le16 length;    /* Data buffer length */
-			uint8_t cso;           /* Checksum offset */
-			uint8_t cmd;           /* Descriptor control */
+			__le16 length; /* Data buffer length */
+			uint8_t cso; /* Checksum offset */
+			uint8_t cmd; /* Descriptor control */
 		} flags;
 	} lower;
 	union {
 		__le32 data;
 		struct {
-			uint8_t status;        /* Descriptor status */
-			uint8_t css;           /* Checksum start */
+			uint8_t status; /* Descriptor status */
+			uint8_t css; /* Checksum start */
 			__le16 vlan;
 		} fields;
 	} upper;
@@ -2813,10 +3309,10 @@ union ixgbe_adv_tx_desc {
 /* Receive Descriptor - Legacy */
 struct ixgbe_legacy_rx_desc {
 	__le64 buffer_addr; /* Address of the descriptor's data buffer */
-	__le16 length;      /* Length of data DMAed into data buffer */
-	__le16 csum;        /* Packet checksum */
-	uint8_t status;     /* Descriptor status */
-	uint8_t errors;     /* Descriptor Errors */
+	__le16 length; /* Length of data DMAed into data buffer */
+	__le16 csum; /* Packet checksum */
+	uint8_t status;   /* Descriptor status */
+	uint8_t errors;   /* Descriptor Errors */
 	__le16 vlan;
 };
 
@@ -2899,6 +3395,7 @@ struct ixgbe_adv_tx_context_desc {
 #define IXGBE_ADVTXD_TUCMD_L4T_UDP	0x00000000 /* L4 Packet TYPE of UDP */
 #define IXGBE_ADVTXD_TUCMD_L4T_TCP	0x00000800 /* L4 Packet TYPE of TCP */
 #define IXGBE_ADVTXD_TUCMD_L4T_SCTP	0x00001000 /* L4 Packet TYPE of SCTP */
+#define IXGBE_ADVTXD_TUCMD_L4T_RSV	0x00001800 /* RSV L4 Packet TYPE */
 #define IXGBE_ADVTXD_TUCMD_MKRREQ	0x00002000 /* req Markers and CRC */
 #define IXGBE_ADVTXD_POPTS_IPSEC	0x00000400 /* IPSec offload request */
 #define IXGBE_ADVTXD_TUCMD_IPSEC_TYPE_ESP 0x00002000 /* IPSec Type ESP */
@@ -2921,12 +3418,14 @@ struct ixgbe_adv_tx_context_desc {
 #define IXGBE_ADVTXD_TUNNEL_TYPE_SHIFT	16 /* Adv Tx Desc Tunnel Type shift */
 #define IXGBE_ADVTXD_OUTERIPCS_SHIFT	17 /* Adv Tx Desc OUTERIPCS Shift */
 #define IXGBE_ADVTXD_TUNNEL_TYPE_NVGRE	1  /* Adv Tx Desc Tunnel Type NVGRE */
-
+/* Adv Tx Desc OUTERIPCS Shift for X550EM_a */
+#define IXGBE_ADVTXD_OUTERIPCS_SHIFT_X550EM_a	26
 /* Autonegotiation advertised speeds */
 typedef uint32_t ixgbe_autoneg_advertised;
 /* Link speed */
 typedef uint32_t ixgbe_link_speed;
 #define IXGBE_LINK_SPEED_UNKNOWN	0
+#define IXGBE_LINK_SPEED_10_FULL	0x0002
 #define IXGBE_LINK_SPEED_100_FULL	0x0008
 #define IXGBE_LINK_SPEED_1GB_FULL	0x0020
 #define IXGBE_LINK_SPEED_2_5GB_FULL	0x0400
@@ -2939,29 +3438,162 @@ typedef uint32_t ixgbe_link_speed;
 					 IXGBE_LINK_SPEED_10GB_FULL)
 
 /* Physical layer type */
-typedef uint32_t ixgbe_physical_layer;
+typedef uint64_t ixgbe_physical_layer;
 #define IXGBE_PHYSICAL_LAYER_UNKNOWN		0
-#define IXGBE_PHYSICAL_LAYER_10GBASE_T		0x0001
-#define IXGBE_PHYSICAL_LAYER_1000BASE_T		0x0002
-#define IXGBE_PHYSICAL_LAYER_100BASE_TX		0x0004
-#define IXGBE_PHYSICAL_LAYER_SFP_PLUS_CU	0x0008
-#define IXGBE_PHYSICAL_LAYER_10GBASE_LR		0x0010
-#define IXGBE_PHYSICAL_LAYER_10GBASE_LRM	0x0020
-#define IXGBE_PHYSICAL_LAYER_10GBASE_SR		0x0040
-#define IXGBE_PHYSICAL_LAYER_10GBASE_KX4	0x0080
-#define IXGBE_PHYSICAL_LAYER_10GBASE_CX4	0x0100
-#define IXGBE_PHYSICAL_LAYER_1000BASE_KX	0x0200
-#define IXGBE_PHYSICAL_LAYER_1000BASE_BX	0x0400
-#define IXGBE_PHYSICAL_LAYER_10GBASE_KR		0x0800
-#define IXGBE_PHYSICAL_LAYER_10GBASE_XAUI	0x1000
-#define IXGBE_PHYSICAL_LAYER_SFP_ACTIVE_DA	0x2000
-#define IXGBE_PHYSICAL_LAYER_1000BASE_SX	0x4000
-#define IXGBE_PHYSICAL_LAYER_1000BASE_LX	0x8000
+#define IXGBE_PHYSICAL_LAYER_10GBASE_T		0x00001
+#define IXGBE_PHYSICAL_LAYER_1000BASE_T		0x00002
+#define IXGBE_PHYSICAL_LAYER_100BASE_TX		0x00004
+#define IXGBE_PHYSICAL_LAYER_SFP_PLUS_CU	0x00008
+#define IXGBE_PHYSICAL_LAYER_10GBASE_LR		0x00010
+#define IXGBE_PHYSICAL_LAYER_10GBASE_LRM	0x00020
+#define IXGBE_PHYSICAL_LAYER_10GBASE_SR		0x00040
+#define IXGBE_PHYSICAL_LAYER_10GBASE_KX4	0x00080
+#define IXGBE_PHYSICAL_LAYER_10GBASE_CX4	0x00100
+#define IXGBE_PHYSICAL_LAYER_1000BASE_KX	0x00200
+#define IXGBE_PHYSICAL_LAYER_1000BASE_BX	0x00400
+#define IXGBE_PHYSICAL_LAYER_10GBASE_KR		0x00800
+#define IXGBE_PHYSICAL_LAYER_10GBASE_XAUI	0x01000
+#define IXGBE_PHYSICAL_LAYER_SFP_ACTIVE_DA	0x02000
+#define IXGBE_PHYSICAL_LAYER_1000BASE_SX	0x04000
+#define IXGBE_PHYSICAL_LAYER_10BASE_T		0x08000 /* deprecated ? */
+#define IXGBE_PHYSICAL_LAYER_1000BASE_LX  0x8000
+#define IXGBE_PHYSICAL_LAYER_2500BASE_KX	0x10000
 
 /* Flow Control Data Sheet defined values
  * Calculation and defines taken from 802.1bb Annex O
  */
 
+/* IXGBE - deprecated */
+#define IXGBE_TAF_SYM_PAUSE    0x400
+#define IXGBE_TAF_ASM_PAUSE    0x800
+#define IXGBE_ERR_MBX   -100
+#define IXGBE_I2C_EEPROM_DEV_ADDR2  0xA2
+#define IXGBE_SFF_SFF_8472_ESCB   0x76
+#define IXGBE_SFF_SOFT_RS_SELECT_10G  0x8
+#define IXGBE_SFF_SOFT_RS_SELECT_1G 0x0
+#define IXGBE_SFF_SFF_8472_OSCB   0x6E
+#define IXGBE_SFF_SOFT_RS_SELECT_MASK 0x8
+#define IXGBE_VFMAILBOX   0x002FC
+#define IXGBE_VFMAILBOX_SIZE  16
+#define IXGBE_VFMAILBOX_R2C_BITS  0x000000B0
+#define IXGBE_MBVFICR_VFREQ_VF1   0x00000001
+#define IXGBE_MBVFICR_VFACK_VF1   0x00010000
+#define IXGBE_PFMAILBOX_PFU 0x00000008
+#define IXGBE_PFMAILBOX_STS 0x00000001
+#define IXGBE_PFMAILBOX_ACK 0x00000002
+#define IXGBE_I2C_EEPROM_DEV_ADDR 0xA0
+#define IXGBE_I2C_EEPROM_READ_MASK  0x100
+#define IXGBE_I2C_EEPROM_STATUS_MASK  0x3
+#define IXGBE_I2C_EEPROM_STATUS_IN_PROGRESS 0x3
+#define IXGBE_I2C_EEPROM_STATUS_PASS  0x1
+#define IXGBE_CS4227      0xBE
+#define IXGBE_PE      0xE0
+#define IXGBE_PE_BIT1     (1 << 1)
+#define IXGBE_PE_OUTPUT     1 /* Output register offset */
+#define IXGBE_PE_CONFIG     3 /* Config register offset */
+#define IXGBE_CS4227_RESET_HOLD   500
+#define IXGBE_CS4227_RESET_DELAY  450
+#define IXGBE_CS4227_RETRIES    15
+#define IXGBE_CS4227_EFUSE_STATUS 0x0181
+#define IXGBE_CS4227_EEPROM_LOAD_OK 0x0001
+#define IXGBE_CS4227_CHECK_DELAY  30  /* milliseconds */
+#define IXGBE_CS4227_SCRATCH    2
+#define IXGBE_CS4227_EEPROM_STATUS  0x5001
+#define IXGBE_CS4227_RESET_COMPLETE 0x5AA5
+#define IXGBE_CS4227_RESET_PENDING  0x1357
+#define IXGBE_CS4227_LINE_SPARE22_MSB 0x12AD  /* Reg to program speed */
+#define IXGBE_CS4227_SPEED_10G    0
+#define IXGBE_CS4227_LINE_SPARE24_LSB 0x12B0
+#define IXGBE_CS4227_EDC_MODE_CX1  0x0002
+#define IXGBE_CS4227_EDC_MODE_SR 0x0004
+#define IXGBE_SFF_IDENTIFIER		0x0
+#define IXGBE_SFF_IDENTIFIER_SFP	0x3
+#define IXGBE_SFF_1GBE_COMP_CODES	0x6
+#define IXGBE_SFF_10GBE_COMP_CODES	0x3
+#define IXGBE_SFF_CABLE_TECHNOLOGY	0x8
+#define IXGBE_SFF_VENDOR_OUI_BYTE1	0x26
+#define IXGBE_SFF_VENDOR_OUI_BYTE2	0x27
+#define IXGBE_SFF_1GBASELX_CAPABLE	0x2
+#define IXGBE_SFF_1GBASET_CAPABLE	0x8
+#define IXGBE_SFF_10GBASESR_CAPABLE	0x10
+#define IXGBE_SFF_10GBASELR_CAPABLE	0x20
+#define IXGBE_SFF_DA_PASSIVE_CABLE	0x4
+#define IXGBE_SFF_DA_BAD_HP_CABLE	0x80
+#define IXGBE_SFF_DA_ACTIVE_CABLE	0x8
+#define IXGBE_SFF_CABLE_SPEC_COMP	0x3C
+#define IXGBE_SFF_DA_SPEC_ACTIVE_LIMITING	0x4
+#define IXGBE_SFF_1GBASESX_CAPABLE	0x1
+#define IXGBE_SFF_VENDOR_OUI_BYTE0	0x25
+#define IXGBE_SFF_VENDOR_OUI_BYTE1	0x26
+#define IXGBE_SFF_VENDOR_OUI_BYTE2	0x27
+#define IXGBE_SFF_VENDOR_OUI_BYTE0_SHIFT	24
+#define IXGBE_SFF_VENDOR_OUI_BYTE1_SHIFT	16
+#define IXGBE_SFF_VENDOR_OUI_BYTE2_SHIFT	8
+#define IXGBE_SFF_VENDOR_OUI_TYCO	0x00407600
+#define IXGBE_SFF_VENDOR_OUI_FTL	0x00906500
+#define IXGBE_SFF_QSFP_VENDOR_OUI_BYTE0	0xA5
+#define IXGBE_SFF_QSFP_VENDOR_OUI_BYTE1	0xA6
+#define IXGBE_SFF_QSFP_VENDOR_OUI_BYTE2	0xA7
+#define IXGBE_SFF_QSFP_CONNECTOR	0x82
+#define IXGBE_SFF_QSFP_10GBE_COMP	0x83
+#define IXGBE_SFF_QSFP_1GBE_COMP	0x86
+#define IXGBE_SFF_QSFP_CABLE_LENGTH	0x92
+#define IXGBE_SFF_QSFP_DEVICE_TECH	0x93
+#define IXGBE_SFF_VENDOR_OUI_FTL	0x00906500
+#define IXGBE_SFF_VENDOR_OUI_AVAGO	0x00176A00
+#define IXGBE_SFF_VENDOR_OUI_INTEL	0x001B2100
+#define IXGBE_SFF_IDENTIFIER		0x0
+#define IXGBE_SFF_IDENTIFIER_SFP	0x3
+#define IXGBE_SFF_VENDOR_OUI_BYTE0	0x25
+#define IXGBE_SFF_VENDOR_OUI_BYTE1	0x26
+#define IXGBE_SFF_VENDOR_OUI_BYTE2	0x27
+#define IXGBE_SFF_1GBE_COMP_CODES	0x6
+#define IXGBE_SFF_10GBE_COMP_CODES	0x3
+#define IXGBE_SFF_CABLE_TECHNOLOGY	0x8
+#define IXGBE_SFF_CABLE_SPEC_COMP	0x3C
+#define IXGBE_SFF_SFF_8472_SWAP		0x5C
+#define IXGBE_SFF_SFF_8472_COMP		0x5E
+#define IXGBE_SFF_SFF_8472_OSCB		0x6E
+#define IXGBE_SFF_SFF_8472_ESCB		0x76
+#define IXGBE_SFF_IDENTIFIER_QSFP_PLUS	0xD
+#define IXGBE_SFF_DA_PASSIVE_CABLE	0x4
+#define IXGBE_SFF_DA_ACTIVE_CABLE	0x8
+#define IXGBE_SFF_DA_SPEC_ACTIVE_LIMITING	0x4
+#define IXGBE_SFF_1GBASESX_CAPABLE	0x1
+#define IXGBE_SFF_1GBASELX_CAPABLE	0x2
+#define IXGBE_SFF_1GBASET_CAPABLE	0x8
+#define IXGBE_SFF_10GBASESR_CAPABLE	0x10
+#define IXGBE_SFF_10GBASELR_CAPABLE	0x20
+#define IXGBE_SFF_DA_BAD_HP_CABLE	0x80
+#define IXGBE_SFF_SOFT_RS_SELECT_MASK	0x8
+#define IXGBE_SFF_SOFT_RS_SELECT_10G	0x8
+#define IXGBE_SFF_SOFT_RS_SELECT_1G	0x0
+#define IXGBE_SFF_ADDRESSING_MODE	0x4
+#define IXGBE_SFF_QSFP_DA_ACTIVE_CABLE	0x1
+#define IXGBE_SFF_QSFP_DA_PASSIVE_CABLE	0x8
+#define IXGBE_SFF_QSFP_CONNECTOR_NOT_SEPARABLE	0x23
+#define IXGBE_SFF_QSFP_TRANSMITER_850NM_VCSEL	0x0
+#define IXGBE_I2C_EEPROM_READ_MASK	0x100
+#define IXGBE_I2C_EEPROM_STATUS_MASK	0x3
+#define IXGBE_I2C_EEPROM_STATUS_NO_OPERATION	0x0
+#define IXGBE_I2C_EEPROM_STATUS_PASS	0x1
+#define IXGBE_I2C_EEPROM_STATUS_FAIL	0x2
+#define IXGBE_I2C_EEPROM_STATUS_IN_PROGRESS	0x3
+#define IXGBE_SFP_DETECT_RETRIES	10
+#define IXGBE_I2C_T_HD_STA	4
+#define IXGBE_I2C_T_LOW		5
+#define IXGBE_I2C_T_HIGH	4
+#define IXGBE_I2C_T_SU_STA	5
+#define IXGBE_I2C_T_HD_DATA	5
+#define IXGBE_I2C_T_SU_DATA	1
+#define IXGBE_I2C_T_RISE	1
+#define IXGBE_I2C_T_FALL	1
+#define IXGBE_I2C_T_SU_STO	4
+#define IXGBE_I2C_T_BUF		5
+#define IXGBE_TN_LASI_STATUS_REG	0x9005
+#define IXGBE_TN_LASI_STATUS_TEMP_ALARM	0x0008
+
+
 /* BitTimes (BT) conversion */
 #define IXGBE_BT2KB(BT)		((BT + (8 * 1024 - 1)) / (8 * 1024))
 #define IXGBE_B2BT(BT)		(BT * 8)
@@ -3103,6 +3735,37 @@ union ixgbe_atr_hash_dword {
 };
 
 
+#define IXGBE_MVALS_INIT(m)	\
+	IXGBE_CAT(EEC, m),		\
+	IXGBE_CAT(FLA, m),		\
+	IXGBE_CAT(GRC, m),		\
+	IXGBE_CAT(SRAMREL, m),		\
+	IXGBE_CAT(FACTPS, m),		\
+	IXGBE_CAT(SWSM, m),		\
+	IXGBE_CAT(SWFW_SYNC, m),	\
+	IXGBE_CAT(FWSM, m),		\
+	IXGBE_CAT(SDP0_GPIEN, m),	\
+	IXGBE_CAT(SDP1_GPIEN, m),	\
+	IXGBE_CAT(SDP2_GPIEN, m),	\
+	IXGBE_CAT(EICR_GPI_SDP0, m),	\
+	IXGBE_CAT(EICR_GPI_SDP1, m),	\
+	IXGBE_CAT(EICR_GPI_SDP2, m),	\
+	IXGBE_CAT(CIAA, m),		\
+	IXGBE_CAT(CIAD, m),		\
+	IXGBE_CAT(I2C_CLK_IN, m),	\
+	IXGBE_CAT(I2C_CLK_OUT, m),	\
+	IXGBE_CAT(I2C_DATA_IN, m),	\
+	IXGBE_CAT(I2C_DATA_OUT, m),	\
+	IXGBE_CAT(I2C_DATA_OE_N_EN, m),	\
+	IXGBE_CAT(I2C_BB_EN, m),	\
+	IXGBE_CAT(I2C_CLK_OE_N_EN, m),	\
+	IXGBE_CAT(I2CCTL, m)
+
+enum ixgbe_mvals {
+	IXGBE_MVALS_INIT(_IDX),
+	IXGBE_MVALS_IDX_LIMIT
+};
+
 /*
  * Unavailable: The FCoE Boot Option ROM is not present in the flash.
  * Disabled: Present; boot order is not set for any targets on the port.
@@ -3130,8 +3793,10 @@ enum ixgbe_mac_type {
 	ixgbe_mac_X540_vf,
 	ixgbe_mac_X550,
 	ixgbe_mac_X550EM_x,
+	ixgbe_mac_X550EM_a,
 	ixgbe_mac_X550_vf,
 	ixgbe_mac_X550EM_x_vf,
+	ixgbe_mac_X550EM_a_vf,
 	ixgbe_num_macs
 };
 
@@ -3142,7 +3807,9 @@ enum ixgbe_phy_type {
 	ixgbe_phy_aq,
 	ixgbe_phy_x550em_kr,
 	ixgbe_phy_x550em_kx4,
+	ixgbe_phy_x550em_xfi,
 	ixgbe_phy_x550em_ext_t,
+	ixgbe_phy_ext_1g_t,
 	ixgbe_phy_cu_unknown,
 	ixgbe_phy_qt,
 	ixgbe_phy_xaui,
@@ -3160,6 +3827,8 @@ enum ixgbe_phy_type {
 	ixgbe_phy_qsfp_intel,
 	ixgbe_phy_qsfp_unknown,
 	ixgbe_phy_sfp_unsupported, /*Enforce bit set with unsupported module*/
+	ixgbe_phy_sgmii,
+	ixgbe_phy_fw,
 	ixgbe_phy_generic
 };
 
@@ -3275,7 +3944,8 @@ struct ixgbe_bus_info {
 	enum ixgbe_bus_type type;
 
 	uint16_t func;
-	uint16_t lan_id;
+	uint8_t lan_id;
+	uint16_t instance_id;
 };
 
 /* Flow control parameters */
@@ -3375,15 +4045,16 @@ struct ixgbe_hw_stats {
 struct ixgbe_hw;
 
 /* iterator type for walking multicast address lists */
-typedef uint8_t* (*ixgbe_mc_addr_itr)(struct ixgbe_hw *hw,
-				      uint8_t **mc_addr_ptr,
-				      uint32_t *vmdq);
+typedef uint8_t* (*ixgbe_mc_addr_itr) (struct ixgbe_hw *hw, uint8_t **mc_addr_ptr,
+				  uint32_t *vmdq);
 
 /* Function pointer table */
 struct ixgbe_eeprom_operations {
 	int32_t (*init_params)(struct ixgbe_hw *);
 	int32_t (*read)(struct ixgbe_hw *, uint16_t, uint16_t *);
+	int32_t (*read_buffer)(struct ixgbe_hw *, uint16_t, uint16_t, uint16_t *);
 	int32_t (*write)(struct ixgbe_hw *, uint16_t, uint16_t);
+	int32_t (*write_buffer)(struct ixgbe_hw *, uint16_t, uint16_t, uint16_t *);
 	int32_t (*validate_checksum)(struct ixgbe_hw *, uint16_t *);
 	int32_t (*update_checksum)(struct ixgbe_hw *);
 	int32_t (*calc_checksum)(struct ixgbe_hw *);
@@ -3394,11 +4065,18 @@ struct ixgbe_mac_operations {
 	int32_t (*reset_hw)(struct ixgbe_hw *);
 	int32_t (*start_hw)(struct ixgbe_hw *);
 	int32_t (*clear_hw_cntrs)(struct ixgbe_hw *);
+	void (*enable_relaxed_ordering)(struct ixgbe_hw *);
 	enum ixgbe_media_type (*get_media_type)(struct ixgbe_hw *);
-	uint32_t (*get_supported_physical_layer)(struct ixgbe_hw *);
+	uint64_t (*get_supported_physical_layer)(struct ixgbe_hw *);
 	int32_t (*get_mac_addr)(struct ixgbe_hw *, uint8_t *);
+	int32_t (*get_san_mac_addr)(struct ixgbe_hw *, uint8_t *);
+	int32_t (*set_san_mac_addr)(struct ixgbe_hw *, uint8_t *);
+	int32_t (*get_device_caps)(struct ixgbe_hw *, uint16_t *);
+	int32_t (*get_wwn_prefix)(struct ixgbe_hw *, uint16_t *, uint16_t *);
+	int32_t (*get_fcoe_boot_status)(struct ixgbe_hw *, uint16_t *);
 	int32_t (*stop_adapter)(struct ixgbe_hw *);
 	int32_t (*get_bus_info)(struct ixgbe_hw *);
+	int32_t (*negotiate_api_version)(struct ixgbe_hw *, int);
 	void (*set_lan_id)(struct ixgbe_hw *);
 	int32_t (*read_analog_reg8)(struct ixgbe_hw*, uint32_t, uint8_t*);
 	int32_t (*write_analog_reg8)(struct ixgbe_hw*, uint32_t, uint8_t);
@@ -3408,6 +4086,7 @@ struct ixgbe_mac_operations {
 	int32_t (*enable_sec_rx_path)(struct ixgbe_hw *);
 	int32_t (*acquire_swfw_sync)(struct ixgbe_hw *, uint32_t);
 	void (*release_swfw_sync)(struct ixgbe_hw *, uint32_t);
+	void (*init_swfw_sync)(struct ixgbe_hw *);
 	int32_t (*prot_autoc_read)(struct ixgbe_hw *, bool *, uint32_t *);
 	int32_t (*prot_autoc_write)(struct ixgbe_hw *, uint32_t, bool);
 
@@ -3419,29 +4098,40 @@ struct ixgbe_mac_operations {
 	int32_t (*setup_mac_link)(struct ixgbe_hw *, ixgbe_link_speed, bool);
 	int32_t (*check_link)(struct ixgbe_hw *, ixgbe_link_speed *, bool *, bool);
 	int32_t (*get_link_capabilities)(struct ixgbe_hw *, ixgbe_link_speed *,
-					 bool *);
+				     bool *);
 	void (*set_rate_select_speed)(struct ixgbe_hw *, ixgbe_link_speed);
 
+	/* Packet Buffer manipulation */
+	void (*setup_rxpba)(struct ixgbe_hw *, int, uint32_t, int);
+
 	/* LED */
 	int32_t (*led_on)(struct ixgbe_hw *, uint32_t);
 	int32_t (*led_off)(struct ixgbe_hw *, uint32_t);
 	int32_t (*blink_led_start)(struct ixgbe_hw *, uint32_t);
 	int32_t (*blink_led_stop)(struct ixgbe_hw *, uint32_t);
+	int32_t (*init_led_link_act)(struct ixgbe_hw *);
 
 	/* RAR, Multicast, VLAN */
 	int32_t (*set_rar)(struct ixgbe_hw *, uint32_t, uint8_t *, uint32_t, uint32_t);
+	int32_t (*set_uc_addr)(struct ixgbe_hw *, uint32_t, uint8_t *);
 	int32_t (*clear_rar)(struct ixgbe_hw *, uint32_t);
 	int32_t (*insert_mac_addr)(struct ixgbe_hw *, uint8_t *, uint32_t);
 	int32_t (*set_vmdq)(struct ixgbe_hw *, uint32_t, uint32_t);
+	int32_t (*set_vmdq_san_mac)(struct ixgbe_hw *, uint32_t);
 	int32_t (*clear_vmdq)(struct ixgbe_hw *, uint32_t, uint32_t);
 	int32_t (*init_rx_addrs)(struct ixgbe_hw *);
+	int32_t (*update_uc_addr_list)(struct ixgbe_hw *, uint8_t *, uint32_t,
+				   ixgbe_mc_addr_itr);
 	int32_t (*update_mc_addr_list)(struct ixgbe_hw *, uint8_t *, uint32_t,
-				       ixgbe_mc_addr_itr, bool clear);
+				   ixgbe_mc_addr_itr, bool clear);
+	int32_t (*update_xcast_mode)(struct ixgbe_hw *, int);
 	int32_t (*enable_mc)(struct ixgbe_hw *);
 	int32_t (*disable_mc)(struct ixgbe_hw *);
 	int32_t (*clear_vfta)(struct ixgbe_hw *);
-	int32_t (*set_vfta)(struct ixgbe_hw *, uint32_t, uint32_t, bool);
-	int32_t (*set_vlvf)(struct ixgbe_hw *, uint32_t, uint32_t, bool, bool *);
+	int32_t (*set_vfta)(struct ixgbe_hw *, uint32_t, uint32_t, bool, bool);
+	int32_t (*set_vlvf)(struct ixgbe_hw *, uint32_t, uint32_t, bool, uint32_t *, uint32_t,
+			bool);
+	int32_t (*set_rlpml)(struct ixgbe_hw *, uint16_t);
 	int32_t (*init_uta_tables)(struct ixgbe_hw *);
 	void (*set_mac_anti_spoofing)(struct ixgbe_hw *, bool, int);
 	void (*set_vlan_anti_spoofing)(struct ixgbe_hw *, bool, int);
@@ -3449,13 +4139,32 @@ struct ixgbe_mac_operations {
 	/* Flow Control */
 	int32_t (*fc_enable)(struct ixgbe_hw *);
 	int32_t (*setup_fc)(struct ixgbe_hw *);
+	void (*fc_autoneg)(struct ixgbe_hw *);
 
 	/* Manageability interface */
+	int32_t (*set_fw_drv_ver)(struct ixgbe_hw *, uint8_t, uint8_t, uint8_t, uint8_t, uint16_t,
+			      const char *);
+	int32_t (*bypass_rw) (struct ixgbe_hw *hw, uint32_t cmd, uint32_t *status);
+	bool (*bypass_valid_rd) (uint32_t in_reg, uint32_t out_reg);
+	int32_t (*bypass_set) (struct ixgbe_hw *hw, uint32_t cmd, uint32_t event, uint32_t action);
+	int32_t (*bypass_rd_eep) (struct ixgbe_hw *hw, uint32_t addr, uint8_t *value);
+	void (*get_rtrup2tc)(struct ixgbe_hw *hw, uint8_t *map);
 	void (*disable_rx)(struct ixgbe_hw *hw);
 	void (*enable_rx)(struct ixgbe_hw *hw);
-
-	/* Misc */
-	void (*stop_mac_link_on_d3)(struct ixgbe_hw *);
+  void (*stop_mac_link_on_d3)(struct ixgbe_hw *);
+	void (*set_source_address_pruning)(struct ixgbe_hw *, bool,
+					   unsigned int);
+	void (*set_ethertype_anti_spoofing)(struct ixgbe_hw *, bool, int);
+	int32_t (*dmac_update_tcs)(struct ixgbe_hw *hw);
+	int32_t (*dmac_config_tcs)(struct ixgbe_hw *hw);
+	int32_t (*dmac_config)(struct ixgbe_hw *hw);
+	int32_t (*setup_eee)(struct ixgbe_hw *hw, bool enable_eee);
+	int32_t (*read_iosf_sb_reg)(struct ixgbe_hw *, uint32_t, uint32_t, uint32_t *);
+	int32_t (*write_iosf_sb_reg)(struct ixgbe_hw *, uint32_t, uint32_t, uint32_t);
+	void (*disable_mdd)(struct ixgbe_hw *hw);
+	void (*enable_mdd)(struct ixgbe_hw *hw);
+	void (*mdd_event)(struct ixgbe_hw *hw, uint32_t *vf_bitmap);
+	void (*restore_mdd_vf)(struct ixgbe_hw *hw, uint32_t vf);
 };
 
 struct ixgbe_phy_operations {
@@ -3474,22 +4183,40 @@ struct ixgbe_phy_operations {
 	int32_t (*get_firmware_version)(struct ixgbe_hw *, uint16_t *);
 	int32_t (*read_i2c_byte)(struct ixgbe_hw *, uint8_t, uint8_t, uint8_t *);
 	int32_t (*write_i2c_byte)(struct ixgbe_hw *, uint8_t, uint8_t, uint8_t);
+	int32_t (*read_i2c_sff8472)(struct ixgbe_hw *, uint8_t , uint8_t *);
 	int32_t (*read_i2c_eeprom)(struct ixgbe_hw *, uint8_t , uint8_t *);
 	int32_t (*write_i2c_eeprom)(struct ixgbe_hw *, uint8_t, uint8_t);
 	void (*i2c_bus_clear)(struct ixgbe_hw *);
-	int32_t (*read_i2c_combined)(struct ixgbe_hw *, uint8_t addr, uint16_t reg, uint16_t *val);
+	/*depreatced*/
+	int32_t (*read_i2c_combined)(struct ixgbe_hw *, uint8_t addr, uint16_t reg, uint16_t *val); 
 	int32_t (*write_i2c_combined)(struct ixgbe_hw *, uint8_t addr, uint16_t reg, uint16_t val);
-	int32_t (*check_overtemp)(struct ixgbe_hw *);
-	int32_t (*set_phy_power)(struct ixgbe_hw *, bool on);
-	int32_t (*handle_lasi)(struct ixgbe_hw *hw);
 	int32_t (*read_i2c_combined_unlocked)(struct ixgbe_hw *, uint8_t addr, uint16_t reg,
 					      uint16_t *value);
 	int32_t (*write_i2c_combined_unlocked)(struct ixgbe_hw *, uint8_t addr, uint16_t reg,
 					       uint16_t value);
+	/**/
+	int32_t (*check_overtemp)(struct ixgbe_hw *);
+	int32_t (*set_phy_power)(struct ixgbe_hw *, bool on);
+	int32_t (*enter_lplu)(struct ixgbe_hw *);
+	int32_t (*handle_lasi)(struct ixgbe_hw *hw);
 	int32_t (*read_i2c_byte_unlocked)(struct ixgbe_hw *, uint8_t offset, uint8_t addr,
-					  uint8_t *value);
+				      uint8_t *value);
 	int32_t (*write_i2c_byte_unlocked)(struct ixgbe_hw *, uint8_t offset, uint8_t addr,
-					   uint8_t value);
+				       uint8_t value);
+};
+
+struct ixgbe_link_operations {
+	int32_t (*read_link)(struct ixgbe_hw *, uint8_t addr, uint16_t reg, uint16_t *val);
+	int32_t (*read_link_unlocked)(struct ixgbe_hw *, uint8_t addr, uint16_t reg,
+				  uint16_t *val);
+	int32_t (*write_link)(struct ixgbe_hw *, uint8_t addr, uint16_t reg, uint16_t val);
+	int32_t (*write_link_unlocked)(struct ixgbe_hw *, uint8_t addr, uint16_t reg,
+				   uint16_t val);
+};
+
+struct ixgbe_link_info {
+	struct ixgbe_link_operations ops;
+	uint8_t addr;
 };
 
 struct ixgbe_eeprom_info {
@@ -3508,6 +4235,11 @@ struct ixgbe_mac_info {
 	enum ixgbe_mac_type type;
 	uint8_t addr[IXGBE_ETH_LENGTH_OF_ADDRESS];
 	uint8_t perm_addr[IXGBE_ETH_LENGTH_OF_ADDRESS];
+	uint8_t san_addr[IXGBE_ETH_LENGTH_OF_ADDRESS];
+	/* prefix for World Wide Node Name (WWNN) */
+	uint16_t wwnn_prefix;
+	/* prefix for World Wide Port Name (WWPN) */
+	uint16_t wwpn_prefix;
 #define IXGBE_MAX_MTA			128
 	uint32_t mta_shadow[IXGBE_MAX_MTA];
 	int32_t mc_filter_type;
@@ -3519,14 +4251,18 @@ struct ixgbe_mac_info {
 	uint32_t max_tx_queues;
 	uint32_t max_rx_queues;
 	uint32_t orig_autoc;
+	uint8_t  san_mac_rar_index;
 	bool get_link_status;
 	uint32_t orig_autoc2;
-	uint32_t max_msix_vectors;
-	int msix_vectors_from_pcie;
+	uint16_t max_msix_vectors;
+	bool arc_subsystem_valid;
 	bool orig_link_settings_stored;
 	bool autotry_restart;
 	uint8_t flags;
+	struct ixgbe_dmac_config dmac_config;
+	bool set_lben;
 	uint32_t  max_link_up_time;
+	uint8_t   led_link_act;
 };
 
 struct ixgbe_phy_info {
@@ -3542,6 +4278,8 @@ struct ixgbe_phy_info {
 	bool reset_disable;
 	ixgbe_autoneg_advertised autoneg_advertised;
 	ixgbe_link_speed speeds_supported;
+	ixgbe_link_speed eee_speeds_supported;
+	ixgbe_link_speed eee_speeds_advertised;
 	enum ixgbe_smart_speed smart_speed;
 	bool smart_speed_active;
 	bool multispeed_fiber;
@@ -3550,93 +4288,7 @@ struct ixgbe_phy_info {
 	uint32_t nw_mng_if_sel;
 };
 
-/* MBX */
-#define IXGBE_VFMAILBOX_SIZE	16 /* 16 32 bit words - 64 bytes */
-#define IXGBE_ERR_MBX		-100
-
-#define IXGBE_VFMAILBOX		0x002FC
-#define IXGBE_VFMBMEM		0x00200
-
-/* Define mailbox register bits */
-#define IXGBE_VFMAILBOX_REQ	0x00000001 /* Request for PF Ready bit */
-#define IXGBE_VFMAILBOX_ACK	0x00000002 /* Ack PF message received */
-#define IXGBE_VFMAILBOX_VFU	0x00000004 /* VF owns the mailbox buffer */
-#define IXGBE_VFMAILBOX_PFU	0x00000008 /* PF owns the mailbox buffer */
-#define IXGBE_VFMAILBOX_PFSTS	0x00000010 /* PF wrote a message in the MB */
-#define IXGBE_VFMAILBOX_PFACK	0x00000020 /* PF ack the previous VF msg */
-#define IXGBE_VFMAILBOX_RSTI	0x00000040 /* PF has reset indication */
-#define IXGBE_VFMAILBOX_RSTD	0x00000080 /* PF has indicated reset done */
-#define IXGBE_VFMAILBOX_R2C_BITS	0x000000B0 /* All read to clear bits */
-
-#define IXGBE_PFMAILBOX_STS	0x00000001 /* Initiate message send to VF */
-#define IXGBE_PFMAILBOX_ACK	0x00000002 /* Ack message recv'd from VF */
-#define IXGBE_PFMAILBOX_VFU	0x00000004 /* VF owns the mailbox buffer */
-#define IXGBE_PFMAILBOX_PFU	0x00000008 /* PF owns the mailbox buffer */
-#define IXGBE_PFMAILBOX_RVFU	0x00000010 /* Reset VFU - used when VF stuck */
-
-#define IXGBE_MBVFICR_VFREQ_MASK	0x0000FFFF /* bits for VF messages */
-#define IXGBE_MBVFICR_VFREQ_VF1		0x00000001 /* bit for VF 1 message */
-#define IXGBE_MBVFICR_VFACK_MASK	0xFFFF0000 /* bits for VF acks */
-#define IXGBE_MBVFICR_VFACK_VF1		0x00010000 /* bit for VF 1 ack */
-
-
-/* If it's a IXGBE_VF_* msg then it originates in the VF and is sent to the
- * PF.  The reverse is TRUE if it is IXGBE_PF_*.
- * Message ACK's are the value or'd with 0xF0000000
- */
-#define IXGBE_VT_MSGTYPE_ACK	0x80000000 /* Messages below or'd with
-					    * this are the ACK */
-#define IXGBE_VT_MSGTYPE_NACK	0x40000000 /* Messages below or'd with
-					    * this are the NACK */
-#define IXGBE_VT_MSGTYPE_CTS	0x20000000 /* Indicates that VF is still
-					    * clear to send requests */
-#define IXGBE_VT_MSGINFO_SHIFT	16
-/* bits 23:16 are used for extra info for certain messages */
-#define IXGBE_VT_MSGINFO_MASK	(0xFF << IXGBE_VT_MSGINFO_SHIFT)
-
-#define IXGBE_VF_RESET		0x01 /* VF requests reset */
-#define IXGBE_VF_SET_MAC_ADDR	0x02 /* VF requests PF to set MAC addr */
-#define IXGBE_VF_SET_MULTICAST	0x03 /* VF requests PF to set MC addr */
-#define IXGBE_VF_SET_VLAN	0x04 /* VF requests PF to set VLAN */
-
-/* mailbox API, version 1.0 VF requests */
-#define IXGBE_VF_SET_LPE	0x05 /* VF requests PF to set VMOLR.LPE */
-#define IXGBE_VF_SET_MACVLAN	0x06 /* VF requests PF for unicast filter */
-#define IXGBE_VF_API_NEGOTIATE	0x08 /* negotiate API version */
-
-/* mailbox API, version 1.1 VF requests */
-#define IXGBE_VF_GET_QUEUES	0x09 /* get queue configuration */
-
-/* GET_QUEUES return data indices within the mailbox */
-#define IXGBE_VF_TX_QUEUES	1	/* number of Tx queues supported */
-#define IXGBE_VF_RX_QUEUES	2	/* number of Rx queues supported */
-#define IXGBE_VF_TRANS_VLAN	3	/* Indication of port vlan */
-#define IXGBE_VF_DEF_QUEUE	4	/* Default queue offset */
-
-/* length of permanent address message returned from PF */
-#define IXGBE_VF_PERMADDR_MSG_LEN	4
-/* word in permanent address message with the current multicast type */
-#define IXGBE_VF_MC_TYPE_WORD		3
-
-#define IXGBE_PF_CONTROL_MSG		0x0100 /* PF control message */
-
-/* mailbox API, version 2.0 VF requests */
-#define IXGBE_VF_API_NEGOTIATE		0x08 /* negotiate API version */
-#define IXGBE_VF_GET_QUEUES		0x09 /* get queue configuration */
-#define IXGBE_VF_ENABLE_MACADDR		0x0A /* enable MAC address */
-#define IXGBE_VF_DISABLE_MACADDR	0x0B /* disable MAC address */
-#define IXGBE_VF_GET_MACADDRS		0x0C /* get all configured MAC addrs */
-#define IXGBE_VF_SET_MCAST_PROMISC	0x0D /* enable multicast promiscuous */
-#define IXGBE_VF_GET_MTU		0x0E /* get bounds on MTU */
-#define IXGBE_VF_SET_MTU		0x0F /* set a specific MTU */
-
-/* mailbox API, version 2.0 PF requests */
-#define IXGBE_PF_TRANSPARENT_VLAN	0x0101 /* enable transparent vlan */
-
-#define IXGBE_VF_MBX_INIT_TIMEOUT	2000 /* number of retries on mailbox */
-#define IXGBE_VF_MBX_INIT_DELAY		500  /* microseconds between retries */
-
-/* end MBX */
+// #include "ixgbe_mbx.h"
 
 struct ixgbe_mbx_operations {
 	void (*init_params)(struct ixgbe_hw *hw);
@@ -3668,15 +4320,17 @@ struct ixgbe_mbx_info {
 };
 
 struct ixgbe_hw {
-	uint8_t *hw_addr;
+	uint8_t IOMEM *hw_addr;
 	void *back;
 	struct ixgbe_mac_info mac;
 	struct ixgbe_addr_filter_info addr_ctrl;
 	struct ixgbe_fc_info fc;
 	struct ixgbe_phy_info phy;
+	struct ixgbe_link_info link;
 	struct ixgbe_eeprom_info eeprom;
 	struct ixgbe_bus_info bus;
 	struct ixgbe_mbx_info mbx;
+	const uint32_t *mvals;
 	uint16_t device_id;
 	uint16_t vendor_id;
 	uint16_t subsystem_device_id;
@@ -3685,8 +4339,15 @@ struct ixgbe_hw {
 	bool adapter_stopped;
 	int api_version;
 	bool force_full_reset;
+	bool allow_unsupported_sfp;
+	bool wol_enabled;
+	bool need_crosstalk_fix;
 };
 
+#define ixgbe_call_func(hw, func, params, error) \
+		(func != NULL) ? func params : error
+
+
 /* Error Codes */
 #define IXGBE_SUCCESS				0
 #define IXGBE_ERR_EEPROM			-1
@@ -3722,43 +4383,176 @@ struct ixgbe_hw {
 #define IXGBE_ERR_INVALID_ARGUMENT		-32
 #define IXGBE_ERR_HOST_INTERFACE_COMMAND	-33
 #define IXGBE_ERR_OUT_OF_MEM			-34
+#define IXGBE_BYPASS_FW_WRITE_FAILURE		-35
 #define IXGBE_ERR_FEATURE_NOT_SUPPORTED		-36
 #define IXGBE_ERR_EEPROM_PROTECTED_REGION	-37
 #define IXGBE_ERR_FDIR_CMD_INCOMPLETE		-38
+#define IXGBE_ERR_FW_RESP_INVALID		-39
+#define IXGBE_ERR_TOKEN_RETRY			-40
 
 #define IXGBE_NOT_IMPLEMENTED			0x7FFFFFFF
 
+
+#define BYPASS_PAGE_CTL0	0x00000000
+#define BYPASS_PAGE_CTL1	0x40000000
+#define BYPASS_PAGE_CTL2	0x80000000
+#define BYPASS_PAGE_M		0xc0000000
+#define BYPASS_WE		0x20000000
+
+#define BYPASS_AUTO	0x0
+#define BYPASS_NOP	0x0
+#define BYPASS_NORM	0x1
+#define BYPASS_BYPASS	0x2
+#define BYPASS_ISOLATE	0x3
+
+#define BYPASS_EVENT_MAIN_ON	0x1
+#define BYPASS_EVENT_AUX_ON	0x2
+#define BYPASS_EVENT_MAIN_OFF	0x3
+#define BYPASS_EVENT_AUX_OFF	0x4
+#define BYPASS_EVENT_WDT_TO	0x5
+#define BYPASS_EVENT_USR	0x6
+
+#define BYPASS_MODE_OFF_M	0x00000003
+#define BYPASS_STATUS_OFF_M	0x0000000c
+#define BYPASS_AUX_ON_M		0x00000030
+#define BYPASS_MAIN_ON_M	0x000000c0
+#define BYPASS_MAIN_OFF_M	0x00000300
+#define BYPASS_AUX_OFF_M	0x00000c00
+#define BYPASS_WDTIMEOUT_M	0x00003000
+#define BYPASS_WDT_ENABLE_M	0x00004000
+#define BYPASS_WDT_VALUE_M	0x00070000
+
+#define BYPASS_MODE_OFF_SHIFT	0
+#define BYPASS_STATUS_OFF_SHIFT	2
+#define BYPASS_AUX_ON_SHIFT	4
+#define BYPASS_MAIN_ON_SHIFT	6
+#define BYPASS_MAIN_OFF_SHIFT	8
+#define BYPASS_AUX_OFF_SHIFT	10
+#define BYPASS_WDTIMEOUT_SHIFT	12
+#define BYPASS_WDT_ENABLE_SHIFT	14
+#define BYPASS_WDT_TIME_SHIFT	16
+
+#define BYPASS_WDT_1	0x0
+#define BYPASS_WDT_1_5	0x1
+#define BYPASS_WDT_2	0x2
+#define BYPASS_WDT_3	0x3
+#define BYPASS_WDT_4	0x4
+#define BYPASS_WDT_8	0x5
+#define BYPASS_WDT_16	0x6
+#define BYPASS_WDT_32	0x7
+#define BYPASS_WDT_OFF	0xffff
+
+#define BYPASS_CTL1_TIME_M	0x01ffffff
+#define BYPASS_CTL1_VALID_M	0x02000000
+#define BYPASS_CTL1_OFFTRST_M	0x04000000
+#define BYPASS_CTL1_WDT_PET_M	0x08000000
+
+#define BYPASS_CTL1_VALID	0x02000000
+#define BYPASS_CTL1_OFFTRST	0x04000000
+#define BYPASS_CTL1_WDT_PET	0x08000000
+
+#define BYPASS_CTL2_DATA_M	0x000000ff
+#define BYPASS_CTL2_OFFSET_M	0x0000ff00
+#define BYPASS_CTL2_RW_M	0x00010000
+#define BYPASS_CTL2_HEAD_M	0x0ff00000
+
+#define BYPASS_CTL2_OFFSET_SHIFT	8
+#define BYPASS_CTL2_HEAD_SHIFT		20
+
+#define BYPASS_CTL2_RW		0x00010000
+
+struct ixgbe_bypass_eeprom {
+	uint32_t logs;
+	uint32_t clear_off;
+	uint8_t actions;
+};
+
+#define BYPASS_MAX_LOGS		43
+#define BYPASS_LOG_SIZE		5
+#define BYPASS_LOG_LINE_SIZE	37
+
+#define BYPASS_EEPROM_VER_ADD	0x02
+
+#define BYPASS_LOG_TIME_M	0x01ffffff
+#define BYPASS_LOG_TIME_VALID_M	0x02000000
+#define BYPASS_LOG_HEAD_M	0x04000000
+#define BYPASS_LOG_CLEAR_M	0x08000000
+#define BYPASS_LOG_EVENT_M	0xf0000000
+#define BYPASS_LOG_ACTION_M	0x03
+
+#define BYPASS_LOG_EVENT_SHIFT	28
+#define BYPASS_LOG_CLEAR_SHIFT	24 /* bit offset */
+
 #define IXGBE_FUSES0_GROUP(_i)		(0x11158 + ((_i) * 4))
 #define IXGBE_FUSES0_300MHZ		(1 << 5)
-#define IXGBE_FUSES0_REV1		(1 << 6)
+#define IXGBE_FUSES0_REV_MASK		(3 << 6)
 
 #define IXGBE_KRM_PORT_CAR_GEN_CTRL(P)	((P) ? 0x8010 : 0x4010)
+#define IXGBE_KRM_LINK_S1(P)		((P) ? 0x8200 : 0x4200)
 #define IXGBE_KRM_LINK_CTRL_1(P)	((P) ? 0x820C : 0x420C)
 #define IXGBE_KRM_AN_CNTL_1(P)		((P) ? 0x822C : 0x422C)
+#define IXGBE_KRM_AN_CNTL_4(P)		((P) ? 0x8238 : 0x4238)
+#define IXGBE_KRM_AN_CNTL_8(P)		((P) ? 0x8248 : 0x4248)
+#define IXGBE_KRM_PCS_KX_AN(P)		((P) ? 0x9918 : 0x5918)
+#define IXGBE_KRM_PCS_KX_AN_LP(P)	((P) ? 0x991C : 0x591C)
+#define IXGBE_KRM_SGMII_CTRL(P)		((P) ? 0x82A0 : 0x42A0)
+#define IXGBE_KRM_LP_BASE_PAGE_HIGH(P)	((P) ? 0x836C : 0x436C)
 #define IXGBE_KRM_DSP_TXFFE_STATE_4(P)	((P) ? 0x8634 : 0x4634)
 #define IXGBE_KRM_DSP_TXFFE_STATE_5(P)	((P) ? 0x8638 : 0x4638)
 #define IXGBE_KRM_RX_TRN_LINKUP_CTRL(P)	((P) ? 0x8B00 : 0x4B00)
 #define IXGBE_KRM_PMD_DFX_BURNIN(P)	((P) ? 0x8E00 : 0x4E00)
+#define IXGBE_KRM_PMD_FLX_MASK_ST20(P)	((P) ? 0x9054 : 0x5054)
 #define IXGBE_KRM_TX_COEFF_CTRL_1(P)	((P) ? 0x9520 : 0x5520)
 #define IXGBE_KRM_RX_ANA_CTL(P)		((P) ? 0x9A00 : 0x5A00)
 
+#define IXGBE_KRM_PMD_FLX_MASK_ST20_SFI_10G_DA		~(0x3 << 20)
+#define IXGBE_KRM_PMD_FLX_MASK_ST20_SFI_10G_SR		(1u << 20)
+#define IXGBE_KRM_PMD_FLX_MASK_ST20_SFI_10G_LR		(0x2 << 20)
+#define IXGBE_KRM_PMD_FLX_MASK_ST20_SGMII_EN		(1u << 25)
+#define IXGBE_KRM_PMD_FLX_MASK_ST20_AN37_EN		(1u << 26)
+#define IXGBE_KRM_PMD_FLX_MASK_ST20_AN_EN		(1u << 27)
+#define IXGBE_KRM_PMD_FLX_MASK_ST20_SPEED_10M		~(0x7 << 28)
+#define IXGBE_KRM_PMD_FLX_MASK_ST20_SPEED_100M		(1u << 28)
+#define IXGBE_KRM_PMD_FLX_MASK_ST20_SPEED_1G		(0x2 << 28)
+#define IXGBE_KRM_PMD_FLX_MASK_ST20_SPEED_10G		(0x3 << 28)
+#define IXGBE_KRM_PMD_FLX_MASK_ST20_SPEED_AN		(0x4 << 28)
+#define IXGBE_KRM_PMD_FLX_MASK_ST20_SPEED_2_5G		(0x7 << 28)
+#define IXGBE_KRM_PMD_FLX_MASK_ST20_SPEED_MASK		(0x7 << 28)
+#define IXGBE_KRM_PMD_FLX_MASK_ST20_FW_AN_RESTART	(1u << 31)
+
 #define IXGBE_KRM_PORT_CAR_GEN_CTRL_NELB_32B		(1 << 9)
 #define IXGBE_KRM_PORT_CAR_GEN_CTRL_NELB_KRPCS		(1 << 11)
 
 #define IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_MASK	(0x7 << 8)
 #define IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_1G	(2 << 8)
 #define IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_10G	(4 << 8)
+#define IXGBE_KRM_LINK_CTRL_1_TETH_AN_SGMII_EN		(1 << 12)
+#define IXGBE_KRM_LINK_CTRL_1_TETH_AN_CLAUSE_37_EN	(1 << 13)
 #define IXGBE_KRM_LINK_CTRL_1_TETH_AN_FEC_REQ		(1 << 14)
 #define IXGBE_KRM_LINK_CTRL_1_TETH_AN_CAP_FEC		(1 << 15)
 #define IXGBE_KRM_LINK_CTRL_1_TETH_AN_CAP_KX		(1 << 16)
 #define IXGBE_KRM_LINK_CTRL_1_TETH_AN_CAP_KR		(1 << 18)
 #define IXGBE_KRM_LINK_CTRL_1_TETH_EEE_CAP_KX		(1 << 24)
 #define IXGBE_KRM_LINK_CTRL_1_TETH_EEE_CAP_KR		(1 << 26)
+#define IXGBE_KRM_LINK_S1_MAC_AN_COMPLETE		(1 << 28)
 #define IXGBE_KRM_LINK_CTRL_1_TETH_AN_ENABLE		(1 << 29)
 #define IXGBE_KRM_LINK_CTRL_1_TETH_AN_RESTART		(1 << 31)
 
 #define IXGBE_KRM_AN_CNTL_1_SYM_PAUSE			(1 << 28)
 #define IXGBE_KRM_AN_CNTL_1_ASM_PAUSE			(1 << 29)
+#define IXGBE_KRM_PCS_KX_AN_SYM_PAUSE			(1 << 1)
+#define IXGBE_KRM_PCS_KX_AN_ASM_PAUSE			(1 << 2)
+#define IXGBE_KRM_PCS_KX_AN_LP_SYM_PAUSE		(1 << 2)
+#define IXGBE_KRM_PCS_KX_AN_LP_ASM_PAUSE		(1 << 3)
+#define IXGBE_KRM_AN_CNTL_4_ECSR_AN37_OVER_73		(1 << 29)
+#define IXGBE_KRM_AN_CNTL_8_LINEAR			(1 << 0)
+#define IXGBE_KRM_AN_CNTL_8_LIMITING			(1 << 1)
+
+#define IXGBE_KRM_LP_BASE_PAGE_HIGH_SYM_PAUSE		(1 << 10)
+#define IXGBE_KRM_LP_BASE_PAGE_HIGH_ASM_PAUSE		(1 << 11)
+
+#define IXGBE_KRM_SGMII_CTRL_MAC_TAR_FORCE_100_D	(1 << 12)
+#define IXGBE_KRM_SGMII_CTRL_MAC_TAR_FORCE_10_D		(1 << 19)
 
 #define IXGBE_KRM_DSP_TXFFE_STATE_C0_EN			(1 << 6)
 #define IXGBE_KRM_DSP_TXFFE_STATE_CP1_CN1_EN		(1 << 15)
@@ -3792,131 +4586,18 @@ struct ixgbe_hw {
 #define IXGBE_SB_IOSF_TARGET_KR_PHY	0
 
 #define IXGBE_NW_MNG_IF_SEL		0x00011178
-#define IXGBE_NW_MNG_IF_SEL_INT_PHY_MODE (1 << 24)
-
-/* PHY */
-#define IXGBE_I2C_EEPROM_DEV_ADDR	0xA0
-#define IXGBE_I2C_EEPROM_DEV_ADDR2	0xA2
-#define IXGBE_I2C_EEPROM_BANK_LEN	0xFF
-
-/* EEPROM byte offsets */
-#define IXGBE_SFF_IDENTIFIER		0x0
-#define IXGBE_SFF_IDENTIFIER_SFP	0x3
-#define IXGBE_SFF_VENDOR_OUI_BYTE0	0x25
-#define IXGBE_SFF_VENDOR_OUI_BYTE1	0x26
-#define IXGBE_SFF_VENDOR_OUI_BYTE2	0x27
-#define IXGBE_SFF_1GBE_COMP_CODES	0x6
-#define IXGBE_SFF_10GBE_COMP_CODES	0x3
-#define IXGBE_SFF_CABLE_TECHNOLOGY	0x8
-#define IXGBE_SFF_CABLE_SPEC_COMP	0x3C
-#define IXGBE_SFF_SFF_8472_SWAP		0x5C
-#define IXGBE_SFF_SFF_8472_COMP		0x5E
-#define IXGBE_SFF_SFF_8472_OSCB		0x6E
-#define IXGBE_SFF_SFF_8472_ESCB		0x76
-#define IXGBE_SFF_IDENTIFIER_QSFP_PLUS	0xD
-#define IXGBE_SFF_QSFP_VENDOR_OUI_BYTE0	0xA5
-#define IXGBE_SFF_QSFP_VENDOR_OUI_BYTE1	0xA6
-#define IXGBE_SFF_QSFP_VENDOR_OUI_BYTE2	0xA7
-#define IXGBE_SFF_QSFP_CONNECTOR	0x82
-#define IXGBE_SFF_QSFP_10GBE_COMP	0x83
-#define IXGBE_SFF_QSFP_1GBE_COMP	0x86
-#define IXGBE_SFF_QSFP_CABLE_LENGTH	0x92
-#define IXGBE_SFF_QSFP_DEVICE_TECH	0x93
-
-/* Bitmasks */
-#define IXGBE_SFF_DA_PASSIVE_CABLE	0x4
-#define IXGBE_SFF_DA_ACTIVE_CABLE	0x8
-#define IXGBE_SFF_DA_SPEC_ACTIVE_LIMITING	0x4
-#define IXGBE_SFF_1GBASESX_CAPABLE	0x1
-#define IXGBE_SFF_1GBASELX_CAPABLE	0x2
-#define IXGBE_SFF_1GBASET_CAPABLE	0x8
-#define IXGBE_SFF_10GBASESR_CAPABLE	0x10
-#define IXGBE_SFF_10GBASELR_CAPABLE	0x20
-#define IXGBE_SFF_DA_BAD_HP_CABLE	0x80
-#define IXGBE_SFF_SOFT_RS_SELECT_MASK	0x8
-#define IXGBE_SFF_SOFT_RS_SELECT_10G	0x8
-#define IXGBE_SFF_SOFT_RS_SELECT_1G	0x0
-#define IXGBE_SFF_ADDRESSING_MODE	0x4
-#define IXGBE_SFF_QSFP_DA_ACTIVE_CABLE	0x1
-#define IXGBE_SFF_QSFP_DA_PASSIVE_CABLE	0x8
-#define IXGBE_SFF_QSFP_CONNECTOR_NOT_SEPARABLE	0x23
-#define IXGBE_SFF_QSFP_TRANSMITER_850NM_VCSEL	0x0
-#define IXGBE_I2C_EEPROM_READ_MASK	0x100
-#define IXGBE_I2C_EEPROM_STATUS_MASK	0x3
-#define IXGBE_I2C_EEPROM_STATUS_NO_OPERATION	0x0
-#define IXGBE_I2C_EEPROM_STATUS_PASS	0x1
-#define IXGBE_I2C_EEPROM_STATUS_FAIL	0x2
-#define IXGBE_I2C_EEPROM_STATUS_IN_PROGRESS	0x3
-
-#define IXGBE_CS4227			0xBE	/* CS4227 address */
-#define IXGBE_CS4227_GLOBAL_ID_LSB	0
-#define IXGBE_CS4227_SCRATCH		2
-#define IXGBE_CS4227_GLOBAL_ID_VALUE	0x03E5
-#define IXGBE_CS4227_RESET_PENDING	0x1357
-#define IXGBE_CS4227_RESET_COMPLETE	0x5AA5
-#define IXGBE_CS4227_RETRIES		15
-#define IXGBE_CS4227_EFUSE_STATUS	0x0181
-#define IXGBE_CS4227_LINE_SPARE22_MSB	0x12AD	/* Reg to program speed */
-#define IXGBE_CS4227_LINE_SPARE24_LSB	0x12B0	/* Reg to program EDC */
-#define IXGBE_CS4227_HOST_SPARE22_MSB	0x1AAD	/* Reg to program speed */
-#define IXGBE_CS4227_HOST_SPARE24_LSB	0x1AB0	/* Reg to program EDC */
-#define IXGBE_CS4227_EEPROM_STATUS	0x5001
-#define IXGBE_CS4227_EEPROM_LOAD_OK	0x0001
-#define IXGBE_CS4227_SPEED_1G		0x8000
-#define IXGBE_CS4227_SPEED_10G		0
-#define IXGBE_CS4227_EDC_MODE_CX1	0x0002
-#define IXGBE_CS4227_EDC_MODE_SR	0x0004
-#define IXGBE_CS4227_EDC_MODE_DIAG	0x0008
-#define IXGBE_CS4227_RESET_HOLD		500	/* microseconds */
-#define IXGBE_CS4227_RESET_DELAY	450	/* milliseconds */
-#define IXGBE_CS4227_CHECK_DELAY	30	/* milliseconds */
-#define IXGBE_PE			0xE0	/* Port expander address */
-#define IXGBE_PE_OUTPUT			1	/* Output register offset */
-#define IXGBE_PE_CONFIG			3	/* Config register offset */
-#define IXGBE_PE_BIT1			(1 << 1)
-
-/* Flow control defines */
-#define IXGBE_TAF_SYM_PAUSE		0x400
-#define IXGBE_TAF_ASM_PAUSE		0x800
-
-/* Bit-shift macros */
-#define IXGBE_SFF_VENDOR_OUI_BYTE0_SHIFT	24
-#define IXGBE_SFF_VENDOR_OUI_BYTE1_SHIFT	16
-#define IXGBE_SFF_VENDOR_OUI_BYTE2_SHIFT	8
-
-/* Vendor OUIs: format of OUI is 0x[byte0][byte1][byte2][00] */
-#define IXGBE_SFF_VENDOR_OUI_TYCO	0x00407600
-#define IXGBE_SFF_VENDOR_OUI_FTL	0x00906500
-#define IXGBE_SFF_VENDOR_OUI_AVAGO	0x00176A00
-#define IXGBE_SFF_VENDOR_OUI_INTEL	0x001B2100
-
-/* I2C SDA and SCL timing parameters for standard mode */
-#define IXGBE_I2C_T_HD_STA	4
-#define IXGBE_I2C_T_LOW		5
-#define IXGBE_I2C_T_HIGH	4
-#define IXGBE_I2C_T_SU_STA	5
-#define IXGBE_I2C_T_HD_DATA	5
-#define IXGBE_I2C_T_SU_DATA	1
-#define IXGBE_I2C_T_RISE	1
-#define IXGBE_I2C_T_FALL	1
-#define IXGBE_I2C_T_SU_STO	4
-#define IXGBE_I2C_T_BUF		5
-
-#ifndef IXGBE_SFP_DETECT_RETRIES
-#define IXGBE_SFP_DETECT_RETRIES	10
-#endif
-
-#define IXGBE_TN_LASI_STATUS_REG	0x9005
-#define IXGBE_TN_LASI_STATUS_TEMP_ALARM	0x0008
-
-/* SFP+ SFF-8472 Compliance */
-#define IXGBE_SFF_SFF_8472_UNSUP	0x00
-#define IXGBE_SFF_SFF_8472_REV_9_3	0x01
-#define IXGBE_SFF_SFF_8472_REV_9_5	0x02
-#define IXGBE_SFF_SFF_8472_REV_10_2	0x03
-#define IXGBE_SFF_SFF_8472_REV_10_4	0x04
-#define IXGBE_SFF_SFF_8472_REV_11_0	0x05
-
-/* end PHY */
+#define IXGBE_NW_MNG_IF_SEL_MDIO_ACT	(1u << 1)
+#define IXGBE_NW_MNG_IF_SEL_MDIO_IF_MODE	(1u << 2)
+#define IXGBE_NW_MNG_IF_SEL_EN_SHARED_MDIO	(1u << 13)
+#define IXGBE_NW_MNG_IF_SEL_PHY_SPEED_10M	(1u << 17)
+#define IXGBE_NW_MNG_IF_SEL_PHY_SPEED_100M	(1u << 18)
+#define IXGBE_NW_MNG_IF_SEL_PHY_SPEED_1G	(1u << 19)
+#define IXGBE_NW_MNG_IF_SEL_PHY_SPEED_2_5G	(1u << 20)
+#define IXGBE_NW_MNG_IF_SEL_PHY_SPEED_10G	(1u << 21)
+#define IXGBE_NW_MNG_IF_SEL_SGMII_ENABLE	(1u << 25)
+#define IXGBE_NW_MNG_IF_SEL_INT_PHY_MODE (1 << 24) /* X552 reg field only */
+#define IXGBE_NW_MNG_IF_SEL_MDIO_PHY_ADD_SHIFT 3
+#define IXGBE_NW_MNG_IF_SEL_MDIO_PHY_ADD	\
+				(0x1F << IXGBE_NW_MNG_IF_SEL_MDIO_PHY_ADD_SHIFT)
 
 #endif /* _IXGBE_TYPE_H_ */
Index: ./dev/pci/ixgbe_x540.c
===================================================================
RCS file: /cvs/src/sys/dev/pci/ixgbe_x540.c,v
retrieving revision 1.9
diff -u -p -r1.9 ixgbe_x540.c
--- ./dev/pci/ixgbe_x540.c	17 Nov 2016 21:08:27 -0000	1.9
+++ ./dev/pci/ixgbe_x540.c	17 Sep 2018 19:59:56 -0000
@@ -1,8 +1,8 @@
-/*	$OpenBSD: ixgbe_x540.c,v 1.9 2016/11/17 21:08:27 mikeb Exp $	*/
-
+/* $OpenBSD$ */
 /******************************************************************************
+  SPDX-License-Identifier: BSD-3-Clause
 
-  Copyright (c) 2001-2015, Intel Corporation
+  Copyright (c) 2001-2017, Intel Corporation
   All rights reserved.
 
   Redistribution and use in source and binary forms, with or without
@@ -32,7 +32,7 @@
   POSSIBILITY OF SUCH DAMAGE.
 
 ******************************************************************************/
-/*$FreeBSD: head/sys/dev/ixgbe/ixgbe_x540.c 295093 2016-01-31 15:14:23Z smh $*/
+/*$FreeBSD$*/
 
 #include <dev/pci/ixgbe.h>
 #include <dev/pci/ixgbe_type.h>
@@ -44,27 +44,34 @@
 #define IXGBE_X540_VFT_TBL_SIZE		128
 #define IXGBE_X540_RX_PB_SIZE		384
 
-int32_t ixgbe_update_flash_X540(struct ixgbe_hw *hw);
-int32_t ixgbe_poll_flash_update_done_X540(struct ixgbe_hw *hw);
-int32_t ixgbe_get_swfw_sync_semaphore(struct ixgbe_hw *hw);
-void ixgbe_release_swfw_sync_semaphore(struct ixgbe_hw *hw);
+static int32_t ixgbe_poll_flash_update_done_X540(struct ixgbe_hw *hw);
+static int32_t ixgbe_get_swfw_sync_semaphore(struct ixgbe_hw *hw);
+static void ixgbe_release_swfw_sync_semaphore(struct ixgbe_hw *hw);
 
+int32_t ixgbe_get_link_capabilities_X540(struct ixgbe_hw *hw,
+				     ixgbe_link_speed *speed, bool *autoneg);
 enum ixgbe_media_type ixgbe_get_media_type_X540(struct ixgbe_hw *hw);
 int32_t ixgbe_setup_mac_link_X540(struct ixgbe_hw *hw, ixgbe_link_speed speed,
-				  bool link_up_wait_to_complete);
+			      bool link_up_wait_to_complete);
 int32_t ixgbe_reset_hw_X540(struct ixgbe_hw *hw);
 int32_t ixgbe_start_hw_X540(struct ixgbe_hw *hw);
-uint32_t ixgbe_get_supported_physical_layer_X540(struct ixgbe_hw *hw);
+uint64_t ixgbe_get_supported_physical_layer_X540(struct ixgbe_hw *hw);
 
 int32_t ixgbe_init_eeprom_params_X540(struct ixgbe_hw *hw);
 int32_t ixgbe_read_eerd_X540(struct ixgbe_hw *hw, uint16_t offset, uint16_t *data);
+int32_t ixgbe_read_eerd_buffer_X540(struct ixgbe_hw *hw, uint16_t offset, uint16_t words,
+				uint16_t *data);
 int32_t ixgbe_write_eewr_X540(struct ixgbe_hw *hw, uint16_t offset, uint16_t data);
+int32_t ixgbe_write_eewr_buffer_X540(struct ixgbe_hw *hw, uint16_t offset, uint16_t words,
+				 uint16_t *data);
 int32_t ixgbe_update_eeprom_checksum_X540(struct ixgbe_hw *hw);
 int32_t ixgbe_validate_eeprom_checksum_X540(struct ixgbe_hw *hw, uint16_t *checksum_val);
 int32_t ixgbe_calc_eeprom_checksum_X540(struct ixgbe_hw *hw);
+int32_t ixgbe_update_flash_X540(struct ixgbe_hw *hw);
 
 int32_t ixgbe_acquire_swfw_sync_X540(struct ixgbe_hw *hw, uint32_t mask);
 void ixgbe_release_swfw_sync_X540(struct ixgbe_hw *hw, uint32_t mask);
+void ixgbe_init_swfw_sync_X540(struct ixgbe_hw *hw);
 
 int32_t ixgbe_blink_led_start_X540(struct ixgbe_hw *hw, uint32_t index);
 int32_t ixgbe_blink_led_stop_X540(struct ixgbe_hw *hw, uint32_t index);
@@ -88,10 +95,13 @@ int32_t ixgbe_init_ops_X540(struct ixgbe
 	ret_val = ixgbe_init_phy_ops_generic(hw);
 	ret_val = ixgbe_init_ops_generic(hw);
 
+
 	/* EEPROM */
 	eeprom->ops.init_params = ixgbe_init_eeprom_params_X540;
 	eeprom->ops.read = ixgbe_read_eerd_X540;
+	eeprom->ops.read_buffer = ixgbe_read_eerd_buffer_X540;
 	eeprom->ops.write = ixgbe_write_eewr_X540;
+	eeprom->ops.write_buffer = ixgbe_write_eewr_buffer_X540;
 	eeprom->ops.update_checksum = ixgbe_update_eeprom_checksum_X540;
 	eeprom->ops.validate_checksum = ixgbe_validate_eeprom_checksum_X540;
 	eeprom->ops.calc_checksum = ixgbe_calc_eeprom_checksum_X540;
@@ -103,31 +113,48 @@ int32_t ixgbe_init_ops_X540(struct ixgbe
 
 	/* MAC */
 	mac->ops.reset_hw = ixgbe_reset_hw_X540;
+	mac->ops.enable_relaxed_ordering = ixgbe_enable_relaxed_ordering_gen2;
 	mac->ops.get_media_type = ixgbe_get_media_type_X540;
 	mac->ops.get_supported_physical_layer =
 				    ixgbe_get_supported_physical_layer_X540;
 	mac->ops.read_analog_reg8 = NULL;
 	mac->ops.write_analog_reg8 = NULL;
 	mac->ops.start_hw = ixgbe_start_hw_X540;
+	mac->ops.get_san_mac_addr = ixgbe_get_san_mac_addr_generic;
+	mac->ops.set_san_mac_addr = ixgbe_set_san_mac_addr_generic;
+	mac->ops.get_device_caps = ixgbe_get_device_caps_generic;
+	mac->ops.get_wwn_prefix = ixgbe_get_wwn_prefix_generic;
+	mac->ops.get_fcoe_boot_status = ixgbe_get_fcoe_boot_status_generic;
 	mac->ops.acquire_swfw_sync = ixgbe_acquire_swfw_sync_X540;
 	mac->ops.release_swfw_sync = ixgbe_release_swfw_sync_X540;
+	mac->ops.init_swfw_sync = ixgbe_init_swfw_sync_X540;
 	mac->ops.disable_sec_rx_path = ixgbe_disable_sec_rx_path_generic;
 	mac->ops.enable_sec_rx_path = ixgbe_enable_sec_rx_path_generic;
 
 	/* RAR, Multicast, VLAN */
 	mac->ops.set_vmdq = ixgbe_set_vmdq_generic;
+	mac->ops.set_vmdq_san_mac = ixgbe_set_vmdq_san_mac_generic;
 	mac->ops.clear_vmdq = ixgbe_clear_vmdq_generic;
 	mac->ops.insert_mac_addr = ixgbe_insert_mac_addr_generic;
 	mac->rar_highwater = 1;
 	mac->ops.set_vfta = ixgbe_set_vfta_generic;
+	mac->ops.set_vlvf = ixgbe_set_vlvf_generic;
 	mac->ops.clear_vfta = ixgbe_clear_vfta_generic;
 	mac->ops.init_uta_tables = ixgbe_init_uta_tables_generic;
+	mac->ops.set_mac_anti_spoofing = ixgbe_set_mac_anti_spoofing;
+	mac->ops.set_vlan_anti_spoofing = ixgbe_set_vlan_anti_spoofing;
 
 	/* Link */
 	mac->ops.get_link_capabilities =
 				ixgbe_get_copper_link_capabilities_generic;
 	mac->ops.setup_link = ixgbe_setup_mac_link_X540;
+	mac->ops.setup_rxpba = ixgbe_set_rxpba_generic;
 	mac->ops.check_link = ixgbe_check_mac_link_generic;
+	mac->ops.bypass_rw = ixgbe_bypass_rw_generic;
+	mac->ops.bypass_valid_rd = ixgbe_bypass_valid_rd_generic;
+	mac->ops.bypass_set = ixgbe_bypass_set_generic;
+	mac->ops.bypass_rd_eep = ixgbe_bypass_rd_eep_generic;
+
 
 	mac->mcft_size		= IXGBE_X540_MC_TBL_SIZE;
 	mac->vft_size		= IXGBE_X540_VFT_TBL_SIZE;
@@ -135,7 +162,15 @@ int32_t ixgbe_init_ops_X540(struct ixgbe
 	mac->rx_pb_size		= IXGBE_X540_RX_PB_SIZE;
 	mac->max_rx_queues	= IXGBE_X540_MAX_RX_QUEUES;
 	mac->max_tx_queues	= IXGBE_X540_MAX_TX_QUEUES;
-	mac->max_msix_vectors	= 0 /*ixgbe_get_pcie_msix_count_generic(hw)*/;
+	mac->max_msix_vectors	= ixgbe_get_pcie_msix_count_generic(hw);
+
+	/*
+	 * FWSM register
+	 * ARC supported; valid only if manageability features are
+	 * enabled.
+	 */
+	mac->arc_subsystem_valid = !!(IXGBE_READ_REG(hw, IXGBE_FWSM_BY_MAC(hw))
+				     & IXGBE_FWSM_MODE_MASK);
 
 	hw->mbx.ops.init_params = ixgbe_init_mbx_params_pf;
 
@@ -143,16 +178,38 @@ int32_t ixgbe_init_ops_X540(struct ixgbe
 	mac->ops.blink_led_start = ixgbe_blink_led_start_X540;
 	mac->ops.blink_led_stop = ixgbe_blink_led_stop_X540;
 
+	/* Manageability interface */
+	mac->ops.set_fw_drv_ver = ixgbe_set_fw_drv_ver_generic;
+
+	mac->ops.get_rtrup2tc = ixgbe_dcb_get_rtrup2tc_generic;
+
 	return ret_val;
 }
 
 /**
+ *  ixgbe_get_link_capabilities_X540 - Determines link capabilities
+ *  @hw: pointer to hardware structure
+ *  @speed: pointer to link speed
+ *  @autoneg: TRUE when autoneg or autotry is enabled
+ *
+ *  Determines the link capabilities by reading the AUTOC register.
+ **/
+int32_t ixgbe_get_link_capabilities_X540(struct ixgbe_hw *hw,
+				     ixgbe_link_speed *speed,
+				     bool *autoneg)
+{
+	ixgbe_get_copper_link_capabilities_generic(hw, speed, autoneg);
+
+	return IXGBE_SUCCESS;
+}
+
+/**
  *  ixgbe_get_media_type_X540 - Get media type
  *  @hw: pointer to hardware structure
  *
  *  Returns the media type (fiber, copper, backplane)
  **/
-enum ixgbe_media_type ixgbe_get_media_type_X540(struct ixgbe_hw *hw)
+enum ixgbe_media_type ixgbe_get_media_type_X540(UNUSED struct ixgbe_hw *hw)
 {
 	return ixgbe_media_type_copper;
 }
@@ -164,12 +221,11 @@ enum ixgbe_media_type ixgbe_get_media_ty
  *  @autoneg_wait_to_complete: TRUE when waiting for completion is needed
  **/
 int32_t ixgbe_setup_mac_link_X540(struct ixgbe_hw *hw,
-				  ixgbe_link_speed speed,
-				  bool autoneg_wait_to_complete)
+			      ixgbe_link_speed speed,
+			      bool autoneg_wait_to_complete)
 {
 	DEBUGFUNC("ixgbe_setup_mac_link_X540");
-	return hw->phy.ops.setup_link_speed(hw, speed,
-					    autoneg_wait_to_complete);
+	return hw->phy.ops.setup_link_speed(hw, speed, autoneg_wait_to_complete);
 }
 
 /**
@@ -183,6 +239,7 @@ int32_t ixgbe_reset_hw_X540(struct ixgbe
 {
 	int32_t status;
 	uint32_t ctrl, i;
+	uint32_t swfw_mask = hw->phy.phy_semaphore_mask;
 
 	DEBUGFUNC("ixgbe_reset_hw_X540");
 
@@ -195,10 +252,17 @@ int32_t ixgbe_reset_hw_X540(struct ixgbe
 	ixgbe_clear_tx_pending(hw);
 
 mac_reset_top:
+	status = hw->mac.ops.acquire_swfw_sync(hw, swfw_mask);
+	if (status != IXGBE_SUCCESS) {
+		ERROR_REPORT2(IXGBE_ERROR_CAUTION,
+			"semaphore failed with %d", status);
+		return IXGBE_ERR_SWFW_SYNC;
+	}
 	ctrl = IXGBE_CTRL_RST;
 	ctrl |= IXGBE_READ_REG(hw, IXGBE_CTRL);
 	IXGBE_WRITE_REG(hw, IXGBE_CTRL, ctrl);
 	IXGBE_WRITE_FLUSH(hw);
+	hw->mac.ops.release_swfw_sync(hw, swfw_mask);
 
 	/* Poll for reset bit to self-clear indicating reset is complete */
 	for (i = 0; i < 10; i++) {
@@ -210,7 +274,8 @@ mac_reset_top:
 
 	if (ctrl & IXGBE_CTRL_RST_MASK) {
 		status = IXGBE_ERR_RESET_FAILED;
-		DEBUGOUT("Reset polling failed to complete.\n");
+		ERROR_REPORT1(IXGBE_ERROR_POLLING,
+			     "Reset polling failed to complete.\n");
 	}
 	msec_delay(100);
 
@@ -238,6 +303,29 @@ mac_reset_top:
 	hw->mac.num_rar_entries = 128;
 	hw->mac.ops.init_rx_addrs(hw);
 
+	/* Store the permanent SAN mac address */
+	hw->mac.ops.get_san_mac_addr(hw, hw->mac.san_addr);
+
+	/* Add the SAN MAC address to the RAR only if it's a valid address */
+	if (ixgbe_validate_mac_addr(hw->mac.san_addr) == 0) {
+		/* Save the SAN MAC RAR index */
+		hw->mac.san_mac_rar_index = hw->mac.num_rar_entries - 1;
+
+		hw->mac.ops.set_rar(hw, hw->mac.san_mac_rar_index,
+				    hw->mac.san_addr, 0, IXGBE_RAH_AV);
+
+		/* clear VMDq pool/queue selection for this RAR */
+		hw->mac.ops.clear_vmdq(hw, hw->mac.san_mac_rar_index,
+				       IXGBE_CLEAR_VMDQ_ALL);
+
+		/* Reserve the last RAR for the SAN MAC address */
+		hw->mac.num_rar_entries--;
+	}
+
+	/* Store the alternative WWNN/WWPN prefix */
+	hw->mac.ops.get_wwn_prefix(hw, &hw->mac.wwnn_prefix,
+				   &hw->mac.wwpn_prefix);
+
 reset_hw_out:
 	return status;
 }
@@ -272,9 +360,9 @@ out:
  *
  *  Determines physical layer capabilities of the current configuration.
  **/
-uint32_t ixgbe_get_supported_physical_layer_X540(struct ixgbe_hw *hw)
+uint64_t ixgbe_get_supported_physical_layer_X540(struct ixgbe_hw *hw)
 {
-	uint32_t physical_layer = IXGBE_PHYSICAL_LAYER_UNKNOWN;
+	uint64_t physical_layer = IXGBE_PHYSICAL_LAYER_UNKNOWN;
 	uint16_t ext_ability = 0;
 
 	DEBUGFUNC("ixgbe_get_supported_physical_layer_X540");
@@ -310,7 +398,7 @@ int32_t ixgbe_init_eeprom_params_X540(st
 		eeprom->semaphore_delay = 10;
 		eeprom->type = ixgbe_flash;
 
-		eec = IXGBE_READ_REG(hw, IXGBE_EEC);
+		eec = IXGBE_READ_REG(hw, IXGBE_EEC_BY_MAC(hw));
 		eeprom_size = (uint16_t)((eec & IXGBE_EEC_SIZE) >>
 				    IXGBE_EEC_SIZE_SHIFT);
 		eeprom->word_size = 1 << (eeprom_size +
@@ -348,6 +436,33 @@ int32_t ixgbe_read_eerd_X540(struct ixgb
 }
 
 /**
+ *  ixgbe_read_eerd_buffer_X540- Read EEPROM word(s) using EERD
+ *  @hw: pointer to hardware structure
+ *  @offset: offset of  word in the EEPROM to read
+ *  @words: number of words
+ *  @data: word(s) read from the EEPROM
+ *
+ *  Reads a 16 bit word(s) from the EEPROM using the EERD register.
+ **/
+int32_t ixgbe_read_eerd_buffer_X540(struct ixgbe_hw *hw,
+				uint16_t offset, uint16_t words, uint16_t *data)
+{
+	int32_t status = IXGBE_SUCCESS;
+
+	DEBUGFUNC("ixgbe_read_eerd_buffer_X540");
+	if (hw->mac.ops.acquire_swfw_sync(hw, IXGBE_GSSR_EEP_SM) ==
+	    IXGBE_SUCCESS) {
+		status = ixgbe_read_eerd_buffer_generic(hw, offset,
+							words, data);
+		hw->mac.ops.release_swfw_sync(hw, IXGBE_GSSR_EEP_SM);
+	} else {
+		status = IXGBE_ERR_SWFW_SYNC;
+	}
+
+	return status;
+}
+
+/**
  *  ixgbe_write_eewr_X540 - Write EEPROM word using EEWR
  *  @hw: pointer to hardware structure
  *  @offset: offset of  word in the EEPROM to write
@@ -372,6 +487,33 @@ int32_t ixgbe_write_eewr_X540(struct ixg
 }
 
 /**
+ *  ixgbe_write_eewr_buffer_X540 - Write EEPROM word(s) using EEWR
+ *  @hw: pointer to hardware structure
+ *  @offset: offset of  word in the EEPROM to write
+ *  @words: number of words
+ *  @data: word(s) write to the EEPROM
+ *
+ *  Write a 16 bit word(s) to the EEPROM using the EEWR register.
+ **/
+int32_t ixgbe_write_eewr_buffer_X540(struct ixgbe_hw *hw,
+				 uint16_t offset, uint16_t words, uint16_t *data)
+{
+	int32_t status = IXGBE_SUCCESS;
+
+	DEBUGFUNC("ixgbe_write_eewr_buffer_X540");
+	if (hw->mac.ops.acquire_swfw_sync(hw, IXGBE_GSSR_EEP_SM) ==
+	    IXGBE_SUCCESS) {
+		status = ixgbe_write_eewr_buffer_generic(hw, offset,
+							 words, data);
+		hw->mac.ops.release_swfw_sync(hw, IXGBE_GSSR_EEP_SM);
+	} else {
+		status = IXGBE_ERR_SWFW_SYNC;
+	}
+
+	return status;
+}
+
+/**
  *  ixgbe_calc_eeprom_checksum_X540 - Calculates and returns the checksum
  *
  *  This function does not use synchronization for EERD and EEWR. It can
@@ -388,7 +530,6 @@ int32_t ixgbe_calc_eeprom_checksum_X540(
 	uint16_t length = 0;
 	uint16_t pointer = 0;
 	uint16_t word = 0;
-	uint16_t checksum_last_word = IXGBE_EEPROM_CHECKSUM;
 	uint16_t ptr_start = IXGBE_PCIE_ANALOG_PTR;
 
 	/* Do not use hw->eeprom.ops.read because we do not want to take
@@ -398,14 +539,15 @@ int32_t ixgbe_calc_eeprom_checksum_X540(
 
 	DEBUGFUNC("ixgbe_calc_eeprom_checksum_X540");
 
-	/* Include 0x0-0x3F in the checksum */
-	for (i = 0; i <= checksum_last_word; i++) {
+	/* Include 0x0 up to IXGBE_EEPROM_CHECKSUM; do not include the
+	 * checksum itself
+	 */
+	for (i = 0; i < IXGBE_EEPROM_CHECKSUM; i++) {
 		if (ixgbe_read_eerd_generic(hw, i, &word)) {
 			DEBUGOUT("EEPROM read failed\n");
 			return IXGBE_ERR_EEPROM;
 		}
-		if (i != IXGBE_EEPROM_CHECKSUM)
-			checksum += word;
+		checksum += word;
 	}
 
 	/* Include all data from pointers 0x3, 0x6-0xE.  This excludes the
@@ -458,7 +600,7 @@ int32_t ixgbe_calc_eeprom_checksum_X540(
  *  caller does not need checksum_val, the value can be NULL.
  **/
 int32_t ixgbe_validate_eeprom_checksum_X540(struct ixgbe_hw *hw,
-					    uint16_t *checksum_val)
+					uint16_t *checksum_val)
 {
 	int32_t status;
 	uint16_t checksum;
@@ -497,7 +639,8 @@ int32_t ixgbe_validate_eeprom_checksum_X
 	 * calculated checksum
 	 */
 	if (read_checksum != checksum) {
-		DEBUGOUT("Invalid EEPROM checksum\n");
+		ERROR_REPORT1(IXGBE_ERROR_INVALID_STATE,
+			     "Invalid EEPROM checksum");
 		status = IXGBE_ERR_EEPROM_CHECKSUM;
 	}
 
@@ -580,8 +723,8 @@ int32_t ixgbe_update_flash_X540(struct i
 		goto out;
 	}
 
-	flup = IXGBE_READ_REG(hw, IXGBE_EEC) | IXGBE_EEC_FLUP;
-	IXGBE_WRITE_REG(hw, IXGBE_EEC, flup);
+	flup = IXGBE_READ_REG(hw, IXGBE_EEC_BY_MAC(hw)) | IXGBE_EEC_FLUP;
+	IXGBE_WRITE_REG(hw, IXGBE_EEC_BY_MAC(hw), flup);
 
 	status = ixgbe_poll_flash_update_done_X540(hw);
 	if (status == IXGBE_SUCCESS)
@@ -590,11 +733,11 @@ int32_t ixgbe_update_flash_X540(struct i
 		DEBUGOUT("Flash update time out\n");
 
 	if (hw->mac.type == ixgbe_mac_X540 && hw->revision_id == 0) {
-		flup = IXGBE_READ_REG(hw, IXGBE_EEC);
+		flup = IXGBE_READ_REG(hw, IXGBE_EEC_BY_MAC(hw));
 
 		if (flup & IXGBE_EEC_SEC1VAL) {
 			flup |= IXGBE_EEC_FLUP;
-			IXGBE_WRITE_REG(hw, IXGBE_EEC, flup);
+			IXGBE_WRITE_REG(hw, IXGBE_EEC_BY_MAC(hw), flup);
 		}
 
 		status = ixgbe_poll_flash_update_done_X540(hw);
@@ -614,7 +757,7 @@ out:
  *  Polls the FLUDONE (bit 26) of the EEC Register to determine when the
  *  flash update is done.
  **/
-int32_t ixgbe_poll_flash_update_done_X540(struct ixgbe_hw *hw)
+static int32_t ixgbe_poll_flash_update_done_X540(struct ixgbe_hw *hw)
 {
 	uint32_t i;
 	uint32_t reg;
@@ -623,13 +766,18 @@ int32_t ixgbe_poll_flash_update_done_X54
 	DEBUGFUNC("ixgbe_poll_flash_update_done_X540");
 
 	for (i = 0; i < IXGBE_FLUDONE_ATTEMPTS; i++) {
-		reg = IXGBE_READ_REG(hw, IXGBE_EEC);
+		reg = IXGBE_READ_REG(hw, IXGBE_EEC_BY_MAC(hw));
 		if (reg & IXGBE_EEC_FLUDONE) {
 			status = IXGBE_SUCCESS;
 			break;
 		}
 		msec_delay(5);
 	}
+
+	if (i == IXGBE_FLUDONE_ATTEMPTS)
+		ERROR_REPORT1(IXGBE_ERROR_POLLING,
+			     "Flash update status polling timed out");
+
 	return status;
 }
 
@@ -662,19 +810,24 @@ int32_t ixgbe_acquire_swfw_sync_X540(str
 
 	swmask |= swi2c_mask;
 	fwmask |= swi2c_mask << 2;
+	if (hw->mac.type >= ixgbe_mac_X550)
+		timeout = 1000;
+
 	for (i = 0; i < timeout; i++) {
 		/* SW NVM semaphore bit is used for access to all
 		 * SW_FW_SYNC bits (not just NVM)
 		 */
-		if (ixgbe_get_swfw_sync_semaphore(hw))
+		if (ixgbe_get_swfw_sync_semaphore(hw)) {
+			DEBUGOUT("Failed to get NVM access and register semaphore, returning IXGBE_ERR_SWFW_SYNC\n");
 			return IXGBE_ERR_SWFW_SYNC;
+		}
 
-		swfw_sync = IXGBE_READ_REG(hw, IXGBE_SWFW_SYNC);
+		swfw_sync = IXGBE_READ_REG(hw, IXGBE_SWFW_SYNC_BY_MAC(hw));
 		if (!(swfw_sync & (fwmask | swmask | hwmask))) {
 			swfw_sync |= swmask;
-			IXGBE_WRITE_REG(hw, IXGBE_SWFW_SYNC, swfw_sync);
+			IXGBE_WRITE_REG(hw, IXGBE_SWFW_SYNC_BY_MAC(hw),
+					swfw_sync);
 			ixgbe_release_swfw_sync_semaphore(hw);
-			msec_delay(5);
 			return IXGBE_SUCCESS;
 		}
 		/* Firmware currently using resource (fwmask), hardware
@@ -685,22 +838,19 @@ int32_t ixgbe_acquire_swfw_sync_X540(str
 		msec_delay(5);
 	}
 
-	/* Failed to get SW only semaphore */
-	if (swmask == IXGBE_GSSR_SW_MNG_SM) {
-		return IXGBE_ERR_SWFW_SYNC;
-	}
-
 	/* If the resource is not released by the FW/HW the SW can assume that
 	 * the FW/HW malfunctions. In that case the SW should set the SW bit(s)
 	 * of the requested resource(s) while ignoring the corresponding FW/HW
 	 * bits in the SW_FW_SYNC register.
 	 */
-	if (ixgbe_get_swfw_sync_semaphore(hw))
+	if (ixgbe_get_swfw_sync_semaphore(hw)) {
+		DEBUGOUT("Failed to get NVM sempahore and register semaphore while forcefully ignoring FW sempahore bit(s) and setting SW semaphore bit(s), returning IXGBE_ERR_SWFW_SYNC\n");
 		return IXGBE_ERR_SWFW_SYNC;
-	swfw_sync = IXGBE_READ_REG(hw, IXGBE_SWFW_SYNC);
+	}
+	swfw_sync = IXGBE_READ_REG(hw, IXGBE_SWFW_SYNC_BY_MAC(hw));
 	if (swfw_sync & (fwmask | hwmask)) {
 		swfw_sync |= swmask;
-		IXGBE_WRITE_REG(hw, IXGBE_SWFW_SYNC, swfw_sync);
+		IXGBE_WRITE_REG(hw, IXGBE_SWFW_SYNC_BY_MAC(hw), swfw_sync);
 		ixgbe_release_swfw_sync_semaphore(hw);
 		msec_delay(5);
 		return IXGBE_SUCCESS;
@@ -712,15 +862,18 @@ int32_t ixgbe_acquire_swfw_sync_X540(str
 	 */
 	if (swfw_sync & swmask) {
 		uint32_t rmask = IXGBE_GSSR_EEP_SM | IXGBE_GSSR_PHY0_SM |
-				 IXGBE_GSSR_PHY1_SM | IXGBE_GSSR_MAC_CSR_SM;
+			    IXGBE_GSSR_PHY1_SM | IXGBE_GSSR_MAC_CSR_SM |
+			    IXGBE_GSSR_SW_MNG_SM;
 
 		if (swi2c_mask)
 			rmask |= IXGBE_GSSR_I2C_MASK;
 		ixgbe_release_swfw_sync_X540(hw, rmask);
 		ixgbe_release_swfw_sync_semaphore(hw);
+		DEBUGOUT("Resource not released by other SW, returning IXGBE_ERR_SWFW_SYNC\n");
 		return IXGBE_ERR_SWFW_SYNC;
 	}
 	ixgbe_release_swfw_sync_semaphore(hw);
+	DEBUGOUT("Returning error IXGBE_ERR_SWFW_SYNC\n");
 
 	return IXGBE_ERR_SWFW_SYNC;
 }
@@ -744,12 +897,12 @@ void ixgbe_release_swfw_sync_X540(struct
 		swmask |= mask & IXGBE_GSSR_I2C_MASK;
 	ixgbe_get_swfw_sync_semaphore(hw);
 
-	swfw_sync = IXGBE_READ_REG(hw, IXGBE_SWFW_SYNC);
+	swfw_sync = IXGBE_READ_REG(hw, IXGBE_SWFW_SYNC_BY_MAC(hw));
 	swfw_sync &= ~swmask;
-	IXGBE_WRITE_REG(hw, IXGBE_SWFW_SYNC, swfw_sync);
+	IXGBE_WRITE_REG(hw, IXGBE_SWFW_SYNC_BY_MAC(hw), swfw_sync);
 
 	ixgbe_release_swfw_sync_semaphore(hw);
-	msec_delay(5);
+	msec_delay(2);
 }
 
 /**
@@ -758,7 +911,7 @@ void ixgbe_release_swfw_sync_X540(struct
  *
  *  Sets the hardware semaphores so SW/FW can gain control of shared resources
  **/
-int32_t ixgbe_get_swfw_sync_semaphore(struct ixgbe_hw *hw)
+static int32_t ixgbe_get_swfw_sync_semaphore(struct ixgbe_hw *hw)
 {
 	int32_t status = IXGBE_ERR_EEPROM;
 	uint32_t timeout = 2000;
@@ -773,7 +926,7 @@ int32_t ixgbe_get_swfw_sync_semaphore(st
 		 * If the SMBI bit is 0 when we read it, then the bit will be
 		 * set and we have the semaphore
 		 */
-		swsm = IXGBE_READ_REG(hw, IXGBE_SWSM);
+		swsm = IXGBE_READ_REG(hw, IXGBE_SWSM_BY_MAC(hw));
 		if (!(swsm & IXGBE_SWSM_SMBI)) {
 			status = IXGBE_SUCCESS;
 			break;
@@ -784,7 +937,7 @@ int32_t ixgbe_get_swfw_sync_semaphore(st
 	/* Now get the semaphore between SW/FW through the REGSMP bit */
 	if (status == IXGBE_SUCCESS) {
 		for (i = 0; i < timeout; i++) {
-			swsm = IXGBE_READ_REG(hw, IXGBE_SWFW_SYNC);
+			swsm = IXGBE_READ_REG(hw, IXGBE_SWFW_SYNC_BY_MAC(hw));
 			if (!(swsm & IXGBE_SWFW_REGSMP))
 				break;
 
@@ -796,14 +949,15 @@ int32_t ixgbe_get_swfw_sync_semaphore(st
 		 * was not granted because we don't have access to the EEPROM
 		 */
 		if (i >= timeout) {
-			DEBUGOUT("REGSMP Software NVM semaphore not "
-				 "granted.\n");
+			ERROR_REPORT1(IXGBE_ERROR_POLLING,
+				"REGSMP Software NVM semaphore not granted.\n");
 			ixgbe_release_swfw_sync_semaphore(hw);
 			status = IXGBE_ERR_EEPROM;
 		}
 	} else {
-		DEBUGOUT("Software semaphore SMBI between device drivers "
-			 "not granted.\n");
+		ERROR_REPORT1(IXGBE_ERROR_POLLING,
+			     "Software semaphore SMBI between device drivers "
+			     "not granted.\n");
 	}
 
 	return status;
@@ -815,7 +969,7 @@ int32_t ixgbe_get_swfw_sync_semaphore(st
  *
  *  This function clears hardware semaphore bits.
  **/
-void ixgbe_release_swfw_sync_semaphore(struct ixgbe_hw *hw)
+static void ixgbe_release_swfw_sync_semaphore(struct ixgbe_hw *hw)
 {
 	uint32_t swsm;
 
@@ -823,18 +977,48 @@ void ixgbe_release_swfw_sync_semaphore(s
 
 	/* Release both semaphores by writing 0 to the bits REGSMP and SMBI */
 
-	swsm = IXGBE_READ_REG(hw, IXGBE_SWFW_SYNC);
+	swsm = IXGBE_READ_REG(hw, IXGBE_SWFW_SYNC_BY_MAC(hw));
 	swsm &= ~IXGBE_SWFW_REGSMP;
-	IXGBE_WRITE_REG(hw, IXGBE_SWFW_SYNC, swsm);
+	IXGBE_WRITE_REG(hw, IXGBE_SWFW_SYNC_BY_MAC(hw), swsm);
 
-	swsm = IXGBE_READ_REG(hw, IXGBE_SWSM);
+	swsm = IXGBE_READ_REG(hw, IXGBE_SWSM_BY_MAC(hw));
 	swsm &= ~IXGBE_SWSM_SMBI;
-	IXGBE_WRITE_REG(hw, IXGBE_SWSM, swsm);
+	IXGBE_WRITE_REG(hw, IXGBE_SWSM_BY_MAC(hw), swsm);
 
 	IXGBE_WRITE_FLUSH(hw);
 }
 
 /**
+ *  ixgbe_init_swfw_sync_X540 - Release hardware semaphore
+ *  @hw: pointer to hardware structure
+ *
+ *  This function reset hardware semaphore bits for a semaphore that may
+ *  have be left locked due to a catastrophic failure.
+ **/
+void ixgbe_init_swfw_sync_X540(struct ixgbe_hw *hw)
+{
+	uint32_t rmask;
+
+	/* First try to grab the semaphore but we don't need to bother
+	 * looking to see whether we got the lock or not since we do
+	 * the same thing regardless of whether we got the lock or not.
+	 * We got the lock - we release it.
+	 * We timeout trying to get the lock - we force its release.
+	 */
+	ixgbe_get_swfw_sync_semaphore(hw);
+	ixgbe_release_swfw_sync_semaphore(hw);
+
+	/* Acquire and release all software resources. */
+	rmask = IXGBE_GSSR_EEP_SM | IXGBE_GSSR_PHY0_SM |
+		IXGBE_GSSR_PHY1_SM | IXGBE_GSSR_MAC_CSR_SM |
+		IXGBE_GSSR_SW_MNG_SM;
+
+	rmask |= IXGBE_GSSR_I2C_MASK;
+	ixgbe_acquire_swfw_sync_X540(hw, rmask);
+	ixgbe_release_swfw_sync_X540(hw, rmask);
+}
+
+/**
  * ixgbe_blink_led_start_X540 - Blink LED based on index.
  * @hw: pointer to hardware structure
  * @index: led number to blink
@@ -851,6 +1035,9 @@ int32_t ixgbe_blink_led_start_X540(struc
 
 	DEBUGFUNC("ixgbe_blink_led_start_X540");
 
+	if (index > 3)
+		return IXGBE_ERR_PARAM;
+
 	/*
 	 * Link should be up in order for the blink bit in the LED control
 	 * register to work. Force link and speed in the MAC if link is down.
@@ -884,6 +1071,9 @@ int32_t ixgbe_blink_led_stop_X540(struct
 {
 	uint32_t macc_reg;
 	uint32_t ledctl_reg;
+
+	if (index > 3)
+		return IXGBE_ERR_PARAM;
 
 	DEBUGFUNC("ixgbe_blink_led_stop_X540");
 
Index: ./dev/pci/ixgbe_x550.c
===================================================================
RCS file: /cvs/src/sys/dev/pci/ixgbe_x550.c,v
retrieving revision 1.4
diff -u -p -r1.4 ixgbe_x550.c
--- ./dev/pci/ixgbe_x550.c	6 Dec 2016 16:21:20 -0000	1.4
+++ ./dev/pci/ixgbe_x550.c	17 Sep 2018 19:59:56 -0000
@@ -1,8 +1,7 @@
-/*	$OpenBSD: ixgbe_x550.c,v 1.4 2016/12/06 16:21:20 mikeb Exp $	*/
-
+/* $OpenBSD$ */
 /******************************************************************************
 
-  Copyright (c) 2001-2015, Intel Corporation
+  Copyright (c) 2001-2017, Intel Corporation
   All rights reserved.
 
   Redistribution and use in source and binary forms, with or without
@@ -32,44 +31,67 @@
   POSSIBILITY OF SUCH DAMAGE.
 
 ******************************************************************************/
-/*$FreeBSD: head/sys/dev/ixgbe/ixgbe_x550.c 295093 2016-01-31 15:14:23Z smh $*/
+/*$FreeBSD$*/
 
 #include <dev/pci/ixgbe.h>
 #include <dev/pci/ixgbe_type.h>
+#include <dev/pci/ixgbe_api.h>
+#include <dev/pci/ixgbe_phy.h>
 
-extern int32_t ixgbe_init_eeprom_params_X540(struct ixgbe_hw *hw);
-extern int32_t ixgbe_acquire_swfw_sync_X540(struct ixgbe_hw *hw, uint32_t mask);
-extern void ixgbe_release_swfw_sync_X540(struct ixgbe_hw *hw, uint32_t mask);
+static int32_t ixgbe_setup_ixfi_x550em(struct ixgbe_hw *hw, ixgbe_link_speed *speed);
+static int32_t ixgbe_acquire_swfw_sync_X550a(struct ixgbe_hw *, uint32_t mask);
+static void ixgbe_release_swfw_sync_X550a(struct ixgbe_hw *, uint32_t mask);
+static int32_t ixgbe_read_mng_if_sel_x550em(struct ixgbe_hw *hw);
+
+static int32_t ixgbe_setup_mac_link_sfp_x550a(struct ixgbe_hw *hw,
+                                    ixgbe_link_speed speed,
+                                    UNUSED bool autoneg_wait_to_complete);
+
+int32_t ixgbe_dmac_config_X550(struct ixgbe_hw *hw);
+int32_t ixgbe_dmac_config_tcs_X550(struct ixgbe_hw *hw);
+int32_t ixgbe_dmac_update_tcs_X550(struct ixgbe_hw *hw);
 
 int32_t ixgbe_get_bus_info_X550em(struct ixgbe_hw *hw);
 int32_t ixgbe_init_eeprom_params_X550(struct ixgbe_hw *hw);
 int32_t ixgbe_update_eeprom_checksum_X550(struct ixgbe_hw *hw);
 int32_t ixgbe_calc_eeprom_checksum_X550(struct ixgbe_hw *hw);
-int32_t ixgbe_calc_checksum_X550(struct ixgbe_hw *hw, uint16_t *buffer,
-				 uint32_t buffer_size);
-int32_t ixgbe_validate_eeprom_checksum_X550(struct ixgbe_hw *hw,
-					    uint16_t *checksum_val);
+int32_t ixgbe_calc_checksum_X550(struct ixgbe_hw *hw, uint16_t *buffer, uint32_t buffer_size);
+int32_t ixgbe_validate_eeprom_checksum_X550(struct ixgbe_hw *hw, uint16_t *checksum_val);
 int32_t ixgbe_update_flash_X550(struct ixgbe_hw *hw);
+int32_t ixgbe_write_ee_hostif_buffer_X550(struct ixgbe_hw *hw,
+				      uint16_t offset, uint16_t words, uint16_t *data);
 int32_t ixgbe_write_ee_hostif_X550(struct ixgbe_hw *hw, uint16_t offset,
 			       uint16_t data);
 int32_t ixgbe_read_ee_hostif_buffer_X550(struct ixgbe_hw *hw,
-					 uint16_t offset, uint16_t words,
-					 uint16_t *data);
+				     uint16_t offset, uint16_t words, uint16_t *data);
 int32_t ixgbe_read_ee_hostif_X550(struct ixgbe_hw *hw, uint16_t offset,
-				  uint16_t *data);
-int32_t ixgbe_read_ee_hostif_data_X550(struct ixgbe_hw *hw, uint16_t offset,
-				       uint16_t *data);
+uint16_t				*data);
 int32_t ixgbe_write_ee_hostif_data_X550(struct ixgbe_hw *hw, uint16_t offset,
-					uint16_t data);
+				    uint16_t data);
+void ixgbe_set_source_address_pruning_X550(struct ixgbe_hw *hw, bool enable,
+					   unsigned int pool);
+void ixgbe_set_ethertype_anti_spoofing_X550(struct ixgbe_hw *hw,
+					    bool enable, int vf);
 int32_t ixgbe_write_iosf_sb_reg_x550(struct ixgbe_hw *hw, uint32_t reg_addr,
-				     uint32_t device_type, uint32_t data);
+				 uint32_t device_type, uint32_t data);
 int32_t ixgbe_read_iosf_sb_reg_x550(struct ixgbe_hw *hw, uint32_t reg_addr,
-				    uint32_t device_type, uint32_t *data);
+	uint32_t device_type, uint32_t *data);
+int32_t ixgbe_set_fw_drv_ver_x550(struct ixgbe_hw *hw, uint8_t maj, uint8_t min,
+			      uint8_t build, uint8_t ver, uint16_t len, const char *str);
+int32_t ixgbe_get_phy_token(struct ixgbe_hw *);
+int32_t ixgbe_put_phy_token(struct ixgbe_hw *);
+int32_t ixgbe_write_iosf_sb_reg_x550a(struct ixgbe_hw *hw, uint32_t reg_addr,
+	uint32_t device_type, uint32_t data);
+int32_t ixgbe_read_iosf_sb_reg_x550a(struct ixgbe_hw *hw, uint32_t reg_addr,
+	uint32_t device_type, uint32_t *data);
+void ixgbe_disable_mdd_X550(struct ixgbe_hw *hw);
+void ixgbe_enable_mdd_X550(struct ixgbe_hw *hw);
+void ixgbe_mdd_event_X550(struct ixgbe_hw *hw, uint32_t *vf_bitmap);
+void ixgbe_restore_mdd_vf_X550(struct ixgbe_hw *hw, uint32_t vf);
 enum ixgbe_media_type ixgbe_get_media_type_X550em(struct ixgbe_hw *hw);
 int32_t ixgbe_setup_sfp_modules_X550em(struct ixgbe_hw *hw);
 int32_t ixgbe_get_link_capabilities_X550em(struct ixgbe_hw *hw,
-					   ixgbe_link_speed *speed,
-					   bool *autoneg);
+				       ixgbe_link_speed *speed, bool *autoneg);
 void ixgbe_init_mac_link_ops_X550em(struct ixgbe_hw *hw);
 int32_t ixgbe_reset_hw_X550em(struct ixgbe_hw *hw);
 int32_t ixgbe_init_phy_ops_X550em(struct ixgbe_hw *hw);
@@ -77,27 +99,41 @@ int32_t ixgbe_setup_kr_x550em(struct ixg
 int32_t ixgbe_init_ext_t_x550em(struct ixgbe_hw *hw);
 int32_t ixgbe_setup_internal_phy_t_x550em(struct ixgbe_hw *hw);
 int32_t ixgbe_setup_phy_loopback_x550em(struct ixgbe_hw *hw);
-uint32_t ixgbe_get_supported_physical_layer_X550em(struct ixgbe_hw *hw);
+uint64_t ixgbe_get_supported_physical_layer_X550em(struct ixgbe_hw *hw);
 void ixgbe_disable_rx_x550(struct ixgbe_hw *hw);
 int32_t ixgbe_get_lcd_t_x550em(struct ixgbe_hw *hw, ixgbe_link_speed *lcd_speed);
+int32_t ixgbe_enter_lplu_t_x550em(struct ixgbe_hw *hw);
 int32_t ixgbe_acquire_swfw_sync_X550em(struct ixgbe_hw *hw, uint32_t mask);
 void ixgbe_release_swfw_sync_X550em(struct ixgbe_hw *hw, uint32_t mask);
 int32_t ixgbe_setup_fc_X550em(struct ixgbe_hw *hw);
 int32_t ixgbe_setup_mac_link_sfp_x550em(struct ixgbe_hw *hw,
-					ixgbe_link_speed speed,
-					bool autoneg_wait_to_complete);
+				    ixgbe_link_speed speed,
+				    bool autoneg_wait_to_complete);
+int32_t ixgbe_read_phy_reg_x550a(struct ixgbe_hw *hw, uint32_t reg_addr,
+			       uint32_t device_type, uint16_t *phy_data);
+int32_t ixgbe_write_phy_reg_x550a(struct ixgbe_hw *hw, uint32_t reg_addr,
+				uint32_t device_type, uint16_t phy_data);
+int32_t ixgbe_setup_fc_fiber_x550em_a(struct ixgbe_hw *hw);
+int32_t ixgbe_setup_fc_backplane_x550em_a(struct ixgbe_hw *hw);
+int32_t ixgbe_setup_fc_sgmii_x550em_a(struct ixgbe_hw *hw);
+void ixgbe_fc_autoneg_fiber_x550em_a(struct ixgbe_hw *hw);
+void ixgbe_fc_autoneg_backplane_x550em_a(struct ixgbe_hw *hw);
+void ixgbe_fc_autoneg_sgmii_x550em_a(struct ixgbe_hw *hw);
 int32_t ixgbe_handle_lasi_ext_t_x550em(struct ixgbe_hw *hw);
 int32_t ixgbe_setup_mac_link_t_X550em(struct ixgbe_hw *hw,
-				      ixgbe_link_speed speed,
-				      bool autoneg_wait_to_complete);
+				  ixgbe_link_speed speed,
+				  bool autoneg_wait_to_complete);
 int32_t ixgbe_check_link_t_X550em(struct ixgbe_hw *hw, ixgbe_link_speed *speed,
-				  bool *link_up, bool link_up_wait_to_complete);
+			      bool *link_up, bool link_up_wait_to_complete);
 int32_t ixgbe_reset_phy_t_X550em(struct ixgbe_hw *hw);
 int32_t ixgbe_identify_sfp_module_X550em(struct ixgbe_hw *hw);
 int32_t ixgbe_led_on_t_X550em(struct ixgbe_hw *hw, uint32_t led_idx);
 int32_t ixgbe_led_off_t_X550em(struct ixgbe_hw *hw, uint32_t led_idx);
 
-int32_t ixgbe_setup_ixfi_x550em(struct ixgbe_hw *hw, ixgbe_link_speed *speed);
+extern int32_t ixgbe_init_eeprom_params_X540(struct ixgbe_hw *hw);
+extern int32_t ixgbe_acquire_swfw_sync_X540(struct ixgbe_hw *hw, uint32_t mask);
+extern void ixgbe_release_swfw_sync_X540(struct ixgbe_hw *hw, uint32_t mask);
+
 
 /**
  *  ixgbe_init_ops_X550 - Inits func ptrs and MAC type
@@ -115,18 +151,44 @@ int32_t ixgbe_init_ops_X550(struct ixgbe
 	DEBUGFUNC("ixgbe_init_ops_X550");
 
 	ret_val = ixgbe_init_ops_X540(hw);
+	mac->ops.dmac_config = ixgbe_dmac_config_X550;
+	mac->ops.dmac_config_tcs = ixgbe_dmac_config_tcs_X550;
+	mac->ops.dmac_update_tcs = ixgbe_dmac_update_tcs_X550;
+	mac->ops.setup_eee = NULL;
+	mac->ops.set_source_address_pruning =
+			ixgbe_set_source_address_pruning_X550;
+	mac->ops.set_ethertype_anti_spoofing =
+			ixgbe_set_ethertype_anti_spoofing_X550;
 
+	mac->ops.get_rtrup2tc = ixgbe_dcb_get_rtrup2tc_generic;
 	eeprom->ops.init_params = ixgbe_init_eeprom_params_X550;
 	eeprom->ops.calc_checksum = ixgbe_calc_eeprom_checksum_X550;
 	eeprom->ops.read = ixgbe_read_ee_hostif_X550;
+	eeprom->ops.read_buffer = ixgbe_read_ee_hostif_buffer_X550;
 	eeprom->ops.write = ixgbe_write_ee_hostif_X550;
+	eeprom->ops.write_buffer = ixgbe_write_ee_hostif_buffer_X550;
 	eeprom->ops.update_checksum = ixgbe_update_eeprom_checksum_X550;
 	eeprom->ops.validate_checksum = ixgbe_validate_eeprom_checksum_X550;
 
+	mac->ops.disable_mdd = ixgbe_disable_mdd_X550;
+	mac->ops.enable_mdd = ixgbe_enable_mdd_X550;
+	mac->ops.mdd_event = ixgbe_mdd_event_X550;
+	mac->ops.restore_mdd_vf = ixgbe_restore_mdd_vf_X550;
 	mac->ops.disable_rx = ixgbe_disable_rx_x550;
-	if (hw->device_id == IXGBE_DEV_ID_X550EM_X_10G_T) {
+	/* Manageability interface */
+	mac->ops.set_fw_drv_ver = ixgbe_set_fw_drv_ver_x550;
+	switch (hw->device_id) {
+	case IXGBE_DEV_ID_X550EM_X_1G_T:
+		hw->mac.ops.led_on = NULL;
+		hw->mac.ops.led_off = NULL;
+		break;
+	case IXGBE_DEV_ID_X550EM_X_10G_T:
+	case IXGBE_DEV_ID_X550EM_A_10G_T:
 		hw->mac.ops.led_on = ixgbe_led_on_t_X550em;
 		hw->mac.ops.led_off = ixgbe_led_off_t_X550em;
+		break;
+	default:
+		break;
 	}
 	return ret_val;
 }
@@ -139,10 +201,9 @@ int32_t ixgbe_init_ops_X550(struct ixgbe
  *
  * Returns status code
  **/
-int32_t ixgbe_read_cs4227(struct ixgbe_hw *hw, uint16_t reg, uint16_t *value)
+static int32_t ixgbe_read_cs4227(struct ixgbe_hw *hw, uint16_t reg, uint16_t *value)
 {
-	return hw->phy.ops.read_i2c_combined_unlocked(hw, IXGBE_CS4227, reg,
-						      value);
+	return hw->link.ops.read_link_unlocked(hw, hw->link.addr, reg, value);
 }
 
 /**
@@ -153,10 +214,9 @@ int32_t ixgbe_read_cs4227(struct ixgbe_h
  *
  * Returns status code
  **/
-int32_t ixgbe_write_cs4227(struct ixgbe_hw *hw, uint16_t reg, uint16_t value)
+static int32_t ixgbe_write_cs4227(struct ixgbe_hw *hw, uint16_t reg, uint16_t value)
 {
-	return hw->phy.ops.write_i2c_combined_unlocked(hw, IXGBE_CS4227, reg,
-						       value);
+	return hw->link.ops.write_link_unlocked(hw, hw->link.addr, reg, value);
 }
 
 /**
@@ -167,13 +227,14 @@ int32_t ixgbe_write_cs4227(struct ixgbe_
  *
  * Returns status code
  **/
-int32_t ixgbe_read_pe(struct ixgbe_hw *hw, uint8_t reg, uint8_t *value)
+static int32_t ixgbe_read_pe(struct ixgbe_hw *hw, uint8_t reg, uint8_t *value)
 {
 	int32_t status;
 
-	status = hw->phy.ops.read_i2c_byte_unlocked(hw, reg, IXGBE_PE, value);
+	status = ixgbe_read_i2c_byte_unlocked(hw, reg, IXGBE_PE, value);
 	if (status != IXGBE_SUCCESS)
-		DEBUGOUT1("port expander access failed with %d\n", status);
+		ERROR_REPORT2(IXGBE_ERROR_CAUTION,
+			      "port expander access failed with %d\n", status);
 	return status;
 }
 
@@ -185,13 +246,14 @@ int32_t ixgbe_read_pe(struct ixgbe_hw *h
  *
  * Returns status code
  **/
-int32_t ixgbe_write_pe(struct ixgbe_hw *hw, uint8_t reg, uint8_t value)
+static int32_t ixgbe_write_pe(struct ixgbe_hw *hw, uint8_t reg, uint8_t value)
 {
 	int32_t status;
 
-	status = hw->phy.ops.write_i2c_byte_unlocked(hw, reg, IXGBE_PE, value);
+	status = ixgbe_write_i2c_byte_unlocked(hw, reg, IXGBE_PE, value);
 	if (status != IXGBE_SUCCESS)
-		DEBUGOUT1("port expander access failed with %d\n", status);
+		ERROR_REPORT2(IXGBE_ERROR_CAUTION,
+			      "port expander access failed with %d\n", status);
 	return status;
 }
 
@@ -202,7 +264,7 @@ int32_t ixgbe_write_pe(struct ixgbe_hw *
  * This function assumes that the caller has acquired the proper semaphore.
  * Returns error code
  **/
-int32_t ixgbe_reset_cs4227(struct ixgbe_hw *hw)
+static int32_t ixgbe_reset_cs4227(struct ixgbe_hw *hw)
 {
 	int32_t status;
 	uint32_t retry;
@@ -255,14 +317,16 @@ int32_t ixgbe_reset_cs4227(struct ixgbe_
 		msec_delay(IXGBE_CS4227_CHECK_DELAY);
 	}
 	if (retry == IXGBE_CS4227_RETRIES) {
-		DEBUGOUT("CS4227 reset did not complete.\n");
+		ERROR_REPORT1(IXGBE_ERROR_INVALID_STATE,
+			"CS4227 reset did not complete.");
 		return IXGBE_ERR_PHY;
 	}
 
 	status = ixgbe_read_cs4227(hw, IXGBE_CS4227_EEPROM_STATUS, &value);
 	if (status != IXGBE_SUCCESS ||
 	    !(value & IXGBE_CS4227_EEPROM_LOAD_OK)) {
-		DEBUGOUT("CS4227 EEPROM did not load successfully.\n");
+		ERROR_REPORT1(IXGBE_ERROR_INVALID_STATE,
+			"CS4227 EEPROM did not load successfully.");
 		return IXGBE_ERR_PHY;
 	}
 
@@ -273,7 +337,7 @@ int32_t ixgbe_reset_cs4227(struct ixgbe_
  * ixgbe_check_cs4227 - Check CS4227 and reset as needed
  * @hw: pointer to hardware structure
  **/
-void ixgbe_check_cs4227(struct ixgbe_hw *hw)
+static void ixgbe_check_cs4227(struct ixgbe_hw *hw)
 {
 	int32_t status = IXGBE_SUCCESS;
 	uint32_t swfw_mask = hw->phy.phy_semaphore_mask;
@@ -283,7 +347,8 @@ void ixgbe_check_cs4227(struct ixgbe_hw 
 	for (retry = 0; retry < IXGBE_CS4227_RETRIES; retry++) {
 		status = hw->mac.ops.acquire_swfw_sync(hw, swfw_mask);
 		if (status != IXGBE_SUCCESS) {
-			DEBUGOUT1("semaphore failed with %d\n", status);
+			ERROR_REPORT2(IXGBE_ERROR_CAUTION,
+				"semaphore failed with %d", status);
 			msec_delay(IXGBE_CS4227_CHECK_DELAY);
 			continue;
 		}
@@ -308,7 +373,8 @@ void ixgbe_check_cs4227(struct ixgbe_hw 
 	if (retry == IXGBE_CS4227_RETRIES) {
 		status = hw->mac.ops.acquire_swfw_sync(hw, swfw_mask);
 		if (status != IXGBE_SUCCESS) {
-			DEBUGOUT1("semaphore failed with %d\n", status);
+			ERROR_REPORT2(IXGBE_ERROR_CAUTION,
+				      "semaphore failed with %d", status);
 			return;
 		}
 	}
@@ -316,7 +382,8 @@ void ixgbe_check_cs4227(struct ixgbe_hw 
 	/* Reset the CS4227. */
 	status = ixgbe_reset_cs4227(hw);
 	if (status != IXGBE_SUCCESS) {
-		DEBUGOUT1("CS4227 reset failed: %d\n", status);
+		ERROR_REPORT2(IXGBE_ERROR_INVALID_STATE,
+			"CS4227 reset failed: %d", status);
 		goto out;
 	}
 
@@ -329,7 +396,8 @@ void ixgbe_check_cs4227(struct ixgbe_hw 
 	msec_delay(10);
 	status = hw->mac.ops.acquire_swfw_sync(hw, swfw_mask);
 	if (status != IXGBE_SUCCESS) {
-		DEBUGOUT1("semaphore failed with %d\n", status);
+		ERROR_REPORT2(IXGBE_ERROR_CAUTION,
+			"semaphore failed with %d", status);
 		return;
 	}
 
@@ -346,7 +414,7 @@ out:
  * ixgbe_setup_mux_ctl - Setup ESDP register for I2C mux control
  * @hw: pointer to hardware structure
  **/
-void ixgbe_setup_mux_ctl(struct ixgbe_hw *hw)
+static void ixgbe_setup_mux_ctl(struct ixgbe_hw *hw)
 {
 	uint32_t esdp = IXGBE_READ_REG(hw, IXGBE_ESDP);
 
@@ -365,54 +433,257 @@ void ixgbe_setup_mux_ctl(struct ixgbe_hw
  *
  * Returns error code
  */
-int32_t ixgbe_identify_phy_x550em(struct ixgbe_hw *hw)
+static int32_t ixgbe_identify_phy_x550em(struct ixgbe_hw *hw)
 {
-	int32_t ret_val;
+	hw->mac.ops.set_lan_id(hw);
+
+	ixgbe_read_mng_if_sel_x550em(hw);
 
 	switch (hw->device_id) {
+	case IXGBE_DEV_ID_X550EM_A_SFP:
+		return ixgbe_identify_module_generic(hw);
 	case IXGBE_DEV_ID_X550EM_X_SFP:
 		/* set up for CS4227 usage */
-		hw->phy.phy_semaphore_mask = IXGBE_GSSR_SHARED_I2C_SM;
 		ixgbe_setup_mux_ctl(hw);
 		ixgbe_check_cs4227(hw);
+		/* Fallthrough */
 
-		ret_val = ixgbe_identify_module_generic(hw);
-
-		/* Set PHY type none if no SFP detected */
-		if (ret_val == IXGBE_ERR_SFP_NOT_PRESENT) {
-			hw->phy.type = ixgbe_phy_none;
-			return IXGBE_SUCCESS;
-		}
-		return ret_val;
+	case IXGBE_DEV_ID_X550EM_A_SFP_N:
+		return ixgbe_identify_module_generic(hw);
 		break;
 	case IXGBE_DEV_ID_X550EM_X_KX4:
 		hw->phy.type = ixgbe_phy_x550em_kx4;
 		break;
+	case IXGBE_DEV_ID_X550EM_X_XFI:
+		hw->phy.type = ixgbe_phy_x550em_xfi;
+		break;
 	case IXGBE_DEV_ID_X550EM_X_KR:
+	case IXGBE_DEV_ID_X550EM_A_KR:
+	case IXGBE_DEV_ID_X550EM_A_KR_L:
 		hw->phy.type = ixgbe_phy_x550em_kr;
 		break;
-	case IXGBE_DEV_ID_X550EM_X_1G_T:
+	case IXGBE_DEV_ID_X550EM_A_10G_T:
 	case IXGBE_DEV_ID_X550EM_X_10G_T:
 		return ixgbe_identify_phy_generic(hw);
+	case IXGBE_DEV_ID_X550EM_X_1G_T:
+		hw->phy.type = ixgbe_phy_ext_1g_t;
+		break;
+	case IXGBE_DEV_ID_X550EM_A_1G_T:
+	case IXGBE_DEV_ID_X550EM_A_1G_T_L:
+		hw->phy.type = ixgbe_phy_fw;
+		if (hw->bus.lan_id)
+			hw->phy.phy_semaphore_mask |= IXGBE_GSSR_PHY1_SM;
+		else
+			hw->phy.phy_semaphore_mask |= IXGBE_GSSR_PHY0_SM;
+		break;
 	default:
 		break;
 	}
 	return IXGBE_SUCCESS;
 }
 
-int32_t ixgbe_read_phy_reg_x550em(struct ixgbe_hw *hw, uint32_t reg_addr,
-				  uint32_t device_type, uint16_t *phy_data)
+/**
+ * ixgbe_fw_phy_activity - Perform an activity on a PHY
+ * @hw: pointer to hardware structure
+ * @activity: activity to perform
+ * @data: Pointer to 4 32-bit words of data
+ */
+int32_t ixgbe_fw_phy_activity(struct ixgbe_hw *hw, uint16_t activity,
+			  uint32_t (*data)[FW_PHY_ACT_DATA_COUNT])
+{
+	union {
+		struct ixgbe_hic_phy_activity_req cmd;
+		struct ixgbe_hic_phy_activity_resp rsp;
+	} hic;
+	uint16_t retries = FW_PHY_ACT_RETRIES;
+	int32_t rc;
+	uint16_t i;
+
+	do {
+		memset(&hic, 0, sizeof(hic));
+		hic.cmd.hdr.cmd = FW_PHY_ACT_REQ_CMD;
+		hic.cmd.hdr.buf_len = FW_PHY_ACT_REQ_LEN;
+		hic.cmd.hdr.checksum = FW_DEFAULT_CHECKSUM;
+		hic.cmd.port_number = hw->bus.lan_id;
+		hic.cmd.activity_id = IXGBE_CPU_TO_LE16(activity);
+		for (i = 0; i < FW_PHY_ACT_DATA_COUNT; ++i)
+			hic.cmd.data[i] = IXGBE_CPU_TO_BE32((*data)[i]);
+
+		rc = ixgbe_host_interface_command(hw, (uint32_t *)&hic.cmd,
+						  sizeof(hic.cmd),
+						  IXGBE_HI_COMMAND_TIMEOUT,
+						  TRUE);
+		if (rc != IXGBE_SUCCESS)
+			return rc;
+		if (hic.rsp.hdr.cmd_or_resp.ret_status ==
+		    FW_CEM_RESP_STATUS_SUCCESS) {
+			for (i = 0; i < FW_PHY_ACT_DATA_COUNT; ++i)
+				(*data)[i] = IXGBE_BE32_TO_CPU(hic.rsp.data[i]);
+			return IXGBE_SUCCESS;
+		}
+		usec_delay(20);
+		--retries;
+	} while (retries > 0);
+
+	return IXGBE_ERR_HOST_INTERFACE_COMMAND;
+}
+
+static const struct {
+	uint16_t fw_speed;
+	ixgbe_link_speed phy_speed;
+} ixgbe_fw_map[] = {
+	{ FW_PHY_ACT_LINK_SPEED_10, IXGBE_LINK_SPEED_10_FULL },
+	{ FW_PHY_ACT_LINK_SPEED_100, IXGBE_LINK_SPEED_100_FULL },
+	{ FW_PHY_ACT_LINK_SPEED_1G, IXGBE_LINK_SPEED_1GB_FULL },
+	{ FW_PHY_ACT_LINK_SPEED_2_5G, IXGBE_LINK_SPEED_2_5GB_FULL },
+	{ FW_PHY_ACT_LINK_SPEED_5G, IXGBE_LINK_SPEED_5GB_FULL },
+	{ FW_PHY_ACT_LINK_SPEED_10G, IXGBE_LINK_SPEED_10GB_FULL },
+};
+
+/**
+ * ixgbe_get_phy_id_fw - Get the phy ID via firmware command
+ * @hw: pointer to hardware structure
+ *
+ * Returns error code
+ */
+static int32_t ixgbe_get_phy_id_fw(struct ixgbe_hw *hw)
+{
+	uint32_t info[FW_PHY_ACT_DATA_COUNT] = { 0 };
+	uint16_t phy_speeds;
+	uint16_t phy_id_lo;
+	int32_t rc;
+	uint16_t i;
+
+	rc = ixgbe_fw_phy_activity(hw, FW_PHY_ACT_GET_PHY_INFO, &info);
+	if (rc)
+		return rc;
+
+	hw->phy.speeds_supported = 0;
+	phy_speeds = info[0] & FW_PHY_INFO_SPEED_MASK;
+	for (i = 0; i < sizeof(ixgbe_fw_map) / sizeof(ixgbe_fw_map[0]); ++i) {
+		if (phy_speeds & ixgbe_fw_map[i].fw_speed)
+			hw->phy.speeds_supported |= ixgbe_fw_map[i].phy_speed;
+	}
+	if (!hw->phy.autoneg_advertised)
+		hw->phy.autoneg_advertised = hw->phy.speeds_supported;
+
+	hw->phy.id = info[0] & FW_PHY_INFO_ID_HI_MASK;
+	phy_id_lo = info[1] & FW_PHY_INFO_ID_LO_MASK;
+	hw->phy.id |= phy_id_lo & IXGBE_PHY_REVISION_MASK;
+	hw->phy.revision = phy_id_lo & ~IXGBE_PHY_REVISION_MASK;
+	if (!hw->phy.id || hw->phy.id == IXGBE_PHY_REVISION_MASK)
+		return IXGBE_ERR_PHY_ADDR_INVALID;
+	return IXGBE_SUCCESS;
+}
+
+/**
+ * ixgbe_identify_phy_fw - Get PHY type based on firmware command
+ * @hw: pointer to hardware structure
+ *
+ * Returns error code
+ */
+static int32_t ixgbe_identify_phy_fw(struct ixgbe_hw *hw)
+{
+	if (hw->bus.lan_id)
+		hw->phy.phy_semaphore_mask = IXGBE_GSSR_PHY1_SM;
+	else
+		hw->phy.phy_semaphore_mask = IXGBE_GSSR_PHY0_SM;
+
+	hw->phy.type = ixgbe_phy_fw;
+	hw->phy.ops.read_reg = NULL;
+	hw->phy.ops.write_reg = NULL;
+	return ixgbe_get_phy_id_fw(hw);
+}
+
+/**
+ * ixgbe_shutdown_fw_phy - Shutdown a firmware-controlled PHY
+ * @hw: pointer to hardware structure
+ *
+ * Returns error code
+ */
+int32_t ixgbe_shutdown_fw_phy(struct ixgbe_hw *hw)
+{
+	uint32_t setup[FW_PHY_ACT_DATA_COUNT] = { 0 };
+
+	setup[0] = FW_PHY_ACT_FORCE_LINK_DOWN_OFF;
+	return ixgbe_fw_phy_activity(hw, FW_PHY_ACT_FORCE_LINK_DOWN, &setup);
+}
+
+static int32_t ixgbe_read_phy_reg_x550em(UNUSED struct ixgbe_hw *hw, UNUSED uint32_t reg_addr,
+				     UNUSED uint32_t device_type, UNUSED uint16_t *phy_data)
 {
 	return IXGBE_NOT_IMPLEMENTED;
 }
 
-int32_t ixgbe_write_phy_reg_x550em(struct ixgbe_hw *hw, uint32_t reg_addr,
-				   uint32_t device_type, uint16_t phy_data)
+static int32_t ixgbe_write_phy_reg_x550em(UNUSED struct ixgbe_hw *hw, UNUSED uint32_t reg_addr,
+				      UNUSED uint32_t device_type, UNUSED uint16_t phy_data)
 {
 	return IXGBE_NOT_IMPLEMENTED;
 }
 
 /**
+ * ixgbe_read_i2c_combined_generic - Perform I2C read combined operation
+ * @hw: pointer to the hardware structure
+ * @addr: I2C bus address to read from
+ * @reg: I2C device register to read from
+ * @val: pointer to location to receive read value
+ *
+ * Returns an error code on error.
+ **/
+static int32_t ixgbe_read_i2c_combined_generic(struct ixgbe_hw *hw, uint8_t addr,
+					   uint16_t reg, uint16_t *val)
+{
+	return ixgbe_read_i2c_combined_generic_int(hw, addr, reg, val, TRUE);
+}
+
+/**
+ * ixgbe_read_i2c_combined_generic_unlocked - Do I2C read combined operation
+ * @hw: pointer to the hardware structure
+ * @addr: I2C bus address to read from
+ * @reg: I2C device register to read from
+ * @val: pointer to location to receive read value
+ *
+ * Returns an error code on error.
+ **/
+static int32_t
+ixgbe_read_i2c_combined_generic_unlocked(struct ixgbe_hw *hw, uint8_t addr,
+					 uint16_t reg, uint16_t *val)
+{
+	return ixgbe_read_i2c_combined_generic_int(hw, addr, reg, val, FALSE);
+}
+
+/**
+ * ixgbe_write_i2c_combined_generic - Perform I2C write combined operation
+ * @hw: pointer to the hardware structure
+ * @addr: I2C bus address to write to
+ * @reg: I2C device register to write to
+ * @val: value to write
+ *
+ * Returns an error code on error.
+ **/
+static int32_t ixgbe_write_i2c_combined_generic(struct ixgbe_hw *hw,
+					    uint8_t addr, uint16_t reg, uint16_t val)
+{
+	return ixgbe_write_i2c_combined_generic_int(hw, addr, reg, val, TRUE);
+}
+
+/**
+ * ixgbe_write_i2c_combined_generic_unlocked - Do I2C write combined operation
+ * @hw: pointer to the hardware structure
+ * @addr: I2C bus address to write to
+ * @reg: I2C device register to write to
+ * @val: value to write
+ *
+ * Returns an error code on error.
+ **/
+static int32_t
+ixgbe_write_i2c_combined_generic_unlocked(struct ixgbe_hw *hw,
+					  uint8_t addr, uint16_t reg, uint16_t val)
+{
+	return ixgbe_write_i2c_combined_generic_int(hw, addr, reg, val, FALSE);
+}
+
+/**
 *  ixgbe_init_ops_X550EM - Inits func ptrs and MAC type
 *  @hw: pointer to hardware structure
 *
@@ -437,6 +708,18 @@ int32_t ixgbe_init_ops_X550EM(struct ixg
 	 * the values being set in the x540 function.
 	 */
 
+	/* Bypass not supported in x550EM */
+	mac->ops.bypass_rw = NULL;
+	mac->ops.bypass_valid_rd = NULL;
+	mac->ops.bypass_set = NULL;
+	mac->ops.bypass_rd_eep = NULL;
+
+	/* FCOE not supported in x550EM */
+	mac->ops.get_san_mac_addr = NULL;
+	mac->ops.set_san_mac_addr = NULL;
+	mac->ops.get_wwn_prefix = NULL;
+	mac->ops.get_fcoe_boot_status = NULL;
+
 	/* IPsec not supported in x550EM */
 	mac->ops.disable_sec_rx_path = NULL;
 	mac->ops.enable_sec_rx_path = NULL;
@@ -449,6 +732,7 @@ int32_t ixgbe_init_ops_X550EM(struct ixg
 	hw->bus.type = ixgbe_bus_type_internal;
 	mac->ops.get_bus_info = ixgbe_get_bus_info_X550em;
 
+
 	mac->ops.get_media_type = ixgbe_get_media_type_X550em;
 	mac->ops.setup_sfp = ixgbe_setup_sfp_modules_X550em;
 	mac->ops.get_link_capabilities = ixgbe_get_link_capabilities_X550em;
@@ -461,12 +745,25 @@ int32_t ixgbe_init_ops_X550EM(struct ixg
 	else
 		mac->ops.setup_fc = ixgbe_setup_fc_X550em;
 
-	mac->ops.acquire_swfw_sync = ixgbe_acquire_swfw_sync_X550em;
-	mac->ops.release_swfw_sync = ixgbe_release_swfw_sync_X550em;
-
 	/* PHY */
 	phy->ops.init = ixgbe_init_phy_ops_X550em;
-	phy->ops.identify = ixgbe_identify_phy_x550em;
+	switch (hw->device_id) {
+	case IXGBE_DEV_ID_X550EM_A_1G_T:
+	case IXGBE_DEV_ID_X550EM_A_1G_T_L:
+		mac->ops.setup_fc = NULL;
+		phy->ops.identify = ixgbe_identify_phy_fw;
+		phy->ops.set_phy_power = NULL;
+		phy->ops.get_firmware_version = NULL;
+		break;
+	case IXGBE_DEV_ID_X550EM_X_1G_T:
+		mac->ops.setup_fc = NULL;
+		phy->ops.identify = ixgbe_identify_phy_x550em;
+		phy->ops.set_phy_power = NULL;
+		break;
+	default:
+		phy->ops.identify = ixgbe_identify_phy_x550em;
+	}
+
 	if (mac->ops.get_media_type(hw) != ixgbe_media_type_copper)
 		phy->ops.set_phy_power = NULL;
 
@@ -474,7 +771,9 @@ int32_t ixgbe_init_ops_X550EM(struct ixg
 	/* EEPROM */
 	eeprom->ops.init_params = ixgbe_init_eeprom_params_X540;
 	eeprom->ops.read = ixgbe_read_ee_hostif_X550;
+	eeprom->ops.read_buffer = ixgbe_read_ee_hostif_buffer_X550;
 	eeprom->ops.write = ixgbe_write_ee_hostif_X550;
+	eeprom->ops.write_buffer = ixgbe_write_ee_hostif_buffer_X550;
 	eeprom->ops.update_checksum = ixgbe_update_eeprom_checksum_X550;
 	eeprom->ops.validate_checksum = ixgbe_validate_eeprom_checksum_X550;
 	eeprom->ops.calc_checksum = ixgbe_calc_eeprom_checksum_X550;
@@ -483,163 +782,804 @@ int32_t ixgbe_init_ops_X550EM(struct ixg
 }
 
 /**
- *  ixgbe_init_eeprom_params_X550 - Initialize EEPROM params
- *  @hw: pointer to hardware structure
- *
- *  Initializes the EEPROM parameters ixgbe_eeprom_info within the
- *  ixgbe_hw struct in order to set up EEPROM access.
- **/
-int32_t ixgbe_init_eeprom_params_X550(struct ixgbe_hw *hw)
+ * ixgbe_setup_fw_link - Setup firmware-controlled PHYs
+ * @hw: pointer to hardware structure
+ */
+static int32_t ixgbe_setup_fw_link(struct ixgbe_hw *hw)
 {
-	struct ixgbe_eeprom_info *eeprom = &hw->eeprom;
-	uint32_t eec;
-	uint16_t eeprom_size;
-
-	DEBUGFUNC("ixgbe_init_eeprom_params_X550");
+	uint32_t setup[FW_PHY_ACT_DATA_COUNT] = { 0 };
+	int32_t rc;
+	uint16_t i;
 
-	if (eeprom->type == ixgbe_eeprom_uninitialized) {
-		eeprom->semaphore_delay = 10;
-		eeprom->type = ixgbe_flash;
+	if (hw->phy.reset_disable || ixgbe_check_reset_blocked(hw))
+		return 0;
 
-		eec = IXGBE_READ_REG(hw, IXGBE_EEC);
-		eeprom_size = (uint16_t)((eec & IXGBE_EEC_SIZE) >>
-				    IXGBE_EEC_SIZE_SHIFT);
-		eeprom->word_size = 1 << (eeprom_size +
-					  IXGBE_EEPROM_WORD_SIZE_SHIFT);
+	if (hw->fc.strict_ieee && hw->fc.requested_mode == ixgbe_fc_rx_pause) {
+		ERROR_REPORT1(IXGBE_ERROR_UNSUPPORTED,
+			      "ixgbe_fc_rx_pause not valid in strict IEEE mode\n");
+		return IXGBE_ERR_INVALID_LINK_SETTINGS;
+	}
 
-		DEBUGOUT2("Eeprom params: type = %d, size = %d\n",
-			  eeprom->type, eeprom->word_size);
+	switch (hw->fc.requested_mode) {
+	case ixgbe_fc_full:
+		setup[0] |= FW_PHY_ACT_SETUP_LINK_PAUSE_RXTX <<
+			    FW_PHY_ACT_SETUP_LINK_PAUSE_SHIFT;
+		break;
+	case ixgbe_fc_rx_pause:
+		setup[0] |= FW_PHY_ACT_SETUP_LINK_PAUSE_RX <<
+			    FW_PHY_ACT_SETUP_LINK_PAUSE_SHIFT;
+		break;
+	case ixgbe_fc_tx_pause:
+		setup[0] |= FW_PHY_ACT_SETUP_LINK_PAUSE_TX <<
+			    FW_PHY_ACT_SETUP_LINK_PAUSE_SHIFT;
+		break;
+	default:
+		break;
 	}
 
+	for (i = 0; i < sizeof(ixgbe_fw_map) / sizeof(ixgbe_fw_map[0]); ++i) {
+		if (hw->phy.autoneg_advertised & ixgbe_fw_map[i].phy_speed)
+			setup[0] |= ixgbe_fw_map[i].fw_speed;
+	}
+	setup[0] |= FW_PHY_ACT_SETUP_LINK_HP | FW_PHY_ACT_SETUP_LINK_AN;
+
+	if (hw->phy.eee_speeds_advertised)
+		setup[0] |= FW_PHY_ACT_SETUP_LINK_EEE;
+
+	rc = ixgbe_fw_phy_activity(hw, FW_PHY_ACT_SETUP_LINK, &setup);
+	if (rc)
+		return rc;
+	if (setup[0] == FW_PHY_ACT_SETUP_LINK_RSP_DOWN)
+		return IXGBE_ERR_OVERTEMP;
 	return IXGBE_SUCCESS;
 }
 
 /**
- * ixgbe_iosf_wait - Wait for IOSF command completion
+ * ixgbe_fc_autoneg_fw _ Set up flow control for FW-controlled PHYs
  * @hw: pointer to hardware structure
- * @ctrl: pointer to location to receive final IOSF control value
- *
- * Returns failing status on timeout
  *
- * Note: ctrl can be NULL if the IOSF control register value is not needed
- **/
-int32_t ixgbe_iosf_wait(struct ixgbe_hw *hw, uint32_t *ctrl)
+ *  Called at init time to set up flow control.
+ */
+static int32_t ixgbe_fc_autoneg_fw(struct ixgbe_hw *hw)
 {
-	uint32_t i, command = 0;
+	if (hw->fc.requested_mode == ixgbe_fc_default)
+		hw->fc.requested_mode = ixgbe_fc_full;
 
-	/* Check every 10 usec to see if the address cycle completed.
-	 * The SB IOSF BUSY bit will clear when the operation is
-	 * complete
-	 */
-	for (i = 0; i < IXGBE_MDIO_COMMAND_TIMEOUT; i++) {
-		command = IXGBE_READ_REG(hw, IXGBE_SB_IOSF_INDIRECT_CTRL);
-		if ((command & IXGBE_SB_IOSF_CTRL_BUSY) == 0)
-			break;
-		usec_delay(10);
-	}
-	if (ctrl)
-		*ctrl = command;
-	if (i == IXGBE_MDIO_COMMAND_TIMEOUT) {
-		DEBUGOUT( "Wait timed out\n");
-		return IXGBE_ERR_PHY;
-	}
+	return ixgbe_setup_fw_link(hw);
+}
 
-	return IXGBE_SUCCESS;
+/**
+ * ixgbe_setup_eee_fw - Enable/disable EEE support
+ * @hw: pointer to the HW structure
+ * @enable_eee: boolean flag to enable EEE
+ *
+ * Enable/disable EEE based on enable_eee flag.
+ * This function controls EEE for firmware-based PHY implementations.
+ */
+static int32_t ixgbe_setup_eee_fw(struct ixgbe_hw *hw, bool enable_eee)
+{
+	if (!!hw->phy.eee_speeds_advertised == enable_eee)
+		return IXGBE_SUCCESS;
+	if (enable_eee)
+		hw->phy.eee_speeds_advertised = hw->phy.eee_speeds_supported;
+	else
+		hw->phy.eee_speeds_advertised = 0;
+	return hw->phy.ops.setup_link(hw);
 }
 
 /**
- *  ixgbe_write_iosf_sb_reg_x550 - Writes a value to specified register of the IOSF
- *  device
- *  @hw: pointer to hardware structure
- *  @reg_addr: 32 bit PHY register to write
- *  @device_type: 3 bit device type
- *  @data: Data to write to the register
- **/
-int32_t ixgbe_write_iosf_sb_reg_x550(struct ixgbe_hw *hw, uint32_t reg_addr,
-				     uint32_t device_type, uint32_t data)
+*  ixgbe_init_ops_X550EM_a - Inits func ptrs and MAC type
+*  @hw: pointer to hardware structure
+*
+*  Initialize the function pointers and for MAC type X550EM_a.
+*  Does not touch the hardware.
+**/
+int32_t ixgbe_init_ops_X550EM_a(struct ixgbe_hw *hw)
 {
-	uint32_t gssr = IXGBE_GSSR_PHY1_SM | IXGBE_GSSR_PHY0_SM;
-	uint32_t command, error;
-	int32_t ret;
+	struct ixgbe_mac_info *mac = &hw->mac;
+	int32_t ret_val;
 
-	ret = hw->mac.ops.acquire_swfw_sync(hw, gssr);
-	if (ret != IXGBE_SUCCESS)
-		return ret;
+	DEBUGFUNC("ixgbe_init_ops_X550EM_a");
 
-	ret = ixgbe_iosf_wait(hw, NULL);
-	if (ret != IXGBE_SUCCESS)
-		goto out;
+	/* Start with generic X550EM init */
+	ret_val = ixgbe_init_ops_X550EM(hw);
 
-	command = ((reg_addr << IXGBE_SB_IOSF_CTRL_ADDR_SHIFT) |
-		   (device_type << IXGBE_SB_IOSF_CTRL_TARGET_SELECT_SHIFT));
+	if (hw->device_id == IXGBE_DEV_ID_X550EM_A_SGMII ||
+	    hw->device_id == IXGBE_DEV_ID_X550EM_A_SGMII_L) {
+		mac->ops.read_iosf_sb_reg = ixgbe_read_iosf_sb_reg_x550;
+		mac->ops.write_iosf_sb_reg = ixgbe_write_iosf_sb_reg_x550;
+	} else {
+		mac->ops.read_iosf_sb_reg = ixgbe_read_iosf_sb_reg_x550a;
+		mac->ops.write_iosf_sb_reg = ixgbe_write_iosf_sb_reg_x550a;
+	}
+	mac->ops.acquire_swfw_sync = ixgbe_acquire_swfw_sync_X550a;
+	mac->ops.release_swfw_sync = ixgbe_release_swfw_sync_X550a;
 
-	/* Write IOSF control register */
-	IXGBE_WRITE_REG(hw, IXGBE_SB_IOSF_INDIRECT_CTRL, command);
+	switch (mac->ops.get_media_type(hw)) {
+	case ixgbe_media_type_fiber:
+		mac->ops.setup_fc = NULL;
+		mac->ops.fc_autoneg = ixgbe_fc_autoneg_fiber_x550em_a;
+		break;
+	case ixgbe_media_type_backplane:
+		mac->ops.fc_autoneg = ixgbe_fc_autoneg_backplane_x550em_a;
+		mac->ops.setup_fc = ixgbe_setup_fc_backplane_x550em_a;
+		break;
+	default:
+		break;
+	}
 
-	/* Write IOSF data register */
-	IXGBE_WRITE_REG(hw, IXGBE_SB_IOSF_INDIRECT_DATA, data);
+	switch (hw->device_id) {
+	case IXGBE_DEV_ID_X550EM_A_1G_T:
+	case IXGBE_DEV_ID_X550EM_A_1G_T_L:
+		mac->ops.fc_autoneg = ixgbe_fc_autoneg_sgmii_x550em_a;
+		mac->ops.setup_fc = ixgbe_fc_autoneg_fw;
+		mac->ops.setup_eee = ixgbe_setup_eee_fw;
+		hw->phy.eee_speeds_supported = IXGBE_LINK_SPEED_100_FULL |
+					       IXGBE_LINK_SPEED_1GB_FULL;
+		hw->phy.eee_speeds_advertised = hw->phy.eee_speeds_supported;
+		break;
+	default:
+		break;
+	}
 
-	ret = ixgbe_iosf_wait(hw, &command);
+	return ret_val;
+}
 
-	if ((command & IXGBE_SB_IOSF_CTRL_RESP_STAT_MASK) != 0) {
-		error = (command & IXGBE_SB_IOSF_CTRL_CMPL_ERR_MASK) >>
-			 IXGBE_SB_IOSF_CTRL_CMPL_ERR_SHIFT;
-		DEBUGOUT1("Failed to write, error %x\n", error);
-		ret = IXGBE_ERR_PHY;
+/**
+*  ixgbe_init_ops_X550EM_x - Inits func ptrs and MAC type
+*  @hw: pointer to hardware structure
+*
+*  Initialize the function pointers and for MAC type X550EM_x.
+*  Does not touch the hardware.
+**/
+int32_t ixgbe_init_ops_X550EM_x(struct ixgbe_hw *hw)
+{
+	struct ixgbe_mac_info *mac = &hw->mac;
+	struct ixgbe_link_info *link = &hw->link;
+	int32_t ret_val;
+
+	DEBUGFUNC("ixgbe_init_ops_X550EM_x");
+
+	/* Start with generic X550EM init */
+	ret_val = ixgbe_init_ops_X550EM(hw);
+
+	mac->ops.read_iosf_sb_reg = ixgbe_read_iosf_sb_reg_x550;
+	mac->ops.write_iosf_sb_reg = ixgbe_write_iosf_sb_reg_x550;
+	mac->ops.acquire_swfw_sync = ixgbe_acquire_swfw_sync_X550em;
+	mac->ops.release_swfw_sync = ixgbe_release_swfw_sync_X550em;
+	link->ops.read_link = ixgbe_read_i2c_combined_generic;
+	link->ops.read_link_unlocked = ixgbe_read_i2c_combined_generic_unlocked;
+	link->ops.write_link = ixgbe_write_i2c_combined_generic;
+	link->ops.write_link_unlocked =
+				      ixgbe_write_i2c_combined_generic_unlocked;
+	link->addr = IXGBE_CS4227;
+
+	if (hw->device_id == IXGBE_DEV_ID_X550EM_X_1G_T) {
+		mac->ops.setup_fc = NULL;
+		mac->ops.setup_eee = NULL;
+		mac->ops.init_led_link_act = NULL;
 	}
 
-out:
-	hw->mac.ops.release_swfw_sync(hw, gssr);
-	return ret;
+	return ret_val;
 }
 
 /**
- *  ixgbe_read_iosf_sb_reg_x550 - Writes a value to specified register of the IOSF
- *  device
+ *  ixgbe_dmac_config_X550
  *  @hw: pointer to hardware structure
- *  @reg_addr: 32 bit PHY register to write
- *  @device_type: 3 bit device type
- *  @phy_data: Pointer to read data from the register
+ *
+ *  Configure DMA coalescing. If enabling dmac, dmac is activated.
+ *  When disabling dmac, dmac enable dmac bit is cleared.
  **/
-int32_t ixgbe_read_iosf_sb_reg_x550(struct ixgbe_hw *hw, uint32_t reg_addr,
-				    uint32_t device_type, uint32_t *data)
+int32_t ixgbe_dmac_config_X550(struct ixgbe_hw *hw)
 {
-	uint32_t gssr = IXGBE_GSSR_PHY1_SM | IXGBE_GSSR_PHY0_SM;
-	uint32_t command, error;
-	int32_t ret;
+	uint32_t reg, high_pri_tc;
 
-	ret = hw->mac.ops.acquire_swfw_sync(hw, gssr);
-	if (ret != IXGBE_SUCCESS)
-		return ret;
+	DEBUGFUNC("ixgbe_dmac_config_X550");
 
-	ret = ixgbe_iosf_wait(hw, NULL);
-	if (ret != IXGBE_SUCCESS)
-		goto out;
+	/* Disable DMA coalescing before configuring */
+	reg = IXGBE_READ_REG(hw, IXGBE_DMACR);
+	reg &= ~IXGBE_DMACR_DMAC_EN;
+	IXGBE_WRITE_REG(hw, IXGBE_DMACR, reg);
 
-	command = ((reg_addr << IXGBE_SB_IOSF_CTRL_ADDR_SHIFT) |
-		   (device_type << IXGBE_SB_IOSF_CTRL_TARGET_SELECT_SHIFT));
+	/* Disable DMA Coalescing if the watchdog timer is 0 */
+	if (!hw->mac.dmac_config.watchdog_timer)
+		goto out;
 
-	/* Write IOSF control register */
-	IXGBE_WRITE_REG(hw, IXGBE_SB_IOSF_INDIRECT_CTRL, command);
+	ixgbe_dmac_config_tcs_X550(hw);
 
-	ret = ixgbe_iosf_wait(hw, &command);
+	/* Configure DMA Coalescing Control Register */
+	reg = IXGBE_READ_REG(hw, IXGBE_DMACR);
 
-	if ((command & IXGBE_SB_IOSF_CTRL_RESP_STAT_MASK) != 0) {
-		error = (command & IXGBE_SB_IOSF_CTRL_CMPL_ERR_MASK) >>
-			 IXGBE_SB_IOSF_CTRL_CMPL_ERR_SHIFT;
-		DEBUGOUT1("Failed to read, error %x\n", error);
-		ret = IXGBE_ERR_PHY;
-	}
+	/* Set the watchdog timer in units of 40.96 usec */
+	reg &= ~IXGBE_DMACR_DMACWT_MASK;
+	reg |= (hw->mac.dmac_config.watchdog_timer * 100) / 4096;
+
+	reg &= ~IXGBE_DMACR_HIGH_PRI_TC_MASK;
+	/* If fcoe is enabled, set high priority traffic class */
+	if (hw->mac.dmac_config.fcoe_en) {
+		high_pri_tc = 1 << hw->mac.dmac_config.fcoe_tc;
+		reg |= ((high_pri_tc << IXGBE_DMACR_HIGH_PRI_TC_SHIFT) &
+			IXGBE_DMACR_HIGH_PRI_TC_MASK);
+	}
+	reg |= IXGBE_DMACR_EN_MNG_IND;
+
+	/* Enable DMA coalescing after configuration */
+	reg |= IXGBE_DMACR_DMAC_EN;
+	IXGBE_WRITE_REG(hw, IXGBE_DMACR, reg);
 
-	if (ret == IXGBE_SUCCESS)
+out:
+	return IXGBE_SUCCESS;
+}
+
+/**
+ *  ixgbe_dmac_config_tcs_X550
+ *  @hw: pointer to hardware structure
+ *
+ *  Configure DMA coalescing threshold per TC. The dmac enable bit must
+ *  be cleared before configuring.
+ **/
+int32_t ixgbe_dmac_config_tcs_X550(struct ixgbe_hw *hw)
+{
+	uint32_t tc, reg, pb_headroom, rx_pb_size, maxframe_size_kb;
+
+	DEBUGFUNC("ixgbe_dmac_config_tcs_X550");
+
+	/* Configure DMA coalescing enabled */
+	switch (hw->mac.dmac_config.link_speed) {
+	case IXGBE_LINK_SPEED_10_FULL:
+	case IXGBE_LINK_SPEED_100_FULL:
+		pb_headroom = IXGBE_DMACRXT_100M;
+		break;
+	case IXGBE_LINK_SPEED_1GB_FULL:
+		pb_headroom = IXGBE_DMACRXT_1G;
+		break;
+	default:
+		pb_headroom = IXGBE_DMACRXT_10G;
+		break;
+	}
+
+	maxframe_size_kb = ((IXGBE_READ_REG(hw, IXGBE_MAXFRS) >>
+			     IXGBE_MHADD_MFS_SHIFT) / 1024);
+
+	/* Set the per Rx packet buffer receive threshold */
+	for (tc = 0; tc < IXGBE_DCB_MAX_TRAFFIC_CLASS; tc++) {
+		reg = IXGBE_READ_REG(hw, IXGBE_DMCTH(tc));
+		reg &= ~IXGBE_DMCTH_DMACRXT_MASK;
+
+		if (tc < hw->mac.dmac_config.num_tcs) {
+			/* Get Rx PB size */
+			rx_pb_size = IXGBE_READ_REG(hw, IXGBE_RXPBSIZE(tc));
+			rx_pb_size = (rx_pb_size & IXGBE_RXPBSIZE_MASK) >>
+				IXGBE_RXPBSIZE_SHIFT;
+
+			/* Calculate receive buffer threshold in kilobytes */
+			if (rx_pb_size > pb_headroom)
+				rx_pb_size = rx_pb_size - pb_headroom;
+			else
+				rx_pb_size = 0;
+
+			/* Minimum of MFS shall be set for DMCTH */
+			reg |= (rx_pb_size > maxframe_size_kb) ?
+				rx_pb_size : maxframe_size_kb;
+		}
+		IXGBE_WRITE_REG(hw, IXGBE_DMCTH(tc), reg);
+	}
+	return IXGBE_SUCCESS;
+}
+
+/**
+ *  ixgbe_dmac_update_tcs_X550
+ *  @hw: pointer to hardware structure
+ *
+ *  Disables dmac, updates per TC settings, and then enables dmac.
+ **/
+int32_t ixgbe_dmac_update_tcs_X550(struct ixgbe_hw *hw)
+{
+	uint32_t reg;
+
+	DEBUGFUNC("ixgbe_dmac_update_tcs_X550");
+
+	/* Disable DMA coalescing before configuring */
+	reg = IXGBE_READ_REG(hw, IXGBE_DMACR);
+	reg &= ~IXGBE_DMACR_DMAC_EN;
+	IXGBE_WRITE_REG(hw, IXGBE_DMACR, reg);
+
+	ixgbe_dmac_config_tcs_X550(hw);
+
+	/* Enable DMA coalescing after configuration */
+	reg = IXGBE_READ_REG(hw, IXGBE_DMACR);
+	reg |= IXGBE_DMACR_DMAC_EN;
+	IXGBE_WRITE_REG(hw, IXGBE_DMACR, reg);
+
+	return IXGBE_SUCCESS;
+}
+
+/**
+ *  ixgbe_init_eeprom_params_X550 - Initialize EEPROM params
+ *  @hw: pointer to hardware structure
+ *
+ *  Initializes the EEPROM parameters ixgbe_eeprom_info within the
+ *  ixgbe_hw struct in order to set up EEPROM access.
+ **/
+int32_t ixgbe_init_eeprom_params_X550(struct ixgbe_hw *hw)
+{
+	struct ixgbe_eeprom_info *eeprom = &hw->eeprom;
+	uint32_t eec;
+	uint16_t eeprom_size;
+
+	DEBUGFUNC("ixgbe_init_eeprom_params_X550");
+
+	if (eeprom->type == ixgbe_eeprom_uninitialized) {
+		eeprom->semaphore_delay = 10;
+		eeprom->type = ixgbe_flash;
+
+		eec = IXGBE_READ_REG(hw, IXGBE_EEC);
+		eeprom_size = (uint16_t)((eec & IXGBE_EEC_SIZE) >>
+				    IXGBE_EEC_SIZE_SHIFT);
+		eeprom->word_size = 1 << (eeprom_size +
+					  IXGBE_EEPROM_WORD_SIZE_SHIFT);
+
+		DEBUGOUT2("Eeprom params: type = %d, size = %d\n",
+			  eeprom->type, eeprom->word_size);
+	}
+
+	return IXGBE_SUCCESS;
+}
+
+/**
+ * ixgbe_set_source_address_pruning_X550 - Enable/Disbale source address pruning
+ * @hw: pointer to hardware structure
+ * @enable: enable or disable source address pruning
+ * @pool: Rx pool to set source address pruning for
+ **/
+void ixgbe_set_source_address_pruning_X550(struct ixgbe_hw *hw, bool enable,
+					   unsigned int pool)
+{
+	uint64_t pfflp;
+
+	/* max rx pool is 63 */
+	if (pool > 63)
+		return;
+
+	pfflp = (uint64_t)IXGBE_READ_REG(hw, IXGBE_PFFLPL);
+	pfflp |= (uint64_t)IXGBE_READ_REG(hw, IXGBE_PFFLPH) << 32;
+
+	if (enable)
+		pfflp |= (1ULL << pool);
+	else
+		pfflp &= ~(1ULL << pool);
+
+	IXGBE_WRITE_REG(hw, IXGBE_PFFLPL, (uint32_t)pfflp);
+	IXGBE_WRITE_REG(hw, IXGBE_PFFLPH, (uint32_t)(pfflp >> 32));
+}
+
+/**
+ *  ixgbe_set_ethertype_anti_spoofing_X550 - Enable/Disable Ethertype anti-spoofing
+ *  @hw: pointer to hardware structure
+ *  @enable: enable or disable switch for Ethertype anti-spoofing
+ *  @vf: Virtual Function pool - VF Pool to set for Ethertype anti-spoofing
+ *
+ **/
+void ixgbe_set_ethertype_anti_spoofing_X550(struct ixgbe_hw *hw,
+		bool enable, int vf)
+{
+	int vf_target_reg = vf >> 3;
+	int vf_target_shift = vf % 8 + IXGBE_SPOOF_ETHERTYPEAS_SHIFT;
+	uint32_t pfvfspoof;
+
+	DEBUGFUNC("ixgbe_set_ethertype_anti_spoofing_X550");
+
+	pfvfspoof = IXGBE_READ_REG(hw, IXGBE_PFVFSPOOF(vf_target_reg));
+	if (enable)
+		pfvfspoof |= (1 << vf_target_shift);
+	else
+		pfvfspoof &= ~(1 << vf_target_shift);
+
+	IXGBE_WRITE_REG(hw, IXGBE_PFVFSPOOF(vf_target_reg), pfvfspoof);
+}
+
+/**
+ * ixgbe_iosf_wait - Wait for IOSF command completion
+ * @hw: pointer to hardware structure
+ * @ctrl: pointer to location to receive final IOSF control value
+ *
+ * Returns failing status on timeout
+ *
+ * Note: ctrl can be NULL if the IOSF control register value is not needed
+ **/
+static int32_t ixgbe_iosf_wait(struct ixgbe_hw *hw, uint32_t *ctrl)
+{
+	uint32_t i, command = 0;
+
+	/* Check every 10 usec to see if the address cycle completed.
+	 * The SB IOSF BUSY bit will clear when the operation is
+	 * complete
+	 */
+	for (i = 0; i < IXGBE_MDIO_COMMAND_TIMEOUT; i++) {
+		command = IXGBE_READ_REG(hw, IXGBE_SB_IOSF_INDIRECT_CTRL);
+		if ((command & IXGBE_SB_IOSF_CTRL_BUSY) == 0)
+			break;
+		usec_delay(10);
+	}
+	if (ctrl)
+		*ctrl = command;
+	if (i == IXGBE_MDIO_COMMAND_TIMEOUT) {
+		ERROR_REPORT1(IXGBE_ERROR_POLLING, "Wait timed out\n");
+		return IXGBE_ERR_PHY;
+	}
+
+	return IXGBE_SUCCESS;
+}
+
+/**
+ *  ixgbe_write_iosf_sb_reg_x550 - Writes a value to specified register
+ *  of the IOSF device
+ *  @hw: pointer to hardware structure
+ *  @reg_addr: 32 bit PHY register to write
+ *  @device_type: 3 bit device type
+ *  @data: Data to write to the register
+ **/
+int32_t ixgbe_write_iosf_sb_reg_x550(struct ixgbe_hw *hw, uint32_t reg_addr,
+			    uint32_t device_type, uint32_t data)
+{
+	uint32_t gssr = IXGBE_GSSR_PHY1_SM | IXGBE_GSSR_PHY0_SM;
+	uint32_t command, error __unused;
+	int32_t ret;
+
+	ret = ixgbe_acquire_swfw_semaphore(hw, gssr);
+	if (ret != IXGBE_SUCCESS)
+		return ret;
+
+	ret = ixgbe_iosf_wait(hw, NULL);
+	if (ret != IXGBE_SUCCESS)
+		goto out;
+
+	command = ((reg_addr << IXGBE_SB_IOSF_CTRL_ADDR_SHIFT) |
+		   (device_type << IXGBE_SB_IOSF_CTRL_TARGET_SELECT_SHIFT));
+
+	/* Write IOSF control register */
+	IXGBE_WRITE_REG(hw, IXGBE_SB_IOSF_INDIRECT_CTRL, command);
+
+	/* Write IOSF data register */
+	IXGBE_WRITE_REG(hw, IXGBE_SB_IOSF_INDIRECT_DATA, data);
+
+	ret = ixgbe_iosf_wait(hw, &command);
+
+	if ((command & IXGBE_SB_IOSF_CTRL_RESP_STAT_MASK) != 0) {
+		error = (command & IXGBE_SB_IOSF_CTRL_CMPL_ERR_MASK) >>
+			 IXGBE_SB_IOSF_CTRL_CMPL_ERR_SHIFT;
+		ERROR_REPORT2(IXGBE_ERROR_POLLING,
+			      "Failed to write, error %x\n", error);
+		ret = IXGBE_ERR_PHY;
+	}
+
+out:
+	ixgbe_release_swfw_semaphore(hw, gssr);
+	return ret;
+}
+
+/**
+ *  ixgbe_read_iosf_sb_reg_x550 - Reads specified register of the IOSF device
+ *  @hw: pointer to hardware structure
+ *  @reg_addr: 32 bit PHY register to write
+ *  @device_type: 3 bit device type
+ *  @data: Pointer to read data from the register
+ **/
+int32_t ixgbe_read_iosf_sb_reg_x550(struct ixgbe_hw *hw, uint32_t reg_addr,
+			   uint32_t device_type, uint32_t *data)
+{
+	uint32_t gssr = IXGBE_GSSR_PHY1_SM | IXGBE_GSSR_PHY0_SM;
+	uint32_t command, error __unused;
+	int32_t ret;
+
+	ret = ixgbe_acquire_swfw_semaphore(hw, gssr);
+	if (ret != IXGBE_SUCCESS)
+		return ret;
+
+	ret = ixgbe_iosf_wait(hw, NULL);
+	if (ret != IXGBE_SUCCESS)
+		goto out;
+
+	command = ((reg_addr << IXGBE_SB_IOSF_CTRL_ADDR_SHIFT) |
+		   (device_type << IXGBE_SB_IOSF_CTRL_TARGET_SELECT_SHIFT));
+
+	/* Write IOSF control register */
+	IXGBE_WRITE_REG(hw, IXGBE_SB_IOSF_INDIRECT_CTRL, command);
+
+	ret = ixgbe_iosf_wait(hw, &command);
+
+	if ((command & IXGBE_SB_IOSF_CTRL_RESP_STAT_MASK) != 0) {
+		error = (command & IXGBE_SB_IOSF_CTRL_CMPL_ERR_MASK) >>
+			 IXGBE_SB_IOSF_CTRL_CMPL_ERR_SHIFT;
+		ERROR_REPORT2(IXGBE_ERROR_POLLING,
+				"Failed to read, error %x\n", error);
+		ret = IXGBE_ERR_PHY;
+	}
+
+	if (ret == IXGBE_SUCCESS)
 		*data = IXGBE_READ_REG(hw, IXGBE_SB_IOSF_INDIRECT_DATA);
 
 out:
-	hw->mac.ops.release_swfw_sync(hw, gssr);
+	ixgbe_release_swfw_semaphore(hw, gssr);
 	return ret;
 }
 
 /**
+ * ixgbe_get_phy_token - Get the token for shared phy access
+ * @hw: Pointer to hardware structure
+ */
+
+int32_t ixgbe_get_phy_token(struct ixgbe_hw *hw)
+{
+	struct ixgbe_hic_phy_token_req token_cmd;
+	int32_t status;
+
+	token_cmd.hdr.cmd = FW_PHY_TOKEN_REQ_CMD;
+	token_cmd.hdr.buf_len = FW_PHY_TOKEN_REQ_LEN;
+	token_cmd.hdr.cmd_or_resp.cmd_resv = 0;
+	token_cmd.hdr.checksum = FW_DEFAULT_CHECKSUM;
+	token_cmd.port_number = hw->bus.lan_id;
+	token_cmd.command_type = FW_PHY_TOKEN_REQ;
+	token_cmd.pad = 0;
+	status = ixgbe_host_interface_command(hw, (uint32_t *)&token_cmd,
+					      sizeof(token_cmd),
+					      IXGBE_HI_COMMAND_TIMEOUT,
+					      TRUE);
+	if (status) {
+		DEBUGOUT1("Issuing host interface command failed with Status = %d\n",
+			  status);
+		return status;
+	}
+	if (token_cmd.hdr.cmd_or_resp.ret_status == FW_PHY_TOKEN_OK)
+		return IXGBE_SUCCESS;
+	if (token_cmd.hdr.cmd_or_resp.ret_status != FW_PHY_TOKEN_RETRY) {
+		DEBUGOUT1("Host interface command returned 0x%08x , returning IXGBE_ERR_FW_RESP_INVALID\n",
+			  token_cmd.hdr.cmd_or_resp.ret_status);
+		return IXGBE_ERR_FW_RESP_INVALID;
+	}
+
+	DEBUGOUT("Returning  IXGBE_ERR_TOKEN_RETRY\n");
+	return IXGBE_ERR_TOKEN_RETRY;
+}
+
+/**
+ * ixgbe_put_phy_token - Put the token for shared phy access
+ * @hw: Pointer to hardware structure
+ */
+
+int32_t ixgbe_put_phy_token(struct ixgbe_hw *hw)
+{
+	struct ixgbe_hic_phy_token_req token_cmd;
+	int32_t status;
+
+	token_cmd.hdr.cmd = FW_PHY_TOKEN_REQ_CMD;
+	token_cmd.hdr.buf_len = FW_PHY_TOKEN_REQ_LEN;
+	token_cmd.hdr.cmd_or_resp.cmd_resv = 0;
+	token_cmd.hdr.checksum = FW_DEFAULT_CHECKSUM;
+	token_cmd.port_number = hw->bus.lan_id;
+	token_cmd.command_type = FW_PHY_TOKEN_REL;
+	token_cmd.pad = 0;
+	status = ixgbe_host_interface_command(hw, (uint32_t *)&token_cmd,
+					      sizeof(token_cmd),
+					      IXGBE_HI_COMMAND_TIMEOUT,
+					      TRUE);
+	if (status)
+		return status;
+	if (token_cmd.hdr.cmd_or_resp.ret_status == FW_PHY_TOKEN_OK)
+		return IXGBE_SUCCESS;
+
+	DEBUGOUT("Put PHY Token host interface command failed");
+	return IXGBE_ERR_FW_RESP_INVALID;
+}
+
+/**
+ *  ixgbe_write_iosf_sb_reg_x550a - Writes a value to specified register
+ *  of the IOSF device
+ *  @hw: pointer to hardware structure
+ *  @reg_addr: 32 bit PHY register to write
+ *  @device_type: 3 bit device type
+ *  @data: Data to write to the register
+ **/
+int32_t ixgbe_write_iosf_sb_reg_x550a(struct ixgbe_hw *hw, uint32_t reg_addr,
+				  UNUSED uint32_t device_type, uint32_t data)
+{
+	struct ixgbe_hic_internal_phy_req write_cmd;
+	int32_t status;
+
+	memset(&write_cmd, 0, sizeof(write_cmd));
+	write_cmd.hdr.cmd = FW_INT_PHY_REQ_CMD;
+	write_cmd.hdr.buf_len = FW_INT_PHY_REQ_LEN;
+	write_cmd.hdr.checksum = FW_DEFAULT_CHECKSUM;
+	write_cmd.port_number = hw->bus.lan_id;
+	write_cmd.command_type = FW_INT_PHY_REQ_WRITE;
+	write_cmd.address = IXGBE_CPU_TO_BE16(reg_addr);
+	write_cmd.write_data = IXGBE_CPU_TO_BE32(data);
+
+	status = ixgbe_host_interface_command(hw, (uint32_t *)&write_cmd,
+					      sizeof(write_cmd),
+					      IXGBE_HI_COMMAND_TIMEOUT, FALSE);
+
+	return status;
+}
+
+/**
+ *  ixgbe_read_iosf_sb_reg_x550a - Reads specified register of the IOSF device
+ *  @hw: pointer to hardware structure
+ *  @reg_addr: 32 bit PHY register to write
+ *  @device_type: 3 bit device type
+ *  @data: Pointer to read data from the register
+ **/
+int32_t ixgbe_read_iosf_sb_reg_x550a(struct ixgbe_hw *hw, uint32_t reg_addr,
+				 UNUSED uint32_t device_type, uint32_t *data)
+{
+	union {
+		struct ixgbe_hic_internal_phy_req cmd;
+		struct ixgbe_hic_internal_phy_resp rsp;
+	} hic;
+	int32_t status;
+
+	memset(&hic, 0, sizeof(hic));
+	hic.cmd.hdr.cmd = FW_INT_PHY_REQ_CMD;
+	hic.cmd.hdr.buf_len = FW_INT_PHY_REQ_LEN;
+	hic.cmd.hdr.checksum = FW_DEFAULT_CHECKSUM;
+	hic.cmd.port_number = hw->bus.lan_id;
+	hic.cmd.command_type = FW_INT_PHY_REQ_READ;
+	hic.cmd.address = IXGBE_CPU_TO_BE16(reg_addr);
+
+	status = ixgbe_host_interface_command(hw, (uint32_t *)&hic.cmd,
+					      sizeof(hic.cmd),
+					      IXGBE_HI_COMMAND_TIMEOUT, TRUE);
+
+	/* Extract the register value from the response. */
+	*data = IXGBE_BE32_TO_CPU(hic.rsp.read_data);
+
+	return status;
+}
+
+/**
+ *  ixgbe_disable_mdd_X550
+ *  @hw: pointer to hardware structure
+ *
+ *  Disable malicious driver detection
+ **/
+void ixgbe_disable_mdd_X550(struct ixgbe_hw *hw)
+{
+	uint32_t reg;
+
+	DEBUGFUNC("ixgbe_disable_mdd_X550");
+
+	/* Disable MDD for TX DMA and interrupt */
+	reg = IXGBE_READ_REG(hw, IXGBE_DMATXCTL);
+	reg &= ~(IXGBE_DMATXCTL_MDP_EN | IXGBE_DMATXCTL_MBINTEN);
+	IXGBE_WRITE_REG(hw, IXGBE_DMATXCTL, reg);
+
+	/* Disable MDD for RX and interrupt */
+	reg = IXGBE_READ_REG(hw, IXGBE_RDRXCTL);
+	reg &= ~(IXGBE_RDRXCTL_MDP_EN | IXGBE_RDRXCTL_MBINTEN);
+	IXGBE_WRITE_REG(hw, IXGBE_RDRXCTL, reg);
+}
+
+/**
+ *  ixgbe_enable_mdd_X550
+ *  @hw: pointer to hardware structure
+ *
+ *  Enable malicious driver detection
+ **/
+void ixgbe_enable_mdd_X550(struct ixgbe_hw *hw)
+{
+	uint32_t reg;
+
+	DEBUGFUNC("ixgbe_enable_mdd_X550");
+
+	/* Enable MDD for TX DMA and interrupt */
+	reg = IXGBE_READ_REG(hw, IXGBE_DMATXCTL);
+	reg |= (IXGBE_DMATXCTL_MDP_EN | IXGBE_DMATXCTL_MBINTEN);
+	IXGBE_WRITE_REG(hw, IXGBE_DMATXCTL, reg);
+
+	/* Enable MDD for RX and interrupt */
+	reg = IXGBE_READ_REG(hw, IXGBE_RDRXCTL);
+	reg |= (IXGBE_RDRXCTL_MDP_EN | IXGBE_RDRXCTL_MBINTEN);
+	IXGBE_WRITE_REG(hw, IXGBE_RDRXCTL, reg);
+}
+
+/**
+ *  ixgbe_restore_mdd_vf_X550
+ *  @hw: pointer to hardware structure
+ *  @vf: vf index
+ *
+ *  Restore VF that was disabled during malicious driver detection event
+ **/
+void ixgbe_restore_mdd_vf_X550(struct ixgbe_hw *hw, uint32_t vf)
+{
+	uint32_t idx, reg, num_qs, start_q, bitmask;
+
+	DEBUGFUNC("ixgbe_restore_mdd_vf_X550");
+
+	/* Map VF to queues */
+	reg = IXGBE_READ_REG(hw, IXGBE_MRQC);
+	switch (reg & IXGBE_MRQC_MRQE_MASK) {
+	case IXGBE_MRQC_VMDQRT8TCEN:
+		num_qs = 8;  /* 16 VFs / pools */
+		bitmask = 0x000000FF;
+		break;
+	case IXGBE_MRQC_VMDQRSS32EN:
+	case IXGBE_MRQC_VMDQRT4TCEN:
+		num_qs = 4;  /* 32 VFs / pools */
+		bitmask = 0x0000000F;
+		break;
+	default:            /* 64 VFs / pools */
+		num_qs = 2;
+		bitmask = 0x00000003;
+		break;
+	}
+	start_q = vf * num_qs;
+
+	/* Release vf's queues by clearing WQBR_TX and WQBR_RX (RW1C) */
+	idx = start_q / 32;
+	reg = 0;
+	reg |= (bitmask << (start_q % 32));
+	IXGBE_WRITE_REG(hw, IXGBE_WQBR_TX(idx), reg);
+	IXGBE_WRITE_REG(hw, IXGBE_WQBR_RX(idx), reg);
+}
+
+/**
+ *  ixgbe_mdd_event_X550
+ *  @hw: pointer to hardware structure
+ *  @vf_bitmap: vf bitmap of malicious vfs
+ *
+ *  Handle malicious driver detection event.
+ **/
+void ixgbe_mdd_event_X550(struct ixgbe_hw *hw, uint32_t *vf_bitmap)
+{
+	uint32_t wqbr;
+	uint32_t i, j, reg, q, shift, vf, idx;
+
+	DEBUGFUNC("ixgbe_mdd_event_X550");
+
+	/* figure out pool size for mapping to vf's */
+	reg = IXGBE_READ_REG(hw, IXGBE_MRQC);
+	switch (reg & IXGBE_MRQC_MRQE_MASK) {
+	case IXGBE_MRQC_VMDQRT8TCEN:
+		shift = 3;  /* 16 VFs / pools */
+		break;
+	case IXGBE_MRQC_VMDQRSS32EN:
+	case IXGBE_MRQC_VMDQRT4TCEN:
+		shift = 2;  /* 32 VFs / pools */
+		break;
+	default:
+		shift = 1;  /* 64 VFs / pools */
+		break;
+	}
+
+	/* Read WQBR_TX and WQBR_RX and check for malicious queues */
+	for (i = 0; i < 4; i++) {
+		wqbr = IXGBE_READ_REG(hw, IXGBE_WQBR_TX(i));
+		wqbr |= IXGBE_READ_REG(hw, IXGBE_WQBR_RX(i));
+
+		if (!wqbr)
+			continue;
+
+		/* Get malicious queue */
+		for (j = 0; j < 32 && wqbr; j++) {
+
+			if (!(wqbr & (1 << j)))
+				continue;
+
+			/* Get queue from bitmask */
+			q = j + (i * 32);
+
+			/* Map queue to vf */
+			vf = (q >> shift);
+
+			/* Set vf bit in vf_bitmap */
+			idx = vf / 32;
+			vf_bitmap[idx] |= (1 << (vf % 32));
+			wqbr &= ~(1 << j);
+		}
+	}
+}
+
+/**
  *  ixgbe_get_media_type_X550em - Get media type
  *  @hw: pointer to hardware structure
  *
@@ -655,13 +1595,30 @@ enum ixgbe_media_type ixgbe_get_media_ty
 	switch (hw->device_id) {
 	case IXGBE_DEV_ID_X550EM_X_KR:
 	case IXGBE_DEV_ID_X550EM_X_KX4:
+	case IXGBE_DEV_ID_X550EM_X_XFI:
+	case IXGBE_DEV_ID_X550EM_A_KR:
+	case IXGBE_DEV_ID_X550EM_A_KR_L:
 		media_type = ixgbe_media_type_backplane;
 		break;
 	case IXGBE_DEV_ID_X550EM_X_SFP:
+	case IXGBE_DEV_ID_X550EM_A_SFP:
+	case IXGBE_DEV_ID_X550EM_A_SFP_N:
+	case IXGBE_DEV_ID_X550EM_A_QSFP:
+	case IXGBE_DEV_ID_X550EM_A_QSFP_N:
 		media_type = ixgbe_media_type_fiber;
 		break;
 	case IXGBE_DEV_ID_X550EM_X_1G_T:
 	case IXGBE_DEV_ID_X550EM_X_10G_T:
+	case IXGBE_DEV_ID_X550EM_A_10G_T:
+		media_type = ixgbe_media_type_copper;
+		break;
+	case IXGBE_DEV_ID_X550EM_A_SGMII:
+	case IXGBE_DEV_ID_X550EM_A_SGMII_L:
+		media_type = ixgbe_media_type_backplane;
+		hw->phy.type = ixgbe_phy_sgmii;
+		break;
+	case IXGBE_DEV_ID_X550EM_A_1G_T:
+	case IXGBE_DEV_ID_X550EM_A_1G_T_L:
 		media_type = ixgbe_media_type_copper;
 		break;
 	default:
@@ -676,7 +1633,7 @@ enum ixgbe_media_type ixgbe_get_media_ty
  *  @hw: pointer to hardware structure
  *  @linear: TRUE if SFP module is linear
  */
-int32_t ixgbe_supported_sfp_modules_X550em(struct ixgbe_hw *hw, bool *linear)
+static int32_t ixgbe_supported_sfp_modules_X550em(struct ixgbe_hw *hw, bool *linear)
 {
 	DEBUGFUNC("ixgbe_supported_sfp_modules_X550em");
 
@@ -748,10 +1705,199 @@ int32_t ixgbe_setup_sfp_modules_X550em(s
 	if (status != IXGBE_SUCCESS)
 		return status;
 
-	ixgbe_init_mac_link_ops_X550em(hw);
-	hw->phy.ops.reset = NULL;
+	ixgbe_init_mac_link_ops_X550em(hw);
+	hw->phy.ops.reset = NULL;
+
+	return IXGBE_SUCCESS;
+}
+
+/**
+*  ixgbe_restart_an_internal_phy_x550em - restart autonegotiation for the
+*  internal PHY
+*  @hw: pointer to hardware structure
+**/
+static int32_t ixgbe_restart_an_internal_phy_x550em(struct ixgbe_hw *hw)
+{
+	int32_t status;
+	uint32_t link_ctrl;
+
+	/* Restart auto-negotiation. */
+	status = hw->mac.ops.read_iosf_sb_reg(hw,
+				       IXGBE_KRM_LINK_CTRL_1(hw->bus.lan_id),
+				       IXGBE_SB_IOSF_TARGET_KR_PHY, &link_ctrl);
+
+	if (status) {
+		DEBUGOUT("Auto-negotiation did not complete\n");
+		return status;
+	}
+
+	link_ctrl |= IXGBE_KRM_LINK_CTRL_1_TETH_AN_RESTART;
+	status = hw->mac.ops.write_iosf_sb_reg(hw,
+					IXGBE_KRM_LINK_CTRL_1(hw->bus.lan_id),
+					IXGBE_SB_IOSF_TARGET_KR_PHY, link_ctrl);
+
+	if (hw->mac.type == ixgbe_mac_X550EM_a) {
+		uint32_t flx_mask_st20;
+
+		/* Indicate to FW that AN restart has been asserted */
+		status = hw->mac.ops.read_iosf_sb_reg(hw,
+				IXGBE_KRM_PMD_FLX_MASK_ST20(hw->bus.lan_id),
+				IXGBE_SB_IOSF_TARGET_KR_PHY, &flx_mask_st20);
+
+		if (status) {
+			DEBUGOUT("Auto-negotiation did not complete\n");
+			return status;
+		}
+
+		flx_mask_st20 |= IXGBE_KRM_PMD_FLX_MASK_ST20_FW_AN_RESTART;
+		status = hw->mac.ops.write_iosf_sb_reg(hw,
+				IXGBE_KRM_PMD_FLX_MASK_ST20(hw->bus.lan_id),
+				IXGBE_SB_IOSF_TARGET_KR_PHY, flx_mask_st20);
+	}
+
+	return status;
+}
+
+/**
+ * ixgbe_setup_sgmii - Set up link for sgmii
+ * @hw: pointer to hardware structure
+ * @speed: new link speed
+ * @autoneg_wait: TRUE when waiting for completion is needed
+ */
+static int32_t ixgbe_setup_sgmii(struct ixgbe_hw *hw, ixgbe_link_speed speed,
+			     bool autoneg_wait)
+{
+	struct ixgbe_mac_info *mac = &hw->mac;
+	uint32_t lval, sval, flx_val;
+	int32_t rc;
+
+	rc = mac->ops.read_iosf_sb_reg(hw,
+				       IXGBE_KRM_LINK_CTRL_1(hw->bus.lan_id),
+				       IXGBE_SB_IOSF_TARGET_KR_PHY, &lval);
+	if (rc)
+		return rc;
+
+	lval &= ~IXGBE_KRM_LINK_CTRL_1_TETH_AN_ENABLE;
+	lval &= ~IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_MASK;
+	lval |= IXGBE_KRM_LINK_CTRL_1_TETH_AN_SGMII_EN;
+	lval |= IXGBE_KRM_LINK_CTRL_1_TETH_AN_CLAUSE_37_EN;
+	lval |= IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_1G;
+	rc = mac->ops.write_iosf_sb_reg(hw,
+					IXGBE_KRM_LINK_CTRL_1(hw->bus.lan_id),
+					IXGBE_SB_IOSF_TARGET_KR_PHY, lval);
+	if (rc)
+		return rc;
+
+	rc = mac->ops.read_iosf_sb_reg(hw,
+				       IXGBE_KRM_SGMII_CTRL(hw->bus.lan_id),
+				       IXGBE_SB_IOSF_TARGET_KR_PHY, &sval);
+	if (rc)
+		return rc;
+
+	sval |= IXGBE_KRM_SGMII_CTRL_MAC_TAR_FORCE_10_D;
+	sval |= IXGBE_KRM_SGMII_CTRL_MAC_TAR_FORCE_100_D;
+	rc = mac->ops.write_iosf_sb_reg(hw,
+					IXGBE_KRM_SGMII_CTRL(hw->bus.lan_id),
+					IXGBE_SB_IOSF_TARGET_KR_PHY, sval);
+	if (rc)
+		return rc;
+
+	rc = mac->ops.read_iosf_sb_reg(hw,
+				    IXGBE_KRM_PMD_FLX_MASK_ST20(hw->bus.lan_id),
+				    IXGBE_SB_IOSF_TARGET_KR_PHY, &flx_val);
+	if (rc)
+		return rc;
+
+	flx_val &= ~IXGBE_KRM_PMD_FLX_MASK_ST20_SPEED_MASK;
+	flx_val |= IXGBE_KRM_PMD_FLX_MASK_ST20_SPEED_1G;
+	flx_val &= ~IXGBE_KRM_PMD_FLX_MASK_ST20_AN_EN;
+	flx_val |= IXGBE_KRM_PMD_FLX_MASK_ST20_SGMII_EN;
+	flx_val |= IXGBE_KRM_PMD_FLX_MASK_ST20_AN37_EN;
+
+	rc = mac->ops.write_iosf_sb_reg(hw,
+				    IXGBE_KRM_PMD_FLX_MASK_ST20(hw->bus.lan_id),
+				    IXGBE_SB_IOSF_TARGET_KR_PHY, flx_val);
+	if (rc)
+		return rc;
+
+	rc = ixgbe_restart_an_internal_phy_x550em(hw);
+	if (rc)
+		return rc;
+
+	return hw->phy.ops.setup_link_speed(hw, speed, autoneg_wait);
+}
+
+/**
+ * ixgbe_setup_sgmii_fw - Set up link for internal PHY SGMII auto-negotiation
+ * @hw: pointer to hardware structure
+ * @speed: new link speed
+ * @autoneg_wait: TRUE when waiting for completion is needed
+ */
+static int32_t ixgbe_setup_sgmii_fw(struct ixgbe_hw *hw, ixgbe_link_speed speed,
+				bool autoneg_wait)
+{
+	struct ixgbe_mac_info *mac = &hw->mac;
+	uint32_t lval, sval, flx_val;
+	int32_t rc;
+
+	rc = mac->ops.read_iosf_sb_reg(hw,
+				       IXGBE_KRM_LINK_CTRL_1(hw->bus.lan_id),
+				       IXGBE_SB_IOSF_TARGET_KR_PHY, &lval);
+	if (rc)
+		return rc;
+
+	lval &= ~IXGBE_KRM_LINK_CTRL_1_TETH_AN_ENABLE;
+	lval &= ~IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_MASK;
+	lval |= IXGBE_KRM_LINK_CTRL_1_TETH_AN_SGMII_EN;
+	lval |= IXGBE_KRM_LINK_CTRL_1_TETH_AN_CLAUSE_37_EN;
+	lval &= ~IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_1G;
+	rc = mac->ops.write_iosf_sb_reg(hw,
+					IXGBE_KRM_LINK_CTRL_1(hw->bus.lan_id),
+					IXGBE_SB_IOSF_TARGET_KR_PHY, lval);
+	if (rc)
+		return rc;
+
+	rc = mac->ops.read_iosf_sb_reg(hw,
+				       IXGBE_KRM_SGMII_CTRL(hw->bus.lan_id),
+				       IXGBE_SB_IOSF_TARGET_KR_PHY, &sval);
+	if (rc)
+		return rc;
+
+	sval &= ~IXGBE_KRM_SGMII_CTRL_MAC_TAR_FORCE_10_D;
+	sval &= ~IXGBE_KRM_SGMII_CTRL_MAC_TAR_FORCE_100_D;
+	rc = mac->ops.write_iosf_sb_reg(hw,
+					IXGBE_KRM_SGMII_CTRL(hw->bus.lan_id),
+					IXGBE_SB_IOSF_TARGET_KR_PHY, sval);
+	if (rc)
+		return rc;
+
+	rc = mac->ops.write_iosf_sb_reg(hw,
+					IXGBE_KRM_LINK_CTRL_1(hw->bus.lan_id),
+					IXGBE_SB_IOSF_TARGET_KR_PHY, lval);
+	if (rc)
+		return rc;
+
+	rc = mac->ops.read_iosf_sb_reg(hw,
+				    IXGBE_KRM_PMD_FLX_MASK_ST20(hw->bus.lan_id),
+				    IXGBE_SB_IOSF_TARGET_KR_PHY, &flx_val);
+	if (rc)
+		return rc;
+
+	flx_val &= ~IXGBE_KRM_PMD_FLX_MASK_ST20_SPEED_MASK;
+	flx_val |= IXGBE_KRM_PMD_FLX_MASK_ST20_SPEED_AN;
+	flx_val &= ~IXGBE_KRM_PMD_FLX_MASK_ST20_AN_EN;
+	flx_val |= IXGBE_KRM_PMD_FLX_MASK_ST20_SGMII_EN;
+	flx_val |= IXGBE_KRM_PMD_FLX_MASK_ST20_AN37_EN;
+
+	rc = mac->ops.write_iosf_sb_reg(hw,
+				    IXGBE_KRM_PMD_FLX_MASK_ST20(hw->bus.lan_id),
+				    IXGBE_SB_IOSF_TARGET_KR_PHY, flx_val);
+	if (rc)
+		return rc;
+
+	rc = ixgbe_restart_an_internal_phy_x550em(hw);
 
-	return IXGBE_SUCCESS;
+	return hw->phy.ops.setup_link_speed(hw, speed, autoneg_wait);
 }
 
 /**
@@ -764,8 +1910,8 @@ void ixgbe_init_mac_link_ops_X550em(stru
 
 	DEBUGFUNC("ixgbe_init_mac_link_ops_X550em");
 
-	 switch (hw->mac.ops.get_media_type(hw)) {
-	 case ixgbe_media_type_fiber:
+	switch (hw->mac.ops.get_media_type(hw)) {
+	case ixgbe_media_type_fiber:
 		/* CS4227 does not support autoneg, so disable the laser control
 		 * functions for SFP+ fiber
 		 */
@@ -773,17 +1919,43 @@ void ixgbe_init_mac_link_ops_X550em(stru
 		mac->ops.enable_tx_laser = NULL;
 		mac->ops.flap_tx_laser = NULL;
 		mac->ops.setup_link = ixgbe_setup_mac_link_multispeed_fiber;
-		mac->ops.setup_mac_link = ixgbe_setup_mac_link_sfp_x550em;
 		mac->ops.set_rate_select_speed =
 					ixgbe_set_soft_rate_select_speed;
+
+		if ((hw->device_id == IXGBE_DEV_ID_X550EM_A_SFP_N) ||
+		    (hw->device_id == IXGBE_DEV_ID_X550EM_A_SFP))
+			mac->ops.setup_mac_link =
+						ixgbe_setup_mac_link_sfp_x550a;
+		else
+			mac->ops.setup_mac_link =
+						ixgbe_setup_mac_link_sfp_x550em;
 		break;
 	case ixgbe_media_type_copper:
-		mac->ops.setup_link = ixgbe_setup_mac_link_t_X550em;
-		mac->ops.check_link = ixgbe_check_link_t_X550em;
+		if (hw->device_id == IXGBE_DEV_ID_X550EM_X_1G_T)
+			break;
+		if (hw->mac.type == ixgbe_mac_X550EM_a) {
+			if (hw->device_id == IXGBE_DEV_ID_X550EM_A_1G_T ||
+			    hw->device_id == IXGBE_DEV_ID_X550EM_A_1G_T_L) {
+				mac->ops.setup_link = ixgbe_setup_sgmii_fw;
+				mac->ops.check_link =
+						   ixgbe_check_mac_link_generic;
+			} else {
+				mac->ops.setup_link =
+						  ixgbe_setup_mac_link_t_X550em;
+			}
+		} else {
+			mac->ops.setup_link = ixgbe_setup_mac_link_t_X550em;
+			mac->ops.check_link = ixgbe_check_link_t_X550em;
+		}
+		break;
+	case ixgbe_media_type_backplane:
+		if (hw->device_id == IXGBE_DEV_ID_X550EM_A_SGMII ||
+		    hw->device_id == IXGBE_DEV_ID_X550EM_A_SGMII_L)
+			mac->ops.setup_link = ixgbe_setup_sgmii;
 		break;
 	default:
 		break;
-	 }
+	}
 }
 
 /**
@@ -793,11 +1965,18 @@ void ixgbe_init_mac_link_ops_X550em(stru
  *  @autoneg: TRUE when autoneg or autotry is enabled
  */
 int32_t ixgbe_get_link_capabilities_X550em(struct ixgbe_hw *hw,
-					   ixgbe_link_speed *speed,
-					   bool *autoneg)
+				       ixgbe_link_speed *speed,
+				       bool *autoneg)
 {
 	DEBUGFUNC("ixgbe_get_link_capabilities_X550em");
 
+
+	if (hw->phy.type == ixgbe_phy_fw) {
+		*autoneg = TRUE;
+		*speed = hw->phy.speeds_supported;
+		return 0;
+	}
+
 	/* SFP */
 	if (hw->phy.media_type == ixgbe_media_type_fiber) {
 
@@ -820,8 +1999,30 @@ int32_t ixgbe_get_link_capabilities_X550
 		else
 			*speed = IXGBE_LINK_SPEED_10GB_FULL;
 	} else {
-		*speed = IXGBE_LINK_SPEED_10GB_FULL |
-			 IXGBE_LINK_SPEED_1GB_FULL;
+		switch (hw->phy.type) {
+		case ixgbe_phy_ext_1g_t:
+		case ixgbe_phy_sgmii:
+			*speed = IXGBE_LINK_SPEED_1GB_FULL;
+			break;
+		case ixgbe_phy_x550em_kr:
+			if (hw->mac.type == ixgbe_mac_X550EM_a) {
+				/* check different backplane modes */
+				if (hw->phy.nw_mng_if_sel &
+					   IXGBE_NW_MNG_IF_SEL_PHY_SPEED_2_5G) {
+					*speed = IXGBE_LINK_SPEED_2_5GB_FULL;
+					break;
+				} else if (hw->device_id ==
+						   IXGBE_DEV_ID_X550EM_A_KR_L) {
+					*speed = IXGBE_LINK_SPEED_1GB_FULL;
+					break;
+				}
+			}
+			/* fall through */
+		default:
+			*speed = IXGBE_LINK_SPEED_10GB_FULL |
+				 IXGBE_LINK_SPEED_1GB_FULL;
+			break;
+		}
 		*autoneg = TRUE;
 	}
 
@@ -840,7 +2041,7 @@ int32_t ixgbe_get_link_capabilities_X550
  * Return IXGBE_ERR_OVERTEMP if interrupt is high temperature
  * failure alarm, else return PHY access status.
  */
-int32_t ixgbe_get_lasi_ext_t_x550em(struct ixgbe_hw *hw, bool *lsc)
+static int32_t ixgbe_get_lasi_ext_t_x550em(struct ixgbe_hw *hw, bool *lsc)
 {
 	uint32_t status;
 	uint16_t reg;
@@ -927,7 +2128,7 @@ int32_t ixgbe_get_lasi_ext_t_x550em(stru
  *
  * Returns PHY access status
  */
-int32_t ixgbe_enable_lasi_ext_t_x550em(struct ixgbe_hw *hw)
+static int32_t ixgbe_enable_lasi_ext_t_x550em(struct ixgbe_hw *hw)
 {
 	uint32_t status;
 	uint16_t reg;
@@ -937,21 +2138,34 @@ int32_t ixgbe_enable_lasi_ext_t_x550em(s
 	status = ixgbe_get_lasi_ext_t_x550em(hw, &lsc);
 
 	/* Enable link status change alarm */
-	status = hw->phy.ops.read_reg(hw, IXGBE_MDIO_PMA_TX_VEN_LASI_INT_MASK,
-				      IXGBE_MDIO_AUTO_NEG_DEV_TYPE, &reg);
 
-	if (status != IXGBE_SUCCESS)
-		return status;
+	/* Enable the LASI interrupts on X552 devices to receive notifications
+	 * of the link configurations of the external PHY and correspondingly
+	 * support the configuration of the internal iXFI link, since iXFI does
+	 * not support auto-negotiation. This is not required for X553 devices
+	 * having KR support, which performs auto-negotiations and which is used
+	 * as the internal link to the external PHY. Hence adding a check here
+	 * to avoid enabling LASI interrupts for X553 devices.
+	 */
+	if (hw->mac.type != ixgbe_mac_X550EM_a) {
+		status = hw->phy.ops.read_reg(hw,
+					IXGBE_MDIO_PMA_TX_VEN_LASI_INT_MASK,
+					IXGBE_MDIO_AUTO_NEG_DEV_TYPE, &reg);
 
-	reg |= IXGBE_MDIO_PMA_TX_VEN_LASI_INT_EN;
+		if (status != IXGBE_SUCCESS)
+			return status;
 
-	status = hw->phy.ops.write_reg(hw, IXGBE_MDIO_PMA_TX_VEN_LASI_INT_MASK,
-				       IXGBE_MDIO_AUTO_NEG_DEV_TYPE, reg);
+		reg |= IXGBE_MDIO_PMA_TX_VEN_LASI_INT_EN;
 
-	if (status != IXGBE_SUCCESS)
-		return status;
+		status = hw->phy.ops.write_reg(hw,
+					IXGBE_MDIO_PMA_TX_VEN_LASI_INT_MASK,
+					IXGBE_MDIO_AUTO_NEG_DEV_TYPE, reg);
+
+		if (status != IXGBE_SUCCESS)
+			return status;
+	}
 
-	/* Enables high temperature failure alarm */
+	/* Enable high temperature failure and global fault alarms */
 	status = hw->phy.ops.read_reg(hw, IXGBE_MDIO_GLOBAL_INT_MASK,
 				      IXGBE_MDIO_VENDOR_SPECIFIC_1_DEV_TYPE,
 				      &reg);
@@ -959,7 +2173,8 @@ int32_t ixgbe_enable_lasi_ext_t_x550em(s
 	if (status != IXGBE_SUCCESS)
 		return status;
 
-	reg |= IXGBE_MDIO_GLOBAL_INT_HI_TEMP_EN;
+	reg |= (IXGBE_MDIO_GLOBAL_INT_HI_TEMP_EN |
+		IXGBE_MDIO_GLOBAL_INT_DEV_FAULT_EN);
 
 	status = hw->phy.ops.write_reg(hw, IXGBE_MDIO_GLOBAL_INT_MASK,
 				       IXGBE_MDIO_VENDOR_SPECIFIC_1_DEV_TYPE,
@@ -1010,15 +2225,15 @@ int32_t ixgbe_enable_lasi_ext_t_x550em(s
  *
  *  Configures the integrated KR PHY.
  **/
-int32_t ixgbe_setup_kr_speed_x550em(struct ixgbe_hw *hw,
-				    ixgbe_link_speed speed)
+static int32_t ixgbe_setup_kr_speed_x550em(struct ixgbe_hw *hw,
+				       ixgbe_link_speed speed)
 {
 	int32_t status;
 	uint32_t reg_val;
 
-	status = ixgbe_read_iosf_sb_reg_x550(hw,
-		IXGBE_KRM_LINK_CTRL_1(hw->bus.lan_id),
-		IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_val);
+	status = hw->mac.ops.read_iosf_sb_reg(hw,
+					IXGBE_KRM_LINK_CTRL_1(hw->bus.lan_id),
+					IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_val);
 	if (status)
 		return status;
 
@@ -1034,13 +2249,102 @@ int32_t ixgbe_setup_kr_speed_x550em(stru
 	if (speed & IXGBE_LINK_SPEED_1GB_FULL)
 		reg_val |= IXGBE_KRM_LINK_CTRL_1_TETH_AN_CAP_KX;
 
-	/* Restart auto-negotiation. */
-	reg_val |= IXGBE_KRM_LINK_CTRL_1_TETH_AN_RESTART;
-	status = ixgbe_write_iosf_sb_reg_x550(hw,
-		IXGBE_KRM_LINK_CTRL_1(hw->bus.lan_id),
-		IXGBE_SB_IOSF_TARGET_KR_PHY, reg_val);
+	status = hw->mac.ops.write_iosf_sb_reg(hw,
+					IXGBE_KRM_LINK_CTRL_1(hw->bus.lan_id),
+					IXGBE_SB_IOSF_TARGET_KR_PHY, reg_val);
 
-	return status;
+	if (hw->mac.type == ixgbe_mac_X550EM_a) {
+		/* Set lane mode  to KR auto negotiation */
+		status = hw->mac.ops.read_iosf_sb_reg(hw,
+				    IXGBE_KRM_PMD_FLX_MASK_ST20(hw->bus.lan_id),
+				    IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_val);
+
+		if (status)
+			return status;
+
+		reg_val &= ~IXGBE_KRM_PMD_FLX_MASK_ST20_SPEED_MASK;
+		reg_val |= IXGBE_KRM_PMD_FLX_MASK_ST20_SPEED_AN;
+		reg_val |= IXGBE_KRM_PMD_FLX_MASK_ST20_AN_EN;
+		reg_val &= ~IXGBE_KRM_PMD_FLX_MASK_ST20_AN37_EN;
+		reg_val &= ~IXGBE_KRM_PMD_FLX_MASK_ST20_SGMII_EN;
+
+		status = hw->mac.ops.write_iosf_sb_reg(hw,
+				    IXGBE_KRM_PMD_FLX_MASK_ST20(hw->bus.lan_id),
+				    IXGBE_SB_IOSF_TARGET_KR_PHY, reg_val);
+	}
+
+	return ixgbe_restart_an_internal_phy_x550em(hw);
+}
+
+/**
+ * ixgbe_reset_phy_fw - Reset firmware-controlled PHYs
+ * @hw: pointer to hardware structure
+ */
+static int32_t ixgbe_reset_phy_fw(struct ixgbe_hw *hw)
+{
+	uint32_t store[FW_PHY_ACT_DATA_COUNT] = { 0 };
+	int32_t rc;
+
+	if (hw->phy.reset_disable || ixgbe_check_reset_blocked(hw))
+		return IXGBE_SUCCESS;
+
+	rc = ixgbe_fw_phy_activity(hw, FW_PHY_ACT_PHY_SW_RESET, &store);
+	if (rc)
+		return rc;
+	memset(store, 0, sizeof(store));
+
+	rc = ixgbe_fw_phy_activity(hw, FW_PHY_ACT_INIT_PHY, &store);
+	if (rc)
+		return rc;
+
+	return ixgbe_setup_fw_link(hw);
+}
+
+/**
+ * ixgbe_check_overtemp_fw - Check firmware-controlled PHYs for overtemp
+ * @hw: pointer to hardware structure
+ */
+static int32_t ixgbe_check_overtemp_fw(struct ixgbe_hw *hw)
+{
+	uint32_t store[FW_PHY_ACT_DATA_COUNT] = { 0 };
+	int32_t rc;
+
+	rc = ixgbe_fw_phy_activity(hw, FW_PHY_ACT_GET_LINK_INFO, &store);
+	if (rc)
+		return rc;
+
+	if (store[0] & FW_PHY_ACT_GET_LINK_INFO_TEMP) {
+		ixgbe_shutdown_fw_phy(hw);
+		return IXGBE_ERR_OVERTEMP;
+	}
+	return IXGBE_SUCCESS;
+}
+
+/**
+ *  ixgbe_read_mng_if_sel_x550em - Read NW_MNG_IF_SEL register
+ *  @hw: pointer to hardware structure
+ *
+ *  Read NW_MNG_IF_SEL register and save field values, and check for valid field
+ *  values.
+ **/
+static int32_t ixgbe_read_mng_if_sel_x550em(struct ixgbe_hw *hw)
+{
+	/* Save NW management interface connected on board. This is used
+	 * to determine internal PHY mode.
+	 */
+	hw->phy.nw_mng_if_sel = IXGBE_READ_REG(hw, IXGBE_NW_MNG_IF_SEL);
+
+	/* If X552 (X550EM_a) and MDIO is connected to external PHY, then set
+	 * PHY address. This register field was has only been used for X552.
+	 */
+	if (hw->mac.type == ixgbe_mac_X550EM_a &&
+	    hw->phy.nw_mng_if_sel & IXGBE_NW_MNG_IF_SEL_MDIO_ACT) {
+		hw->phy.addr = (hw->phy.nw_mng_if_sel &
+				IXGBE_NW_MNG_IF_SEL_MDIO_PHY_ADD) >>
+			       IXGBE_NW_MNG_IF_SEL_MDIO_PHY_ADD_SHIFT;
+	}
+
+	return IXGBE_SUCCESS;
 }
 
 /**
@@ -1054,31 +2358,57 @@ int32_t ixgbe_setup_kr_speed_x550em(stru
 int32_t ixgbe_init_phy_ops_X550em(struct ixgbe_hw *hw)
 {
 	struct ixgbe_phy_info *phy = &hw->phy;
-	ixgbe_link_speed speed;
 	int32_t ret_val;
 
 	DEBUGFUNC("ixgbe_init_phy_ops_X550em");
 
 	hw->mac.ops.set_lan_id(hw);
+	ixgbe_read_mng_if_sel_x550em(hw);
 
 	if (hw->mac.ops.get_media_type(hw) == ixgbe_media_type_fiber) {
 		phy->phy_semaphore_mask = IXGBE_GSSR_SHARED_I2C_SM;
 		ixgbe_setup_mux_ctl(hw);
-
-		/* Save NW management interface connected on board. This is used
-		 * to determine internal PHY mode.
-		 */
-		phy->nw_mng_if_sel = IXGBE_READ_REG(hw, IXGBE_NW_MNG_IF_SEL);
-		if (phy->nw_mng_if_sel & IXGBE_NW_MNG_IF_SEL_INT_PHY_MODE) {
-			speed = IXGBE_LINK_SPEED_10GB_FULL |
-				IXGBE_LINK_SPEED_1GB_FULL;
-		}
 		phy->ops.identify_sfp = ixgbe_identify_sfp_module_X550em;
 	}
 
+	switch (hw->device_id) {
+	case IXGBE_DEV_ID_X550EM_A_1G_T:
+	case IXGBE_DEV_ID_X550EM_A_1G_T_L:
+		phy->ops.read_reg_mdi = NULL;
+		phy->ops.write_reg_mdi = NULL;
+		hw->phy.ops.read_reg = NULL;
+		hw->phy.ops.write_reg = NULL;
+		phy->ops.check_overtemp = ixgbe_check_overtemp_fw;
+		if (hw->bus.lan_id)
+			hw->phy.phy_semaphore_mask |= IXGBE_GSSR_PHY1_SM;
+		else
+			hw->phy.phy_semaphore_mask |= IXGBE_GSSR_PHY0_SM;
+
+		break;
+	case IXGBE_DEV_ID_X550EM_A_10G_T:
+	case IXGBE_DEV_ID_X550EM_A_SFP:
+		hw->phy.ops.read_reg = ixgbe_read_phy_reg_x550a;
+		hw->phy.ops.write_reg = ixgbe_write_phy_reg_x550a;
+		if (hw->bus.lan_id)
+			hw->phy.phy_semaphore_mask |= IXGBE_GSSR_PHY1_SM;
+		else
+			hw->phy.phy_semaphore_mask |= IXGBE_GSSR_PHY0_SM;
+		break;
+	case IXGBE_DEV_ID_X550EM_X_SFP:
+		/* set up for CS4227 usage */
+		hw->phy.phy_semaphore_mask = IXGBE_GSSR_SHARED_I2C_SM;
+		break;
+	case IXGBE_DEV_ID_X550EM_X_1G_T:
+		phy->ops.read_reg_mdi = NULL;
+		phy->ops.write_reg_mdi = NULL;
+	default:
+		break;
+	}
+
 	/* Identify the PHY or SFP module */
 	ret_val = phy->ops.identify(hw);
-	if (ret_val == IXGBE_ERR_SFP_NOT_SUPPORTED)
+	if (ret_val == IXGBE_ERR_SFP_NOT_SUPPORTED ||
+	    ret_val == IXGBE_ERR_PHY_ADDR_INVALID)
 		return ret_val;
 
 	/* Setup function pointers based on detected hardware */
@@ -1098,27 +2428,40 @@ int32_t ixgbe_init_phy_ops_X550em(struct
 		phy->ops.read_reg = ixgbe_read_phy_reg_x550em;
 		phy->ops.write_reg = ixgbe_write_phy_reg_x550em;
 		break;
+	case ixgbe_phy_ext_1g_t:
+		/* link is managed by FW */
+		phy->ops.setup_link = NULL;
+		phy->ops.reset = NULL;
+		break;
+	case ixgbe_phy_x550em_xfi:
+		/* link is managed by HW */
+		phy->ops.setup_link = NULL;
+		phy->ops.read_reg = ixgbe_read_phy_reg_x550em;
+		phy->ops.write_reg = ixgbe_write_phy_reg_x550em;
+		break;
 	case ixgbe_phy_x550em_ext_t:
-		/* Save NW management interface connected on board. This is used
-		 * to determine internal PHY mode
-		 */
-		phy->nw_mng_if_sel = IXGBE_READ_REG(hw, IXGBE_NW_MNG_IF_SEL);
-
 		/* If internal link mode is XFI, then setup iXFI internal link,
 		 * else setup KR now.
 		 */
-		if (!(phy->nw_mng_if_sel & IXGBE_NW_MNG_IF_SEL_INT_PHY_MODE)) {
-			phy->ops.setup_internal_link =
+		phy->ops.setup_internal_link =
 					      ixgbe_setup_internal_phy_t_x550em;
-		} else {
-			speed = IXGBE_LINK_SPEED_10GB_FULL |
-				IXGBE_LINK_SPEED_1GB_FULL;
-			ret_val = ixgbe_setup_kr_speed_x550em(hw, speed);
-		}
+
+		/* setup SW LPLU only for first revision of X550EM_x */
+		if ((hw->mac.type == ixgbe_mac_X550EM_x) &&
+		    !(IXGBE_FUSES0_REV_MASK &
+		      IXGBE_READ_REG(hw, IXGBE_FUSES0_GROUP(0))))
+			phy->ops.enter_lplu = ixgbe_enter_lplu_t_x550em;
 
 		phy->ops.handle_lasi = ixgbe_handle_lasi_ext_t_x550em;
 		phy->ops.reset = ixgbe_reset_phy_t_X550em;
 		break;
+	case ixgbe_phy_sgmii:
+		phy->ops.setup_link = NULL;
+		break;
+	case ixgbe_phy_fw:
+		phy->ops.setup_link = ixgbe_setup_fw_link;
+		phy->ops.reset = ixgbe_reset_phy_fw;
+		break;
 	default:
 		break;
 	}
@@ -1126,6 +2469,38 @@ int32_t ixgbe_init_phy_ops_X550em(struct
 }
 
 /**
+ * ixgbe_set_mdio_speed - Set MDIO clock speed
+ *  @hw: pointer to hardware structure
+ */
+static void ixgbe_set_mdio_speed(struct ixgbe_hw *hw)
+{
+	uint32_t hlreg0;
+
+	switch (hw->device_id) {
+	case IXGBE_DEV_ID_X550EM_X_10G_T:
+	case IXGBE_DEV_ID_X550EM_A_SGMII:
+	case IXGBE_DEV_ID_X550EM_A_SGMII_L:
+	case IXGBE_DEV_ID_X550EM_A_10G_T:
+	case IXGBE_DEV_ID_X550EM_A_SFP:
+	case IXGBE_DEV_ID_X550EM_A_QSFP:
+		/* Config MDIO clock speed before the first MDIO PHY access */
+		hlreg0 = IXGBE_READ_REG(hw, IXGBE_HLREG0);
+		hlreg0 &= ~IXGBE_HLREG0_MDCSPD;
+		IXGBE_WRITE_REG(hw, IXGBE_HLREG0, hlreg0);
+		break;
+	case IXGBE_DEV_ID_X550EM_A_1G_T:
+	case IXGBE_DEV_ID_X550EM_A_1G_T_L:
+		/* Select fast MDIO clock speed for these devices */
+		hlreg0 = IXGBE_READ_REG(hw, IXGBE_HLREG0);
+		hlreg0 |= IXGBE_HLREG0_MDCSPD;
+		IXGBE_WRITE_REG(hw, IXGBE_HLREG0, hlreg0);
+		break;
+	default:
+		break;
+	}
+}
+
+/**
  *  ixgbe_reset_hw_X550em - Perform hardware reset
  *  @hw: pointer to hardware structure
  *
@@ -1139,37 +2514,43 @@ int32_t ixgbe_reset_hw_X550em(struct ixg
 	int32_t status;
 	uint32_t ctrl = 0;
 	uint32_t i;
-	uint32_t hlreg0;
 	bool link_up = FALSE;
+	uint32_t swfw_mask = hw->phy.phy_semaphore_mask;
 
 	DEBUGFUNC("ixgbe_reset_hw_X550em");
 
 	/* Call adapter stop to disable Tx/Rx and clear interrupts */
 	status = hw->mac.ops.stop_adapter(hw);
-	if (status != IXGBE_SUCCESS)
+	if (status != IXGBE_SUCCESS) {
+		DEBUGOUT1("Failed to stop adapter, STATUS = %d\n", status);
 		return status;
-
+	}
 	/* flush pending Tx transactions */
 	ixgbe_clear_tx_pending(hw);
 
-	if (hw->device_id == IXGBE_DEV_ID_X550EM_X_10G_T) {
-		/* Config MDIO clock speed before the first MDIO PHY access */
-		hlreg0 = IXGBE_READ_REG(hw, IXGBE_HLREG0);
-		hlreg0 &= ~IXGBE_HLREG0_MDCSPD;
-		IXGBE_WRITE_REG(hw, IXGBE_HLREG0, hlreg0);
-	}
+	ixgbe_set_mdio_speed(hw);
 
 	/* PHY ops must be identified and initialized prior to reset */
 	status = hw->phy.ops.init(hw);
 
-	if (status == IXGBE_ERR_SFP_NOT_SUPPORTED)
+	if (status)
+		DEBUGOUT1("Failed to initialize PHY ops, STATUS = %d\n",
+			  status);
+
+	if (status == IXGBE_ERR_SFP_NOT_SUPPORTED ||
+	    status == IXGBE_ERR_PHY_ADDR_INVALID) {
+		DEBUGOUT("Returning from reset HW due to PHY init failure\n");
 		return status;
+	}
 
 	/* start the external PHY */
 	if (hw->phy.type == ixgbe_phy_x550em_ext_t) {
 		status = ixgbe_init_ext_t_x550em(hw);
-		if (status)
+		if (status) {
+			DEBUGOUT1("Failed to start the external PHY, STATUS = %d\n",
+				  status);
 			return status;
+		}
 	}
 
 	/* Setup SFP module if there is one present. */
@@ -1182,8 +2563,10 @@ int32_t ixgbe_reset_hw_X550em(struct ixg
 		return status;
 
 	/* Reset PHY */
-	if (!hw->phy.reset_disable && hw->phy.ops.reset)
-		hw->phy.ops.reset(hw);
+	if (!hw->phy.reset_disable && hw->phy.ops.reset) {
+		if (hw->phy.ops.reset(hw) == IXGBE_ERR_OVERTEMP)
+			return IXGBE_ERR_OVERTEMP;
+	}
 
 mac_reset_top:
 	/* Issue global reset to the MAC.  Needs to be SW reset if link is up.
@@ -1198,9 +2581,16 @@ mac_reset_top:
 			ctrl = IXGBE_CTRL_RST;
 	}
 
+	status = hw->mac.ops.acquire_swfw_sync(hw, swfw_mask);
+	if (status != IXGBE_SUCCESS) {
+		ERROR_REPORT2(IXGBE_ERROR_CAUTION,
+			"semaphore failed with %d", status);
+		return IXGBE_ERR_SWFW_SYNC;
+	}
 	ctrl |= IXGBE_READ_REG(hw, IXGBE_CTRL);
 	IXGBE_WRITE_REG(hw, IXGBE_CTRL, ctrl);
 	IXGBE_WRITE_FLUSH(hw);
+	hw->mac.ops.release_swfw_sync(hw, swfw_mask);
 
 	/* Poll for reset bit to self-clear meaning reset is complete */
 	for (i = 0; i < 10; i++) {
@@ -1236,9 +2626,14 @@ mac_reset_top:
 	hw->mac.num_rar_entries = 128;
 	hw->mac.ops.init_rx_addrs(hw);
 
+	ixgbe_set_mdio_speed(hw);
+
 	if (hw->device_id == IXGBE_DEV_ID_X550EM_X_SFP)
 		ixgbe_setup_mux_ctl(hw);
 
+	if (status != IXGBE_SUCCESS)
+		DEBUGOUT1("Reset HW failed, STATUS = %d\n", status);
+
 	return status;
 }
 
@@ -1288,23 +2683,30 @@ int32_t ixgbe_init_ext_t_x550em(struct i
 /**
  *  ixgbe_setup_kr_x550em - Configure the KR PHY.
  *  @hw: pointer to hardware structure
- *
- *  Configures the integrated KR PHY.
  **/
 int32_t ixgbe_setup_kr_x550em(struct ixgbe_hw *hw)
 {
+	/* leave link alone for 2.5G */
+	if (hw->phy.autoneg_advertised & IXGBE_LINK_SPEED_2_5GB_FULL)
+		return IXGBE_SUCCESS;
+
+	if (ixgbe_check_reset_blocked(hw))
+		return 0;
+
 	return ixgbe_setup_kr_speed_x550em(hw, hw->phy.autoneg_advertised);
 }
 
 /**
  *  ixgbe_setup_mac_link_sfp_x550em - Setup internal/external the PHY for SFP
  *  @hw: pointer to hardware structure
+ *  @speed: new link speed
+ *  @autoneg_wait_to_complete: unused
  *
  *  Configure the external PHY and the integrated KR PHY for SFP support.
  **/
 int32_t ixgbe_setup_mac_link_sfp_x550em(struct ixgbe_hw *hw,
-					ixgbe_link_speed speed,
-					bool autoneg_wait_to_complete)
+				    ixgbe_link_speed speed,
+				    UNUSED bool autoneg_wait_to_complete)
 {
 	int32_t ret_val;
 	uint16_t reg_slice, reg_val;
@@ -1323,113 +2725,200 @@ int32_t ixgbe_setup_mac_link_sfp_x550em(
 	if (ret_val != IXGBE_SUCCESS)
 		return ret_val;
 
-	if (!(hw->phy.nw_mng_if_sel & IXGBE_NW_MNG_IF_SEL_INT_PHY_MODE)) {
-		/* Configure CS4227 LINE side to 10G SR. */
-		reg_slice = IXGBE_CS4227_LINE_SPARE22_MSB +
-			    (hw->bus.lan_id << 12);
-		reg_val = IXGBE_CS4227_SPEED_10G;
-		ret_val = hw->phy.ops.write_i2c_combined(hw, IXGBE_CS4227,
-							 reg_slice, reg_val);
+	/* Configure internal PHY for KR/KX. */
+	ixgbe_setup_kr_speed_x550em(hw, speed);
 
-		reg_slice = IXGBE_CS4227_LINE_SPARE24_LSB +
-			    (hw->bus.lan_id << 12);
+	/* Configure CS4227 LINE side to proper mode. */
+	reg_slice = IXGBE_CS4227_LINE_SPARE24_LSB +
+		    (hw->bus.lan_id << 12);
+	if (setup_linear)
+		reg_val = (IXGBE_CS4227_EDC_MODE_CX1 << 1) | 0x1;
+	else
 		reg_val = (IXGBE_CS4227_EDC_MODE_SR << 1) | 0x1;
-		ret_val = hw->phy.ops.write_i2c_combined(hw, IXGBE_CS4227,
-							 reg_slice, reg_val);
-
-		/* Configure CS4227 for HOST connection rate then type. */
-		reg_slice = IXGBE_CS4227_HOST_SPARE22_MSB +
-			    (hw->bus.lan_id << 12);
-		reg_val = (speed & IXGBE_LINK_SPEED_10GB_FULL) ?
-		IXGBE_CS4227_SPEED_10G : IXGBE_CS4227_SPEED_1G;
-		ret_val = hw->phy.ops.write_i2c_combined(hw, IXGBE_CS4227,
-							 reg_slice, reg_val);
-
-		reg_slice = IXGBE_CS4227_HOST_SPARE24_LSB +
-			    (hw->bus.lan_id << 12);
-		if (setup_linear)
-			reg_val = (IXGBE_CS4227_EDC_MODE_CX1 << 1) | 0x1;
-		else
-			reg_val = (IXGBE_CS4227_EDC_MODE_SR << 1) | 0x1;
-		ret_val = hw->phy.ops.write_i2c_combined(hw, IXGBE_CS4227,
-							 reg_slice, reg_val);
-
-		/* Setup XFI internal link. */
-		ret_val = ixgbe_setup_ixfi_x550em(hw, &speed);
-	} else {
-		/* Configure internal PHY for KR/KX. */
-		ixgbe_setup_kr_speed_x550em(hw, speed);
-
-		/* Configure CS4227 LINE side to proper mode. */
-		reg_slice = IXGBE_CS4227_LINE_SPARE24_LSB +
-			    (hw->bus.lan_id << 12);
-		if (setup_linear)
-			reg_val = (IXGBE_CS4227_EDC_MODE_CX1 << 1) | 0x1;
-		else
-			reg_val = (IXGBE_CS4227_EDC_MODE_SR << 1) | 0x1;
-		ret_val = hw->phy.ops.write_i2c_combined(hw, IXGBE_CS4227,
-							 reg_slice, reg_val);
-	}
+	ret_val = hw->link.ops.write_link(hw, hw->link.addr, reg_slice,
+					  reg_val);
 	return ret_val;
 }
 
 /**
- *  ixgbe_setup_ixfi_x550em - Configure the KR PHY for iXFI mode.
+ *  ixgbe_setup_sfi_x550a - Configure the internal PHY for native SFI mode
  *  @hw: pointer to hardware structure
  *  @speed: the link speed to force
  *
- *  Configures the integrated KR PHY to use iXFI mode. Used to connect an
- *  internal and external PHY at a specific speed, without autonegotiation.
+ *  Configures the integrated PHY for native SFI mode. Used to connect the
+ *  internal PHY directly to an SFP cage, without autonegotiation.
  **/
-int32_t ixgbe_setup_ixfi_x550em(struct ixgbe_hw *hw, ixgbe_link_speed *speed)
+static int32_t ixgbe_setup_sfi_x550a(struct ixgbe_hw *hw, ixgbe_link_speed *speed)
 {
+	struct ixgbe_mac_info *mac = &hw->mac;
 	int32_t status;
 	uint32_t reg_val;
 
-	/* Disable AN and force speed to 10G Serial. */
-	status = ixgbe_read_iosf_sb_reg_x550(hw,
-					IXGBE_KRM_LINK_CTRL_1(hw->bus.lan_id),
-					IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_val);
+	/* Disable all AN and force speed to 10G Serial. */
+	status = mac->ops.read_iosf_sb_reg(hw,
+				IXGBE_KRM_PMD_FLX_MASK_ST20(hw->bus.lan_id),
+				IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_val);
 	if (status != IXGBE_SUCCESS)
 		return status;
 
-	reg_val &= ~IXGBE_KRM_LINK_CTRL_1_TETH_AN_ENABLE;
-	reg_val &= ~IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_MASK;
+	reg_val &= ~IXGBE_KRM_PMD_FLX_MASK_ST20_AN_EN;
+	reg_val &= ~IXGBE_KRM_PMD_FLX_MASK_ST20_AN37_EN;
+	reg_val &= ~IXGBE_KRM_PMD_FLX_MASK_ST20_SGMII_EN;
+	reg_val &= ~IXGBE_KRM_PMD_FLX_MASK_ST20_SPEED_MASK;
 
 	/* Select forced link speed for internal PHY. */
 	switch (*speed) {
 	case IXGBE_LINK_SPEED_10GB_FULL:
-		reg_val |= IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_10G;
+		reg_val |= IXGBE_KRM_PMD_FLX_MASK_ST20_SPEED_10G;
 		break;
 	case IXGBE_LINK_SPEED_1GB_FULL:
-		reg_val |= IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_1G;
+		reg_val |= IXGBE_KRM_PMD_FLX_MASK_ST20_SPEED_1G;
 		break;
 	default:
-		/* Other link speeds are not supported by internal KR PHY. */
+		/* Other link speeds are not supported by internal PHY. */
 		return IXGBE_ERR_LINK_SETUP;
 	}
 
-	status = ixgbe_write_iosf_sb_reg_x550(hw,
-					IXGBE_KRM_LINK_CTRL_1(hw->bus.lan_id),
-					IXGBE_SB_IOSF_TARGET_KR_PHY, reg_val);
-	if (status != IXGBE_SUCCESS)
-		return status;
+	status = mac->ops.write_iosf_sb_reg(hw,
+				IXGBE_KRM_PMD_FLX_MASK_ST20(hw->bus.lan_id),
+				IXGBE_SB_IOSF_TARGET_KR_PHY, reg_val);
+
+	/* Toggle port SW reset by AN reset. */
+	status = ixgbe_restart_an_internal_phy_x550em(hw);
+
+	return status;
+}
+
+/**
+ *  ixgbe_setup_mac_link_sfp_x550a - Setup internal PHY for SFP
+ *  @hw: pointer to hardware structure
+ *  @speed: new link speed
+ *  @autoneg_wait_to_complete: unused
+ *
+ *  Configure the the integrated PHY for SFP support.
+ **/
+int32_t ixgbe_setup_mac_link_sfp_x550a(struct ixgbe_hw *hw,
+				    ixgbe_link_speed speed,
+				    UNUSED bool autoneg_wait_to_complete)
+{
+	int32_t ret_val;
+	uint16_t reg_phy_ext;
+	bool setup_linear = FALSE;
+	uint32_t reg_slice, reg_phy_int, slice_offset;
+
+	/* Check if SFP module is supported and linear */
+	ret_val = ixgbe_supported_sfp_modules_X550em(hw, &setup_linear);
+
+	/* If no SFP module present, then return success. Return success since
+	 * SFP not present error is not excepted in the setup MAC link flow.
+	 */
+	if (ret_val == IXGBE_ERR_SFP_NOT_PRESENT)
+		return IXGBE_SUCCESS;
+
+	if (ret_val != IXGBE_SUCCESS)
+		return ret_val;
+
+	if (hw->device_id == IXGBE_DEV_ID_X550EM_A_SFP_N) {
+		/* Configure internal PHY for native SFI based on module type */
+		ret_val = hw->mac.ops.read_iosf_sb_reg(hw,
+				   IXGBE_KRM_PMD_FLX_MASK_ST20(hw->bus.lan_id),
+				   IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_phy_int);
+
+		if (ret_val != IXGBE_SUCCESS)
+			return ret_val;
+
+		reg_phy_int &= IXGBE_KRM_PMD_FLX_MASK_ST20_SFI_10G_DA;
+		if (!setup_linear)
+			reg_phy_int |= IXGBE_KRM_PMD_FLX_MASK_ST20_SFI_10G_SR;
+
+		ret_val = hw->mac.ops.write_iosf_sb_reg(hw,
+				   IXGBE_KRM_PMD_FLX_MASK_ST20(hw->bus.lan_id),
+				   IXGBE_SB_IOSF_TARGET_KR_PHY, reg_phy_int);
+
+		if (ret_val != IXGBE_SUCCESS)
+			return ret_val;
+
+		/* Setup SFI internal link. */
+		ret_val = ixgbe_setup_sfi_x550a(hw, &speed);
+	} else {
+		/* Configure internal PHY for KR/KX. */
+		ixgbe_setup_kr_speed_x550em(hw, speed);
+
+		if (hw->phy.addr == 0x0 || hw->phy.addr == 0xFFFF) {
+			/* Find Address */
+			DEBUGOUT("Invalid NW_MNG_IF_SEL.MDIO_PHY_ADD value\n");
+			return IXGBE_ERR_PHY_ADDR_INVALID;
+		}
+
+		/* Get external PHY SKU id */
+		ret_val = hw->phy.ops.read_reg(hw, IXGBE_CS4227_EFUSE_PDF_SKU,
+					IXGBE_MDIO_ZERO_DEV_TYPE, &reg_phy_ext);
+
+		if (ret_val != IXGBE_SUCCESS)
+			return ret_val;
+
+		/* When configuring quad port CS4223, the MAC instance is part
+		 * of the slice offset.
+		 */
+		if (reg_phy_ext == IXGBE_CS4223_SKU_ID)
+			slice_offset = (hw->bus.lan_id +
+					(hw->bus.instance_id << 1)) << 12;
+		else
+			slice_offset = hw->bus.lan_id << 12;
+
+		/* Configure CS4227/CS4223 LINE side to proper mode. */
+		reg_slice = IXGBE_CS4227_LINE_SPARE24_LSB + slice_offset;
+
+		ret_val = hw->phy.ops.read_reg(hw, reg_slice,
+					IXGBE_MDIO_ZERO_DEV_TYPE, &reg_phy_ext);
+
+		if (ret_val != IXGBE_SUCCESS)
+			return ret_val;
+
+		reg_phy_ext &= ~((IXGBE_CS4227_EDC_MODE_CX1 << 1) |
+				 (IXGBE_CS4227_EDC_MODE_SR << 1));
+
+		if (setup_linear)
+			reg_phy_ext = (IXGBE_CS4227_EDC_MODE_CX1 << 1) | 0x1;
+		else
+			reg_phy_ext = (IXGBE_CS4227_EDC_MODE_SR << 1) | 0x1;
+		ret_val = hw->phy.ops.write_reg(hw, reg_slice,
+					 IXGBE_MDIO_ZERO_DEV_TYPE, reg_phy_ext);
+
+		/* Flush previous write with a read */
+		ret_val = hw->phy.ops.read_reg(hw, reg_slice,
+					IXGBE_MDIO_ZERO_DEV_TYPE, &reg_phy_ext);
+	}
+	return ret_val;
+}
+
+/**
+ *  ixgbe_setup_ixfi_x550em_x - MAC specific iXFI configuration
+ *  @hw: pointer to hardware structure
+ *
+ *  iXfI configuration needed for ixgbe_mac_X550EM_x devices.
+ **/
+static int32_t ixgbe_setup_ixfi_x550em_x(struct ixgbe_hw *hw)
+{
+	struct ixgbe_mac_info *mac = &hw->mac;
+	int32_t status;
+	uint32_t reg_val;
 
 	/* Disable training protocol FSM. */
-	status = ixgbe_read_iosf_sb_reg_x550(hw,
+	status = mac->ops.read_iosf_sb_reg(hw,
 				IXGBE_KRM_RX_TRN_LINKUP_CTRL(hw->bus.lan_id),
 				IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_val);
 	if (status != IXGBE_SUCCESS)
 		return status;
 	reg_val |= IXGBE_KRM_RX_TRN_LINKUP_CTRL_CONV_WO_PROTOCOL;
-	status = ixgbe_write_iosf_sb_reg_x550(hw,
+	status = mac->ops.write_iosf_sb_reg(hw,
 				IXGBE_KRM_RX_TRN_LINKUP_CTRL(hw->bus.lan_id),
 				IXGBE_SB_IOSF_TARGET_KR_PHY, reg_val);
 	if (status != IXGBE_SUCCESS)
 		return status;
 
 	/* Disable Flex from training TXFFE. */
-	status = ixgbe_read_iosf_sb_reg_x550(hw,
+	status = mac->ops.read_iosf_sb_reg(hw,
 				IXGBE_KRM_DSP_TXFFE_STATE_4(hw->bus.lan_id),
 				IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_val);
 	if (status != IXGBE_SUCCESS)
@@ -1437,12 +2926,12 @@ int32_t ixgbe_setup_ixfi_x550em(struct i
 	reg_val &= ~IXGBE_KRM_DSP_TXFFE_STATE_C0_EN;
 	reg_val &= ~IXGBE_KRM_DSP_TXFFE_STATE_CP1_CN1_EN;
 	reg_val &= ~IXGBE_KRM_DSP_TXFFE_STATE_CO_ADAPT_EN;
-	status = ixgbe_write_iosf_sb_reg_x550(hw,
+	status = mac->ops.write_iosf_sb_reg(hw,
 				IXGBE_KRM_DSP_TXFFE_STATE_4(hw->bus.lan_id),
 				IXGBE_SB_IOSF_TARGET_KR_PHY, reg_val);
 	if (status != IXGBE_SUCCESS)
 		return status;
-	status = ixgbe_read_iosf_sb_reg_x550(hw,
+	status = mac->ops.read_iosf_sb_reg(hw,
 				IXGBE_KRM_DSP_TXFFE_STATE_5(hw->bus.lan_id),
 				IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_val);
 	if (status != IXGBE_SUCCESS)
@@ -1450,14 +2939,14 @@ int32_t ixgbe_setup_ixfi_x550em(struct i
 	reg_val &= ~IXGBE_KRM_DSP_TXFFE_STATE_C0_EN;
 	reg_val &= ~IXGBE_KRM_DSP_TXFFE_STATE_CP1_CN1_EN;
 	reg_val &= ~IXGBE_KRM_DSP_TXFFE_STATE_CO_ADAPT_EN;
-	status = ixgbe_write_iosf_sb_reg_x550(hw,
+	status = mac->ops.write_iosf_sb_reg(hw,
 				IXGBE_KRM_DSP_TXFFE_STATE_5(hw->bus.lan_id),
 				IXGBE_SB_IOSF_TARGET_KR_PHY, reg_val);
 	if (status != IXGBE_SUCCESS)
 		return status;
 
 	/* Enable override for coefficients. */
-	status = ixgbe_read_iosf_sb_reg_x550(hw,
+	status = mac->ops.read_iosf_sb_reg(hw,
 				IXGBE_KRM_TX_COEFF_CTRL_1(hw->bus.lan_id),
 				IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_val);
 	if (status != IXGBE_SUCCESS)
@@ -1466,22 +2955,68 @@ int32_t ixgbe_setup_ixfi_x550em(struct i
 	reg_val |= IXGBE_KRM_TX_COEFF_CTRL_1_CZERO_EN;
 	reg_val |= IXGBE_KRM_TX_COEFF_CTRL_1_CPLUS1_OVRRD_EN;
 	reg_val |= IXGBE_KRM_TX_COEFF_CTRL_1_CMINUS1_OVRRD_EN;
-	status = ixgbe_write_iosf_sb_reg_x550(hw,
+	status = mac->ops.write_iosf_sb_reg(hw,
 				IXGBE_KRM_TX_COEFF_CTRL_1(hw->bus.lan_id),
 				IXGBE_SB_IOSF_TARGET_KR_PHY, reg_val);
-	if (status != IXGBE_SUCCESS)
-		return status;
+	return status;
+}
 
-	/* Toggle port SW reset by AN reset. */
-	status = ixgbe_read_iosf_sb_reg_x550(hw,
+/**
+ *  ixgbe_setup_ixfi_x550em - Configure the KR PHY for iXFI mode.
+ *  @hw: pointer to hardware structure
+ *  @speed: the link speed to force
+ *
+ *  Configures the integrated KR PHY to use iXFI mode. Used to connect an
+ *  internal and external PHY at a specific speed, without autonegotiation.
+ **/
+static int32_t ixgbe_setup_ixfi_x550em(struct ixgbe_hw *hw, ixgbe_link_speed *speed)
+{
+	struct ixgbe_mac_info *mac = &hw->mac;
+	int32_t status;
+	uint32_t reg_val;
+
+	/* iXFI is only supported with X552 */
+	if (mac->type != ixgbe_mac_X550EM_x)
+		return IXGBE_ERR_LINK_SETUP;
+
+	/* Disable AN and force speed to 10G Serial. */
+	status = mac->ops.read_iosf_sb_reg(hw,
 					IXGBE_KRM_LINK_CTRL_1(hw->bus.lan_id),
 					IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_val);
 	if (status != IXGBE_SUCCESS)
 		return status;
-	reg_val |= IXGBE_KRM_LINK_CTRL_1_TETH_AN_RESTART;
-	status = ixgbe_write_iosf_sb_reg_x550(hw,
+
+	reg_val &= ~IXGBE_KRM_LINK_CTRL_1_TETH_AN_ENABLE;
+	reg_val &= ~IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_MASK;
+
+	/* Select forced link speed for internal PHY. */
+	switch (*speed) {
+	case IXGBE_LINK_SPEED_10GB_FULL:
+		reg_val |= IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_10G;
+		break;
+	case IXGBE_LINK_SPEED_1GB_FULL:
+		reg_val |= IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_1G;
+		break;
+	default:
+		/* Other link speeds are not supported by internal KR PHY. */
+		return IXGBE_ERR_LINK_SETUP;
+	}
+
+	status = mac->ops.write_iosf_sb_reg(hw,
 					IXGBE_KRM_LINK_CTRL_1(hw->bus.lan_id),
 					IXGBE_SB_IOSF_TARGET_KR_PHY, reg_val);
+	if (status != IXGBE_SUCCESS)
+		return status;
+
+	/* Additional configuration needed for x550em_x */
+	if (hw->mac.type == ixgbe_mac_X550EM_x) {
+		status = ixgbe_setup_ixfi_x550em_x(hw);
+		if (status != IXGBE_SUCCESS)
+			return status;
+	}
+
+	/* Toggle port SW reset by AN reset. */
+	status = ixgbe_restart_an_internal_phy_x550em(hw);
 
 	return status;
 }
@@ -1493,7 +3028,7 @@ int32_t ixgbe_setup_ixfi_x550em(struct i
  *
  * Returns error code if unable to get link status.
  */
-int32_t ixgbe_ext_phy_t_x550em_get_link(struct ixgbe_hw *hw, bool *link_up)
+static int32_t ixgbe_ext_phy_t_x550em_get_link(struct ixgbe_hw *hw, bool *link_up)
 {
 	uint32_t ret;
 	uint16_t autoneg_status;
@@ -1540,43 +3075,51 @@ int32_t ixgbe_setup_internal_phy_t_x550e
 	if (hw->mac.ops.get_media_type(hw) != ixgbe_media_type_copper)
 		return IXGBE_ERR_CONFIG;
 
-	/* If link is not up, then there is no setup necessary so return  */
-	status = ixgbe_ext_phy_t_x550em_get_link(hw, &link_up);
-	if (status != IXGBE_SUCCESS)
-		return status;
+	if (hw->mac.type == ixgbe_mac_X550EM_x &&
+	    !(hw->phy.nw_mng_if_sel & IXGBE_NW_MNG_IF_SEL_INT_PHY_MODE)) {
+		/* If link is down, there is no setup necessary so return  */
+		status = ixgbe_ext_phy_t_x550em_get_link(hw, &link_up);
+		if (status != IXGBE_SUCCESS)
+			return status;
 
-	if (!link_up)
-		return IXGBE_SUCCESS;
+		if (!link_up)
+			return IXGBE_SUCCESS;
 
-	status = hw->phy.ops.read_reg(hw, IXGBE_MDIO_AUTO_NEG_VENDOR_STAT,
-				      IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
-				      &speed);
-	if (status != IXGBE_SUCCESS)
-		return status;
+		status = hw->phy.ops.read_reg(hw,
+					      IXGBE_MDIO_AUTO_NEG_VENDOR_STAT,
+					      IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
+					      &speed);
+		if (status != IXGBE_SUCCESS)
+			return status;
 
-	/* If link is not still up, then no setup is necessary so return */
-	status = ixgbe_ext_phy_t_x550em_get_link(hw, &link_up);
-	if (status != IXGBE_SUCCESS)
-		return status;
-	if (!link_up)
-		return IXGBE_SUCCESS;
+		/* If link is still down - no setup is required so return */
+		status = ixgbe_ext_phy_t_x550em_get_link(hw, &link_up);
+		if (status != IXGBE_SUCCESS)
+			return status;
+		if (!link_up)
+			return IXGBE_SUCCESS;
 
-	/* clear everything but the speed and duplex bits */
-	speed &= IXGBE_MDIO_AUTO_NEG_VENDOR_STATUS_MASK;
+		/* clear everything but the speed and duplex bits */
+		speed &= IXGBE_MDIO_AUTO_NEG_VENDOR_STATUS_MASK;
 
-	switch (speed) {
-	case IXGBE_MDIO_AUTO_NEG_VENDOR_STATUS_10GB_FULL:
-		force_speed = IXGBE_LINK_SPEED_10GB_FULL;
-		break;
-	case IXGBE_MDIO_AUTO_NEG_VENDOR_STATUS_1GB_FULL:
-		force_speed = IXGBE_LINK_SPEED_1GB_FULL;
-		break;
-	default:
-		/* Internal PHY does not support anything else */
-		return IXGBE_ERR_INVALID_LINK_SETTINGS;
-	}
+		switch (speed) {
+		case IXGBE_MDIO_AUTO_NEG_VENDOR_STATUS_10GB_FULL:
+			force_speed = IXGBE_LINK_SPEED_10GB_FULL;
+			break;
+		case IXGBE_MDIO_AUTO_NEG_VENDOR_STATUS_1GB_FULL:
+			force_speed = IXGBE_LINK_SPEED_1GB_FULL;
+			break;
+		default:
+			/* Internal PHY does not support anything else */
+			return IXGBE_ERR_INVALID_LINK_SETTINGS;
+		}
 
-	return ixgbe_setup_ixfi_x550em(hw, &force_speed);
+		return ixgbe_setup_ixfi_x550em(hw, &force_speed);
+	} else {
+		speed = IXGBE_LINK_SPEED_10GB_FULL |
+			IXGBE_LINK_SPEED_1GB_FULL;
+		return ixgbe_setup_kr_speed_x550em(hw, speed);
+	}
 }
 
 /**
@@ -1591,57 +3134,57 @@ int32_t ixgbe_setup_phy_loopback_x550em(
 	uint32_t reg_val;
 
 	/* Disable AN and force speed to 10G Serial. */
-	status = ixgbe_read_iosf_sb_reg_x550(hw,
-		IXGBE_KRM_LINK_CTRL_1(hw->bus.lan_id),
-		IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_val);
+	status = hw->mac.ops.read_iosf_sb_reg(hw,
+					IXGBE_KRM_LINK_CTRL_1(hw->bus.lan_id),
+					IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_val);
 	if (status != IXGBE_SUCCESS)
 		return status;
 	reg_val &= ~IXGBE_KRM_LINK_CTRL_1_TETH_AN_ENABLE;
 	reg_val &= ~IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_MASK;
 	reg_val |= IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_10G;
-	status = ixgbe_write_iosf_sb_reg_x550(hw,
-		IXGBE_KRM_LINK_CTRL_1(hw->bus.lan_id),
-		IXGBE_SB_IOSF_TARGET_KR_PHY, reg_val);
+	status = hw->mac.ops.write_iosf_sb_reg(hw,
+					IXGBE_KRM_LINK_CTRL_1(hw->bus.lan_id),
+					IXGBE_SB_IOSF_TARGET_KR_PHY, reg_val);
 	if (status != IXGBE_SUCCESS)
 		return status;
 
 	/* Set near-end loopback clocks. */
-	status = ixgbe_read_iosf_sb_reg_x550(hw,
-		IXGBE_KRM_PORT_CAR_GEN_CTRL(hw->bus.lan_id),
-		IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_val);
+	status = hw->mac.ops.read_iosf_sb_reg(hw,
+				IXGBE_KRM_PORT_CAR_GEN_CTRL(hw->bus.lan_id),
+				IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_val);
 	if (status != IXGBE_SUCCESS)
 		return status;
 	reg_val |= IXGBE_KRM_PORT_CAR_GEN_CTRL_NELB_32B;
 	reg_val |= IXGBE_KRM_PORT_CAR_GEN_CTRL_NELB_KRPCS;
-	status = ixgbe_write_iosf_sb_reg_x550(hw,
-		IXGBE_KRM_PORT_CAR_GEN_CTRL(hw->bus.lan_id),
-		IXGBE_SB_IOSF_TARGET_KR_PHY, reg_val);
+	status = hw->mac.ops.write_iosf_sb_reg(hw,
+				IXGBE_KRM_PORT_CAR_GEN_CTRL(hw->bus.lan_id),
+				IXGBE_SB_IOSF_TARGET_KR_PHY, reg_val);
 	if (status != IXGBE_SUCCESS)
 		return status;
 
 	/* Set loopback enable. */
-	status = ixgbe_read_iosf_sb_reg_x550(hw,
-		IXGBE_KRM_PMD_DFX_BURNIN(hw->bus.lan_id),
-		IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_val);
+	status = hw->mac.ops.read_iosf_sb_reg(hw,
+				IXGBE_KRM_PMD_DFX_BURNIN(hw->bus.lan_id),
+				IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_val);
 	if (status != IXGBE_SUCCESS)
 		return status;
 	reg_val |= IXGBE_KRM_PMD_DFX_BURNIN_TX_RX_KR_LB_MASK;
-	status = ixgbe_write_iosf_sb_reg_x550(hw,
-		IXGBE_KRM_PMD_DFX_BURNIN(hw->bus.lan_id),
-		IXGBE_SB_IOSF_TARGET_KR_PHY, reg_val);
+	status = hw->mac.ops.write_iosf_sb_reg(hw,
+				IXGBE_KRM_PMD_DFX_BURNIN(hw->bus.lan_id),
+				IXGBE_SB_IOSF_TARGET_KR_PHY, reg_val);
 	if (status != IXGBE_SUCCESS)
 		return status;
 
 	/* Training bypass. */
-	status = ixgbe_read_iosf_sb_reg_x550(hw,
-		IXGBE_KRM_RX_TRN_LINKUP_CTRL(hw->bus.lan_id),
-		IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_val);
+	status = hw->mac.ops.read_iosf_sb_reg(hw,
+				IXGBE_KRM_RX_TRN_LINKUP_CTRL(hw->bus.lan_id),
+				IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_val);
 	if (status != IXGBE_SUCCESS)
 		return status;
 	reg_val |= IXGBE_KRM_RX_TRN_LINKUP_CTRL_PROTOCOL_BYPASS;
-	status = ixgbe_write_iosf_sb_reg_x550(hw,
-		IXGBE_KRM_RX_TRN_LINKUP_CTRL(hw->bus.lan_id),
-		IXGBE_SB_IOSF_TARGET_KR_PHY, reg_val);
+	status = hw->mac.ops.write_iosf_sb_reg(hw,
+				IXGBE_KRM_RX_TRN_LINKUP_CTRL(hw->bus.lan_id),
+				IXGBE_SB_IOSF_TARGET_KR_PHY, reg_val);
 
 	return status;
 }
@@ -1655,59 +3198,37 @@ int32_t ixgbe_setup_phy_loopback_x550em(
  *
  *  Reads a 16 bit word from the EEPROM using the hostif.
  **/
-int32_t ixgbe_read_ee_hostif_data_X550(struct ixgbe_hw *hw, uint16_t offset,
-				       uint16_t *data)
+int32_t ixgbe_read_ee_hostif_X550(struct ixgbe_hw *hw, uint16_t offset, uint16_t *data)
 {
-	int32_t status;
+	const uint32_t mask = IXGBE_GSSR_SW_MNG_SM | IXGBE_GSSR_EEP_SM;
 	struct ixgbe_hic_read_shadow_ram buffer;
+	int32_t status;
 
-	DEBUGFUNC("ixgbe_read_ee_hostif_data_X550");
+	DEBUGFUNC("ixgbe_read_ee_hostif_X550");
 	buffer.hdr.req.cmd = FW_READ_SHADOW_RAM_CMD;
 	buffer.hdr.req.buf_lenh = 0;
 	buffer.hdr.req.buf_lenl = FW_READ_SHADOW_RAM_LEN;
 	buffer.hdr.req.checksum = FW_DEFAULT_CHECKSUM;
 
 	/* convert offset from words to bytes */
-	buffer.address = htobe32(offset * 2);
+	buffer.address = IXGBE_CPU_TO_BE32(offset * 2);
 	/* one word */
-	buffer.length = htobe16(sizeof(uint16_t));
-
-	status = ixgbe_host_interface_command(hw, (uint32_t *)&buffer,
-					      sizeof(buffer),
-					      IXGBE_HI_COMMAND_TIMEOUT, FALSE);
+	buffer.length = IXGBE_CPU_TO_BE16(sizeof(uint16_t));
+	buffer.pad2 = 0;
+	buffer.pad3 = 0;
 
+	status = hw->mac.ops.acquire_swfw_sync(hw, mask);
 	if (status)
 		return status;
 
-	*data = (uint16_t)IXGBE_READ_REG_ARRAY(hw, IXGBE_FLEX_MNG,
-					  FW_NVM_DATA_OFFSET);
-
-	return 0;
-}
-
-/**
- *  ixgbe_read_ee_hostif_X550 - Read EEPROM word using a host interface command
- *  @hw: pointer to hardware structure
- *  @offset: offset of  word in the EEPROM to read
- *  @data: word read from the EEPROM
- *
- *  Reads a 16 bit word from the EEPROM using the hostif.
- **/
-int32_t ixgbe_read_ee_hostif_X550(struct ixgbe_hw *hw, uint16_t offset,
-				  uint16_t *data)
-{
-	int32_t status = IXGBE_SUCCESS;
-
-	DEBUGFUNC("ixgbe_read_ee_hostif_X550");
-
-	if (hw->mac.ops.acquire_swfw_sync(hw, IXGBE_GSSR_EEP_SM) ==
-	    IXGBE_SUCCESS) {
-		status = ixgbe_read_ee_hostif_data_X550(hw, offset, data);
-		hw->mac.ops.release_swfw_sync(hw, IXGBE_GSSR_EEP_SM);
-	} else {
-		status = IXGBE_ERR_SWFW_SYNC;
+	status = ixgbe_hic_unlocked(hw, (uint32_t *)&buffer, sizeof(buffer),
+				    IXGBE_HI_COMMAND_TIMEOUT);
+	if (!status) {
+		*data = (uint16_t)IXGBE_READ_REG_ARRAY(hw, IXGBE_FLEX_MNG,
+						  FW_NVM_DATA_OFFSET);
 	}
 
+	hw->mac.ops.release_swfw_sync(hw, mask);
 	return status;
 }
 
@@ -1721,9 +3242,9 @@ int32_t ixgbe_read_ee_hostif_X550(struct
  *  Reads a 16 bit word(s) from the EEPROM using the hostif.
  **/
 int32_t ixgbe_read_ee_hostif_buffer_X550(struct ixgbe_hw *hw,
-					 uint16_t offset, uint16_t words,
-					 uint16_t *data)
+				     uint16_t offset, uint16_t words, uint16_t *data)
 {
+	const uint32_t mask = IXGBE_GSSR_SW_MNG_SM | IXGBE_GSSR_EEP_SM;
 	struct ixgbe_hic_read_shadow_ram buffer;
 	uint32_t current_word = 0;
 	uint16_t words_to_read;
@@ -1733,11 +3254,12 @@ int32_t ixgbe_read_ee_hostif_buffer_X550
 	DEBUGFUNC("ixgbe_read_ee_hostif_buffer_X550");
 
 	/* Take semaphore for the entire operation. */
-	status = hw->mac.ops.acquire_swfw_sync(hw, IXGBE_GSSR_EEP_SM);
+	status = hw->mac.ops.acquire_swfw_sync(hw, mask);
 	if (status) {
 		DEBUGOUT("EEPROM read buffer - semaphore failed\n");
 		return status;
 	}
+
 	while (words) {
 		if (words > FW_MAX_READ_BUFFER_SIZE / 2)
 			words_to_read = FW_MAX_READ_BUFFER_SIZE / 2;
@@ -1750,13 +3272,13 @@ int32_t ixgbe_read_ee_hostif_buffer_X550
 		buffer.hdr.req.checksum = FW_DEFAULT_CHECKSUM;
 
 		/* convert offset from words to bytes */
-		buffer.address = htobe32((offset + current_word) * 2);
-		buffer.length = htobe16(words_to_read * 2);
+		buffer.address = IXGBE_CPU_TO_BE32((offset + current_word) * 2);
+		buffer.length = IXGBE_CPU_TO_BE16(words_to_read * 2);
+		buffer.pad2 = 0;
+		buffer.pad3 = 0;
 
-		status = ixgbe_host_interface_command(hw, (uint32_t *)&buffer,
-						      sizeof(buffer),
-						      IXGBE_HI_COMMAND_TIMEOUT,
-						      FALSE);
+		status = ixgbe_hic_unlocked(hw, (uint32_t *)&buffer, sizeof(buffer),
+					    IXGBE_HI_COMMAND_TIMEOUT);
 
 		if (status) {
 			DEBUGOUT("Host interface command failed\n");
@@ -1781,7 +3303,7 @@ int32_t ixgbe_read_ee_hostif_buffer_X550
 	}
 
 out:
-	hw->mac.ops.release_swfw_sync(hw, IXGBE_GSSR_EEP_SM);
+	hw->mac.ops.release_swfw_sync(hw, mask);
 	return status;
 }
 
@@ -1794,7 +3316,7 @@ out:
  *  Write a 16 bit word to the EEPROM using the hostif.
  **/
 int32_t ixgbe_write_ee_hostif_data_X550(struct ixgbe_hw *hw, uint16_t offset,
-					uint16_t data)
+				    uint16_t data)
 {
 	int32_t status;
 	struct ixgbe_hic_write_shadow_ram buffer;
@@ -1807,9 +3329,9 @@ int32_t ixgbe_write_ee_hostif_data_X550(
 	buffer.hdr.req.checksum = FW_DEFAULT_CHECKSUM;
 
 	 /* one word */
-	buffer.length = htobe16(sizeof(uint16_t));
+	buffer.length = IXGBE_CPU_TO_BE16(sizeof(uint16_t));
 	buffer.data = data;
-	buffer.address = htobe32(offset * 2);
+	buffer.address = IXGBE_CPU_TO_BE32(offset * 2);
 
 	status = ixgbe_host_interface_command(hw, (uint32_t *)&buffer,
 					      sizeof(buffer),
@@ -1827,7 +3349,7 @@ int32_t ixgbe_write_ee_hostif_data_X550(
  *  Write a 16 bit word to the EEPROM using the hostif.
  **/
 int32_t ixgbe_write_ee_hostif_X550(struct ixgbe_hw *hw, uint16_t offset,
-				   uint16_t data)
+			       uint16_t data)
 {
 	int32_t status = IXGBE_SUCCESS;
 
@@ -1838,7 +3360,7 @@ int32_t ixgbe_write_ee_hostif_X550(struc
 		status = ixgbe_write_ee_hostif_data_X550(hw, offset, data);
 		hw->mac.ops.release_swfw_sync(hw, IXGBE_GSSR_EEP_SM);
 	} else {
-		DEBUGOUT("write ee hostif failed to get semaphore\n");
+		DEBUGOUT("write ee hostif failed to get semaphore");
 		status = IXGBE_ERR_SWFW_SYNC;
 	}
 
@@ -1846,17 +3368,59 @@ int32_t ixgbe_write_ee_hostif_X550(struc
 }
 
 /**
+ *  ixgbe_write_ee_hostif_buffer_X550 - Write EEPROM word(s) using hostif
+ *  @hw: pointer to hardware structure
+ *  @offset: offset of  word in the EEPROM to write
+ *  @words: number of words
+ *  @data: word(s) write to the EEPROM
+ *
+ *  Write a 16 bit word(s) to the EEPROM using the hostif.
+ **/
+int32_t ixgbe_write_ee_hostif_buffer_X550(struct ixgbe_hw *hw,
+				      uint16_t offset, uint16_t words, uint16_t *data)
+{
+	int32_t status = IXGBE_SUCCESS;
+	uint32_t i = 0;
+
+	DEBUGFUNC("ixgbe_write_ee_hostif_buffer_X550");
+
+	/* Take semaphore for the entire operation. */
+	status = hw->mac.ops.acquire_swfw_sync(hw, IXGBE_GSSR_EEP_SM);
+	if (status != IXGBE_SUCCESS) {
+		DEBUGOUT("EEPROM write buffer - semaphore failed\n");
+		goto out;
+	}
+
+	for (i = 0; i < words; i++) {
+		status = ixgbe_write_ee_hostif_data_X550(hw, offset + i,
+							 data[i]);
+
+		if (status != IXGBE_SUCCESS) {
+			DEBUGOUT("Eeprom buffered write failed\n");
+			break;
+		}
+	}
+
+	hw->mac.ops.release_swfw_sync(hw, IXGBE_GSSR_EEP_SM);
+out:
+
+	return status;
+}
+
+/**
  * ixgbe_checksum_ptr_x550 - Checksum one pointer region
  * @hw: pointer to hardware structure
  * @ptr: pointer offset in eeprom
  * @size: size of section pointed by ptr, if 0 first word will be used as size
  * @csum: address of checksum to update
+ * @buffer: pointer to buffer containing calculated checksum
+ * @buffer_size: size of buffer
  *
  * Returns error status for any failure
  */
-int32_t ixgbe_checksum_ptr_x550(struct ixgbe_hw *hw, uint16_t ptr,
-				uint16_t size, uint16_t *csum, uint16_t *buffer,
-				uint32_t buffer_size)
+static int32_t ixgbe_checksum_ptr_x550(struct ixgbe_hw *hw, uint16_t ptr,
+				   uint16_t size, uint16_t *csum, uint16_t *buffer,
+				   uint32_t buffer_size)
 {
 	uint16_t buf[256];
 	int32_t status;
@@ -1923,8 +3487,7 @@ int32_t ixgbe_checksum_ptr_x550(struct i
  *
  *  Returns a negative error code on error, or the 16-bit checksum
  **/
-int32_t ixgbe_calc_checksum_X550(struct ixgbe_hw *hw, uint16_t *buffer,
-				 uint32_t buffer_size)
+int32_t ixgbe_calc_checksum_X550(struct ixgbe_hw *hw, uint16_t *buffer, uint32_t buffer_size)
 {
 	uint16_t eeprom_ptrs[IXGBE_EEPROM_LAST_WORD + 1];
 	uint16_t *local_buffer;
@@ -2052,7 +3615,8 @@ int32_t ixgbe_validate_eeprom_checksum_X
 	 */
 	if (read_checksum != checksum) {
 		status = IXGBE_ERR_EEPROM_CHECKSUM;
-		DEBUGOUT("Invalid EEPROM checksum\n");
+		ERROR_REPORT1(IXGBE_ERROR_INVALID_STATE,
+			     "Invalid EEPROM checksum");
 	}
 
 	/* If the user cares, return the calculated checksum */
@@ -2134,9 +3698,9 @@ int32_t ixgbe_update_flash_X550(struct i
  *
  *  Determines physical layer capabilities of the current configuration.
  **/
-uint32_t ixgbe_get_supported_physical_layer_X550em(struct ixgbe_hw *hw)
+uint64_t ixgbe_get_supported_physical_layer_X550em(struct ixgbe_hw *hw)
 {
-	uint32_t physical_layer = IXGBE_PHYSICAL_LAYER_UNKNOWN;
+	uint64_t physical_layer = IXGBE_PHYSICAL_LAYER_UNKNOWN;
 	uint16_t ext_ability = 0;
 
 	DEBUGFUNC("ixgbe_get_supported_physical_layer_X550em");
@@ -2145,6 +3709,21 @@ uint32_t ixgbe_get_supported_physical_la
 
 	switch (hw->phy.type) {
 	case ixgbe_phy_x550em_kr:
+		if (hw->mac.type == ixgbe_mac_X550EM_a) {
+			if (hw->phy.nw_mng_if_sel &
+			    IXGBE_NW_MNG_IF_SEL_PHY_SPEED_2_5G) {
+				physical_layer =
+					IXGBE_PHYSICAL_LAYER_2500BASE_KX;
+				break;
+			} else if (hw->device_id ==
+				   IXGBE_DEV_ID_X550EM_A_KR_L) {
+				physical_layer =
+					IXGBE_PHYSICAL_LAYER_1000BASE_KX;
+				break;
+			}
+		}
+		/* fall through */
+	case ixgbe_phy_x550em_xfi:
 		physical_layer = IXGBE_PHYSICAL_LAYER_10GBASE_KR |
 				 IXGBE_PHYSICAL_LAYER_1000BASE_KX;
 		break;
@@ -2161,6 +3740,20 @@ uint32_t ixgbe_get_supported_physical_la
 		if (ext_ability & IXGBE_MDIO_PHY_1000BASET_ABILITY)
 			physical_layer |= IXGBE_PHYSICAL_LAYER_1000BASE_T;
 		break;
+	case ixgbe_phy_fw:
+		if (hw->phy.speeds_supported & IXGBE_LINK_SPEED_1GB_FULL)
+			physical_layer |= IXGBE_PHYSICAL_LAYER_1000BASE_T;
+		if (hw->phy.speeds_supported & IXGBE_LINK_SPEED_100_FULL)
+			physical_layer |= IXGBE_PHYSICAL_LAYER_100BASE_TX;
+		if (hw->phy.speeds_supported & IXGBE_LINK_SPEED_10_FULL)
+			physical_layer |= IXGBE_PHYSICAL_LAYER_10BASE_T;
+		break;
+	case ixgbe_phy_sgmii:
+		physical_layer = IXGBE_PHYSICAL_LAYER_1000BASE_KX;
+		break;
+	case ixgbe_phy_ext_1g_t:
+		physical_layer = IXGBE_PHYSICAL_LAYER_1000BASE_T;
+		break;
 	default:
 		break;
 	}
@@ -2191,39 +3784,157 @@ int32_t ixgbe_get_bus_info_X550em(struct
 	return IXGBE_SUCCESS;
 }
 
-/**
- * ixgbe_disable_rx_x550 - Disable RX unit
- *
- * Enables the Rx DMA unit for x550
- **/
-void ixgbe_disable_rx_x550(struct ixgbe_hw *hw)
-{
-	uint32_t rxctrl;
-	int32_t status;
-	struct ixgbe_hic_disable_rxen fw_cmd;
+/**
+ * ixgbe_disable_rx_x550 - Disable RX unit
+ * @hw: pointer to hardware structure
+ *
+ * Enables the Rx DMA unit for x550
+ **/
+void ixgbe_disable_rx_x550(struct ixgbe_hw *hw)
+{
+	uint32_t rxctrl, pfdtxgswc;
+	int32_t status;
+	struct ixgbe_hic_disable_rxen fw_cmd;
+
+	DEBUGFUNC("ixgbe_enable_rx_dma_x550");
+
+	rxctrl = IXGBE_READ_REG(hw, IXGBE_RXCTRL);
+	if (rxctrl & IXGBE_RXCTRL_RXEN) {
+		pfdtxgswc = IXGBE_READ_REG(hw, IXGBE_PFDTXGSWC);
+		if (pfdtxgswc & IXGBE_PFDTXGSWC_VT_LBEN) {
+			pfdtxgswc &= ~IXGBE_PFDTXGSWC_VT_LBEN;
+			IXGBE_WRITE_REG(hw, IXGBE_PFDTXGSWC, pfdtxgswc);
+			hw->mac.set_lben = TRUE;
+		} else {
+			hw->mac.set_lben = FALSE;
+		}
+
+		fw_cmd.hdr.cmd = FW_DISABLE_RXEN_CMD;
+		fw_cmd.hdr.buf_len = FW_DISABLE_RXEN_LEN;
+		fw_cmd.hdr.checksum = FW_DEFAULT_CHECKSUM;
+		fw_cmd.port_number = (uint8_t)hw->bus.lan_id;
+
+		status = ixgbe_host_interface_command(hw, (uint32_t *)&fw_cmd,
+					sizeof(struct ixgbe_hic_disable_rxen),
+					IXGBE_HI_COMMAND_TIMEOUT, TRUE);
+
+		/* If we fail - disable RX using register write */
+		if (status) {
+			rxctrl = IXGBE_READ_REG(hw, IXGBE_RXCTRL);
+			if (rxctrl & IXGBE_RXCTRL_RXEN) {
+				rxctrl &= ~IXGBE_RXCTRL_RXEN;
+				IXGBE_WRITE_REG(hw, IXGBE_RXCTRL, rxctrl);
+			}
+		}
+	}
+}
+
+/**
+ * ixgbe_enter_lplu_x550em - Transition to low power states
+ *  @hw: pointer to hardware structure
+ *
+ * Configures Low Power Link Up on transition to low power states
+ * (from D0 to non-D0). Link is required to enter LPLU so avoid resetting the
+ * X557 PHY immediately prior to entering LPLU.
+ **/
+int32_t ixgbe_enter_lplu_t_x550em(struct ixgbe_hw *hw)
+{
+	uint16_t an_10g_cntl_reg, autoneg_reg, speed;
+	int32_t status;
+	ixgbe_link_speed lcd_speed;
+	uint32_t save_autoneg;
+	bool link_up;
+
+	/* SW LPLU not required on later HW revisions. */
+	if ((hw->mac.type == ixgbe_mac_X550EM_x) &&
+	    (IXGBE_FUSES0_REV_MASK &
+	     IXGBE_READ_REG(hw, IXGBE_FUSES0_GROUP(0))))
+		return IXGBE_SUCCESS;
+
+	/* If blocked by MNG FW, then don't restart AN */
+	if (ixgbe_check_reset_blocked(hw))
+		return IXGBE_SUCCESS;
+
+	status = ixgbe_ext_phy_t_x550em_get_link(hw, &link_up);
+	if (status != IXGBE_SUCCESS)
+		return status;
+
+	status = ixgbe_read_eeprom(hw, NVM_INIT_CTRL_3, &hw->eeprom.ctrl_word_3);
+
+	if (status != IXGBE_SUCCESS)
+		return status;
+
+	/* If link is down, LPLU disabled in NVM, WoL disabled, or manageability
+	 * disabled, then force link down by entering low power mode.
+	 */
+	if (!link_up || !(hw->eeprom.ctrl_word_3 & NVM_INIT_CTRL_3_LPLU) ||
+	    !(hw->wol_enabled || ixgbe_mng_present(hw)))
+		return ixgbe_set_copper_phy_power(hw, FALSE);
+
+	/* Determine LCD */
+	status = ixgbe_get_lcd_t_x550em(hw, &lcd_speed);
+
+	if (status != IXGBE_SUCCESS)
+		return status;
+
+	/* If no valid LCD link speed, then force link down and exit. */
+	if (lcd_speed == IXGBE_LINK_SPEED_UNKNOWN)
+		return ixgbe_set_copper_phy_power(hw, FALSE);
+
+	status = hw->phy.ops.read_reg(hw, IXGBE_MDIO_AUTO_NEG_VENDOR_STAT,
+				      IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
+				      &speed);
+
+	if (status != IXGBE_SUCCESS)
+		return status;
+
+	/* If no link now, speed is invalid so take link down */
+	status = ixgbe_ext_phy_t_x550em_get_link(hw, &link_up);
+	if (status != IXGBE_SUCCESS)
+		return ixgbe_set_copper_phy_power(hw, FALSE);
+
+	/* clear everything but the speed bits */
+	speed &= IXGBE_MDIO_AUTO_NEG_VEN_STAT_SPEED_MASK;
+
+	/* If current speed is already LCD, then exit. */
+	if (((speed == IXGBE_MDIO_AUTO_NEG_VENDOR_STATUS_1GB) &&
+	     (lcd_speed == IXGBE_LINK_SPEED_1GB_FULL)) ||
+	    ((speed == IXGBE_MDIO_AUTO_NEG_VENDOR_STATUS_10GB) &&
+	     (lcd_speed == IXGBE_LINK_SPEED_10GB_FULL)))
+		return status;
+
+	/* Clear AN completed indication */
+	status = hw->phy.ops.read_reg(hw, IXGBE_MDIO_AUTO_NEG_VENDOR_TX_ALARM,
+				      IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
+				      &autoneg_reg);
+
+	if (status != IXGBE_SUCCESS)
+		return status;
+
+	status = hw->phy.ops.read_reg(hw, IXGBE_MII_10GBASE_T_AUTONEG_CTRL_REG,
+			     IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
+			     &an_10g_cntl_reg);
+
+	if (status != IXGBE_SUCCESS)
+		return status;
+
+	status = hw->phy.ops.read_reg(hw,
+			     IXGBE_MII_AUTONEG_VENDOR_PROVISION_1_REG,
+			     IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
+			     &autoneg_reg);
+
+	if (status != IXGBE_SUCCESS)
+		return status;
 
-	DEBUGFUNC("ixgbe_disable_rx_dma_x550");
+	save_autoneg = hw->phy.autoneg_advertised;
 
-	rxctrl = IXGBE_READ_REG(hw, IXGBE_RXCTRL);
-	if (rxctrl & IXGBE_RXCTRL_RXEN) {
-		fw_cmd.hdr.cmd = FW_DISABLE_RXEN_CMD;
-		fw_cmd.hdr.buf_len = FW_DISABLE_RXEN_LEN;
-		fw_cmd.hdr.checksum = FW_DEFAULT_CHECKSUM;
-		fw_cmd.port_number = (uint8_t)hw->bus.lan_id;
+	/* Setup link at least common link speed */
+	status = hw->mac.ops.setup_link(hw, lcd_speed, FALSE);
 
-		status = ixgbe_host_interface_command(hw, (uint32_t *)&fw_cmd,
-					sizeof(struct ixgbe_hic_disable_rxen),
-					IXGBE_HI_COMMAND_TIMEOUT, TRUE);
+	/* restore autoneg from before setting lplu speed */
+	hw->phy.autoneg_advertised = save_autoneg;
 
-		/* If we fail - disable RX using register write */
-		if (status) {
-			rxctrl = IXGBE_READ_REG(hw, IXGBE_RXCTRL);
-			if (rxctrl & IXGBE_RXCTRL_RXEN) {
-				rxctrl &= ~IXGBE_RXCTRL_RXEN;
-				IXGBE_WRITE_REG(hw, IXGBE_RXCTRL, rxctrl);
-			}
-		}
-	}
+	return status;
 }
 
 /**
@@ -2279,7 +3990,8 @@ int32_t ixgbe_setup_fc_X550em(struct ixg
 
 	/* Validate the requested mode */
 	if (hw->fc.strict_ieee && hw->fc.requested_mode == ixgbe_fc_rx_pause) {
-		DEBUGOUT("ixgbe_fc_rx_pause not valid in strict IEEE mode\n");
+		ERROR_REPORT1(IXGBE_ERROR_UNSUPPORTED,
+			"ixgbe_fc_rx_pause not valid in strict IEEE mode\n");
 		ret_val = IXGBE_ERR_INVALID_LINK_SETTINGS;
 		goto out;
 	}
@@ -2314,15 +4026,19 @@ int32_t ixgbe_setup_fc_X550em(struct ixg
 		asm_dir = 1;
 		break;
 	default:
-		DEBUGOUT("Flow control param set incorrectly\n");
+		ERROR_REPORT1(IXGBE_ERROR_ARGUMENT,
+			"Flow control param set incorrectly\n");
 		ret_val = IXGBE_ERR_CONFIG;
 		goto out;
 	}
 
-	if (hw->device_id == IXGBE_DEV_ID_X550EM_X_KR) {
-		ret_val = ixgbe_read_iosf_sb_reg_x550(hw,
-			IXGBE_KRM_AN_CNTL_1(hw->bus.lan_id),
-			IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_val);
+	switch (hw->device_id) {
+	case IXGBE_DEV_ID_X550EM_X_KR:
+	case IXGBE_DEV_ID_X550EM_A_KR:
+	case IXGBE_DEV_ID_X550EM_A_KR_L:
+		ret_val = hw->mac.ops.read_iosf_sb_reg(hw,
+					IXGBE_KRM_AN_CNTL_1(hw->bus.lan_id),
+					IXGBE_SB_IOSF_TARGET_KR_PHY, &reg_val);
 		if (ret_val != IXGBE_SUCCESS)
 			goto out;
 		reg_val &= ~(IXGBE_KRM_AN_CNTL_1_SYM_PAUSE |
@@ -2331,12 +4047,18 @@ int32_t ixgbe_setup_fc_X550em(struct ixg
 			reg_val |= IXGBE_KRM_AN_CNTL_1_SYM_PAUSE;
 		if (asm_dir)
 			reg_val |= IXGBE_KRM_AN_CNTL_1_ASM_PAUSE;
-		ret_val = ixgbe_write_iosf_sb_reg_x550(hw,
-			IXGBE_KRM_AN_CNTL_1(hw->bus.lan_id),
-			IXGBE_SB_IOSF_TARGET_KR_PHY, reg_val);
+		ret_val = hw->mac.ops.write_iosf_sb_reg(hw,
+					IXGBE_KRM_AN_CNTL_1(hw->bus.lan_id),
+					IXGBE_SB_IOSF_TARGET_KR_PHY, reg_val);
 
 		/* This device does not fully support AN. */
 		hw->fc.disable_fc_autoneg = TRUE;
+		break;
+	case IXGBE_DEV_ID_X550EM_X_XFI:
+		hw->fc.disable_fc_autoneg = TRUE;
+		break;
+	default:
+		break;
 	}
 
 out:
@@ -2344,11 +4066,243 @@ out:
 }
 
 /**
+ *  ixgbe_fc_autoneg_backplane_x550em_a - Enable flow control IEEE clause 37
+ *  @hw: pointer to hardware structure
+ *
+ *  Enable flow control according to IEEE clause 37.
+ **/
+void ixgbe_fc_autoneg_backplane_x550em_a(struct ixgbe_hw *hw)
+{
+	uint32_t link_s1, lp_an_page_low, an_cntl_1;
+	int32_t status = IXGBE_ERR_FC_NOT_NEGOTIATED;
+	ixgbe_link_speed speed;
+	bool link_up;
+
+	/* AN should have completed when the cable was plugged in.
+	 * Look for reasons to bail out.  Bail out if:
+	 * - FC autoneg is disabled, or if
+	 * - link is not up.
+	 */
+	if (hw->fc.disable_fc_autoneg) {
+		ERROR_REPORT1(IXGBE_ERROR_UNSUPPORTED,
+			     "Flow control autoneg is disabled");
+		goto out;
+	}
+
+	hw->mac.ops.check_link(hw, &speed, &link_up, FALSE);
+	if (!link_up) {
+		ERROR_REPORT1(IXGBE_ERROR_SOFTWARE, "The link is down");
+		goto out;
+	}
+
+	/* Check at auto-negotiation has completed */
+	status = hw->mac.ops.read_iosf_sb_reg(hw,
+					IXGBE_KRM_LINK_S1(hw->bus.lan_id),
+					IXGBE_SB_IOSF_TARGET_KR_PHY, &link_s1);
+
+	if (status != IXGBE_SUCCESS ||
+	    (link_s1 & IXGBE_KRM_LINK_S1_MAC_AN_COMPLETE) == 0) {
+		DEBUGOUT("Auto-Negotiation did not complete\n");
+		status = IXGBE_ERR_FC_NOT_NEGOTIATED;
+		goto out;
+	}
+
+	/* Read the 10g AN autoc and LP ability registers and resolve
+	 * local flow control settings accordingly
+	 */
+	status = hw->mac.ops.read_iosf_sb_reg(hw,
+				IXGBE_KRM_AN_CNTL_1(hw->bus.lan_id),
+				IXGBE_SB_IOSF_TARGET_KR_PHY, &an_cntl_1);
+
+	if (status != IXGBE_SUCCESS) {
+		DEBUGOUT("Auto-Negotiation did not complete\n");
+		goto out;
+	}
+
+	status = hw->mac.ops.read_iosf_sb_reg(hw,
+				IXGBE_KRM_LP_BASE_PAGE_HIGH(hw->bus.lan_id),
+				IXGBE_SB_IOSF_TARGET_KR_PHY, &lp_an_page_low);
+
+	if (status != IXGBE_SUCCESS) {
+		DEBUGOUT("Auto-Negotiation did not complete\n");
+		goto out;
+	}
+
+	status = ixgbe_negotiate_fc(hw, an_cntl_1, lp_an_page_low,
+				    IXGBE_KRM_AN_CNTL_1_SYM_PAUSE,
+				    IXGBE_KRM_AN_CNTL_1_ASM_PAUSE,
+				    IXGBE_KRM_LP_BASE_PAGE_HIGH_SYM_PAUSE,
+				    IXGBE_KRM_LP_BASE_PAGE_HIGH_ASM_PAUSE);
+
+out:
+	if (status == IXGBE_SUCCESS) {
+		hw->fc.fc_was_autonegged = TRUE;
+	} else {
+		hw->fc.fc_was_autonegged = FALSE;
+		hw->fc.current_mode = hw->fc.requested_mode;
+	}
+}
+
+/**
+ *  ixgbe_fc_autoneg_fiber_x550em_a - passthrough FC settings
+ *  @hw: pointer to hardware structure
+ *
+ **/
+void ixgbe_fc_autoneg_fiber_x550em_a(struct ixgbe_hw *hw)
+{
+	hw->fc.fc_was_autonegged = FALSE;
+	hw->fc.current_mode = hw->fc.requested_mode;
+}
+
+/**
+ *  ixgbe_fc_autoneg_sgmii_x550em_a - Enable flow control IEEE clause 37
+ *  @hw: pointer to hardware structure
+ *
+ *  Enable flow control according to IEEE clause 37.
+ **/
+void ixgbe_fc_autoneg_sgmii_x550em_a(struct ixgbe_hw *hw)
+{
+	int32_t status = IXGBE_ERR_FC_NOT_NEGOTIATED;
+	uint32_t info[FW_PHY_ACT_DATA_COUNT] = { 0 };
+	ixgbe_link_speed speed;
+	bool link_up;
+
+	/* AN should have completed when the cable was plugged in.
+	 * Look for reasons to bail out.  Bail out if:
+	 * - FC autoneg is disabled, or if
+	 * - link is not up.
+	 */
+	if (hw->fc.disable_fc_autoneg) {
+		ERROR_REPORT1(IXGBE_ERROR_UNSUPPORTED,
+			     "Flow control autoneg is disabled");
+		goto out;
+	}
+
+	hw->mac.ops.check_link(hw, &speed, &link_up, FALSE);
+	if (!link_up) {
+		ERROR_REPORT1(IXGBE_ERROR_SOFTWARE, "The link is down");
+		goto out;
+	}
+
+	/* Check if auto-negotiation has completed */
+	status = ixgbe_fw_phy_activity(hw, FW_PHY_ACT_GET_LINK_INFO, &info);
+	if (status != IXGBE_SUCCESS ||
+	    !(info[0] & FW_PHY_ACT_GET_LINK_INFO_AN_COMPLETE)) {
+		DEBUGOUT("Auto-Negotiation did not complete\n");
+		status = IXGBE_ERR_FC_NOT_NEGOTIATED;
+		goto out;
+	}
+
+	/* Negotiate the flow control */
+	status = ixgbe_negotiate_fc(hw, info[0], info[0],
+				    FW_PHY_ACT_GET_LINK_INFO_FC_RX,
+				    FW_PHY_ACT_GET_LINK_INFO_FC_TX,
+				    FW_PHY_ACT_GET_LINK_INFO_LP_FC_RX,
+				    FW_PHY_ACT_GET_LINK_INFO_LP_FC_TX);
+
+out:
+	if (status == IXGBE_SUCCESS) {
+		hw->fc.fc_was_autonegged = TRUE;
+	} else {
+		hw->fc.fc_was_autonegged = FALSE;
+		hw->fc.current_mode = hw->fc.requested_mode;
+	}
+}
+
+/**
+ *  ixgbe_setup_fc_backplane_x550em_a - Set up flow control
+ *  @hw: pointer to hardware structure
+ *
+ *  Called at init time to set up flow control.
+ **/
+int32_t ixgbe_setup_fc_backplane_x550em_a(struct ixgbe_hw *hw)
+{
+	int32_t status = IXGBE_SUCCESS;
+	uint32_t an_cntl = 0;
+
+	DEBUGFUNC("ixgbe_setup_fc_backplane_x550em_a");
+
+	/* Validate the requested mode */
+	if (hw->fc.strict_ieee && hw->fc.requested_mode == ixgbe_fc_rx_pause) {
+		ERROR_REPORT1(IXGBE_ERROR_UNSUPPORTED,
+			      "ixgbe_fc_rx_pause not valid in strict IEEE mode\n");
+		return IXGBE_ERR_INVALID_LINK_SETTINGS;
+	}
+
+	if (hw->fc.requested_mode == ixgbe_fc_default)
+		hw->fc.requested_mode = ixgbe_fc_full;
+
+	/* Set up the 1G and 10G flow control advertisement registers so the
+	 * HW will be able to do FC autoneg once the cable is plugged in.  If
+	 * we link at 10G, the 1G advertisement is harmless and vice versa.
+	 */
+	status = hw->mac.ops.read_iosf_sb_reg(hw,
+					IXGBE_KRM_AN_CNTL_1(hw->bus.lan_id),
+					IXGBE_SB_IOSF_TARGET_KR_PHY, &an_cntl);
+
+	if (status != IXGBE_SUCCESS) {
+		DEBUGOUT("Auto-Negotiation did not complete\n");
+		return status;
+	}
+
+	/* The possible values of fc.requested_mode are:
+	 * 0: Flow control is completely disabled
+	 * 1: Rx flow control is enabled (we can receive pause frames,
+	 *    but not send pause frames).
+	 * 2: Tx flow control is enabled (we can send pause frames but
+	 *    we do not support receiving pause frames).
+	 * 3: Both Rx and Tx flow control (symmetric) are enabled.
+	 * other: Invalid.
+	 */
+	switch (hw->fc.requested_mode) {
+	case ixgbe_fc_none:
+		/* Flow control completely disabled by software override. */
+		an_cntl &= ~(IXGBE_KRM_AN_CNTL_1_SYM_PAUSE |
+			     IXGBE_KRM_AN_CNTL_1_ASM_PAUSE);
+		break;
+	case ixgbe_fc_tx_pause:
+		/* Tx Flow control is enabled, and Rx Flow control is
+		 * disabled by software override.
+		 */
+		an_cntl |= IXGBE_KRM_AN_CNTL_1_ASM_PAUSE;
+		an_cntl &= ~IXGBE_KRM_AN_CNTL_1_SYM_PAUSE;
+		break;
+	case ixgbe_fc_rx_pause:
+		/* Rx Flow control is enabled and Tx Flow control is
+		 * disabled by software override. Since there really
+		 * isn't a way to advertise that we are capable of RX
+		 * Pause ONLY, we will advertise that we support both
+		 * symmetric and asymmetric Rx PAUSE, as such we fall
+		 * through to the fc_full statement.  Later, we will
+		 * disable the adapter's ability to send PAUSE frames.
+		 */
+	case ixgbe_fc_full:
+		/* Flow control (both Rx and Tx) is enabled by SW override. */
+		an_cntl |= IXGBE_KRM_AN_CNTL_1_SYM_PAUSE |
+			   IXGBE_KRM_AN_CNTL_1_ASM_PAUSE;
+		break;
+	default:
+		ERROR_REPORT1(IXGBE_ERROR_ARGUMENT,
+			      "Flow control param set incorrectly\n");
+		return IXGBE_ERR_CONFIG;
+	}
+
+	status = hw->mac.ops.write_iosf_sb_reg(hw,
+					IXGBE_KRM_AN_CNTL_1(hw->bus.lan_id),
+					IXGBE_SB_IOSF_TARGET_KR_PHY, an_cntl);
+
+	/* Restart auto-negotiation. */
+	status = ixgbe_restart_an_internal_phy_x550em(hw);
+
+	return status;
+}
+
+/**
  * ixgbe_set_mux - Set mux for port 1 access with CS4227
  * @hw: pointer to hardware structure
  * @state: set mux if 1, clear if 0
  */
-void ixgbe_set_mux(struct ixgbe_hw *hw, uint8_t state)
+static void ixgbe_set_mux(struct ixgbe_hw *hw, uint8_t state)
 {
 	uint32_t esdp;
 
@@ -2404,6 +4358,134 @@ void ixgbe_release_swfw_sync_X550em(stru
 }
 
 /**
+ *  ixgbe_acquire_swfw_sync_X550a - Acquire SWFW semaphore
+ *  @hw: pointer to hardware structure
+ *  @mask: Mask to specify which semaphore to acquire
+ *
+ *  Acquires the SWFW semaphore and get the shared phy token as needed
+ */
+static int32_t ixgbe_acquire_swfw_sync_X550a(struct ixgbe_hw *hw, uint32_t mask)
+{
+	uint32_t hmask = mask & ~IXGBE_GSSR_TOKEN_SM;
+	int retries = FW_PHY_TOKEN_RETRIES;
+	int32_t status = IXGBE_SUCCESS;
+
+	DEBUGFUNC("ixgbe_acquire_swfw_sync_X550a");
+
+	while (--retries) {
+		status = IXGBE_SUCCESS;
+		if (hmask)
+			status = ixgbe_acquire_swfw_sync_X540(hw, hmask);
+		if (status) {
+			DEBUGOUT1("Could not acquire SWFW semaphore, Status = %d\n",
+				  status);
+			return status;
+		}
+		if (!(mask & IXGBE_GSSR_TOKEN_SM))
+			return IXGBE_SUCCESS;
+
+		status = ixgbe_get_phy_token(hw);
+		if (status == IXGBE_ERR_TOKEN_RETRY)
+			DEBUGOUT1("Could not acquire PHY token, Status = %d\n",
+				  status);
+
+		if (status == IXGBE_SUCCESS)
+			return IXGBE_SUCCESS;
+
+		if (hmask)
+			ixgbe_release_swfw_sync_X540(hw, hmask);
+
+		if (status != IXGBE_ERR_TOKEN_RETRY) {
+			DEBUGOUT1("Unable to retry acquiring the PHY token, Status = %d\n",
+				  status);
+			return status;
+		}
+	}
+
+	DEBUGOUT1("Semaphore acquisition retries failed!: PHY ID = 0x%08X\n",
+		  hw->phy.id);
+	return status;
+}
+
+/**
+ *  ixgbe_release_swfw_sync_X550a - Release SWFW semaphore
+ *  @hw: pointer to hardware structure
+ *  @mask: Mask to specify which semaphore to release
+ *
+ *  Releases the SWFW semaphore and puts the shared phy token as needed
+ */
+static void ixgbe_release_swfw_sync_X550a(struct ixgbe_hw *hw, uint32_t mask)
+{
+	uint32_t hmask = mask & ~IXGBE_GSSR_TOKEN_SM;
+
+	DEBUGFUNC("ixgbe_release_swfw_sync_X550a");
+
+	if (mask & IXGBE_GSSR_TOKEN_SM)
+		ixgbe_put_phy_token(hw);
+
+	if (hmask)
+		ixgbe_release_swfw_sync_X540(hw, hmask);
+}
+
+/**
+ *  ixgbe_read_phy_reg_x550a  - Reads specified PHY register
+ *  @hw: pointer to hardware structure
+ *  @reg_addr: 32 bit address of PHY register to read
+ *  @device_type: 5 bit device type
+ *  @phy_data: Pointer to read data from PHY register
+ *
+ *  Reads a value from a specified PHY register using the SWFW lock and PHY
+ *  Token. The PHY Token is needed since the MDIO is shared between to MAC
+ *  instances.
+ **/
+int32_t ixgbe_read_phy_reg_x550a(struct ixgbe_hw *hw, uint32_t reg_addr,
+			       uint32_t device_type, uint16_t *phy_data)
+{
+	int32_t status;
+	uint32_t mask = hw->phy.phy_semaphore_mask | IXGBE_GSSR_TOKEN_SM;
+
+	DEBUGFUNC("ixgbe_read_phy_reg_x550a");
+
+	if (hw->mac.ops.acquire_swfw_sync(hw, mask))
+		return IXGBE_ERR_SWFW_SYNC;
+
+	status = hw->phy.ops.read_reg_mdi(hw, reg_addr, device_type, phy_data);
+
+	hw->mac.ops.release_swfw_sync(hw, mask);
+
+	return status;
+}
+
+/**
+ *  ixgbe_write_phy_reg_x550a - Writes specified PHY register
+ *  @hw: pointer to hardware structure
+ *  @reg_addr: 32 bit PHY register to write
+ *  @device_type: 5 bit device type
+ *  @phy_data: Data to write to the PHY register
+ *
+ *  Writes a value to specified PHY register using the SWFW lock and PHY Token.
+ *  The PHY Token is needed since the MDIO is shared between to MAC instances.
+ **/
+int32_t ixgbe_write_phy_reg_x550a(struct ixgbe_hw *hw, uint32_t reg_addr,
+				uint32_t device_type, uint16_t phy_data)
+{
+	int32_t status;
+	uint32_t mask = hw->phy.phy_semaphore_mask | IXGBE_GSSR_TOKEN_SM;
+
+	DEBUGFUNC("ixgbe_write_phy_reg_x550a");
+
+	if (hw->mac.ops.acquire_swfw_sync(hw, mask) == IXGBE_SUCCESS) {
+		status = hw->phy.ops.write_reg_mdi(hw, reg_addr, device_type,
+						 phy_data);
+		hw->mac.ops.release_swfw_sync(hw, mask);
+	} else {
+		status = IXGBE_ERR_SWFW_SYNC;
+	}
+
+	return status;
+}
+
+/**
  * ixgbe_handle_lasi_ext_t_x550em - Handle external Base T PHY interrupt
  * @hw: pointer to hardware structure
  *
@@ -2424,8 +4506,8 @@ int32_t ixgbe_handle_lasi_ext_t_x550em(s
 	if (status != IXGBE_SUCCESS)
 		return status;
 
-	if (lsc && hw->phy.ops.setup_internal_link)
-		return hw->phy.ops.setup_internal_link(hw);
+	if (lsc)
+		return ixgbe_setup_internal_phy(hw);
 
 	return IXGBE_SUCCESS;
 }
@@ -2442,8 +4524,8 @@ int32_t ixgbe_handle_lasi_ext_t_x550em(s
  * Returns error status for any failure
  **/
 int32_t ixgbe_setup_mac_link_t_X550em(struct ixgbe_hw *hw,
-				      ixgbe_link_speed speed,
-				      bool autoneg_wait_to_complete)
+				  ixgbe_link_speed speed,
+				  bool autoneg_wait_to_complete)
 {
 	int32_t status;
 	ixgbe_link_speed force_speed;
@@ -2458,8 +4540,10 @@ int32_t ixgbe_setup_mac_link_t_X550em(st
 	else
 		force_speed = IXGBE_LINK_SPEED_1GB_FULL;
 
-	/* If internal link mode is XFI, then setup XFI internal link. */
-	if (!(hw->phy.nw_mng_if_sel & IXGBE_NW_MNG_IF_SEL_INT_PHY_MODE)) {
+	/* If X552 and internal link mode is XFI, then setup XFI internal link.
+	 */
+	if (hw->mac.type == ixgbe_mac_X550EM_x &&
+	    !(hw->phy.nw_mng_if_sel & IXGBE_NW_MNG_IF_SEL_INT_PHY_MODE)) {
 		status = ixgbe_setup_ixfi_x550em(hw, &force_speed);
 
 		if (status != IXGBE_SUCCESS)
@@ -2479,10 +4563,10 @@ int32_t ixgbe_setup_mac_link_t_X550em(st
  * Check that both the MAC and X557 external PHY have link.
  **/
 int32_t ixgbe_check_link_t_X550em(struct ixgbe_hw *hw, ixgbe_link_speed *speed,
-				  bool *link_up, bool link_up_wait_to_complete)
+			      bool *link_up, bool link_up_wait_to_complete)
 {
 	uint32_t status;
-	uint16_t autoneg_status;
+	uint16_t i, autoneg_status = 0;
 
 	if (hw->mac.ops.get_media_type(hw) != ixgbe_media_type_copper)
 		return IXGBE_ERR_CONFIG;
@@ -2495,21 +4579,18 @@ int32_t ixgbe_check_link_t_X550em(struct
 		return status;
 
 	/* MAC link is up, so check external PHY link.
-	 * Read this twice back to back to indicate current status.
+	 * X557 PHY. Link status is latching low, and can only be used to detect
+	 * link drop, and not the current status of the link without performing
+	 * back-to-back reads.
 	 */
-	status = hw->phy.ops.read_reg(hw, IXGBE_MDIO_AUTO_NEG_STATUS,
-				      IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
-				      &autoneg_status);
-
-	if (status != IXGBE_SUCCESS)
-		return status;
-
-	status = hw->phy.ops.read_reg(hw, IXGBE_MDIO_AUTO_NEG_STATUS,
-				      IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
-				      &autoneg_status);
+	for (i = 0; i < 2; i++) {
+		status = hw->phy.ops.read_reg(hw, IXGBE_MDIO_AUTO_NEG_STATUS,
+					      IXGBE_MDIO_AUTO_NEG_DEV_TYPE,
+					      &autoneg_status);
 
-	if (status != IXGBE_SUCCESS)
-		return status;
+		if (status != IXGBE_SUCCESS)
+			return status;
+	}
 
 	/* If external PHY link is not up, then indicate link not up */
 	if (!(autoneg_status & IXGBE_MDIO_AUTO_NEG_LINK_STATUS))
@@ -2550,13 +4631,14 @@ int32_t ixgbe_led_on_t_X550em(struct ixg
 		return IXGBE_ERR_PARAM;
 
 	/* To turn on the LED, set mode to ON. */
-	hw->phy.ops.read_reg(hw, IXGBE_X557_LED_PROVISIONING + led_idx,
-			     IXGBE_MDIO_VENDOR_SPECIFIC_1_DEV_TYPE, &phy_data);
+	ixgbe_read_phy_reg(hw, IXGBE_X557_LED_PROVISIONING + led_idx,
+			   IXGBE_MDIO_VENDOR_SPECIFIC_1_DEV_TYPE, &phy_data);
 	phy_data |= IXGBE_X557_LED_MANUAL_SET_MASK;
-	hw->phy.ops.write_reg(hw, IXGBE_X557_LED_PROVISIONING + led_idx,
-			      IXGBE_MDIO_VENDOR_SPECIFIC_1_DEV_TYPE, phy_data);
+	ixgbe_write_phy_reg(hw, IXGBE_X557_LED_PROVISIONING + led_idx,
+			    IXGBE_MDIO_VENDOR_SPECIFIC_1_DEV_TYPE, phy_data);
 
-	return IXGBE_SUCCESS;
+	/* Some designs have the LEDs wired to the MAC */
+	return ixgbe_led_on_generic(hw, led_idx);
 }
 
 /**
@@ -2574,11 +4656,73 @@ int32_t ixgbe_led_off_t_X550em(struct ix
 		return IXGBE_ERR_PARAM;
 
 	/* To turn on the LED, set mode to ON. */
-	hw->phy.ops.read_reg(hw, IXGBE_X557_LED_PROVISIONING + led_idx,
-			     IXGBE_MDIO_VENDOR_SPECIFIC_1_DEV_TYPE, &phy_data);
+	ixgbe_read_phy_reg(hw, IXGBE_X557_LED_PROVISIONING + led_idx,
+			   IXGBE_MDIO_VENDOR_SPECIFIC_1_DEV_TYPE, &phy_data);
 	phy_data &= ~IXGBE_X557_LED_MANUAL_SET_MASK;
-	hw->phy.ops.write_reg(hw, IXGBE_X557_LED_PROVISIONING + led_idx,
-			      IXGBE_MDIO_VENDOR_SPECIFIC_1_DEV_TYPE, phy_data);
+	ixgbe_write_phy_reg(hw, IXGBE_X557_LED_PROVISIONING + led_idx,
+			    IXGBE_MDIO_VENDOR_SPECIFIC_1_DEV_TYPE, phy_data);
 
-	return IXGBE_SUCCESS;
+	/* Some designs have the LEDs wired to the MAC */
+	return ixgbe_led_off_generic(hw, led_idx);
+}
+
+/**
+ *  ixgbe_set_fw_drv_ver_x550 - Sends driver version to firmware
+ *  @hw: pointer to the HW structure
+ *  @maj: driver version major number
+ *  @min: driver version minor number
+ *  @build: driver version build number
+ *  @sub: driver version sub build number
+ *  @len: length of driver_ver string
+ *  @driver_ver: driver string
+ *
+ *  Sends driver version number to firmware through the manageability
+ *  block.  On success return IXGBE_SUCCESS
+ *  else returns IXGBE_ERR_SWFW_SYNC when encountering an error acquiring
+ *  semaphore or IXGBE_ERR_HOST_INTERFACE_COMMAND when command fails.
+ **/
+int32_t ixgbe_set_fw_drv_ver_x550(struct ixgbe_hw *hw, uint8_t maj, uint8_t min,
+			      uint8_t build, uint8_t sub, uint16_t len, const char *driver_ver)
+{
+	struct ixgbe_hic_drv_info2 fw_cmd;
+	int32_t ret_val = IXGBE_SUCCESS;
+	int i;
+
+	DEBUGFUNC("ixgbe_set_fw_drv_ver_x550");
+
+	if ((len == 0) || (driver_ver == NULL) ||
+	   (len > sizeof(fw_cmd.driver_string)))
+		return IXGBE_ERR_INVALID_ARGUMENT;
+
+	fw_cmd.hdr.cmd = FW_CEM_CMD_DRIVER_INFO;
+	fw_cmd.hdr.buf_len = FW_CEM_CMD_DRIVER_INFO_LEN + len;
+	fw_cmd.hdr.cmd_or_resp.cmd_resv = FW_CEM_CMD_RESERVED;
+	fw_cmd.port_num = (uint8_t)hw->bus.func;
+	fw_cmd.ver_maj = maj;
+	fw_cmd.ver_min = min;
+	fw_cmd.ver_build = build;
+	fw_cmd.ver_sub = sub;
+	fw_cmd.hdr.checksum = 0;
+	memcpy(fw_cmd.driver_string, driver_ver, len);
+	fw_cmd.hdr.checksum = ixgbe_calculate_checksum((uint8_t *)&fw_cmd,
+				(FW_CEM_HDR_LEN + fw_cmd.hdr.buf_len));
+
+	for (i = 0; i <= FW_CEM_MAX_RETRIES; i++) {
+		ret_val = ixgbe_host_interface_command(hw, (uint32_t *)&fw_cmd,
+						       sizeof(fw_cmd),
+						       IXGBE_HI_COMMAND_TIMEOUT,
+						       TRUE);
+		if (ret_val != IXGBE_SUCCESS)
+			continue;
+
+		if (fw_cmd.hdr.cmd_or_resp.ret_status ==
+		    FW_CEM_RESP_STATUS_SUCCESS)
+			ret_val = IXGBE_SUCCESS;
+		else
+			ret_val = IXGBE_ERR_HOST_INTERFACE_COMMAND;
+
+		break;
+	}
+
+	return ret_val;
 }
Index: ./dev/pci/pcidevs
===================================================================
RCS file: /cvs/src/sys/dev/pci/pcidevs,v
retrieving revision 1.1840
diff -u -p -r1.1840 pcidevs
--- ./dev/pci/pcidevs	14 Mar 2018 20:07:06 -0000	1.1840
+++ ./dev/pci/pcidevs	17 Sep 2018 19:59:56 -0000
@@ -3510,6 +3510,30 @@ product INTEL CORE6G_U_GT3	0x1926	Iris 5
 product INTEL CORE6G_H_GT4	0x193b	Iris Pro 580
 product INTEL XEONE3_1500V5_GT4	0x193d	Iris Pro P580
 product INTEL 80960RP_ATU	0x1960	80960RP ATU
+product INTEL C3K_SYSA_0		0x1980	C3000 System Agent
+product INTEL C3K_GLREG		0x19a1	C3000 GLREG
+product INTEL C3K_RCEC		0x19a2	C3000 RCEC
+product INTEL C3K_PCIERP_QAT	0x19a3	C3000 PCIe Root Port for QAT
+product INTEL C3K_PCIE_0	0x19a4	C3000 PCIe 0-0
+product INTEL C3K_PCIE_4	0x19a8	C3000 PCIe 1-0
+product INTEL C3K_PCIE_5	0x19a9	C3000 PCIe 1-1
+product INTEL C3K_PCIE_6	0x19aa	C3000 PCIe 1-2
+product INTEL C3K_PCIE_7	0x19ab	C3000 PCIe 1-3
+product INTEL C3K_SMBUS		0x19ac	C3000 SMBUS
+product INTEL C3K_SATA0_0	0x19b0	C3000 Sata 0
+product INTEL C3K_SATA0_2	0x19b2	C3000 Sata 0
+product INTEL C3K_SATA1_2	0x19c2	C3000 Sata 1
+product INTEL C3K_SATA1_15	0x19cf	C3000 Sata 1
+product INTEL C3K_USB23		0x19d0	C3000 USB 2.0/3.0
+product INTEL C3K_PCIE_LAN0	0x19d1	C3000 PCIe Root Port for LAN 0
+product INTEL C3K_PCIE_LAN1	0x19d2	C3000 PCIe Root Port for LAN 1
+product INTEL C3K_ME_HECI_1	0x19d3	C3000 ME HECI 1
+product INTEL C3K_EMMC		0x19db	C3000 eMMC
+product INTEL C3K_LPC		0x19dc	C3000 LPC
+product INTEL C3K_PMC		0x19de	C3000 PMC
+product INTEL C3K_SMBUS_LEGACY	0x19df	C3000 Legacy SMBus
+product INTEL C3K_SPI		0x19e0	C3000 SPI
+product INTEL C3K_QAT		0x19e2	C3000 QAT
 product INTEL 82840_HB		0x1a21	82840 Host
 product INTEL 82840_AGP		0x1a23	82840 AGP
 product INTEL 82840_PCI		0x1a24	82840 PCI
Index: ./dev/pci/pcidevs.h
===================================================================
RCS file: /cvs/src/sys/dev/pci/pcidevs.h,v
retrieving revision 1.1833
diff -u -p -r1.1833 pcidevs.h
--- ./dev/pci/pcidevs.h	14 Mar 2018 20:07:40 -0000	1.1833
+++ ./dev/pci/pcidevs.h	17 Sep 2018 19:59:57 -0000
@@ -3515,6 +3515,30 @@
 #define	PCI_PRODUCT_INTEL_CORE6G_H_GT4	0x193b		/* Iris Pro 580 */
 #define	PCI_PRODUCT_INTEL_XEONE3_1500V5_GT4	0x193d		/* Iris Pro P580 */
 #define	PCI_PRODUCT_INTEL_80960RP_ATU	0x1960		/* 80960RP ATU */
+#define	PCI_PRODUCT_INTEL_C3K_SYSA_0	0x1980		/* C3000 System Agent */
+#define	PCI_PRODUCT_INTEL_C3K_GLREG	0x19a1		/* C3000 GLREG */
+#define	PCI_PRODUCT_INTEL_C3K_RCEC	0x19a2		/* C3000 RCEC */
+#define	PCI_PRODUCT_INTEL_C3K_PCIERP_QAT	0x19a3		/* C3000 PCIe Root Port for QAT */
+#define	PCI_PRODUCT_INTEL_C3K_PCIE_0	0x19a4		/* C3000 PCIe 0-0 */
+#define	PCI_PRODUCT_INTEL_C3K_PCIE_4	0x19a8		/* C3000 PCIe 1-0 */
+#define	PCI_PRODUCT_INTEL_C3K_PCIE_5	0x19a9		/* C3000 PCIe 1-1 */
+#define	PCI_PRODUCT_INTEL_C3K_PCIE_6	0x19aa		/* C3000 PCIe 1-2 */
+#define	PCI_PRODUCT_INTEL_C3K_PCIE_7	0x19ab		/* C3000 PCIe 1-3 */
+#define	PCI_PRODUCT_INTEL_C3K_SMBUS	0x19ac		/* C3000 SMBUS */
+#define	PCI_PRODUCT_INTEL_C3K_SATA0_0	0x19b0		/* C3000 Sata 0 */
+#define	PCI_PRODUCT_INTEL_C3K_SATA0_2	0x19b2		/* C3000 Sata 0 */
+#define	PCI_PRODUCT_INTEL_C3K_SATA1_2	0x19c2		/* C3000 Sata 1 */
+#define	PCI_PRODUCT_INTEL_C3K_SATA1_15	0x19cf		/* C3000 Sata 1 */
+#define	PCI_PRODUCT_INTEL_C3K_USB23	0x19d0		/* C3000 USB 2.0/3.0 */
+#define	PCI_PRODUCT_INTEL_C3K_PCIE_LAN0	0x19d1		/* C3000 PCIe Root Port for LAN 0 */
+#define	PCI_PRODUCT_INTEL_C3K_PCIE_LAN1	0x19d2		/* C3000 PCIe Root Port for LAN 1 */
+#define	PCI_PRODUCT_INTEL_C3K_ME_HECI_1	0x19d3		/* C3000 ME HECI 1 */
+#define	PCI_PRODUCT_INTEL_C3K_EMMC	0x19db		/* C3000 eMMC */
+#define	PCI_PRODUCT_INTEL_C3K_LPC	0x19dc		/* C3000 LPC */
+#define	PCI_PRODUCT_INTEL_C3K_PMC	0x19de		/* C3000 PMC */
+#define	PCI_PRODUCT_INTEL_C3K_SMBUS_LEGACY	0x19df		/* C3000 Legacy SMBus */
+#define	PCI_PRODUCT_INTEL_C3K_SPI	0x19e0		/* C3000 SPI */
+#define	PCI_PRODUCT_INTEL_C3K_QAT	0x19e2		/* C3000 QAT */
 #define	PCI_PRODUCT_INTEL_82840_HB	0x1a21		/* 82840 Host */
 #define	PCI_PRODUCT_INTEL_82840_AGP	0x1a23		/* 82840 AGP */
 #define	PCI_PRODUCT_INTEL_82840_PCI	0x1a24		/* 82840 PCI */
Index: ./dev/pci/pcidevs_data.h
===================================================================
RCS file: /cvs/src/sys/dev/pci/pcidevs_data.h,v
retrieving revision 1.1828
diff -u -p -r1.1828 pcidevs_data.h
--- ./dev/pci/pcidevs_data.h	14 Mar 2018 20:07:40 -0000	1.1828
+++ ./dev/pci/pcidevs_data.h	17 Sep 2018 19:59:57 -0000
@@ -11552,6 +11552,102 @@ static const struct pci_known_product pc
 	    "80960RP ATU",
 	},
 	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_SYSA_0,
+	    "C3000 System Agent",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_GLREG,
+	    "C3000 GLREG",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_RCEC,
+	    "C3000 RCEC",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_PCIERP_QAT,
+	    "C3000 PCIe Root Port for QAT",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_PCIE_0,
+	    "C3000 PCIe 0-0",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_PCIE_4,
+	    "C3000 PCIe 1-0",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_PCIE_5,
+	    "C3000 PCIe 1-1",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_PCIE_6,
+	    "C3000 PCIe 1-2",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_PCIE_7,
+	    "C3000 PCIe 1-3",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_SMBUS,
+	    "C3000 SMBUS",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_SATA0_0,
+	    "C3000 Sata 0",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_SATA0_2,
+	    "C3000 Sata 0",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_SATA1_2,
+	    "C3000 Sata 1",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_SATA1_15,
+	    "C3000 Sata 1",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_USB23,
+	    "C3000 USB 2.0/3.0",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_PCIE_LAN0,
+	    "C3000 PCIe Root Port for LAN 0",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_PCIE_LAN1,
+	    "C3000 PCIe Root Port for LAN 1",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_ME_HECI_1,
+	    "C3000 ME HECI 1",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_EMMC,
+	    "C3000 eMMC",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_LPC,
+	    "C3000 LPC",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_PMC,
+	    "C3000 PMC",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_SMBUS_LEGACY,
+	    "C3000 Legacy SMBus",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_SPI,
+	    "C3000 SPI",
+	},
+	{
+	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_C3K_QAT,
+	    "C3000 QAT",
+	},
+	{
 	    PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82840_HB,
 	    "82840 Host",
 	},
